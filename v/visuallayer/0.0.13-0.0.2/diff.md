# Comparing `tmp/visuallayer-0.0.13-py3.9-none-any.whl.zip` & `tmp/visuallayer-0.0.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,21 @@
-Zip file size: 20350 bytes, number of entries: 20
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-12 05:13 visuallayer/__init__.py
--rw-r--r--  2.0 unx     4940 b- defN 23-Jun-12 05:13 visuallayer/sentry.py
--rw-r--r--  2.0 unx       19 b- defN 23-Jun-12 05:13 visuallayer/datasets/__init__.py
--rw-r--r--  2.0 unx     3747 b- defN 23-Jun-12 05:13 visuallayer/datasets/clean_torchvision_food101.py
--rw-r--r--  2.0 unx     4483 b- defN 23-Jun-12 05:13 visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py
--rw-r--r--  2.0 unx     2743 b- defN 23-Jun-12 05:13 visuallayer/datasets/dataset.py
--rw-r--r--  2.0 unx     2349 b- defN 23-Jun-12 05:13 visuallayer/datasets/image_folder.py
--rw-r--r--  2.0 unx     2765 b- defN 23-Jun-12 05:13 visuallayer/datasets/vl_cocodetection.py
--rw-r--r--  2.0 unx     1887 b- defN 23-Jun-12 05:13 visuallayer/datasets/vl_imagenet.py
--rw-r--r--  2.0 unx     3397 b- defN 23-Jun-12 05:13 visuallayer/datasets/vl_kitti.py
--rw-r--r--  2.0 unx     1139 b- defN 23-Jun-12 05:13 visuallayer/datasets/vl_parse_exclude_csv.py
--rw-r--r--  2.0 unx      116 b- defN 23-Jun-12 05:13 visuallayer/datasets/zoo/__init__.py
--rw-r--r--  2.0 unx      904 b- defN 23-Jun-12 05:13 visuallayer/datasets/zoo/utils.py
--rw-r--r--  2.0 unx     2801 b- defN 23-Jun-12 05:13 visuallayer/datasets/zoo/vl_food101.py
--rw-r--r--  2.0 unx     2968 b- defN 23-Jun-12 05:13 visuallayer/datasets/zoo/vl_oxford_iiit.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jun-12 05:13 visuallayer-0.0.13.dist-info/LICENSE
--rw-r--r--  2.0 unx      864 b- defN 23-Jun-12 05:13 visuallayer-0.0.13.dist-info/METADATA
--rw-r--r--  2.0 unx      108 b- defN 23-Jun-12 05:13 visuallayer-0.0.13.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Jun-12 05:13 visuallayer-0.0.13.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1810 b- defN 23-Jun-12 05:13 visuallayer-0.0.13.dist-info/RECORD
-20 files, 48501 bytes uncompressed, 17342 bytes compressed:  64.2%
+Zip file size: 19191 bytes, number of entries: 19
+-rw-rw-r--  2.0 unx       91 b- defN 23-Jun-05 11:41 visuallayer/__init__.py
+-rw-rw-r--  2.0 unx     4940 b- defN 23-Jun-05 04:57 visuallayer/sentry.py
+-rw-rw-r--  2.0 unx       19 b- defN 23-Jun-05 11:52 visuallayer/datasets/__init__.py
+-rw-rw-r--  2.0 unx     4483 b- defN 23-Jun-05 07:53 visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py
+-rw-rw-r--  2.0 unx      942 b- defN 23-Jun-06 09:31 visuallayer/datasets/dataset.py
+-rw-rw-r--  2.0 unx     2349 b- defN 23-Jun-05 05:02 visuallayer/datasets/image_folder.py
+-rw-rw-r--  2.0 unx     2765 b- defN 23-Jun-05 04:57 visuallayer/datasets/vl_cocodetection.py
+-rw-rw-r--  2.0 unx     3733 b- defN 23-Jun-05 04:57 visuallayer/datasets/vl_food101.py
+-rw-rw-r--  2.0 unx     1887 b- defN 23-May-31 05:01 visuallayer/datasets/vl_imagenet.py
+-rw-rw-r--  2.0 unx     3397 b- defN 23-Jun-05 04:57 visuallayer/datasets/vl_kitti.py
+-rw-rw-r--  2.0 unx     1139 b- defN 23-May-30 04:29 visuallayer/datasets/vl_parse_exclude_csv.py
+-rw-rw-r--  2.0 unx       82 b- defN 23-Jun-06 02:56 visuallayer/datasets/zoo/__init__.py
+-rw-rw-r--  2.0 unx      646 b- defN 23-Jun-07 03:50 visuallayer/datasets/zoo/utils.py
+-rw-rw-r--  2.0 unx     5413 b- defN 23-Jun-07 04:21 visuallayer/datasets/zoo/vl_oxford_iiit.py
+-rw-rw-r--  2.0 unx    11357 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/LICENSE
+-rw-rw-r--  2.0 unx      821 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       12 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1692 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/RECORD
+19 files, 45860 bytes uncompressed, 16375 bytes compressed:  64.3%
```

## zipnote {}

```diff
@@ -3,29 +3,29 @@
 
 Filename: visuallayer/sentry.py
 Comment: 
 
 Filename: visuallayer/datasets/__init__.py
 Comment: 
 
-Filename: visuallayer/datasets/clean_torchvision_food101.py
-Comment: 
-
 Filename: visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py
 Comment: 
 
 Filename: visuallayer/datasets/dataset.py
 Comment: 
 
 Filename: visuallayer/datasets/image_folder.py
 Comment: 
 
 Filename: visuallayer/datasets/vl_cocodetection.py
 Comment: 
 
+Filename: visuallayer/datasets/vl_food101.py
+Comment: 
+
 Filename: visuallayer/datasets/vl_imagenet.py
 Comment: 
 
 Filename: visuallayer/datasets/vl_kitti.py
 Comment: 
 
 Filename: visuallayer/datasets/vl_parse_exclude_csv.py
@@ -33,29 +33,26 @@
 
 Filename: visuallayer/datasets/zoo/__init__.py
 Comment: 
 
 Filename: visuallayer/datasets/zoo/utils.py
 Comment: 
 
-Filename: visuallayer/datasets/zoo/vl_food101.py
-Comment: 
-
 Filename: visuallayer/datasets/zoo/vl_oxford_iiit.py
 Comment: 
 
-Filename: visuallayer-0.0.13.dist-info/LICENSE
+Filename: visuallayer-0.0.2.dist-info/LICENSE
 Comment: 
 
-Filename: visuallayer-0.0.13.dist-info/METADATA
+Filename: visuallayer-0.0.2.dist-info/METADATA
 Comment: 
 
-Filename: visuallayer-0.0.13.dist-info/WHEEL
+Filename: visuallayer-0.0.2.dist-info/WHEEL
 Comment: 
 
-Filename: visuallayer-0.0.13.dist-info/top_level.txt
+Filename: visuallayer-0.0.2.dist-info/top_level.txt
 Comment: 
 
-Filename: visuallayer-0.0.13.dist-info/RECORD
+Filename: visuallayer-0.0.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## visuallayer/__init__.py

```diff
@@ -1,4 +1,4 @@
-__version__ = '0.0.13'
+__version__ = '0.0.1'
 from .datasets import *
 from .sentry import init_sentry
 init_sentry()
```

## visuallayer/datasets/dataset.py

```diff
@@ -1,82 +1,61 @@
-import pandas as pd
-from typing import Union, List, Tuple
+from abc import ABC, abstractmethod
 
+class Dataset(ABC):
 
-class Dataset:
     @property
-    def num_images_with_issues(self) -> int:
-        df = pd.read_csv(self.filelist_csv_url)
-        return len(df["filename"].unique())
-
-    @property
-    def info(self) -> None:
-        # Get all attributes and methods of the class
-        dataset_metadata: List[Tuple[str, Union[str, int]]] = [
-            ("Name", self.name),
-            ("Description", self.description),
-            ("License", self.license),
-            ("Homepage URL", self.homepage_url),
-            ("Number of Images", self.num_images),
-            ("Number of Images with Issues", self.num_images_with_issues),
-        ]
-
-        print("Metadata:")
-        for metadata in dataset_metadata:
-            print(f"--> {metadata[0]} - {metadata[1]}")
-
-    @property
-    def report(self) -> pd.DataFrame:
-        df = pd.read_csv(self.issue_count_csv_url)
-        df = df.loc[df["split"] == "all"].drop("split", axis=1).reset_index(drop=True)
-        
-        # Calculate the total sum per column
-        total_count = df['count'].sum()
-        total_pct = df['pct'].sum()
-
-        # Create a DataFrame for the new row and concatenate it with the old DataFrame
-        new_row = pd.DataFrame({'reason': ['Total'], 'count': [total_count], 'pct': [total_pct]})
-        df = pd.concat([df, new_row], ignore_index=True)
-
-        return df
-    
-    def explore(self) -> pd.DataFrame:
-        import base64
-        from itables import init_notebook_mode
-        init_notebook_mode(all_interactive=True)
-
-        def to_img_tag(path):
-            if isinstance(path, str):
-                with open(path, 'rb') as f:
-                    image_data = f.read()
-                    base64_image = base64.b64encode(image_data).decode('utf-8')
-                return '<img src="data:image/png;base64,' + base64_image + '" width="150" >'
-            else:
-                return path  # Return the original value if it's not a string
-
-
-        df = pd.read_csv(self.filelist_csv_url)
-        df["filename_preview"] = df["filename"]
-        df["prototype_preview"] = df["prototype"]
-        df = df.loc[
-            :,
-            [
-                "filename",
-                "filename_preview",
-                "reason",
-                "value",
-                "prototype",
-                "prototype_preview",
-            ],
-        ]
-        df["filename_preview"] = df["filename"].apply(to_img_tag)
-        df["prototype_preview"] = df["prototype"].apply(to_img_tag)
+    @abstractmethod
+    def filelist_csv_url(self):
+        pass
+
+    @property
+    @abstractmethod
+    def issue_count_csv_url(self):
+        pass
+
+    @property
+    @abstractmethod
+    def name(self):
+        pass
 
-        return df
+    @property
+    @abstractmethod
+    def homepage_url(self):
+        pass
 
+    @property
+    @abstractmethod
+    def license(self):
+        pass
+
+    @property
+    @abstractmethod
+    def description(self):
+        pass
+
+    @property
+    @abstractmethod
+    def num_images(self):
+        pass
+
+    @property
+    @abstractmethod
+    def num_images_with_issues(self):
+        pass
+
+    @property
+    @abstractmethod
+    def info(self):
+        pass
+
+    @abstractmethod
+    def report(self):
+        pass
+
+    @abstractmethod
     def export(self, output_format):
         pass
 
-    def export_issues(self, filename: str) -> None:
-        df = pd.read_csv(self.issue_count_csv_url)
-        df.to_csv(filename, index=False)
+    @abstractmethod
+    def export_issues(self, filename):
+        pass
```

## visuallayer/datasets/zoo/__init__.py

```diff
@@ -1,3 +1,2 @@
 from .vl_oxford_iiit import VLOxfordIIITPet
-from .vl_food101 import VLFood101
 from .utils import load, list_datasets
```

## visuallayer/datasets/zoo/utils.py

```diff
@@ -1,31 +1,23 @@
 from .vl_oxford_iiit import VLOxfordIIITPet, VLOriginalOxfordIIITPet
-from .vl_food101 import VLFood101, VLOriginalFood101
 
-dataset = {
-    ("vl-oxford-iiit-pets", "vl"): VLOxfordIIITPet,
-    ("vl-oxford-iiit-pets", "original"): VLOriginalOxfordIIITPet,
-    ("vl-food101", "vl"): VLFood101,
-    ("vl-food101", "original"): VLOriginalFood101,
-}
 
-
-def load(dataset_name: str, variation: str = "vl"):
-    loaded_dataset = dataset.get((dataset_name, variation), CombinationError)
-    return loaded_dataset()
+def load(dataset_name, variant="vl"):
+    if dataset_name == "vl-oxford-iiit-pets":
+        if variant == "original":
+            return VLOriginalOxfordIIITPet()
+        else:
+            return VLOxfordIIITPet()
+    else:
+        raise ValueError(f"Could not find dataset. Did you mean {get_dataset_names()}?")
 
 
 def list_datasets():
-    names = _get_dataset_names()
+    names = get_dataset_names()
     print("Listing all datasets in zoo.")
-    return list(names)
-
-def _get_dataset_names():
-    dataset_names = [key[0] for key in dataset.keys()]
-    return set(dataset_names)
+    return names
 
 
-class CombinationError:
-    def __init__(self):
-        raise NotImplementedError(
-            "This dataset and variation combination is not implemented."
-        )
+def get_dataset_names():
+    datasets = [VLOxfordIIITPet()]
+    datasets_names = [dataset.name for dataset in datasets]
+    return datasets_names
```

## visuallayer/datasets/zoo/vl_oxford_iiit.py

```diff
@@ -1,54 +1,98 @@
 from ..clean_torchvision_oxford_iiit_pet import CleanTorchvisionOxfordIIITPet
 from ..dataset import Dataset
 from dataclasses import dataclass
 import pandas as pd
 from torchvision.datasets import OxfordIIITPet
 from typing import Union, List, Tuple
+from itables import init_notebook_mode
+
+init_notebook_mode(all_interactive=True)
+
 
 @dataclass(frozen=True)
 class VLOxfordIIITPet(Dataset):
+    filelist_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_file_list.csv"
+    issue_count_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_count.csv"
     name: str = "vl-oxford-iiit-pets"
     homepage_url: str = "https://www.robots.ox.ac.uk/~vgg/data/pets/"
-    license: str = "Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)"
+    license: str = (
+        "Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)"
+    )
     description: str = "A modified version of the original Oxford IIIT Pets Dataset removing dataset issues."
     num_images: int = 7349
-    filelist_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_file_list.csv"
-    issue_count_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_count.csv"
-    exclude_csv: str = None
 
-    # Hack: Download the dataset in the current dir
-    def __post_init__(self):
-        OxfordIIITPet(root="./", download=True)
+    @property
+    def num_images_with_issues(self) -> int:
+        df = pd.read_csv(self.filelist_csv_url)
+        return len(df["filename"].unique())
+
+    @property
+    def info(self) -> None:
+        # Get all attributes and methods of the class
+        dataset_metadata: List[Tuple[str, Union[str, int]]] = [
+            ("Name", self.name),
+            ("Description", self.description),
+            ("License", self.license),
+            ("Homepage URL", self.homepage_url),
+            ("Number of Images", self.num_images),
+            ("Number of Images with Issues", self.num_images_with_issues),
+        ]
+
+        print("Metadata:")
+        for metadata in dataset_metadata:
+            print(f"--> {metadata[0]} - {metadata[1]}")
+
+    @property
+    def report(self) -> None:
+        df = pd.read_csv(self.issue_count_csv_url)
+        all_issues_df: pd.DataFrame = (
+            df.loc[df["split"] == "all"].drop("split", axis=1).reset_index(drop=True)
+        )
+
+        print(f"Visual Layer Profiler issues in this dataset:\n")
+
+        # print issues to user
+        for _, row in all_issues_df.iterrows():
+            reason: str = row["reason"]
+            count: int = row["count"]
+            pct: float = row["pct"]
+
+            output: str = f"--> {count:,} {reason.upper()}(S) ({pct:.2f}%)"
+            print(output)
+
+        print(
+            "\nThese images are removed in the `vl` variant of the dataset. To load the original version of the dataset, use variant=`original`. Explore the full data and the issues head to http://visual-layer.com/datasets/dataset/1234-5678-abcd"
+        )
 
     def export(
         self,
         output_format: str,
         variant: str = "vl",
         root: str = "./",
         split: str = "train",
     ):
         if output_format == "pytorch":
             if variant == "vl":
                 print(
                     f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
-                return CleanTorchvisionOxfordIIITPet(root=root, split=split, exclude_csv=self.exclude_csv)
+                return CleanTorchvisionOxfordIIITPet(root=root, split=split)
             elif variant == "original":
                 print(
                     f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
                 return OxfordIIITPet(root=root, split=split, download=True)
         
         elif output_format == "csv":
             if variant == "vl":
                 print(
                     f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
-                dataset = CleanTorchvisionOxfordIIITPet(root=root, split=split, exclude_csv=self.exclude_csv)
+                dataset = CleanTorchvisionOxfordIIITPet(root=root, split=split)
                 samples = {"Image": dataset._images, "Label": dataset._labels}
                 df = pd.DataFrame(samples)
                 return df
             elif variant == "original":
                 print(
                     f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
@@ -58,11 +102,42 @@
                 return df
 
         else:
             raise ValueError(
                 f"Unknown output format: {output_format} or variant {variant}."
             )
 
+    def export_issues(self, filename: str) -> None:
+        df = pd.read_csv(self.issue_count_csv_url)
+        df.to_csv(filename, index=False)
+
+    def explore(self):
+        def to_img_tag(path):
+            if isinstance(path, str):
+                return '<img src="' + path + '" width="150" >'
+            else:
+                return path  # Return the original value if it's not a string
+
+        df = pd.read_csv(self.filelist_csv_url)
+        df["filename_preview"] = df["filename"]
+        df["prototype_preview"] = df["prototype"]
+        df = df.loc[
+            :,
+            [
+                "filename",
+                "filename_preview",
+                "reason",
+                "value",
+                "prototype",
+                "prototype_preview",
+            ],
+        ]
+        df["filename_preview"] = df["filename"].apply(to_img_tag)
+        df["prototype_preview"] = df["prototype"].apply(to_img_tag)
+
+        return df
+
+
 @dataclass(frozen=True)
 class VLOriginalOxfordIIITPet(VLOxfordIIITPet):
     name: str = "oxford-iiit-pets"
     description: str = "The original pets dataset by Oxford IIIT."
```

## Comparing `visuallayer/datasets/clean_torchvision_food101.py` & `visuallayer/datasets/vl_food101.py`

 * *Files 6% similar despite different names*

```diff
@@ -24,15 +24,15 @@
         transforms.CenterCrop(224),
         transforms.ToTensor(),
         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
     ]
 )
 
 
-class CleanTorchvisionFood101(Food101):
+class VLFood101(Food101):
     @v1_sentry_handler
     def __init__(
         self,
         root: str,
         split: str = "train",
         transform: Optional[Callable] = None,
         target_transform: Optional[Callable] = None,
```

## Comparing `visuallayer-0.0.13.dist-info/LICENSE` & `visuallayer-0.0.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `visuallayer-0.0.13.dist-info/METADATA` & `visuallayer-0.0.2.dist-info/METADATA`

 * *Files 11% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 Metadata-Version: 2.1
 Name: visuallayer
-Version: 0.0.13
+Version: 0.0.2
 Summary: Open, Clean Datasets for Computer Vision.
 Home-page: https://github.com/visual-layer/vl-datasets
 Author: Visual Layer
 Author-email: info@visual-layer.com
 License: Apache-2.0
 Keywords: machine learning,computer vision,data-centric
-Platform: UNKNOWN
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: torch
 Requires-Dist: torchvision
 Requires-Dist: pandas
 Requires-Dist: sentry-sdk
 Requires-Dist: scipy
-Requires-Dist: itables
 
 Coming soon.
-
```

## Comparing `visuallayer-0.0.13.dist-info/RECORD` & `visuallayer-0.0.2.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-visuallayer/__init__.py,sha256=PoNCbJYnKM7_WOeJ9ZS4VJHBg9LUs52ecjNMNcCbrVU,92
+visuallayer/__init__.py,sha256=ED_jsdf3kqSiifRC_8zkYY2KYLFCdgo8EY_HZwSzong,91
 visuallayer/sentry.py,sha256=AAmaO2kO8xyh9crTiq6YDnfHSJxyjorioI-Sdk2K7lc,4940
 visuallayer/datasets/__init__.py,sha256=A1TkIulArINdCJtTM1jED6HDemnZ3AlURsyVxENP2ug,19
-visuallayer/datasets/clean_torchvision_food101.py,sha256=-hM-ne5Lokjjd9HG9Dz9PRIt89NCyampPpRM-Zbq12Y,3747
 visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py,sha256=yUwBGTFyy9FI6ct7C3hx-V9nOfywrjCasEM4TtqAT2k,4483
-visuallayer/datasets/dataset.py,sha256=Kv9M6NTziNN_cwsVYYvu6OTruYnx38x8mqmvAw4gXGk,2743
+visuallayer/datasets/dataset.py,sha256=Oe3eCCk5VhKn2siPXC8W6zk_cVHKMAaeXzEERhFC-ro,942
 visuallayer/datasets/image_folder.py,sha256=yT_W1RRsrxVfV2XlCniiKfaUka5k_Ly6s4X39fpP1Oc,2349
 visuallayer/datasets/vl_cocodetection.py,sha256=xwGDWoT2DRMnlnQwu3igiDUVXGNjfjfWR1tTaEpskz0,2765
+visuallayer/datasets/vl_food101.py,sha256=7bVDgxZed1FVnPDlB5BFl2mFCJwheVHLjkXodD3c08k,3733
 visuallayer/datasets/vl_imagenet.py,sha256=li6jc5qcEYHx6f4iFXGuwGycqOw_RKn5V4Zfc2REwhs,1887
 visuallayer/datasets/vl_kitti.py,sha256=aEVqgh3Akw98qmMAk-rZrMK7IZ__wOCLOeunr-FXHvM,3397
 visuallayer/datasets/vl_parse_exclude_csv.py,sha256=kUR0KlJgbJ6Elo-nvRDu9a3UOhcPfS_wr2stx8ZJg84,1139
-visuallayer/datasets/zoo/__init__.py,sha256=tIRVwOnmsj7-jvw_bZ0GGEXYFlhGz9Xz7RKFCGntayA,116
-visuallayer/datasets/zoo/utils.py,sha256=z395kV7v0XMTMFSYgeip0xJzdiaGRMbEdqpA31aTZ38,904
-visuallayer/datasets/zoo/vl_food101.py,sha256=ifUjpWqNLSwvpHh5QEkCm-xAwAmxlmMPkiBNPoFDTAo,2801
-visuallayer/datasets/zoo/vl_oxford_iiit.py,sha256=rHrqQZmDeYiT5IAgvu8fhOaSMfY7SVNjwvvmRX5uAWo,2968
-visuallayer-0.0.13.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-visuallayer-0.0.13.dist-info/METADATA,sha256=mXHurv66dXSJuGHHC5gLbvy1NmbtpmYQZ89DuNk9rqI,864
-visuallayer-0.0.13.dist-info/WHEEL,sha256=YT1wPceIeW2Q5XD-ypzUqEKq0BMVsXhboTN8eU2aMIk,108
-visuallayer-0.0.13.dist-info/top_level.txt,sha256=hxebilWiIk5JiZslpQz8-F1__45rw-otTI9GwhE9Zw0,12
-visuallayer-0.0.13.dist-info/RECORD,,
+visuallayer/datasets/zoo/__init__.py,sha256=vRb7pVKdPoKsCpm1UzStXLtQDkk5mZ_Pxi8HxfHW-qo,82
+visuallayer/datasets/zoo/utils.py,sha256=gkYJPckZyC2DMTreu7IP9drxj1ye2duovRHurOpM4GQ,646
+visuallayer/datasets/zoo/vl_oxford_iiit.py,sha256=2Ba7rMEngftzhv-jXM6LDcmkWCVhfKFXqZ5Y5fQcORI,5413
+visuallayer-0.0.2.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+visuallayer-0.0.2.dist-info/METADATA,sha256=5G0tMasuMKpA9MgJ1xMr8YCCy8aA6LXf0Ymp6MkImvA,821
+visuallayer-0.0.2.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+visuallayer-0.0.2.dist-info/top_level.txt,sha256=hxebilWiIk5JiZslpQz8-F1__45rw-otTI9GwhE9Zw0,12
+visuallayer-0.0.2.dist-info/RECORD,,
```

