# Comparing `tmp/mira-0.9.8-py3-none-any.whl.zip` & `tmp/mira-0.9.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 7185138 bytes, number of entries: 279
+Zip file size: 7185136 bytes, number of entries: 279
 -rw-r--r--  2.0 unx      224 b- defN 80-Jan-01 00:00 mira/__init__.py
 -rw-r--r--  2.0 unx       70 b- defN 80-Jan-01 00:00 mira/classifiers/__init__.py
 -rw-r--r--  2.0 unx     1535 b- defN 80-Jan-01 00:00 mira/classifiers/classifier.py
 -rw-r--r--  2.0 unx     2475 b- defN 80-Jan-01 00:00 mira/classifiers/clip.py
 -rw-r--r--  2.0 unx     3254 b- defN 80-Jan-01 00:00 mira/classifiers/torchvision.py
 -rw-r--r--  2.0 unx      261 b- defN 80-Jan-01 00:00 mira/core/__init__.py
 -rw-r--r--  2.0 unx    13046 b- defN 80-Jan-01 00:00 mira/core/annotation.py
@@ -10,15 +10,15 @@
 -rw-r--r--  2.0 unx     7122 b- defN 80-Jan-01 00:00 mira/core/callbacks.py
 -rw-r--r--  2.0 unx     9028 b- defN 80-Jan-01 00:00 mira/core/experimental.py
 -rw-r--r--  2.0 unx     6722 b- defN 80-Jan-01 00:00 mira/core/files.py
 -rw-r--r--  2.0 unx     7924 b- defN 80-Jan-01 00:00 mira/core/imagemeta.py
 -rw-r--r--  2.0 unx     3987 b- defN 80-Jan-01 00:00 mira/core/protos/scene_pb2.py
 -rw-r--r--  2.0 unx     9334 b- defN 80-Jan-01 00:00 mira/core/resizing.py
 -rw-r--r--  2.0 unx    41842 b- defN 80-Jan-01 00:00 mira/core/scene.py
--rw-r--r--  2.0 unx    26690 b- defN 80-Jan-01 00:00 mira/core/torchtools.py
+-rw-r--r--  2.0 unx    26691 b- defN 80-Jan-01 00:00 mira/core/torchtools.py
 -rw-r--r--  2.0 unx    19748 b- defN 80-Jan-01 00:00 mira/core/utils.py
 -rw-r--r--  2.0 unx      268 b- defN 80-Jan-01 00:00 mira/datasets/__init__.py
 -rw-r--r--  2.0 unx      620 b- defN 80-Jan-01 00:00 mira/datasets/assets/coco_classes.txt
 -rw-r--r--  2.0 unx      774 b- defN 80-Jan-01 00:00 mira/datasets/assets/coco_classes_90.txt
 -rw-r--r--  2.0 unx    10499 b- defN 80-Jan-01 00:00 mira/datasets/assets/imagenet1k_classes.txt
 -rw-r--r--  2.0 unx      134 b- defN 80-Jan-01 00:00 mira/datasets/assets/voc_classes.txt
 -rw-r--r--  2.0 unx     4864 b- defN 80-Jan-01 00:00 mira/datasets/coco.py
@@ -270,12 +270,12 @@
 -rw-r--r--  2.0 unx     1656 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/segmentation_models_pytorch/utils/meter.py
 -rw-r--r--  2.0 unx     2992 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/segmentation_models_pytorch/utils/metrics.py
 -rw-r--r--  2.0 unx     3310 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/segmentation_models_pytorch/utils/train.py
 -rw-r--r--  2.0 unx     3817 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/setup.py
 -rw-r--r--  2.0 unx    11748 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/tests/test_losses.py
 -rw-r--r--  2.0 unx     4501 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/tests/test_models.py
 -rw-r--r--  2.0 unx     1714 b- defN 80-Jan-01 00:00 mira/thirdparty/smp/tests/test_preprocessing.py
--rw-r--r--  2.0 unx     1022 b- defN 80-Jan-01 00:00 mira-0.9.8.dist-info/LICENSE
-?rw-r--r--  2.0 unx       83 b- defN 16-Jan-01 00:00 mira-0.9.8.dist-info/WHEEL
-?rw-r--r--  2.0 unx     2035 b- defN 16-Jan-01 00:00 mira-0.9.8.dist-info/METADATA
-?rw-r--r--  2.0 unx    30337 b- defN 16-Jan-01 00:00 mira-0.9.8.dist-info/RECORD
-279 files, 10363368 bytes uncompressed, 7134792 bytes compressed:  31.2%
+-rw-r--r--  2.0 unx     1022 b- defN 80-Jan-01 00:00 mira-0.9.9.dist-info/LICENSE
+?rw-r--r--  2.0 unx       83 b- defN 16-Jan-01 00:00 mira-0.9.9.dist-info/WHEEL
+?rw-r--r--  2.0 unx     2035 b- defN 16-Jan-01 00:00 mira-0.9.9.dist-info/METADATA
+?rw-r--r--  2.0 unx    30337 b- defN 16-Jan-01 00:00 mira-0.9.9.dist-info/RECORD
+279 files, 10363369 bytes uncompressed, 7134790 bytes compressed:  31.2%
```

## zipnote {}

```diff
@@ -819,20 +819,20 @@
 
 Filename: mira/thirdparty/smp/tests/test_models.py
 Comment: 
 
 Filename: mira/thirdparty/smp/tests/test_preprocessing.py
 Comment: 
 
-Filename: mira-0.9.8.dist-info/LICENSE
+Filename: mira-0.9.9.dist-info/LICENSE
 Comment: 
 
-Filename: mira-0.9.8.dist-info/WHEEL
+Filename: mira-0.9.9.dist-info/WHEEL
 Comment: 
 
-Filename: mira-0.9.8.dist-info/METADATA
+Filename: mira-0.9.9.dist-info/METADATA
 Comment: 
 
-Filename: mira-0.9.8.dist-info/RECORD
+Filename: mira-0.9.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mira/__init__.py

```diff
@@ -1,8 +1,8 @@
 import warnings
 
 warnings.filterwarnings(
     action="ignore",
     message=r".*The output shape of `ResNet50\(include_top=False\)` has been changed since Keras 2\.2\.0\..*",
     category=UserWarning,
 )
-__version__ = "0.9.8"
+__version__ = "0.9.9"
```

## mira/core/torchtools.py

```diff
@@ -48,15 +48,14 @@
 
 DEFAULT_OPTIMIZER_PARAMS = dict(lr=1e-2, opt="sgd", weight_decay=4e-5)
 
 InputType = typing.TypeVar("InputType")
 TrainItem = typing.NamedTuple(
     "TrainItem",
     [
-        ("split", tx.Literal["train", "val"]),
         ("index", int),
         ("transform", np.ndarray),
         ("scene", scene.Scene),
     ],
 )
 TrainState = tx.TypedDict("TrainState", {"directory": tempfile.TemporaryDirectory})
 InvertedTarget = typing.NamedTuple(
@@ -94,15 +93,17 @@
         collections: typing.Dict[str, SplitCollection],
     ) -> typing.Dict[str, typing.Any]:
         pass
 
 
 def train(
     model: "torch.nn.Module",
-    loss: typing.Callable[[typing.List[InputType]], "torch.Tensor"],
+    loss: typing.Callable[
+        [tx.Literal["training", "validation"], typing.List[InputType]], "torch.Tensor"
+    ],
     training: typing.List[InputType],
     skip_partial_batches=False,
     validation: typing.List[InputType] = None,
     batch_size: int = 1,
     augment: typing.Callable[[typing.List[InputType]], typing.List[InputType]] = None,
     epochs=100,
     on_epoch_start: typing.Callable = None,
@@ -163,15 +164,15 @@
                     end = min(start + batch_size, len(train_index))
                     batch = [training[train_index[idx]] for idx in range(start, end)]
                     if len(batch) < batch_size and skip_partial_batches:
                         continue
                     if augment:
                         batch = augment(batch)
                     optimizer.zero_grad()
-                    batch_loss = loss(batch)
+                    batch_loss = loss("training", batch)
                     batch_loss.backward()
                     if clip_grad_norm_params is not None:
                         torch.nn.utils.clip_grad_norm_(
                             model.parameters(), **clip_grad_norm_params
                         )
                     cum_loss += batch_loss.detach().cpu().numpy()
                     avg_loss = cum_loss / end
@@ -179,21 +180,22 @@
                     t.set_postfix(loss=avg_loss)
                     t.update()
                 summaries.append({"loss": avg_loss})
                 if validation:
                     summaries[-1]["val_loss"] = np.sum(
                         [
                             loss(
+                                "validation",
                                 [
                                     validation[idx]
                                     for idx in range(
                                         vstart,
                                         min(vstart + batch_size, len(validation)),
                                     )
-                                ]
+                                ],
                             )
                             .detach()
                             .cpu()
                             .numpy()
                             for vstart in range(0, len(validation), batch_size)
                             if not skip_partial_batches
                             or len(validation) - vstart >= batch_size
@@ -592,29 +594,28 @@
             validation_transforms: A list of transforms for the images in the validation
                 set. If not provided, we assume the identity transform.
         """
         state: TrainState = {
             "directory": tempfile.TemporaryDirectory(prefix=data_dir_prefix),
         }
 
-        def loss(items: typing.List[TrainItem]) -> torch.Tensor:
+        def loss(split: str, items: typing.List[TrainItem]) -> torch.Tensor:
             return self.loss(
                 training.assign(scenes=[i.scene for i in items]),
-                data_dir=os.path.join(state["directory"].name, items[0].split),
+                data_dir=os.path.join(state["directory"].name, split),
                 transforms=np.stack([i.transform for i in items]),
                 indices=[i.index for i in items],
                 save_images=save_images,
             )
 
         def augment(items: typing.List[TrainItem]):
             if not augmenter:
                 return items
             return [
                 TrainItem(
-                    split=base.split,
                     index=base.index,
                     scene=scene,
                     transform=np.matmul(transform, base.transform),
                 )
                 for (scene, transform), base in zip(
                     [
                         i.scene.augment(augmenter, min_visibility=min_visibility)
@@ -644,19 +645,19 @@
                 self.unfreeze_backbone(batchnorm=train_backbone_bn)
             else:
                 self.freeze_backbone()
 
         return train(
             model=self.model,
             training=[
-                TrainItem(split="train", index=index, transform=np.eye(3), scene=scene)
+                TrainItem(index=index, transform=np.eye(3), scene=scene)
                 for index, scene in enumerate(training)
             ],
             validation=[
-                TrainItem(split="val", index=index, transform=transform, scene=scene)
+                TrainItem(index=index, transform=transform, scene=scene)
                 for index, (scene, transform) in enumerate(
                     zip(
                         validation or [],
                         (
                             validation_transforms
                             or np.eye(3, 3)[np.newaxis].repeat(len(validation), axis=0)
                         )
```

## Comparing `mira-0.9.8.dist-info/LICENSE` & `mira-0.9.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mira-0.9.8.dist-info/METADATA` & `mira-0.9.9.dist-info/METADATA`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mira
-Version: 0.9.8
+Version: 0.9.9
 Summary: A package for simplifying object detection
 Home-page: https://github.com/faustomorales/mira
 License: MIT
 Author: Fausto Morales
 Author-email: faustomorales@gmail.com
 Requires-Python: >=3.7.9,<3.11
 Classifier: License :: OSI Approved :: MIT License
```

## Comparing `mira-0.9.8.dist-info/RECORD` & `mira-0.9.9.dist-info/RECORD`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-mira/__init__.py,sha256=J6Vf7nhobJrVtc8IN3MUMwLZUDuBVzQU0k3H9oXHcnY,224
+mira/__init__.py,sha256=nSNbqZkkK1Tz21KztYpsFCHTv13pOw6GRefjure0cEs,224
 mira/classifiers/__init__.py,sha256=h3mZVCY0CohQgr5cZ7eJz-5Cffyrcn9i_CAaVhe2brE,70
 mira/classifiers/classifier.py,sha256=uVIeRYWFB5VJFp1FC4TCX3mzCHwd5d6FsbprPjH5Dic,1535
 mira/classifiers/clip.py,sha256=uhthFB0sso9FdnGM-d8HmKvKrzpLDue8YU3Xt-Sffs0,2475
 mira/classifiers/torchvision.py,sha256=LULjDF_yeZXjHKr6xtYaRZoZU2lQnfnQuMJY0RhT_Tg,3254
 mira/core/__init__.py,sha256=GcTBpyo0JZPhRDdy7en3vuqbOpARfWP7KdVu3WTnU14,261
 mira/core/annotation.py,sha256=8yMyhoqmmMSrTn4eyeinpriVoZsmMyPQdKhJgcmTd2M,13046
 mira/core/augmentations.py,sha256=T5oWoPicjtz1xxtnrmOtTPgPDqyzHHHM1m006J2e2Cw,14175
 mira/core/callbacks.py,sha256=9hsq4E12Zei1Q4N71loElVNFavLIpiRoMjk_R06wwKM,7122
 mira/core/experimental.py,sha256=i-Tbi7GBQSiNcGROGZdI7LQhSJZDg3IExmF-p66p7Wc,9028
 mira/core/files.py,sha256=gxd5boiHdAIBuyHe3FP4lrEwRSzhJ6bGEKvL0iCtDwE,6722
 mira/core/imagemeta.py,sha256=RevkouoVc1pJGth50tKWMiMYQNcvGVs-RfXT-GcpsTY,7924
 mira/core/protos/scene_pb2.py,sha256=U6sVdCMXYQ7qnAdzfmfaR32Z76dUprJfjGabfW4XYzE,3987
 mira/core/resizing.py,sha256=h-CvfJSBBETF5IgWPl6Wd9o7JJSbM65irHRPWhJcRFM,9334
 mira/core/scene.py,sha256=jEtCUWe1X1s-JvqwQYVci3dRsaI4GBJ5xnkqYBM_Szc,41842
-mira/core/torchtools.py,sha256=1HJgdcx573S28yWfMSr-XIRcSH1gYBN09VF4E0HTt2w,26690
+mira/core/torchtools.py,sha256=rMV5LEhFt-CyLQBEoLtBzYmCfHcDMXzTX9OeI3qMQc4,26691
 mira/core/utils.py,sha256=G-iSrPDkgSOtNsf_l-leVk60S1WvMWt6HMZ733hpc7Y,19748
 mira/datasets/__init__.py,sha256=aSUkOhfhVfuUL1J3E-ahFYMvF8IRbW2By5dw51YBY2U,268
 mira/datasets/assets/coco_classes.txt,sha256=12VLJhAVcoQe0c2AqgOqYONfG4rLSuppBsQGaIbxbgc,620
 mira/datasets/assets/coco_classes_90.txt,sha256=H7sR2DpHdnZort0TRhjq4b9FYonmbUyfr2KhEvdLps8,774
 mira/datasets/assets/imagenet1k_classes.txt,sha256=V_7KtE4m1prxv7CLaAYUf24PhJJqrCO-QkP5zOenRMw,10499
 mira/datasets/assets/voc_classes.txt,sha256=fYd_GFyAe8UbTPtPQgL8C04cZyS3grokX-NvjSVPCtc,134
 mira/datasets/coco.py,sha256=bjXE3PESpFwIisKtB_RzRWpljGMYEX_2Bn5DCU4wgDA,4864
@@ -269,11 +269,11 @@
 mira/thirdparty/smp/segmentation_models_pytorch/utils/meter.py,sha256=Drfw0TD3npkS58nwav-yADcQ4JTnVFGeWqY4zlIMaj8,1656
 mira/thirdparty/smp/segmentation_models_pytorch/utils/metrics.py,sha256=RFX17t7fQLzddRA-axe8WIHybXo3NMOKMzWBp5jMo1g,2992
 mira/thirdparty/smp/segmentation_models_pytorch/utils/train.py,sha256=Cz4u1mBG3qeJhRxz092waO54aQ4cSHSG7eKyVBw_JGM,3310
 mira/thirdparty/smp/setup.py,sha256=ncLD56bUKUF_ZDus9lQJ5YWWLnQlwprt_tafSBaGLdY,3817
 mira/thirdparty/smp/tests/test_losses.py,sha256=aZtkR6uINiJl2tDT5CW4h7VhdpUl72tj5Igl1xFMU_g,11748
 mira/thirdparty/smp/tests/test_models.py,sha256=3KefFAfAkT_7JVM1VXsmX22v8gDJ_Vltii9HYDEBIkg,4501
 mira/thirdparty/smp/tests/test_preprocessing.py,sha256=AxjRlE-HwHcQoPxX7aQKx8UyvhJ8uYXwyhs-tWURNzA,1714
-mira-0.9.8.dist-info/LICENSE,sha256=wYHu0lSmCDmaEFnd9ctyyx8aWEGgg6qjDz5nE4U9358,1022
-mira-0.9.8.dist-info/WHEEL,sha256=y3eDiaFVSNTPbgzfNn0nYn5tEn1cX6WrdetDlQM4xWw,83
-mira-0.9.8.dist-info/METADATA,sha256=AELDmAyzFu9oQuxL_97qN2553Z9czj05a_OX3_NpdsI,2035
-mira-0.9.8.dist-info/RECORD,,
+mira-0.9.9.dist-info/LICENSE,sha256=wYHu0lSmCDmaEFnd9ctyyx8aWEGgg6qjDz5nE4U9358,1022
+mira-0.9.9.dist-info/WHEEL,sha256=y3eDiaFVSNTPbgzfNn0nYn5tEn1cX6WrdetDlQM4xWw,83
+mira-0.9.9.dist-info/METADATA,sha256=vH2_1vyCijRnvg8_RnCckXW4WE2HAPwMkqe0FwGh1AU,2035
+mira-0.9.9.dist-info/RECORD,,
```

