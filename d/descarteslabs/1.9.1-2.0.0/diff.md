# Comparing `tmp/descarteslabs-1.9.1.tar.gz` & `tmp/descarteslabs-2.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/descarteslabs-1.9.1.tar", last modified: Tue Dec 21 00:28:05 2021, max compression
+gzip compressed data, was "descarteslabs-2.0.0.tar", last modified: Mon Jun 12 20:04:12 2023, max compression
```

## Comparing `descarteslabs-1.9.1.tar` & `descarteslabs-2.0.0.tar`

### file list

```diff
@@ -1,601 +1,243 @@
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      561 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/LICENSE
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1655 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/PKG-INFO
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    61149 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/README.md
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2707 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/catalog/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2141 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    60141 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/attributes.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    34025 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/band.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    36586 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/catalog_base.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2436 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/catalog_client.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    25961 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/image.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    17288 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/image_upload.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8003 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/named_catalog_base.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    24259 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/product.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19899 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/search.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1152 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/base.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    35757 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_attributes.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    28015 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_band.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    16413 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_catalog_base.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    29362 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_image.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    24677 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_image_upload.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    34066 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_product.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    13381 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_search.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4410 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/catalog/tests/test_summary.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1285 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2189 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/addons.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/auth/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      629 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/auth/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19713 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/auth/auth.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3519 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/auth/cli.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/auth/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/auth/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10654 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/auth/tests/test_auth.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5329 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/auth/tests/test_cli.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     6072 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/deprecation.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2325 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/exceptions.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      259 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1597 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/auth.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8106 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/client.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    12221 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2620 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/generic_client_interceptor.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     6482 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/grpc/tests/test_client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      584 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      849 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/__main__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4061 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/cli.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3048 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/scripts/tests/test_scripts.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1231 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/catalog/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/catalog/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    97166 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/catalog/catalog.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/catalog/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/catalog/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5197 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/catalog/tests/test_catalog.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      759 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2566 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/cli.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    34951 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/metadata.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/smoke_tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/smoke_tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7357 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/metadata/smoke_tests/test_metadata.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      635 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1899 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/cli.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10728 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/places.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3167 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/places/tests/test_places.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       49 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1499 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/cli.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10380 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/geotiff_utils.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    33761 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/raster.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/smoke_tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/smoke_tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    41053 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/smoke_tests/iowa_geometry.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    14689 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/smoke_tests/test_raster.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5557 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/raster/tests/test_raster.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/service/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      853 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/service/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    37515 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/service/service.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/service/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/service/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19392 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/service/tests/test_service.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/storage/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       52 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/storage/__init__.py
--rwxrwxr-x   0 stephen   (1020) stephen   (1021)    10102 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/storage/storage.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/storage/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/storage/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2851 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/storage/tests/test_storage.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      476 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/__init__.py
--rwxrwxr-x   0 stephen   (1020) stephen   (1021)    71339 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tasks.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/dl_test_package/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/dl_test_package/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/dl_test_package/package/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/dl_test_package/package/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      296 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/data/dl_test_package/package/module.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    22333 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/tasks/tests/test_tasks.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/vector/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      274 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/vector/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/client/services/vector/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/vector/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    17373 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/vector/tests/test_vector.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    62548 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/services/vector/vector.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      607 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/client/version.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/discover/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       74 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/discover/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1170 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/discover/client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      130 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8740 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/_tiling.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4304 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/conversions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      191 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8012 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/rasterize.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2904 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/tests/test_conversions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9213 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/tests/test_dltiles.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19006 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/tile.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3872 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/utils.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10539 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dltile/utm.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/dotdict/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      117 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dotdict/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    15672 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dotdict/dotdict.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/dotdict/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dotdict/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    14733 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/dotdict/tests/test_dotdict.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/graft/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/graft/client/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      463 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/client/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19645 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/client/client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/graft/client/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/client/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4683 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/client/tests/test_client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      160 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      223 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5704 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/interpreter.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      848 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/scopedchainmap.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    11134 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/interpreter/tests/test_interpreter.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/graft/syntax/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      465 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/syntax/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3621 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/graft/syntax/syntax.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/http/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/http/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1077 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/http/authorization.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1968 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/http/retry.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/http/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/http/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      553 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/http/tests/test_authorization.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      948 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/http/tests/test_retry.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/property_filtering/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      100 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/property_filtering/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9735 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/property_filtering/filtering.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/currier/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/currier/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    42545 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/currier/currier_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9240 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/currier/currier_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/destinations/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/destinations/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    14902 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/destinations/destinations_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/destinations/destinations_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/discover/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/discover/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    75497 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/discover/discover_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    23031 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/discover/discover_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/errors/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/errors/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4345 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/errors/errors_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/errors/errors_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/formats/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/formats/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    23823 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/formats/formats_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/formats/formats_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/health/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/health/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5797 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/health/health_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2784 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/health/health_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/ibis/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/ibis/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    63368 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/ibis/ibis_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/ibis/ibis_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/job/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/job/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    46071 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/job/job_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9729 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/job/job_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/logging/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/logging/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4608 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/logging/logging_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/logging/logging_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/testing/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/testing/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5318 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/testing/testing_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8199 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/testing/testing_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/types/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/types/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7030 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/types/types_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/types/types_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/typespec/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/typespec/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    14064 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/typespec/typespec_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/typespec/typespec_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/vektorius/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/vektorius/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    53137 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/vektorius/vektorius_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    16243 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/vektorius/vektorius_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/visualization/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/visualization/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7307 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/visualization/visualization_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/visualization/visualization_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/widgets/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/widgets/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    37148 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/widgets/widgets_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      159 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/widgets/widgets_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/workflow/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/workflow/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    42124 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/workflow/workflow_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    12289 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/workflow/workflow_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/proto/xyz/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       72 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/xyz/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    31867 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/xyz/xyz_pb2.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9795 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/proto/xyz/xyz_pb2_grpc.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/registry/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       55 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/registry/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1700 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/registry/registry.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/retry/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      178 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/retry/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7099 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/retry/retry.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/retry/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/retry/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4493 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/retry/tests/test_retry.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/services/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/services/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/services/tasks/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/services/tasks/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      217 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/services/tasks/constants.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/shapely_support/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4598 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/shapely_support/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      258 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4141 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/exporttask.py
--rwxrwxr-x   0 stephen   (1020) stephen   (1021)     9218 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/futuretask.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1827 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/tests/test_exporttask.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5270 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/tests/test_futuretask.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7182 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/tests/test_uploadtask.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9548 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/tasks/uploadtask.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/threading/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/threading/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1043 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/threading/local.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/threading/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/threading/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2973 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/threading/tests/test_local.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      190 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2238 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/context.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1149 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/serialization.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1522 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/tests/test_context.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      286 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/tests/test_deserialize_pyarrow.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      942 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/arrow_serialization/tests/test_roundtrip.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      464 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1899 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/format_to_mimetype.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1219 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/mimetype_to_proto.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1455 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/tests/test_format_to_mimetype.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1335 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/tests/test_mimetype_to_proto.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2682 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/user_destination_options.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      850 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/outputs/user_format_options.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      453 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      171 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/enum_prefix.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1866 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/proto_to_user_dict.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1162 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/tests/test_proto_to_user_dict.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4010 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/tests/test_user_dict_to_proto.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7883 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/user_dict_to_proto.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      916 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/proto_munging/which_has.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/utils/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       67 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/utils/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      624 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/utils/masked_stack.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/utils/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/utils/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1309 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/common/workflows/utils/tests/test_masked_stack.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/discover/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      149 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/discover/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    58544 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/discover/client.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       54 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/exceptions.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/scenes/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1089 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8505 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/_display.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3179 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/_download.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2480 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/_helpers.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    23527 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/_scaling.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7803 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/_search.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10310 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/collection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    46453 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/geocontext.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    38586 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/scene.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    40653 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/scenecollection.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)   126527 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/mock_data.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4226 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_collection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3933 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_display.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4972 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_download.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    20784 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_geocontext.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5665 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_helpers.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    30861 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_scene.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    20477 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_scenecollection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5883 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/scenes/tests/test_search.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/third_party/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/third_party/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/third_party/boltons/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       49 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/third_party/boltons/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    32185 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/third_party/boltons/funcutils.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/vectors/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1461 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7527 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/async_job.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      502 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4018 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/feature.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    43187 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/featurecollection.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/vectors/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      207 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/tests/fixtures.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4171 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/tests/test_async_job.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1897 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/tests/test_feature.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    15917 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/vectors/tests/test_featurecollection.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5524 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      802 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/_channel.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/cereal/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      259 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/cereal/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5121 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/cereal/cereal.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/cereal/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/cereal/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3375 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/cereal/tests/test_cereal.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/client/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      244 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/client/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7452 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/client/client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/client/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/client/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1934 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/client/tests/test_client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/execution/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      176 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/execution/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3953 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/execution/arguments.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2054 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/execution/to_computable.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/inspect/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      139 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/inspect/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7589 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/inspect/client.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2631 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1574 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/clearable.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    13082 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/inspector.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    26056 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/layer.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4830 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/layer_controller.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    16947 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/layer_controller_row.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     6040 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/layer_picker.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1186 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/lonlat.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    21589 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/map_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    35156 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/parameters.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      407 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/utils.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      298 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8423 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/_imagery.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      384 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/_ipywidgets.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1954 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/checkbox.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5478 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/date.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2969 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/input.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     6138 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/select.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4891 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/widgets/slider.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    17785 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/interactive/workflow.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      612 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2563 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    28213 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/job.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7897 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/published_graft.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      539 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19149 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_job.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5931 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_published_graft.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5024 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_tile_url.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      705 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_utils.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4003 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_versionedgraft.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9225 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_workflow.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8251 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/test_xyz.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      986 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tests/utils.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8112 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/tile_url.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    12565 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/toplevel.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1816 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/utils.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    12367 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/versionedgraft.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4891 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/visualization.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    34909 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/workflow.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    26726 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/models/xyz.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      334 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      869 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/tests/test_unmarshal.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    17201 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/types.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      905 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/result_types/unmarshal.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2282 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/_debugging/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       53 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/_debugging/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      172 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/_debugging/_debugging.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      218 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3110 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/array_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    21031 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/base_array.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1574 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/dtype.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7451 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/masked_array.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3820 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/scalar.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4491 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/tests/test_array.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5625 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/array/tests/test_masked_array.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/conditional/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       49 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/conditional/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2592 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/conditional/ifelse.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/conditional/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/conditional/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1568 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/conditional/tests/test_conditional.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/constants/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       77 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/constants/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1334 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/constants/constants.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/constants/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/constants/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      302 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/constants/tests/test_constants.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      438 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2714 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/_check_valid_binop.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7718 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/collection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10790 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/dict_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      816 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/ellipsis.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3345 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/known_dict.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     6126 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/list_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      941 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/range_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2483 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/slice.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10551 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/struct.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1273 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_check_valid_binop.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3231 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_collection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5529 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_dict.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      974 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_knowndict.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4020 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_list.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      240 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_range.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      712 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_slice.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5177 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_struct.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4469 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_tuple.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1296 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tests/test_zip.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9435 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/tuple_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2049 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/containers/zip_.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      623 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    11167 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/codegen.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    26245 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/core.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      148 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/exceptions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10626 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/promote.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    12768 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/tests/test_core.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7889 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/tests/test_promote.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3165 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/core/tests/utils.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      102 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7705 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/datetime_.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2417 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/tests/test_datetime.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2829 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/tests/test_timedelta.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5291 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/datetimes/timedelta.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/function/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       55 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/function/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    26448 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/function/function.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/function/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/function/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    16781 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/function/tests/test_function.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      741 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2148 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/concat.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2331 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/convolution.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     5201 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/feature.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9290 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/featurecollection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    15135 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/geocontext.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4078 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/geometry.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4643 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/geometrycollection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    19560 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/groupby.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    67125 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/image.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    97199 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/imagecollection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3800 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/load_geojson.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10726 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/mixins.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2367 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_bandmixin.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      382 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_concat.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1007 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_feature.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2316 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_featurecollection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3706 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_geocontext.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3051 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_geometry.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      339 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_geometry_mixin.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1873 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_groupby.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10267 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_image.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8500 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_imagecollection.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1424 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_load_geojson.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1280 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/tests/test_where.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3474 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/geospatial/where.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/identifier/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       85 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/identifier/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1464 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/identifier/identifier.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/identifier/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/identifier/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      688 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/identifier/tests/test_identifier.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/math/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      441 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/math/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    10541 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/math/arithmetic.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/math/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/math/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      654 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/math/tests/test_arithmetic.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/mixins/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       62 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/mixins/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3310 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/mixins/numpy_mixin.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2471 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/linalg/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       99 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/linalg/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      235 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/linalg/numpy_linalg.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/ma/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      163 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/ma/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      210 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/ma/numpy_ma.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1257 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/numpy_functions.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9766 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/numpy_ufuncs.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    44969 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/signatures.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2578 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/numpy/utils.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      289 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7984 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/any_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2955 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/bool_.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      446 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/none.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     8524 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/number.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1390 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/primitive.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    20940 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/string.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     3208 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/test_any.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1316 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/test_bool.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/test_none.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     9811 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/test_number.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1171 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/test_primitive.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2740 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/primitives/tests/test_string.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/proxify/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       52 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/proxify/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     2086 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/proxify/proxify.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/widget/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      129 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/widget/__init__.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/widget/tests/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/widget/tests/__init__.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7082 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/widget/tests/test_widget.py
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     7114 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/descarteslabs/workflows/types/widget/widget.py
-drwxrwxr-x   0 stephen   (1020) stephen   (1021)        0 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     1655 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/PKG-INFO
--rw-rw-r--   0 stephen   (1020) stephen   (1021)    23085 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/SOURCES.txt
--rw-rw-r--   0 stephen   (1020) stephen   (1021)        1 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/dependency_links.txt
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       78 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/entry_points.txt
--rw-rw-r--   0 stephen   (1020) stephen   (1021)      828 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/requires.txt
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       14 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/descarteslabs.egg-info/top_level.txt
--rw-rw-r--   0 stephen   (1020) stephen   (1021)       38 2021-12-21 00:28:05.000000 descarteslabs-1.9.1/setup.cfg
--rw-rw-r--   0 stephen   (1020) stephen   (1021)     4622 2021-12-21 00:28:03.000000 descarteslabs-1.9.1/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/
+-rw-r--r--   0 runner    (1001) docker     (123)      561 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)     1330 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    85194 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/README.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/
+-rw-r--r--   0 runner    (1001) docker     (123)     2051 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/auth/
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/auth/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29383 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/auth/auth.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/auth/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/auth/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16934 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/auth/tests/test_auth.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/catalog/
+-rw-r--r--   0 runner    (1001) docker     (123)      644 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/catalog/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/compute/
+-rw-r--r--   0 runner    (1001) docker     (123)      644 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/compute/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/config/
+-rw-r--r--   0 runner    (1001) docker     (123)    10119 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4384 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/config/settings.toml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/config/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/config/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13316 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/config/tests/test_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs/core/
+-rw-r--r--   0 runner    (1001) docker     (123)       51 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.714188 descarteslabs-2.0.0/descarteslabs/core/catalog/
+-rw-r--r--   0 runner    (1001) docker     (123)     3236 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    64062 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/attributes.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36605 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/band.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29762 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/blob.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1096 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/blob_download.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1731 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/blob_upload.py
+-rw-r--r--   0 runner    (1001) docker     (123)    37861 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/catalog_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2323 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/catalog_client.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4995 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)    63243 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/image.py
+-rw-r--r--   0 runner    (1001) docker     (123)    50022 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/image_collection.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1639 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/image_types.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17853 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/image_upload.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8588 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/named_catalog_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21970 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/product.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26305 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/scaling.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21847 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/search.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.714188 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2298 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)   118250 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/mock_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36523 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_attributes.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28972 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_band.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16050 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_catalog_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5506 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_download.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6411 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)    45554 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_image.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14560 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_image_collection.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25515 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_image_upload.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28485 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_product.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30418 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_scaling.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20303 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_search.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4945 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_summary.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.714188 descarteslabs-2.0.0/descarteslabs/core/client/
+-rw-r--r--   0 runner    (1001) docker     (123)     1290 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1023 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/addons.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.714188 descarteslabs-2.0.0/descarteslabs/core/client/auth/
+-rw-r--r--   0 runner    (1001) docker     (123)      120 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/auth/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3576 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/auth/cli.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.714188 descarteslabs-2.0.0/descarteslabs/core/client/auth/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/auth/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5286 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/auth/tests/test_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8707 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/deprecation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/exceptions.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.722189 descarteslabs-2.0.0/descarteslabs/core/client/scripts/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/scripts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1168 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/scripts/__main__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3464 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/scripts/cli.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.722189 descarteslabs-2.0.0/descarteslabs/core/client/scripts/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/scripts/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3034 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/scripts/tests/test_scripts.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.722189 descarteslabs-2.0.0/descarteslabs/core/client/services/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.722189 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/
+-rw-r--r--   0 runner    (1001) docker     (123)      735 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2566 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)    35310 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/metadata.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.722189 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.722189 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/e2e/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/e2e/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7315 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/e2e/test_metadata.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9372 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/test_metadata.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1467 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14392 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/geotiff_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    33564 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/raster.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/e2e/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/e2e/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    41637 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/e2e/iowa_geometry.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14970 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/e2e/test_raster.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7514 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/test_geotiff_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7439 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/test_raster.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5505 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/test_raster_rasterio.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/client/services/service/
+-rw-r--r--   0 runner    (1001) docker     (123)      945 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/service/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7540 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/service/api_service.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29553 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/service/service.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/client/services/service/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/service/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19843 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/services/service/tests/test_service.py
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/client/version.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/common/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.726189 descarteslabs-2.0.0/descarteslabs/core/common/client/
+-rw-r--r--   0 runner    (1001) docker     (123)      759 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/client/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9424 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/client/attributes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5552 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/client/document.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/client/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/client/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5758 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/client/tests/test_attributes.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/collection/
+-rw-r--r--   0 runner    (1001) docker     (123)      664 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/collection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15722 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/collection/collection.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/collection/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/collection/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4793 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/collection/tests/test_collection.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/display/
+-rw-r--r--   0 runner    (1001) docker     (123)      700 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/display/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10941 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/display/_display.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/display/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/display/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4899 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/display/tests/test_display.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/dltile/
+-rw-r--r--   0 runner    (1001) docker     (123)      715 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8502 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/_tiling.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4863 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/conversions.py
+-rw-r--r--   0 runner    (1001) docker     (123)      777 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8344 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/rasterize.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.730189 descarteslabs-2.0.0/descarteslabs/core/common/dltile/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3489 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/tests/test_conversions.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11665 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/tests/test_dltiles.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19529 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/tile.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4329 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11527 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dltile/utm.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/dotdict/
+-rw-r--r--   0 runner    (1001) docker     (123)      702 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dotdict/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16257 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dotdict/dotdict.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/dotdict/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dotdict/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14087 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/dotdict/tests/test_dotdict.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/geo/
+-rw-r--r--   0 runner    (1001) docker     (123)      715 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/geo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    53135 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/geo/geocontext.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/geo/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/geo/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23527 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/geo/tests/test_geocontext.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6145 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/geo/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3713 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/geo/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/http/
+-rw-r--r--   0 runner    (1001) docker     (123)      762 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1566 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/authorization.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8519 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/proxy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2248 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/retry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1439 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/service.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12887 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/session.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/http/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1134 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/tests/test_authorization.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5927 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/tests/test_proxy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3672 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/tests/test_retry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2056 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/http/tests/test_service.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/
+-rw-r--r--   0 runner    (1001) docker     (123)      750 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16486 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/filtering.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8989 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/tests/test_filtering.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/registry/
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/registry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2285 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/registry/registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.734190 descarteslabs-2.0.0/descarteslabs/core/common/retry/
+-rw-r--r--   0 runner    (1001) docker     (123)      764 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/retry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8281 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/retry/retry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/common/retry/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/retry/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5804 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/retry/tests/test_retry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/common/shapely_support/
+-rw-r--r--   0 runner    (1001) docker     (123)     4963 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/shapely_support/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/common/shapely_support/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/shapely_support/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5826 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/shapely_support/tests/test_shapely_support.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/common/threading/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/threading/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1628 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/threading/local.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/common/threading/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/threading/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3529 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/common/threading/tests/test_local.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/compute/
+-rw-r--r--   0 runner    (1001) docker     (123)      709 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26184 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/compute.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2028 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/compute_client.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/compute/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3840 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/tests/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13550 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/tests/test_function.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6595 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/compute/tests/test_job.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/geo/
+-rw-r--r--   0 runner    (1001) docker     (123)      106 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/geo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/scenes/
+-rw-r--r--   0 runner    (1001) docker     (123)     1365 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1040 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)    33638 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/scene.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28225 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/scenecollection.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12610 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/search_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/scenes/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3744 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/tests/mock_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3486 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/tests/test_scene.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7823 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/tests/test_scenecollection.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16157 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/scenes/tests/test_search.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/third_party/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/third_party/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/third_party/boltons/
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/third_party/boltons/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32185 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/third_party/boltons/funcutils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/core/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      188 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/core/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3269 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/exceptions.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/geo/
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/geo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/scenes/
+-rw-r--r--   0 runner    (1001) docker     (123)      643 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/scenes/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/descarteslabs/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)       57 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/descarteslabs/utils/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-12 20:04:12.710188 descarteslabs-2.0.0/descarteslabs.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)     1330 2023-06-12 20:04:12.000000 descarteslabs-2.0.0/descarteslabs.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     8354 2023-06-12 20:04:12.000000 descarteslabs-2.0.0/descarteslabs.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-12 20:04:12.000000 descarteslabs-2.0.0/descarteslabs.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       83 2023-06-12 20:04:12.000000 descarteslabs-2.0.0/descarteslabs.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      590 2023-06-12 20:04:12.000000 descarteslabs-2.0.0/descarteslabs.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       14 2023-06-12 20:04:12.000000 descarteslabs-2.0.0/descarteslabs.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-06-12 20:04:12.738190 descarteslabs-2.0.0/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     4230 2023-06-12 20:04:07.000000 descarteslabs-2.0.0/setup.py
```

### filetype from file(1)

```diff
@@ -1 +1 @@
-POSIX tar archive (GNU)
+POSIX tar archive
```

### Comparing `descarteslabs-1.9.1/LICENSE` & `descarteslabs-2.0.0/LICENSE`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-Copyright 2018-2020 Descartes Labs.
+Copyright 2018-2023 Descartes Labs.
 
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
 
     http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `descarteslabs-1.9.1/README.md` & `descarteslabs-2.0.0/README.md`

 * *Files 14% similar despite different names*

```diff
@@ -7,20 +7,444 @@
 
 By giving data scientists and their line-of-business colleagues the best geospatial data and modeling tools in one package, we help turn AI into a core competency.
 
 Data science teams can use our scaling infrastructure to design models faster than ever, using our massive data archive or their own.
 
 Please visit [https://descarteslabs.com](https://descarteslabs.com) for more information about the Descartes Labs Platform and to request access.
 
-The `descarteslabs` python package, available at [https://pypi.org/project/descarteslabs/](https://pypi.org/project/descarteslabs/), provides client-side access to the Descartes Labs Platform for our customers. You must be a registered customer with access to the platform before you can make use of this package.
+The `descarteslabs` python package, available at [https://pypi.org/project/descarteslabs/](https://pypi.org/project/descarteslabs/), provides client-side access to the Descartes Labs Platform for our customers. You must be a registered customer with access to our Descartes Labs Platform before you can make use of this package with our platform.
 
 The documentation for the latest release can be found at [https://docs.descarteslabs.com](https://docs.descarteslabs.com). For any issues please request Customer Support at [https://support.descarteslabs.com](https://support.descarteslabs.com).
 
 Changelog
 =========
+
+## [2.0.0] - 2023-06-12
+
+(Release notes from all the 2.0.0 release candidates are summarized here for completeness.)
+
+### Supported platforms
+
+- Deprecated support for Python 3.7 (will end of life in July).
+- Added support for Python 3.10 and Python 3.11
+- AWS-only client. For the time being, the AWS client can be used to communicate with the legacy GCP platform (e.g. `DESCARTESLABS_ENV=gcp-production`) but only supports those services that are supported on AWS (`catalog` and `scenes`). This support may break at any point in the future, so it is strictly transitional.
+
+### Dependencies
+
+- Removed many dependencies no longer required due to the removal of GCP-only features.
+- Added support for Shapely 2.X. Note that user code may also be affected by breaking changes in
+  Shapely 2.X. Use of Shapely 1.8 is still supported.
+- Updated requirements to avoid `urllib3>=2.0.0` which breaks all kinds of things.
+
+### Configuration
+
+- Major overhaul of the internals of the config process. To support other clients using namespaced packages within the `descarteslabs` package, the top level has been cleaned up, and most all the real code is down inside `descarteslabs.core`. End users should never have to import anything from `descarteslabs.core`. No more magic packages means that `pylint` will work well with code using `descarteslabs`.
+- Configuration no longer depends upon the authorized user.
+
+### Catalog
+
+- Added support for data storage. The `Blob` class provides mechanism to upload, index, share, and retrieve arbitrary byte sequences (e.g. files). `Blob`s can be searched by namespace and name, geospatial coordinates (points, polygons, etc.), and tags. `Blob`s can be downloaded to a local file, or retrieved directly as a Python `bytes` object. `Blob`s support the same sharing mechanisms as `Product`s, with `owners`, `writers`, and `readers` attributes.
+- Added support to `Property` for `prefix` filtering.
+- The default `geocontext` for image objects no longer specifies a `resolution` but rather a `shape`, to ensure
+  that default rastering preserves the original data and alignment (i.e. no warping of the source image).
+- As with `resolution`, you can now pass a `crs` parameter to the rastering methods (e.g. `Image.ndarray`,
+  `ImageCollection.stack`, etc.) to override the `crs` of the default geocontext.
+- A bug in the code handling the default context for image collections when working with a product with a CRS based on degrees rather than meters has been fixed. Resolutions should always be specified in the units used by the CRS.
+
+### Compute
+
+- Added support for managed batch compute under the `compute` module.
+
+### Raster Client
+
+- Fixed a bug in the handling of small blocks (less than 512 x 512) that caused rasterio to generate bad download files (the desired image block would appear as a smaller sub-block rather than filling the resulting raster).
+
+### Geo
+
+- The defaulting of `align_pixels` has changed slightly for the `AOI` class. Previously it always defaulted to
+  `True`. Now the default is `True` if `resolution` is set, `False` otherwise. This ensures that when specifying
+  a `shape` and a `bounds` rather than a resolution,the `shape` is actually honored.
+- When assigning a `resolution` to an `AOI`, any existing `shape` attribute is automatically unset, since the
+  two attributes are mutually exclusive.
+- The validation of bounds for a geographic CRS has been slightly modified to account for some of the
+  irregularities of whole-globe image products, correcting unintended failures in the past.
+- Fixed problem handling MultiPolygon and GeometryCollection when using Shapely 2.0.
+
+
+## [2.0.0rc5] - 2023-06-01
+
+### Catalog
+
+- Loosen up the restrictions on the allowed alphabet for Blob names. Now almost any printable
+  character is accepted save for newlines and commas.
+- Added new storage types for Blobs: `StorageType.COMPUTE` (for Compute job results) and
+  `StorageType.DYNCOMP` (for saved `dynamic-compute` operations).
+
+### Compute
+
+- Added testing of the client.
+
+## [2.0.0rc4] - 2023-05-17
+
+### Catalog
+
+- The defaulting of the `namespace` value for `Blob`s has changed slightly. If no namespace is specified,
+  it will default to `<org>:<hash>` with the user's org name and unique user hash. Otherwise, any other value,
+  as before, will be prefixed with the user's org name if it isn't already so.
+- `Blob.get` no longer requires a full id. Alternatively, you can give it a `name` and optionally a `namespace`
+  and a `storage_type`, and it will retrieve the `Blob`.
+- Fixed a bug causing summaries of `Blob` searches to fail.
+
+### Compute
+
+- `Function.map` and `Function.rerun` now save the created `Job`s before returning.
+- `Job.get` return values fixed, and removed an extraneous debug print.
+
+### General
+
+- Updated requirements to avoid `urllib3>=2.0.0` which break all kinds of things.
+
+## [2.0.0rc3] - 2023-05-03
+
+### Geo
+
+- The defaulting of `align_pixels` has changed slightly for the `AOI` class. Previously it always defaulted to
+  `True`. Now the default is `True` if `resolution` is set, `False` otherwise. This ensures that when specifying
+  a `shape` and a `bounds` rather than a resolution,the `shape` is actually honored.
+- When assigning a `resolution` to an `AOI`, any existing `shape` attribute is automatically unset, since the
+  two attributes are mutually exclusive.
+- The validation of bounds for a geographic CRS has been slightly modified to account for some of the irregularities
+  of whole-globe image products, correcting unintended failures in the past.
+
+### Catalog
+
+- The default `geocontext` for image objects no longer specifies a `resolution` but rather a `shape`, to ensure
+  that default rastering preserves the original data and alignment (i.e. no warping of the source image).
+- The `Blob.upload` and `Blob.upload_data` methods now return `self`, so they can be used in a fluent style.
+- As with `resolution`, you can now pass a `crs` parameter to the rastering methods (e.g. `Image.ndarray`,
+  `ImageCollection.stack`, etc.) to override the `crs` of the default geocontext.
+
+### Compute
+
+- A bevy of fixes to the client.
+
+## [2.0.0rc2] - 2023-04-19
+
+### Catalog
+
+- Added support for data storage. The `Blob` class provides mechanism to upload, index, share, and retrieve arbitrary byte sequences (e.g. files). `Blob`s can be searched by namespace and name, geospatial coordinates (points, polygons, etc.), and tags. `Blob`s can be downloaded to a local file, or retrieved directly as a Python `bytes` object. `Blob`s support the same sharing mechanisms as `Product`s, with `owners`, `writers`, and `readers` attributes.
+- Added support to `Property` for `prefix` filtering.
+
+### Compute
+
+- Added method to update user credentials for a `Function`.
+- Added methods to retrieve build and job logs.
+
+### General
+
+- Added support for Shapely=2.X.
+
+## [2.0.0rc1] - 2023-04-10
+
+- This is an internal-only release. There is as of yet no updated documentation. However, the user-facing client APIs remain fully compatible with v1.12.1.
+
+### Compute
+
+- Added support for managed batch compute under the `compute` module.
+
+### Auth and Configuration
+
+- Removed the check on the Auth for configuration, since it is all AWS all the time.
+
+### Raster Client
+
+- Fixed a bug in the handling of small blocks (less than 512 x 512) that caused rasterio to generate bad download files (the desired image block would appear as a smaller sub-block rather than filling the resulting raster).
+
+## [2.0.0rc0] - 2023-03-16
+
+- This is an internal-only release. There is as of yet no updated documentation. However, the user-facing client APIs remain fully compatible with v1.12.1.
+
+### Supported platforms
+
+- Deprecated support for Python 3.7 (will end of life in July).
+- Added support for Python 3.10 and Python 3.11
+- AWS-only client. For the time being, the AWS client can be used to communicate with the legacy GCP platform (e.g. `DESCARTESLABS_ENV=gcp-production`) but only supports those services that are supported on AWS (`catalog` and `scenes`). This support may break at any point in the future, so it is strictly transitional.
+
+### Dependencies
+
+- Removed many dependencies no longer required due to the removal of GCP-only features.
+
+### Configuration
+
+- Major overhaul of the internals of the config process. To prepare for supporting other clients using namespaced packages within the `descarteslabs` package, the top level has been cleaned up, and most all the real code is down inside `descarteslabs.core`. However end users should never have to import anything from `descarteslabs.core`. No more magic packages means that `pylint` will work well with code using `descarteslabs`.
+- GCP environments only support `catalog` and `scenes`. All other GCP-only features have been removed.
+
+### Catalog
+
+- A bug in the code handling the default context for image collections when working with a product with a CRS based on degrees rather than meters has been fixed. Resolutions should always be specified in the units used by the CRS.
+
+## [1.12.1] - 2023-02-06
+
+### Workflows
+
+- Fixed a bug causing `descarteslabs.workflows.map.geocontext()` to fail with an import error. This problem
+  also affected the autoscaling feature of workflows map layers.
+
+### Catalog/Scenes/Raster
+
+- Fixed a bug causing downloads of single-band images to fail when utilizing rasterio.
+
+## [1.12.0] - 2023-02-01
+
+### Catalog
+
+- Catalog V2 is now fully supported on the AWS platform, including user ingest.
+- Catalog V2 has been enhanced to provide substantially all the functionality of the Scenes API. The `Image` class now
+  includes methods such as `ndarray` and `download`. A new `ImageCollection` class has been added, mirroring `SceneCollection`.
+  The various `Search` objects now support a new `collect` method which will return appropriate `Collection` types
+  (e.g. `ProductCollection`, `BandCollection`, and of course `ImageCollection`). Please see the updated Catalog V2
+  guide and API documentation for more details.
+- Previously, the internal implementation of the `physical_range` attribute on various band types was inconsistent with
+  that of `data_range` and `display_range`. It has now been made consistent, which means it will either not be set,
+  or will contain a 2-tuple of float values. It is no longer possible to explicitly set it to `None`.
+- Access permissions for bands and images are now managed directly by the product. The `readers`, `writers`, and
+  `owners` attributes have been removed from all the `*Band` classes as well as the `Image` class. Also the
+  `Product.update_related_objects_permissions` and `Product.get_update_permissions_status` methods have been removed
+  as these are no longer necessary or supported.
+- All searches for bands (other than derived bands) and images must specify one or more product ids in the filtering.
+  This requirement can be met by using the `bands()` and `images()` methods of a product to limit the search to that
+  product, or through a `filter(properties.product_id==...)` clause on the search.
+- Products have a new `product_tier` attribute, which can only be set or modified by privileged users.
+- The `Image.upload_ndarray` will now accept either an ndarray or a list of ndarrays, allowing multiple files per image.
+  The band definitions for the product must correspond to the order and properties of the multiple ndarrays.
+
+### Scenes
+
+- With the addition of the Scenes functionality to Catalog V2, you are strongly encouraged to migrate your Scenes-based
+  code to use Catalog V2 instead. Scenes will be deprecated in a future release. Some examples of migrating from Scenes
+  to Catalog V2 are included in the Catalog V2 guide. In the meantime the Scenes API has been completely reimplemented
+  to use Catalog V2 under the hood. From a user perspective, existing code using the Scenes API should continue to
+  function as normal, with the exception of a few differences around some little-used dark corners of the API.
+- The Scenes `search_bands` now enforces the use of a non-empty `products=` parameter value. This was previously
+  documented but not enforced.
+
+### Metadata
+
+- With the addition of the Scenes functionality to Catalog V2, you are strongly encouraged to migrate your Metadata-based
+  code to use Catalog V2 instead. Metadata will be deprecated in a future release.
+- As with Catalog and Scenes, one or more products must now be specified when searching for bands or images.
+
+### Raster
+
+- The Raster client API now requires a `bands=` parameter for all rastering operations, such as `raster`, `ndarray`
+  and `stack`. It no longer defaults to all bands defined on the product.
+
+### DLTile
+
+- An off-by-1/2-pixel problem was identified in the coordinate transforms underlying
+  `DLTile.rowcol_to_latlon` and `DLTile.latlon_to_rowcol`. The problem has been corrected,
+  and you can expect to see slight differences in the results of these two methods.
+
+### REST Clients
+
+- All the REST client types, such as `Metadata` and `Raster`, now support `get_default_client()` and `set_default_client()`
+  instances. This functionality was previously limited to the Catalog V2 `CatalogClient`. Whenever such a client is required,
+  the client libraries use `get_default_client()` rather than using the default constructor. This makes it easy to
+  comprehensively redirect the library to use a specially configured client when necessary.
+
+### Geo package
+
+- The `GeoContext` types that originally were part of the Scenes package are now available in the new `descarteslabs.geo` package,
+  with no dependencies on Scenes. This is the preferred location from which to import these classes.
+
+### Utils package
+
+- The `descarteslabs.utils` package, added in the previous release for the AWS client only, now exists in the GCP client
+  as well, and is the preferred location to pick up the `DotDict` and `DotList` classes, the `display` and `save_image` functions,
+  and the `Properties` class for property filtering in Catalog V2.
+- The `display` method now has added support for multi-image plots, see the API documentation for the `figsize`, `nrows`,
+  `ncols` and `layout_direction` parameters.
+
+### Property filtering
+
+- The `property_filtering.GenericProperties` class has been replaced with `property_filtering.Properties`, but remains
+  for back compatibility.
+- Property filters now support `isnull` and `isnotnull` operations. This can be very useful for properties which may or
+  may not be present, e.g. `properties.cloud_fraction.isnull | properties.cloud_fraction <= 0.2`.
+
+### Configuration and Authentication
+
+- The `Config` exceptions `RuntimeError` and `KeyError` were changed to `ConfigError` exceptions
+  from `descarteslabs.exceptions`.
+- `Auth` now retrieves its URL from the `Config` settings. If no valid configuration can be found,
+  it reverts to the commercial service (`https://iam.descarteslabs.com`).
+
+### General
+- Dependencies for the descarteslabs library have been updated, but remain constrained to continue to support Python 3.7.
+- Numerous bug fixes.
+
+## [1.11.0] - 2022-07-20
+
+### Installation
+
+- The extra requirement options have changed. There are four extra requirement options now, `visualization`, `tables`,
+  `complete`, and `tests`. `visualization` pulls in extra requirements to support operating in a Jupyter notebook or
+  environment, enabling interactive maps and graphical displays. It is not required for operating in a "headless"
+  manner. `tables` pulls in extra requirements to support the `Tables` client. `complete` is the combination of
+  `visualization` and `tables`. `tests` pulls in extra requirements for running the tests. As always,
+  `pip install 'descarteslabs[complete]'` will install a fully enabled client.
+
+### Configuration
+
+- The Descartes Labs client now supports configuration to support operating in different environments. By default,
+  the client will configure itself for standard usage against the GCP platform (`"gcp-production"`), except in the case of AWS Marketplace users, for whom
+  the client will configure itself against the AWS platform (`"aws-production"`).
+  Alternate environments can be configured by setting the `DESCARTESLABS_ENV` environment variable before starting python, or by using a prelude like
+  ```
+  from descarteslabs.config import Settings
+  Settings.select_env("environment-name")
+  ```
+  before any other imports of any part of the descarteslabs client package.
+- The new AWS Enterprise Accelerator release currently includes only Auth, Configuration
+  and the Scenes client.
+
+### Auth and Exceptions
+
+- The `descarteslabs.client.auth` package has moved to `descarteslabs.auth`. It is now imported
+  into the original location at `descarteslabs.client.auth` to continue to work with existing
+  code, but new code should use the new location.
+- The `descarteslabs.client.exceptions` module has moved to `descarteslabs.exceptions`. It is
+  now imported into the original location at `descarteslabs.client.exceptions` to continue to
+  work with existing code, but new code should use the new location.
+
+### Scenes
+
+- Fixed an issue in `scenes.DLTile.from_shape` where there would be incomplete coverage of certain geometries. The function may now return more tiles than before.
+- Added support for the new `all_touched` parameter to the different `GeoContext` types. Default behavior remains the same
+as always, but if you set `all_touched=True` this communicates to the raster service that you want the image(s) rastered
+using GDAL's `CUTLINE_ALL_TOUCHED` option which will change how source pixels are mapped to output pixels. This mode is
+only recommended when using an AOI which is smaller than the source imagery pixel resolution.
+- The DLTile support has been fixed to avoid generating gaps when tiling regions that span
+  a large distance north-to-south and straddle meridians which are boundaries between
+  UTM zones. So methods such as `DLTile.from_shape` may return more tiles than previously,
+  but properly covering the region.
+- Added support for retrieving products and bands.
+  - Methods added: `get_product`, `get_band`, `get_derived_band`, `search_products`,
+    `search_bands`, `search_derived_bands`.
+  - Disallows search without `products` parameter.
+- Scaling support has been enhanced to understand processing levels for newer products. The
+  `Scene.scaling_parameters` and `SceneCollection.scaling_parameters` methods now accept
+  a `processing_level` argument, and this will be factored in to the determination of
+  the default result data type and scaling for all rastering operations such as `Scene.ndarray`
+  and `SceneCollection.mosaic`.
+- If the user provides the `rasterio` package (which implies providing GDAL), then rasterio
+  will be used to save any downloaded images as GeoTIFF, allowing for the use of compression.
+  Otherwise, by default the `tifffile` support will be used to generate the GeoTIFF files
+  but compression is not supported in this mode.
+- As the Places client has been deprecated, so has any use of the `place=` parameter supported
+  by several of the Scenes functions and methods.
+
+### Catalog
+
+- (Core users only) Added support for specifying the image index to use when creating a new `Product`.
+- Added support for defining per-processing-level `data_type`, `data_range`, `display_range`
+  and `physical_range` properties on processing level steps.
+
+### Discover
+
+- Added support for filtering `Assets` by type and name fields.
+  - Supported filter types `blob`, `folder`, `namespace`, `sym_link`, `sts_model`, and `vector`. Specifying multiple types will find assets matching any given type.
+  - The name field supports the following wildcards:
+    - `*` matches 0 or more of any character.
+    - `?` matches 1 of any character.
+  - Find assets matching type of `blob` and having a display name of `file name.json` or `file2name.txt` but **not** `filename.json`:
+    - `Discover().list_assets("asset/namespace/org:some_org", filters="type=blob&name=file?name.*")`
+    - `Discover().list_assets("asset/namespace/org:some_org", filters=AssetListFilter(type=AssetType.BLOB, name="file?name.*"))`
+  - Find assets of type `blob` or `vector`:
+    - `Discover().list_assets("asset/namespace/org:some_org", filters="type=blob,vector")`
+    - `Discover().list_assets("asset/namespace/org:some_org", filters=AssetListFilter(type=[AssetType.BLOB, AssetType.VECTOR], name="file?name.*"))`
+
+### Metadata
+
+- `Metadata.products` and `Metadata.available_products` now properly implement paging so that
+  by default, a DotList containing every matching product accessible to the user is returned.
+
+### Raster
+
+- If the user provides the `rasterio` package (which implies providing GDAL), then rasterio
+  will be used to save any downloaded images as GeoTIFF, allowing for the use of compression.
+  Otherwise, by default the `tifffile` support will be used to generate the GeoTIFF files
+  but compression is not supported in this mode.
+
+### Tables
+
+- Fixed an issue that caused a user's schema to be overwritten if they didn't provide a primary
+  key on table creation.
+- Now uses Discover backend filtering for `list_tables()` instead of filtering on the client to
+  improve performance.
+- `list_tables()` now supports filtering tables by name
+  - `Tables.list_tables(name="Test*.json")`
+
+### Tasks
+
+- New Tasks images for this release bump the versions of several dependencies, please see
+  the Tasks guide for detailed lists of dependencies.
+
+### Workbench
+
+- The new Workbench release bumps the versions of several dependencies.
+
+### Workflows
+
+- Added support for the new `all_touched` parameter to the different `GeoContext` types.
+  See description above under `Scenes`.
+
+### General
+
+- The Places client has been deprecated, and use thereof will generate a deprecation warning.
+- The older Catalog V1 client has been deprecated, and use thereof will generate a deprecation
+  warning. Please use the Catalog V2 client in its place.
+- Documentation has been updated to include the `AWS Enterprise Accelerator" release.
+- With Python 2 far in the rearview mirror, the depedencies on the `six` python package have
+  been removed throughout the library, the distribution and all tasks images.
+
+## [1.10.0] - 2022-01-18
+
+### Python Versions Supported
+
+- Added support for Python 3.9.
+- Removed support for Python 3.6 which is now officially End Of Life.
+
+### Workflows
+- Added support for organizational sharing. You can now share using the `Organization` type:
+  - `workflows.add_reader(Organization("some_org"))`
+
+### Discover
+
+- Added support for organizational sharing. You can now share using the `Organization` type:
+  - `asset.share(with_=Organization("some_org"), as_="Viewer")`
+- Allow user to list their organization's namespace.
+  - `Discover().list_asset("asset/namespace/org:some_org")`
+- Allow user to list their organization's users.
+  - `Discover().list_org_users()`
+
+### Tables - Added
+- Added an **alpha** Tables client. The Tables module lets you organize, upload, and query tabular data and vector geometries. As an alpha release, we reserve the right to modify the Tables client API without any guarantees about backwards compatibility. See the [Tables API](https://docs.descarteslabs.com/descarteslabs/tables/readme.html) and [Tables Guide](https://docs.descarteslabs.com/guides/tables.html) documentation for more details.
+
+### Scenes
+- Added the `progress=` parameter to the various rastering methods such as `Scene.ndarray`,
+  `Scene.download`, `SceneCollection.mosaic`, `SceneCollection.stack`, `SceneCollection.download`
+  and `SceneCollection.download_mosaic`. This can be used to enable or disable the display
+  of progress bars.
+
+### Tasks images
+- Support for Python 3.9 images has been added, and support for Python 3.6 images has been removed.
+- Many of the add on packages have been upgraded to more recently released versions. In particular, `tensorflow` was updated from version 2.3 to version 2.7.
+- GPU support was bumped up from CUDA 10 to CUDA 11.2
+
 ## [1.9.1] - 2021-12-20
 
 ### Raster
 
 - Fixed a bug preventing retry-able errors (such as a 429) from being retried.
 
 ## [1.9.0] - 2021-11-09
@@ -41,15 +465,15 @@
 
 ### Tasks
 
 - Users can now use `descarteslabs.tasks.update_credentials()` to update their task credentials in case they became outdated.
 
 ### Workflows
 
-- We have introduced a hard limit of 120 as the number of outstanding Workflows compute jobs that a single user can have. This limit exists to minimize situations in which a user is unable to complete jobs in a timely manner by ensuring resources cannot be monopolized by any individual user. The API that backs the calls to `compute` will return a `descarteslabs.client.grpc.exceptions.ResourceExhausted` error if the caller has too many outstanding jobs. Prior to this release (1.9.0), these failures would be retried up to some small retry limit. With the latest client release however, the client will fail without retrying on an HTTP 429 (rate limit exceeded) error. For users with large (non-interactive) workloads who dont mind waiting, we added a new `num_retries` parameter to the `compute` function; when specified, the client will handle any 429 errors and retry up to `num_retries` times. 
+- We have introduced a hard limit of 120 as the number of outstanding Workflows compute jobs that a single user can have. This limit exists to minimize situations in which a user is unable to complete jobs in a timely manner by ensuring resources cannot be monopolized by any individual user. The API that backs the calls to `compute` will return a `descarteslabs.client.grpc.exceptions.ResourceExhausted` error if the caller has too many outstanding jobs. Prior to this release (1.9.0), these failures would be retried up to some small retry limit. With the latest client release however, the client will fail without retrying on an HTTP 429 (rate limit exceeded) error. For users with large (non-interactive) workloads who dont mind waiting, we added a new `num_retries` parameter to the `compute` function; when specified, the client will handle any 429 errors and retry up to `num_retries` times.
 - Workflows is currently optimized for interactive use cases. If you are submitting large numbers of long-running Workflows compute jobs with `block=False`, you should consider using Tasks and Scenes rather than the Workflows API.
 - Removed `ResourceExhausted` exceptions from the list of exceptions we automatically catch and retry on for `compute` calls.
 
 ### Documentation
 
 - Lots of improvements, additions, and clarifications in the API documentation.
 
@@ -880,15 +1304,15 @@
 
 ## [0.5.0] - 2017-10-31
 ### Added
 - Blosc Support for raster array compression transport
 - Scrolling support for large metadata searches
 
 ### Changes
-- Offset keyword argument in metadata.search is deprecated. Please use the
+- Offset keyword argument in metadata.search has been deprecated. Please use the
 metadata.features for iterating over large search results
 
 ## [0.4.7] - 2017-10-09
 ### Added
 - Complex filtering expressions for image attributes
 
 ### Fixes
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/attributes.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/attributes.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,32 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import numbers
 import re
 
 from collections.abc import Iterable, Mapping, MutableMapping, MutableSequence
 from datetime import datetime
 from enum import Enum
+
+from strenum import StrEnum
 from pytz import utc
 
-from descarteslabs.common.shapely_support import (
+from ..common.shapely_support import (
     geometry_like_to_shapely,
     shapely_to_geojson,
 )
 
 
 def parse_iso_datetime(date_str):
     try:
@@ -41,15 +57,15 @@
     This exception indicates that the attribute value may have been required, may be
     incorrect, or cannot be serialized.
     """
 
     pass
 
 
-class DocumentState(str, Enum):
+class DocumentState(StrEnum):
     """The state of the catalog object.
 
     Attributes
     ----------
     UNSAVED : enum
         The catalog object was never synchronized with the Descartes Labs catalog.
         All values are considered modified and saving the catalog object will create
@@ -81,14 +97,29 @@
 
     SAVED = "saved"
     MODIFIED = "modified"
     UNSAVED = "unsaved"
     DELETED = "deleted"
 
 
+class StorageState(StrEnum):
+    """The storage state for an image or blob.
+
+    Attributes
+    ----------
+    AVAILABLE : enum
+        The data has been uploaded and can be retrieved or rastered.
+    REMOTE : enum
+        The data is has not been uploaded, but its location is known.
+    """
+
+    AVAILABLE = "available"
+    REMOTE = "remote"
+
+
 class Attribute(object):
     """A description of an attribute as received from the Descartes Labs catalog or
     set by the end-user.
 
     Changing the value of an attribute will set the corresponding CatalogObject to
     modified.
 
@@ -290,15 +321,15 @@
         catalog.  Optionally indicates whether the data should be validated.
 
         Parameters
         ----------
         value : object
             Any Python object
         validate : bool
-            Whether or not the value should be validated.  This value is ``True`` be
+            Whether or not the value should be validated.  This value is ``True`` by
             default, and this method can raise an `AttributeValidationError` in that
             case.
 
         Returns
         -------
         object
             Any Python object.
@@ -352,16 +383,17 @@
 
     Parameters
     ----------
     reference_class : CatalogObject
         The class for the CatalogObject instance that this attribute will hold a
         reference to.
     require_unsaved : bool, optional
-        Whether the reference is allowed even if the CatalogObject instance is not in
-        the `SAVED` state.  ``False`` by default.
+        If ``True``, the referenced CatalogObject instance must be in the `UNSAVED` state
+        when assigned.  If ``False``, then the referenced CatalogOjbect must not be in the
+        `UNSAVED` state.  ``False`` by default.
     **kwargs : optional
         See `Attribute`.
     """
 
     def __init__(self, reference_class, require_unsaved=False, **kwargs):
         # Serializable defaults to `False` for reference objects
         kwargs[self._PARAM_SERIALIZABLE] = kwargs.pop(self._PARAM_SERIALIZABLE, False)
@@ -407,14 +439,16 @@
             instance is `DocumentState.UNSAVED` and `require_unsaved` is ``False``,
             or the referred-to instance not in `DocumentState.UNSAVED` and
             `require_unsaved` is ``True``
         """
         if validate:
             self._raise_if_immutable_or_readonly("set", obj)
 
+        value = self.deserialize(value, validate=validate)
+
         if value is not None:
             if not isinstance(value, self.reference_class):
                 raise AttributeValidationError(
                     "Expected {} instance for attribute '{}' but got '{}'".format(
                         self.reference_class.__name__, self._attribute_name, value
                     )
                 )
@@ -448,15 +482,83 @@
         return "{}_id".format(self._attribute_name)
 
     def serialize(self, value, jsonapi_format=False):
         """Serialize a value to a json-serializable type.
 
         See :meth:`Attribute.serialize`.
         """
-        return value.serialize(modified_only=False, jsonapi_format=jsonapi_format)
+        if hasattr(value, "serialize"):
+            return value.serialize(modified_only=False, jsonapi_format=jsonapi_format)
+        else:
+            return value
+
+    def deserialize(self, value, validate=True):
+        """Deserialize a value to a native type.
+
+        Deserializes a value for this attribute from a plain python type, possibly
+        generated through JSONAPI deserialization as it comes from the Descartes Labs
+        catalog.  Optionally indicates whether the data should be validated.
+
+        Parameters
+        ----------
+        value : object
+            Any Python object
+        validate : bool
+            Whether or not the value should be validated.  This value is ``True`` by
+            default, and this method can raise an `AttributeValidationError` in that
+            case.
+
+        Returns
+        -------
+        object
+            Any Python object.
+
+        Raises
+        ------
+        AttributeValidationError
+            When `validate` is ``True`` and a validation error was encountered.
+        """
+        if isinstance(value, self.reference_class):
+            return value
+
+        if (
+            type(value) is not dict
+            or "data" not in value
+            or "attributes" not in value["data"]
+        ):
+            raise AttributeValidationError(
+                "A CatalogObjectResource expects a {} or a JSONApi Resource object: {}".format(
+                    self.reference_class.__name__,
+                    self._attribute_name,
+                )
+            )
+
+        if value["data"]["type"] != self.reference_class._doc_type:
+            raise AttributeValidationError(
+                "CatalogObjectResource expects a doc type of {} but received {}: {}".format(
+                    self.reference_class._doc_type,
+                    value["type"],
+                    self._attribute_name,
+                )
+            )
+
+        # Note that the JSONAPI spec doesn't really allow nested resources. As such, we simply
+        # do not allow relationships at this level.
+        if "links" in value or "relationships" in value:
+            raise AttributeValidationError(
+                "A CatalogObjectResource does not support links or relationships: {}".format(
+                    self._attribute_name,
+                )
+            )
+
+        # we force unsaved state, as that is the only current use case, and because
+        # if it were a proper resource, it would have to be treated as a related object.
+        return self.reference_class(
+            _saved=False, id=value["data"].get("id"), **value["data"]["attributes"]
+        )
 
 
 class Timestamp(Attribute):
     """A datetime backed timestamp.  No validation is done."""
 
     def serialize(self, value, jsonapi_format=False):
         """Serialize a value to a json-serializable type.
@@ -505,16 +607,20 @@
     **kwargs : optional
         See `Attribute`.
     """
 
     def __init__(self, enum, **kwargs):
         super(EnumAttribute, self).__init__(**kwargs)
 
-        if not (issubclass(enum, str) and issubclass(enum, Enum)):
-            raise TypeError("EnumAttribute expects an 'Enum' with 'str' as mixin")
+        if not issubclass(enum, StrEnum) and (
+            not issubclass(enum, str) or not issubclass(enum, Enum)
+        ):
+            raise TypeError(
+                "EnumAttribute expects a 'StrEnum' or a 'str' and 'Enum' mixin"
+            )
         self._enum_cls = enum
 
     def serialize(self, value, jsonapi_format=False):
         """Serialize a value to a json-serializable type.
 
         See :meth:`Attribute.serialize`.
         """
@@ -750,14 +856,15 @@
 
 
 class AttributeMeta(type):
     """Apply the class attribute instances to the instance."""
 
     _KEY_ATTR_TYPES = "_attribute_types"
     _KEY_REF_ATTR_TYPES = "_reference_attribute_types"
+    _KEY_V1_PROPERTIES = "v1_properties"
 
     def __new__(cls, name, bases, attrs):
         types = {}
         references = {}
 
         # Register all declared attributes
         for attr_name, attr_type in attrs.items():
@@ -782,15 +889,17 @@
                             attrs[attr_name] = attr_type
             if hasattr(b, AttributeMeta._KEY_REF_ATTR_TYPES):
                 for attr_name, attr_type in b._reference_attribute_types.items():
                     # Don't overwrite existing reference attrs
                     if attr_name not in references:
                         references[attr_name] = attr_type
 
-        attrs["ATTRIBUTES"] = tuple(types.keys())
+        attrs["ATTRIBUTES"] = tuple(
+            k for k in types.keys() if k != AttributeMeta._KEY_V1_PROPERTIES
+        )
         attrs[AttributeMeta._KEY_ATTR_TYPES] = types
         attrs[AttributeMeta._KEY_REF_ATTR_TYPES] = references
 
         return super(AttributeMeta, cls).__new__(cls, name, bases, attrs)
 
 
 class MappingAttribute(ModelAttribute, AttributeEqualityMixin, metaclass=AttributeMeta):
@@ -911,16 +1020,18 @@
         """
         if attrs is None:
             return None
 
         if isinstance(attrs, MappingAttribute):
             # mapping attribute objects hold their own state
             data = attrs._attributes
-        else:
+        elif isinstance(attrs, Mapping):
             data = attrs
+        else:
+            return attrs
 
         serialized = {}
         for name, value in data.items():
             attribute_type = self.get_attribute_type(name)
             if attribute_type._serializable:
                 serialized[name] = attribute_type.serialize(value)
 
@@ -959,15 +1070,15 @@
                     self.__class__.__name__, self._attribute_name
                 )
             )
         type_ = type(self)
         return type_(validate=validate, **self._get_attr_params(**values))
 
 
-class ResolutionUnit(str, Enum):
+class ResolutionUnit(StrEnum):
     """Valid units of measure for Resolution.
 
     Attributes
     ----------
     METERS :  enum
         The resolution in meters.
     DEGREES : enum
@@ -1278,15 +1389,15 @@
 
         # ensures subclasses are handled correctly
         type_ = type(self)
         return type_(
             self._attribute_type,
             validate=validate,
             items=values,
-            **self._get_attr_params()
+            **self._get_attr_params(),
         )
 
     # MutableSequence methods
 
     def __getitem__(self, n):
         return self._items[n]
 
@@ -1404,15 +1515,15 @@
 
         if not isinstance(other, (self.__class__, Iterable)):
             return False
 
         if len(self) != len(other):
             return False
 
-        for (i1, i2) in zip(self, other):
+        for i1, i2 in zip(self, other):
             if i1 != i2:
                 return False
 
         return True
 
     def __ge__(self, other):
         if isinstance(other, self.__class__):
@@ -1629,15 +1740,15 @@
 
     def __init__(
         self,
         attribute_type=None,
         coerce=False,
         min_length=None,
         max_length=None,
-        **kwargs
+        **kwargs,
     ):
         super(TupleAttribute, self).__init__(**kwargs)
 
         self.attribute_type = attribute_type
         self.coerce = coerce
         self.min_length = None if min_length is None else int(min_length)
         self.max_length = None if max_length is None else int(max_length)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/band.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/band.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,28 @@
-from enum import Enum
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from collections.abc import Iterable, Mapping, MutableMapping
 
-from descarteslabs.common.property_filtering import GenericProperties
+from strenum import StrEnum
+
+from ..client.deprecation import deprecate
+from ..common.collection import Collection
+from ..common.property_filtering import Properties
 from .catalog_base import CatalogObject, _new_abstract_class
 from .named_catalog_base import NamedCatalogObject
 from .attributes import (
     Attribute,
     EnumAttribute,
     Resolution,
     BooleanAttribute,
@@ -14,18 +31,18 @@
     TypedAttribute,
     ModelAttribute,
     MappingAttribute,
     AttributeValidationError,
 )
 
 
-properties = GenericProperties()
+properties = Properties()
 
 
-class DataType(str, Enum):
+class DataType(StrEnum):
     """Valid data types for bands.
 
     Attributes
     ----------
     BYTE : enum
         An 8 bit unsigned integer value.
     UINT16 : enum
@@ -47,15 +64,15 @@
     INT16 = "Int16"
     UINT32 = "UInt32"
     INT32 = "Int32"
     FLOAT32 = "Float32"
     FLOAT64 = "Float64"
 
 
-class BandType(str, Enum):
+class BandType(StrEnum):
     """Types of bands with different data interpretation.
 
     The type of band is represented in the specific Band class being used
     and is only for informative purposes.
 
     Attributes
     ----------
@@ -76,15 +93,15 @@
     CLASS = "class"
     SPECTRAL = "spectral"
     MASK = "mask"
     MICROWAVE = "microwave"
     GENERIC = "generic"
 
 
-class Colormap(str, Enum):
+class Colormap(StrEnum):
     """Predefined colormaps available to assign to bands.
 
     Most of these colormaps correspond directly to the built-in colormaps of the
     same name in matplotlib. See
     https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html for an
     overview and visual examples.
 
@@ -143,19 +160,49 @@
     function : str
         Name of the processing function to apply. Required.
     parameter : str
         Name of the parameter in the image metadata containing
         the coefficients for the processing function. Required.
     index : int
         Optional index into the named parameter (an array) for the band.
+    data_type : str or DataType
+        Optional data type for pixel values in this band.
+    data_range : tuple(float, float)
+        Optional normal range of pixel values stored in the band.
+    display_range : tuple(float, float)
+        Optional normal range of pixel values stored in the band for display purposes.
+    physical_range : tuple(float, float)
+        Optional normal range of physical values stored in the band.
+    physical_range_unit : str
+        Optional unit of the physical range.
     """
 
     function = TypedAttribute(str)
     parameter = TypedAttribute(str)
     index = TypedAttribute(int)
+    data_type = EnumAttribute(DataType)
+    data_range = TupleAttribute(
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+    )
+    display_range = TupleAttribute(
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+    )
+    physical_range = TupleAttribute(
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+    )
+    physical_range_unit = Attribute()
 
 
 class ProcessingLevelsAttribute(ModelAttribute, MutableMapping):
     """An attribute that contains properties (key/value pairs).
 
     Can be set using a dictionary of items or any `Mapping`, or an instance of this
     attribute.  All keys must be string and values can be string or an iterable
@@ -418,41 +465,42 @@
       wavelength spectrum. Specific attributes:
       :attr:`~SpectralBand.physical_range`,
       :attr:`~SpectralBand.physical_range_unit`,
       :attr:`~SpectralBand.wavelength_nm_center`,
       :attr:`~SpectralBand.wavelength_nm_min`,
       :attr:`~SpectralBand.wavelength_nm_max`,
       :attr:`~SpectralBand.wavelength_nm_fwhm`,
-      :attr:`~descarteslabs.catalog.GenericBand.processing_levels`,
-      :attr:`~descarteslabs.catalog.GenericBand.derived_params`.
+      :attr:`~SpectralBand.processing_levels`,
+      :attr:`~SpectralBand.derived_params`.
     * `MicrowaveBand`: A band that lies in the microwave spectrum, often from SAR or
       passive radar sensors. Specific attributes:
       :attr:`~MicrowaveBand.frequency`,
       :attr:`~MicrowaveBand.bandwidth`,
       :attr:`~MicrowaveBand.physical_range`,
       :attr:`~MicrowaveBand.physical_range_unit`.
     * `MaskBand`: A binary band where by convention a 0 means masked and 1 means
       non-masked. The :attr:`~Band.data_range` and :attr:`~Band.display_range` for
       masks is implicitly ``[0, 1]``. Specific attributes:
       :attr:`~MaskBand.is_alpha`.
     * `ClassBand`: A band that maps a finite set of values that may not be continuous to
       classification categories (e.g. a land use classification). A visualization with
       straight pixel values is typically not useful, so commonly a
       :attr:`~ClassBand.colormap` is used. Specific attributes:
-      :attr:`~ClassBand.colormap`, :attr:`~ClassBand.colormap_name`,
+      :attr:`~ClassBand.colormap`,
+      :attr:`~ClassBand.colormap_name`,
       :attr:`~ClassBand.class_labels`.
     * `GenericBand`: A generic type for bands that are not represented by the other band
       types, e.g., mapping physical values like temperature or angles. Specific
       attributes:
       :attr:`~GenericBand.colormap`,
       :attr:`~GenericBand.colormap_name`,
       :attr:`~GenericBand.physical_range`,
       :attr:`~GenericBand.physical_range_unit`,
-      :attr:`~descarteslabs.catalog.GenericBand.processing_levels`,
-      :attr:`~descarteslabs.catalog.GenericBand.derived_params`.
+      :attr:`~GenericBand.processing_levels`,
+      :attr:`~GenericBand.derived_params`.
     """
 
     _DOC_DESCRIPTION = """A description with further details on the band.
 
         The description can be up to 80,000 characters and is used by
         :py:meth:`Search.find_text`.
 
@@ -481,14 +529,15 @@
         "tuple(float, float), optional: A physical range that pixel values map to."
     )
 
     _doc_type = "band"
     _url = "/bands"
     _derived_type_switch = "type"
     _default_includes = ["product"]
+    # _collection_type set below due to circular problems
 
     description = Attribute(doc="str, optional: " + _DOC_DESCRIPTION)
     type = EnumAttribute(
         BandType,
         doc="""str or BandType: The type of this band, directly corresponding to a `Band` derived class.
 
         The derived classes are `SpectralBand`, `MicrowaveBand`, `MaskBand`,
@@ -580,15 +629,15 @@
     def __init__(self, **kwargs):
         if self._derived_type_switch not in kwargs:
             kwargs[self._derived_type_switch] = self._derived_type
 
         super(Band, self).__init__(**kwargs)
 
     @classmethod
-    def search(cls, client=None):
+    def search(cls, client=None, request_params=None):
         """A search query for all bands.
 
         Returns an instance of the
         :py:class:`~descarteslabs.catalog.Search` class configured for
         searching bands.  Call this on the :py:class:`Band` base class to search all
         types of bands or classes :py:class:`SpectralBand`, :py:class:`MicrowaveBand`,
         :py:class:`MaskBand`, :py:class:`ClassBand` and :py:class:`GenericBand` to search
@@ -602,20 +651,28 @@
             catalog.
 
         Returns
         -------
         :py:class:`~descarteslabs.catalog.Search`
             An instance of the :py:class:`~descarteslabs.catalog.Search` class
         """
-        search = super(Band, cls).search(client)
+        search = super(Band, cls).search(client, request_params=request_params)
         if cls._derived_type:
             search = search.filter(properties.type == cls._derived_type)
         return search
 
 
+class BandCollection(Collection):
+    _item_type = Band
+
+
+# set here due to circular references
+Band._collection_type = BandCollection
+
+
 class SpectralBand(Band):
     """A band that lies somewhere on the visible/NIR/SWIR electro-optical wavelength spectrum.
 
     Instantiating a spectral band indicates that you want to create a *new* Descartes
     Labs catalog spectral band.  If you instead want to retrieve an existing catalog
     spectral band use `Band.get() <descarteslabs.catalog.Band.get>`, or if
     you're not sure use `SpectralBand.get_or_create()
@@ -634,15 +691,21 @@
         exception of properties (`ATTRIBUTES`, `is_modified`, and `state`), any
         attribute listed below can also be used as a keyword argument.  Also see
         `~SpectralBand.ATTRIBUTES`.
     """
 
     _derived_type = BandType.SPECTRAL.value
 
-    physical_range = Attribute(doc=Band._DOC_PHYSICALRANGE)
+    physical_range = TupleAttribute(
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+        doc=Band._DOC_PHYSICALRANGE,
+    )
     physical_range_unit = Attribute(doc="str, optional: Unit of the physical range.")
     wavelength_nm_center = Attribute(
         doc="""float, optional: Weighted center of min/max responsiveness of the band, in nm.
 
         *Filterable, sortable*.
         """
     )
@@ -700,15 +763,21 @@
     )
     bandwidth = Attribute(
         doc="""float, optional: Chirp bandwidth of the sensor in MHz.
 
         *Filterable, sortable*.
         """
     )
-    physical_range = Attribute(doc=Band._DOC_PHYSICALRANGE)
+    physical_range = TupleAttribute(
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+        doc=Band._DOC_PHYSICALRANGE,
+    )
     physical_range_unit = Attribute(doc="str, optional: Unit of the physical range.")
 
 
 class MaskBand(Band):
     """A binary band where by convention a 0 means masked and 1 means non-masked.
 
     The `data_range` and `display_range` for masks is implicitly ``(0, 1)``.
@@ -817,15 +886,21 @@
         exception of properties (`ATTRIBUTES`, `is_modified`, and `state`), any
         attribute listed below can also be used as a keyword argument.  Also see
         `~GenericBand.ATTRIBUTES`.
     """
 
     _derived_type = BandType.GENERIC.value
 
-    physical_range = Attribute(doc=Band._DOC_PHYSICALRANGE)
+    physical_range = TupleAttribute(
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+        doc=Band._DOC_PHYSICALRANGE,
+    )
     physical_range_unit = Attribute(doc="str, optional: Unit of the physical range.")
     colormap_name = EnumAttribute(Colormap, doc=Band._DOC_COLORMAPNAME)
     colormap = Attribute(doc=Band._DOC_COLORMAP)
 
 
 class DerivedBand(CatalogObject):
     """A band with pixel values computed from the data in other bands.
@@ -846,14 +921,15 @@
         be used if not set.
     kwargs : dict, optional
         You cannot set any additional keyword arguments as a derived band is readonly.
     """
 
     _doc_type = "derived_band"
     _url = "/derived_bands"
+    # _collection_type set below due to circular problems
 
     name = Attribute(
         readonly=True,
         doc="""str, readonly: The name of the derived band, globally unique.
 
         *Filterable, sortable*.
         """,
@@ -863,15 +939,22 @@
     )
     data_type = EnumAttribute(
         DataType, readonly=True, doc="str or DataType, readonly: " + Band._DOC_DATATYPE
     )
     data_range = Attribute(
         readonly=True, doc="tuple(float, float), readonly: " + Band._DOC_DATARANGE
     )
-    physical_range = Attribute(readonly=True, doc=Band._DOC_PHYSICALRANGE)
+    physical_range = TupleAttribute(
+        readonly=True,
+        min_length=2,
+        max_length=2,
+        coerce=True,
+        attribute_type=float,
+        doc=Band._DOC_PHYSICALRANGE,
+    )
     bands = Attribute(
         readonly=True,
         doc="""list(str), readonly: List of bands used in the derived band pixel function.
 
         *Filterable*
         """,
     )
@@ -886,15 +969,16 @@
         Raises
         ------
         NotImplementedError
             This method is not supported for DerivedBands.
         """
         raise NotImplementedError("Updating DerivedBands is not permitted")
 
-    def save(self):
+    @deprecate(renamed={"extra_attributes": "request_params"})
+    def save(self, request_params=None):
         """You cannot save a derived band.
 
         Raises
         ------
         NotImplementedError
             This method is not supported for DerivedBands.
         """
@@ -916,7 +1000,15 @@
 
         Raises
         ------
         NotImplementedError
             This method is not supported for DerivedBands.
         """
         raise NotImplementedError("Deleting DerivedBands is not permitted")
+
+
+class DerivedBandCollection(Collection):
+    _item_type = DerivedBand
+
+
+# set here due to circular references
+DerivedBand._collection_type = DerivedBandCollection
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/catalog_base.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/catalog_base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,42 @@
-from six import add_metaclass, iteritems, ensure_str, wraps
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from functools import wraps
 from types import MethodType
 import json
+import urllib.parse
 
-from descarteslabs.client.exceptions import NotFoundError
+from descarteslabs.exceptions import NotFoundError
+from ..client.deprecation import deprecate
+from ..common.collection import Collection
 from .attributes import (
     AttributeMeta,
     AttributeValidationError,
     AttributeEqualityMixin,
+    CatalogObjectReference,
     DocumentState,
     Timestamp,
     ListAttribute,
     ExtraPropertiesAttribute,
     TypedAttribute,
 )
 from .catalog_client import CatalogClient, HttpRequestMethod
+from .search import Search
 
 
 class DeletedObjectError(Exception):
     """Indicates that an action cannot be performed.
 
     Raised when some action cannot be performed because the catalog object
     has been deleted from the Descartes Labs catalog using the delete method
@@ -52,20 +71,20 @@
             ).with_traceback(e.__traceback__) from None
 
     return wrapper
 
 
 def check_derived(f):
     @wraps(f)
-    def wrapper(self, *args, **kwargs):
-        if self._url is None:
+    def wrapper(cls, *args, **kwargs):
+        if cls._url is None:
             raise TypeError(
                 "This method is only available for a derived class of 'CatalogObject'"
             )
-        return f(self, *args, **kwargs)
+        return f(cls, *args, **kwargs)
 
     return wrapper
 
 
 def _new_abstract_class(cls, abstract_cls):
     if cls is abstract_cls:
         raise TypeError(
@@ -96,16 +115,15 @@
         """
                 + new_cls._instance_delete.__doc__
             )
 
         return new_cls
 
 
-@add_metaclass(CatalogObjectMeta)
-class CatalogObjectBase(AttributeEqualityMixin):
+class CatalogObjectBase(AttributeEqualityMixin, metaclass=CatalogObjectMeta):
     """A base class for all representations of top level objects in the Catalog API."""
 
     # The following can be overridden by subclasses to customize behavior:
 
     # JSONAPI type for this model (required)
     _doc_type = None
 
@@ -119,14 +137,17 @@
     _derived_type = None
 
     # Attribute to use to determine the derived type of an instance
     _derived_type_switch = None
 
     _model_classes_by_type_and_derived_type = {}
 
+    # Type returned by collect() on the corresponding Search object
+    _collection_type = Collection
+
     id = TypedAttribute(
         str,
         mutable=False,
         serializable=False,
         doc="""str, immutable: A unique identifier for this object.
 
         Note that if you pass a string that does not begin with your Descartes Labs
@@ -145,14 +166,20 @@
     modified = Timestamp(
         readonly=True,
         doc="""datetime, readonly: The point in time this object was last modified.
 
         *Filterable, sortable*.
         """,
     )
+    v1_properties = TypedAttribute(
+        dict,
+        mutable=False,
+        serializable=False,
+        readonly=True,
+    )
 
     def __new__(cls, *args, **kwargs):
         return _new_abstract_class(cls, CatalogObjectBase)
 
     def __init__(self, **kwargs):
         self.delete = self._instance_delete
         self._client = kwargs.pop("client", None) or CatalogClient.get_default_client()
@@ -162,15 +189,15 @@
         self._deleted = False
 
         self._initialize(
             id=kwargs.pop("id", None),
             saved=kwargs.pop("_saved", False),
             relationships=kwargs.pop("_relationships", None),
             related_objects=kwargs.pop("_related_objects", None),
-            **kwargs
+            **kwargs,
         )
 
     def __del__(self):
         for attr_type in self._attribute_types.values():
             attr_type.__delete__(self, validate=False)
 
     def _clear_attributes(self):
@@ -188,35 +215,35 @@
     def _initialize(
         self,
         id=None,
         saved=False,
         relationships=None,
         related_objects=None,
         deleted=False,
-        **kwargs
+        **kwargs,
     ):
         self._clear_attributes()
         self._saved = saved
         self._deleted = deleted
 
         # This is an immutable attribute; can only be set once
         if id:
             self.id = id
 
-        for (name, val) in iteritems(kwargs):
+        for name, val in kwargs.items():
             # Only silently ignore unknown attributes if data came from service
             attribute_definition = (
                 self._attribute_types.get(name)
                 if saved
                 else self._get_attribute_type(name)
             )
             if attribute_definition is not None:
                 attribute_definition.__set__(self, val, validate=not saved)
 
-        for name, t in iteritems(self._reference_attribute_types):
+        for name, t in self._reference_attribute_types.items():
             id_value = kwargs.get(t.id_field)
             if id_value is not None:
                 object_value = kwargs.get(name)
                 if object_value and object_value.id != id_value:
                     message = (
                         "Conflicting related object reference: '{}' was '{}' "
                         "but '{}' was '{}'"
@@ -230,16 +257,19 @@
                     if related_object is not None:
                         t.__set__(self, related_object, validate=not saved)
 
         if saved:
             self._clear_modified_attributes()
 
     def __repr__(self):
-
-        name = ensure_str(self.name) if getattr(self, "name", None) is not None else ""
+        name = getattr(self, "name", None)
+        if name is None:
+            name = ""
+        elif isinstance(name, bytes):
+            name = name.decode()
 
         sections = [
             # Document type and ID
             "{}: {}\n  id: {}".format(self.__class__.__name__, name, self.id)
         ]
         # related objects and their ids
         for name in sorted(self._reference_attribute_types):
@@ -317,23 +347,42 @@
         Parameters
         ----------
         name : str
             The name of the attribute used for serialization logic.
         value : object
             The value to be serialized.
 
+        Returns
+        -------
+        name : str
+            The name to use in the serialized filter
+        value : str
+            The serialized value
+
         Raises
         ------
         AttributeValidationError
             If the attribute is not serializable.
         """
         attribute_type = cls._get_attribute_type(name)
+
         if isinstance(attribute_type, ListAttribute):
+            # The type is contained in the list
             attribute_type = attribute_type._attribute_type
-        return attribute_type.serialize(value)
+
+        if isinstance(attribute_type, CatalogObjectReference):
+            # This is a little tricky... If the value is an instance containing
+            # `id`, the name was already updated by the Expression to have `_id`
+            # appended to it, and the value will be converted to a string below.
+            # But if the value is a string, this hasn't happened yet and we need
+            # to update the name...
+            if value is None or isinstance(value, str):
+                return (attribute_type.id_field, value)
+
+        return (name, attribute_type.serialize(value))
 
     def _set_modified(self, attr_name, changed=True, validate=True):
         # Verify it is allowed to to be set
         attr = self._get_attribute_type(attr_name)
         if validate:
             if attr._readonly:
                 raise AttributeValidationError(
@@ -383,15 +432,15 @@
             If one or more of the attributes are not part of this catalog object.
         DeletedObjectError
             If this catalog object was deleted.
         """
         original_values = dict(self._attributes)
         original_modified = set(self._modified)
 
-        for (name, val) in iteritems(kwargs):
+        for name, val in kwargs.items():
             try:
                 # A non-existent attribute will raise an AttributeError
                 attribute_definition = self._get_attribute_type(name)
 
                 # A bad value will raise an AttributeValidationError
                 attribute_definition.__set__(self, val)
             except (AttributeError, AttributeValidationError):
@@ -440,15 +489,15 @@
             return DocumentState.UNSAVED
         elif self.is_modified:
             return DocumentState.MODIFIED
         else:
             return DocumentState.SAVED
 
     @classmethod
-    def get(cls, id, client=None):
+    def get(cls, id, client=None, request_params=None):
         """Get an existing object from the Descartes Labs catalog.
 
         If the Descartes Labs catalog object is found, it will be returned in the
         `~descarteslabs.catalog.DocumentState.SAVED` state.  Subsequent changes will
         put the instance in the `~descarteslabs.catalog.DocumentState.MODIFIED` state,
         and you can use :py:meth:`save` to commit those changes and update the Descartes
         Labs catalog object.  Also see the example for :py:meth:`save`.
@@ -471,36 +520,39 @@
         -------
         :py:class:`~descarteslabs.catalog.CatalogObject` or None
             The object you requested, or ``None`` if an object with the given `id`
             does not exist in the Descartes Labs catalog.
 
         Raises
         ------
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
         try:
             data, related_objects = cls._send_data(
-                method=HttpRequestMethod.GET, id=id, client=client
+                method=HttpRequestMethod.GET,
+                id=id,
+                client=client,
+                request_params=request_params,
             )
         except NotFoundError:
             return None
 
         model_class = cls._get_model_class(data)
         if not issubclass(model_class, cls):
             return None
 
         return model_class(
             id=data["id"],
             client=client,
             _saved=True,
             _relationships=data.get("relationships"),
             _related_objects=related_objects,
-            **data["attributes"]
+            **data["attributes"],
         )
 
     @classmethod
     def get_or_create(cls, id, client=None, **kwargs):
         """Get an existing object from the Descartes Labs catalog or create a new object.
 
         If the Descartes Labs catalog object is found, and the remainder of the
@@ -541,30 +593,30 @@
             obj = cls(id=id, client=client, **kwargs)
         else:
             obj.update(**kwargs)
 
         return obj
 
     @classmethod
-    def get_many(cls, ids, ignore_missing=False, client=None):
+    def get_many(cls, ids, ignore_missing=False, client=None, request_params=None):
         """Get existing objects from the Descartes Labs catalog.
 
         All returned Descartes Labs catalog objects will be in the
         `~descarteslabs.catalog.DocumentState.SAVED` state.  Also see :py:meth:`get`.
 
         For bands, if you request a specific band type, for example
         :meth:`SpectralBand.get_many`, you will only receive that type.  Use
         :meth:`Band.get_many` to receive any type.
 
         Parameters
         ----------
         ids : list(str)
             A list of identifiers for the objects you are requesting.
         ignore_missing : bool, optional
-            Whether to raise a `~descarteslabs.client.exceptions.NotFoundError`
+            Whether to raise a `~descarteslabs.exceptions.NotFoundError`
             exception if any of the requested objects are not found in the Descartes
             Labs catalog.  ``False`` by default which raises the exception.
         client : CatalogClient, optional
             A `CatalogClient` instance to use for requests to the Descartes Labs
             catalog.  The
             :py:meth:`~descarteslabs.catalog.CatalogClient.get_default_client` will
             be used if not set.
@@ -575,28 +627,29 @@
             List of the objects you requested in the same order.
 
         Raises
         ------
         NotFoundError
             If any of the requested objects do not exist in the Descartes Labs catalog
             and `ignore_missing` is ``False``.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
 
         if not isinstance(ids, list) or any(not isinstance(id_, str) for id_ in ids):
             raise TypeError("ids must be a list of strings")
 
         id_filter = {"name": "id", "op": "eq", "val": ids}
 
         raw_objects, related_objects = cls._send_data(
             method=HttpRequestMethod.PUT,
             client=client,
             json={"filter": json.dumps([id_filter], separators=(",", ":"))},
+            request_params=request_params,
         )
 
         if not ignore_missing:
             received_ids = set(obj["id"] for obj in raw_objects)
             missing_ids = set(ids) - received_ids
 
             if len(missing_ids) > 0:
@@ -607,15 +660,15 @@
         objects = [
             model_class(
                 id=obj["id"],
                 client=client,
                 _saved=True,
                 _relationships=obj.get("relationships"),
                 _related_objects=related_objects,
-                **obj["attributes"]
+                **obj["attributes"],
             )
             for obj in raw_objects
             for model_class in (cls._get_model_class(obj),)
             if issubclass(model_class, cls)
         ]
 
         return objects
@@ -639,30 +692,30 @@
         -------
         bool
             Returns ``True`` if the given ``id`` represents an existing object in
             the Descartes Labs catalog and ``False`` if not.
 
         Raises
         ------
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
         client = client or CatalogClient.get_default_client()
         r = None
         try:
             r = client.session.head(cls._url + "/" + id)
         except NotFoundError:
             return False
 
         return r and r.ok
 
     @classmethod
     @check_derived
-    def search(cls, client=None):
+    def search(cls, client=None, request_params=None):
         """A search query for all objects of the type this class represents.
 
         Parameters
         ----------
         client : CatalogClient, optional
             A `CatalogClient` instance to use for requests to the Descartes Labs
             catalog.  The
@@ -678,43 +731,42 @@
         Example
         -------
         >>> search = Product.search().limit(10) # doctest: +SKIP
         >>> for result in search: # doctest: +SKIP
                 print(result.name) # doctest: +SKIP
 
         """
-        from .search import Search
-
-        return Search(cls, client=client)
+        return Search(cls, client=client, request_params=request_params)
 
     @check_deleted
-    def save(self, extra_attributes=None):
+    @deprecate(renamed={"extra_attributes": "request_params"})
+    def save(self, request_params=None):
         """Saves this object to the Descartes Labs catalog.
 
         If this instance was created using the constructor, it will be in the
         `~descarteslabs.catalog.DocumentState.UNSAVED` state and is considered a new
         Descartes Labs catalog object that must be created.  If the catalog object
         already exists in this case, this method will raise a
-        `~descarteslabs.client.exceptions.BadRequestError`.
+        `~descarteslabs.exceptions.BadRequestError`.
 
         If this instance was retrieved using :py:meth:`get`, :py:meth:`get_or_create`
         or any other way (for example as part of a :py:meth:`search`), and any of its
         values were changed, it will be in the
         `~descarteslabs.catalog.DocumentState.MODIFIED` state and the existing catalog
         object will be updated.
 
         If this instance was retrieved using :py:meth:`get`, :py:meth:`get_or_create`
         or any other way (for example as part of a :py:meth:`search`), and none of its
         values were changed, it will be in the
-        `~descarteslabs.catalog.DocumentState.SAVED` state, and if no `extra_attributes`
+        `~descarteslabs.catalog.DocumentState.SAVED` state, and if no `request_params`
         parameter is given, nothing will happen.
 
         Parameters
         ----------
-        extra_attributes : dict, optional
+        request_params : dict, optional
             A dictionary of attributes that should be sent to the catalog along with
             attributes already set on this object.  Empty by default.  If not empty,
             and the object is in the `~descarteslabs.catalog.DocumentState.SAVED`
             state, it is updated in the Descartes Labs catalog even though no attributes
             were modified.
 
         Raises
@@ -722,15 +774,15 @@
         ConflictError
             If you're trying to create a new object and the object with given ``id``
             already exists in the Descartes Labs catalog.
         BadRequestError
             If any of the attribute values are invalid.
         DeletedObjectError
             If this catalog object was deleted.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> from descarteslabs.catalog import Product
         >>> new_product = Product(
@@ -758,42 +810,42 @@
         >>> # After you delete it...
         >>> existing_product.delete() # doctest: +SKIP
         True
         >>> product.state # doctest: +SKIP
         <DocumentState.DELETED: 'deleted'>
 
         """
-        if self.state == DocumentState.SAVED and not extra_attributes:
+        if self.state == DocumentState.SAVED and not request_params:
             # Noop, already saved in the catalog
             return
 
         if self.state == DocumentState.UNSAVED:
             method = HttpRequestMethod.POST
             json = self.serialize(modified_only=False, jsonapi_format=True)
         else:
             method = HttpRequestMethod.PATCH
             json = self.serialize(modified_only=True, jsonapi_format=True)
 
-        if extra_attributes:
-            json["data"]["attributes"].update(extra_attributes)
+        if request_params:
+            json["data"]["attributes"].update(request_params)
 
         data, related_objects = self._send_data(
             method=method, id=self.id, json=json, client=self._client
         )
 
         self._initialize(
             id=data["id"],
             saved=True,
             relationships=data.get("relationships"),
             related_objects=related_objects,
-            **data["attributes"]
+            **data["attributes"],
         )
 
     @check_deleted
-    def reload(self):
+    def reload(self, request_params=None):
         """Reload all attributes from the Descartes Labs catalog.
 
         Refresh the state of this catalog object from the object in the Descartes Labs
         catalog.  This may be necessary if there are concurrent updates and the object
         in the Descartes Labs catalog was updated from another client.  The instance
         state must be in the `~descarteslabs.catalog.DocumentState.SAVED` state.
 
@@ -802,15 +854,15 @@
 
         Raises
         ------
         ValueError
             If the catalog object is not in the ``SAVED`` state.
         DeletedObjectError
             If this catalog object was deleted.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> from descarteslabs.catalog import Product
         >>> p = Product(id="my_org_id:my_product_id")
@@ -818,15 +870,15 @@
         >>> p.state # doctest: +SKIP
         <DocumentState.SAVED: 'saved'>
         >>> p.reload() # doctest: +SKIP
         >>> # But once you make changes, you cannot use this method any more
         >>> p.name = "My name has changed"
         >>> p.reload() # doctest: +SKIP
         Traceback (most recent call last):
-            ...
+          ...
         ValueError: Product instance with id my_org_id:my_product_id has not been saved
         >>> # But you can revert
         >>> p = Product.get(p.id) # doctest: +SKIP
         >>> p.state # doctest: +SKIP
         <DocumentState.SAVED: 'saved'>
 
         """
@@ -835,24 +887,27 @@
             raise ValueError(
                 "{} instance with id {} has not been saved".format(
                     self.__class__.__name__, self.id
                 )
             )
 
         data, related_objects = self._send_data(
-            method=HttpRequestMethod.GET, id=self.id, client=self._client
+            method=HttpRequestMethod.GET,
+            id=self.id,
+            client=self._client,
+            request_params=request_params,
         )
 
         # this will effectively wipe all current state & caching
         self._initialize(
             id=data["id"],
             saved=True,
             relationships=data.get("relationships"),
             related_objects=related_objects,
-            **data["attributes"]
+            **data["attributes"],
         )
 
     @classmethod
     @check_derived
     def delete(cls, id, client=None):
         """Delete the catalog object with the given `id`.
 
@@ -872,15 +927,15 @@
             ``True`` if this object was successfully deleted. ``False`` if the
             object was not found.
 
         Raises
         ------
         ConflictError
             If the object has related objects (bands, images) that exist.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> Image.delete('my-image-id') # doctest: +SKIP
         """
@@ -902,36 +957,47 @@
 
         Raises
         ------
         DeletedObjectError
             If this catalog object was already deleted.
         UnsavedObjectError
             If this catalog object is being deleted without having been saved.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
         if self.state == DocumentState.UNSAVED:
             raise UnsavedObjectError("You cannot delete an unsaved object.")
 
         self._client.session.delete(self._url + "/" + self.id)
         self._deleted = True  # non-200 will raise an exception
 
     @classmethod
     @check_derived
-    def _send_data(cls, method, id=None, json=None, client=None):
+    def _send_data(cls, method, id=None, json=None, client=None, request_params=None):
         client = client or CatalogClient.get_default_client()
         session_method = getattr(client.session, method.lower())
         url = cls._url
 
+        query_params = {}
         if method not in (HttpRequestMethod.POST, HttpRequestMethod.PUT):
-            url += "/" + id
+            url += "/" + urllib.parse.quote(id)
+            if request_params:
+                query_params.update(**request_params)
+        elif request_params:
+            if json:
+                json = dict(**json, **request_params)
+            else:
+                json = dict(**request_params)
 
         if cls._default_includes:
-            url += "?include=" + ",".join(cls._default_includes)
+            query_params["include"] = ",".join(cls._default_includes)
+
+        if query_params:
+            url += "?" + urllib.parse.urlencode(query_params)
 
         r = session_method(url, json=json).json()
         data = r["data"]
         related_objects = cls._load_related_objects(r, client)
 
         return data, related_objects
 
@@ -943,52 +1009,24 @@
             for serialized in related_objects_serialized:
                 model_class = cls._get_model_class(serialized)
                 if model_class:
                     related = model_class(
                         id=serialized["id"],
                         client=client,
                         _saved=True,
-                        **serialized["attributes"]
+                        **serialized["attributes"],
                     )
                     related_objects[(serialized["type"], serialized["id"])] = related
 
         return related_objects
 
 
 class CatalogObject(CatalogObjectBase):
-    """A base class for all representations of objects in the Descartes Labs catalog.
-    """
-
-    owners = ListAttribute(
-        TypedAttribute(str),
-        doc="""list(str), optional: User, group, or organization IDs that own this object.
-
-        Defaults to [``user:current_user``, ``org:current_org``].  The owner can edit,
-        delete, and change access to this object.  :ref:`See this note <product_note>`.
+    """A base class for all representations of objects in the Descartes Labs catalog."""
 
-        *Filterable*.
-        """,
-    )
-    readers = ListAttribute(
-        TypedAttribute(str),
-        doc="""list(str), optional: User, group, or organization IDs that can read this object.
-
-        Will be empty by default.  This attribute is only available to the `owners`
-        of a catalog object.  :ref:`See this note <product_note>`.
-        """,
-    )
-    writers = ListAttribute(
-        TypedAttribute(str),
-        doc="""list(str), optional: User, group, or organization IDs that can edit this object.
-
-        Writers will also have read permission.  Writers will be empty by default.
-        See note below.  This attribute is only available to the `owners` of a catalog
-        object.  :ref:`See this note <product_note>`.
-        """,
-    )
     extra_properties = ExtraPropertiesAttribute(
         doc="""dict, optional: A dictionary of up to 50 key/value pairs.
 
         The keys of this dictonary must be strings, and the values of this dictionary
         can be strings or numbers.  This allows for more structured custom metadata
         to be associated with objects.
         """
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/image.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/blob.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,712 +1,823 @@
-from enum import Enum
-import os.path
-import six
-import io
-from tempfile import NamedTemporaryFile
-import warnings
-
-try:
-    import collections.abc as abc
-except ImportError:
-    import collections as abc
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
-import numpy as np
+import io
 
-from descarteslabs.common.property_filtering import GenericProperties
-from descarteslabs.client.services.service import ThirdPartyService
+from strenum import StrEnum
 
-from .catalog_base import DocumentState, check_deleted
-from .named_catalog_base import NamedCatalogObject
+from ..client.services.service import ThirdPartyService
+from ..common.collection import Collection
+from ..common.property_filtering import Properties
 from .attributes import (
+    DocumentState,
     EnumAttribute,
     GeometryAttribute,
-    Timestamp,
     ListAttribute,
-    File,
-    TupleAttribute,
+    StorageState,
+    Timestamp,
     TypedAttribute,
+    parse_iso_datetime,
+)
+from .blob_download import BlobDownload
+from .catalog_base import (
+    CatalogClient,
+    CatalogObject,
+    check_deleted,
 )
+from .search import AggregateDateField, GeoSearch, SummarySearchMixin
+
+
+properties = Properties()
 
-properties = GenericProperties()
 
+class StorageType(StrEnum):
+    """The storage type for a blob.
 
-class StorageState(str, Enum):
-    """The storage state for an image.
+    Attributes
+    ----------
+    COMPUTE : enum
+        Compute service job results.
+    DATA : enum
+        Arbitrary user-managed data. This type may be uploaded by users.
+    DYNCOMP : enum
+        Saved Dynamic Compute objects. This type may be uploaded by users.
+    LOGS : enum
+        Compute service job log output (text files).
+    """
+
+    COMPUTE = "compute"
+    DATA = "data"
+    DYNCOMP = "dyncomp"
+    LOGS = "logs"
+
+
+class BlobSummaryResult(object):
+    """
+    The readonly data returned by :py:meth:`SummaySearch.summary` or
+    :py:meth:`SummaySearch.summary_interval`.
 
     Attributes
     ----------
-    AVAILABLE : enum
-        The image data has been uploaded and can be rastered.
-    REMOTE : enum
-        The image data is has not been uploaded, but its location is known.
+    count : int
+        Number of blobs in the summary.
+    bytes : int
+        Total number of bytes of data across all blobs in the summary.
+    namespaces : list(str)
+        List of namespace IDs for the blobs included in the summary.
+    interval_start: datetime
+        For interval summaries only, a datetime representing the start of the interval period.
+
+    """
+
+    def __init__(
+        self, count=None, bytes=None, namespaces=None, interval_start=None, **kwargs
+    ):
+        self.count = count
+        self.bytes = bytes
+        self.namespaces = namespaces
+        self.interval_start = (
+            parse_iso_datetime(interval_start) if interval_start else None
+        )
+
+    def __repr__(self):
+        text = [
+            "\nSummary for {} blobs:".format(self.count),
+            " - Total bytes: {:,}".format(self.bytes),
+        ]
+        if self.namespaces:
+            text.append(" - Namespaces: {}".format(", ".join(self.namespaces)))
+        if self.interval_start:
+            text.append(" - Interval start: {}".format(self.interval_start))
+        return "\n".join(text)
+
+
+class BlobSearch(SummarySearchMixin, GeoSearch):
+    # Be aware that the `|` characters below add whitespace.  The first one is needed
+    # avoid the `Inheritance` section from appearing before the auto summary.
+    """A search request that iterates over its search results for blobs.
+
+    The `BlobSearch` is identical to `Search` but with a couple of summary methods:
+    :py:meth:`summary` and :py:meth:`summary_interval`.
     """
 
-    AVAILABLE = "available"
-    REMOTE = "remote"
+    SummaryResult = BlobSummaryResult
+    DEFAULT_AGGREGATE_DATE_FIELD = AggregateDateField.CREATED
+
 
+class Blob(CatalogObject):
+    """A stored blob (arbitrary bytes) that can be searched and retrieved.
 
-class Image(NamedCatalogObject):
-    """An image with raster data.
+    Instantiating a blob indicates that you want to create a *new* Descartes Labs
+    storage blob.  If you instead want to retrieve an existing blob use
+    `Blob.get() <descarteslabs.catalog.Blob.get>`.
+    You can also use `Blob.search() <descarteslabs.catalog.Blob.search>`.
+    Also see the example for :py:meth:`~descarteslabs.catalog.Blob.upload`.
 
-    Instantiating an image indicates that you want to create a *new* Descartes Labs
-    catalog image.  If you instead want to retrieve an existing catalog image use
-    `Image.get() <descarteslabs.catalog.Image.get>`, or if you're not sure use
-    `Image.get_or_create() <~descarteslabs.catalog.Image.get_or_create>`.  You
-    can also use `Image.search() <descarteslabs.catalog.Image.search>`.  Also
-    see the example for :py:meth:`~descarteslabs.catalog.Image.save`.
 
     Parameters
     ----------
     client : CatalogClient, optional
         A `CatalogClient` instance to use for requests to the Descartes Labs catalog.
         The :py:meth:`~descarteslabs.catalog.CatalogClient.get_default_client` will
         be used if not set.
     kwargs : dict
-        With the exception of readonly attributes (`created`, `modified`) and with the
-        exception of properties (`ATTRIBUTES`, `is_modified`, and `state`), any
+        With the exception of readonly attributes (`created`, `modified`) and with
+        the exception of properties (`ATTRIBUTES`, `is_modified`, and `state`), any
         attribute listed below can also be used as a keyword argument.  Also see
-        `~Image.ATTRIBUTES`.
-    """
+        `~Blob.ATTRIBUTES`.
 
-    _doc_type = "image"
-    _url = "/images"
-    _default_includes = ["product"]
-    _gcs_upload_service = ThirdPartyService()
 
-    # Geo referencing
-    geometry = GeometryAttribute(
-        doc="""str or shapely.geometry.base.BaseGeometry: Geometry representing the image coverage.
+    .. _blob_note:
 
-        *Filterable*
+    Note
+    ----
+    The ``reader`` and ``writer`` IDs must be prefixed with ``email:``, ``user:``,
+    ``group:`` or ``org:``.  The ``owner`` ID only accepts ``org:`` and ``user:``.
+    Using ``org:`` as an ``owner`` will assign those privileges only to administrators
+    for that organization; using ``org:`` as a ``reader`` or ``writer`` assigns those
+    privileges to everyone in that organization.  The `readers` and `writers` attributes
+    are only visible in full to the `owners`. If you are a `reader` or a `writer` those
+    attributes will only display the element of those lists by which you are gaining
+    read or write access.
+
+    Any user with ``owner`` privileges is able to read the blob attributes or data,
+    modify the blob attributes, or delete the blob, including reading and modifying the
+    ``owners``, ``writers``, and ``readers`` attributes.
+
+    Any user with ``writer`` privileges is able to read the blob attributes or data,
+    or modify the blob attributes, but not delete the blob. A ``writer`` can read the
+    ``owners`` and can only read the entry in the ``writers`` and/or ``readers``
+    by which they gain access to the blob.
+
+    Any user with ``reader`` privileges is able to read the blob attributes or data.
+    A ``reader`` can read the ``owners`` and can only read the entry
+    in the ``writers`` and/or ``readers`` by which they gain access to the blob.
 
-        (use :py:meth:`ImageSearch.intersects
-        <descarteslabs.catalog.ImageSearch.intersects>` to search based on geometry)
-        """
-    )
-    cs_code = TypedAttribute(
-        str,
-        doc="""str: The coordinate reference system used by the image as an EPSG or ESRI code.
+    Also see :doc:`Sharing Resources </guides/sharing>`.
+    """
 
-        An example of a EPSG code is ``"EPSG:4326"``.  One of `cs_code` and `projection`
-        is required.  If both are set and disagree, `cs_code` takes precedence.
-        """,
-    )
-    projection = TypedAttribute(
+    _doc_type = "storage"
+    _url = "/storage"
+    # _collection_type set below due to circular problems
+    _url_client = ThirdPartyService()
+
+    # Blob Attributes
+    namespace = TypedAttribute(
         str,
-        doc="""str: The spatial reference system used by the image.
+        doc="""str: The namespace of this blob.
 
-        The projection can be specified as either a proj.4 string or a a WKT string.
-        One of `cs_code` and `projection` is required.  If both are set and disagree,
-        `cs_code` takes precedence.
-        """,
-    )
-    geotrans = TupleAttribute(
-        min_length=6,
-        max_length=6,
-        coerce=True,
-        attribute_type=float,
-        doc="""tuple of six float elements, optional if `~StorageState.REMOTE`: GDAL-style geotransform matrix.
-
-        A GDAL-style `geotransform matrix
-        <https://gdal.org/user/raster_data_model.html#affine-geotransform>`_ that
-        transforms pixel coordinates into the spatial reference system defined by the
-        `cs_code` or `projection` attributes.
+        All blobs are stored and indexed under a namespace. Namespaces are allowed
+        a restricted alphabet (``a-zA-Z0-9:._-``), and must begin with the user's
+        org name, or their unique user hash if the user has no org. The required
+        prefix is seperated from the rest of the namespace name (if any) by a ``:``.
+        If not provided, the namespace will default to the users org (if any) and
+        the unique user hash. The combined length of the ``namespace`` and the
+        ``name`` cannot exceed 979 bytes.
+
+        *Searchable, sortable*.
         """,
     )
-    x_pixels = TypedAttribute(
-        int,
-        doc="int, optional if `~StorageState.REMOTE`: X dimension of the image in pixels.",
-    )
-    y_pixels = TypedAttribute(
-        int,
-        doc="int, optional if `~StorageState.REMOTE`: Y dimension of the image in pixels.",
-    )
-
-    # Time dimensions
-    acquired = Timestamp(
-        doc="""str or datetime: Timestamp when the image was captured by its sensor or created.
+    name = TypedAttribute(
+        str,
+        doc="""str: The name of this blob.
 
-        *Filterable, sortable*.
-        """
-    )
-    acquired_end = Timestamp(
-        doc="""str or datetime, optional: Timestamp when the image capture by its sensor was completed.
+        All blobs are stored and indexed by name. Names are allowed
+        a restricted alphabet (``a-zA-Z0-9:._/-``), but may not begin or end with a
+        ``/``. The combined length of the ``namespace`` and the ``name`` cannot exceed
+        979 bytes.
 
-        *Filterable, sortable*.
-        """
-    )
-    published = Timestamp(
-        doc="""str or datetime, optional: Timestamp when the data provider published this image.
+        The ``/`` is intended to be used like a directory in a pathname to allow for
+        prefix search operations, but otherwise has no special meaning.
 
-        *Filterable, sortable*.
-        """
+        *Searchable, sortable*.
+        """,
     )
-
-    # Stored files
     storage_state = EnumAttribute(
         StorageState,
-        doc="""str or StorageState: Storage state of the image.
+        doc="""str or StorageState: Storage state of the blob.
 
         The state is `~StorageState.AVAILABLE` if the data is available and can be
-        rastered, `~StorageState.REMOTE` if the data is not currently available.
+        retrieved, `~StorageState.REMOTE` if the data is not currently available.
 
         *Filterable, sortable*.
         """,
     )
-    files = ListAttribute(
-        File, doc="list(File): The list of files holding data for this image."
-    )
+    storage_type = EnumAttribute(
+        StorageType,
+        doc="""str or StorageType: Storage type of the blob.
 
-    # Image properties
-    area = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Surface area the image covers.
+        `~StorageType.DATA` is managed by end users (e.g. via
+        :py:meth:`descarteslabs.catalog.Blob.upload`.
+        Other types are generated and managed by various components of the platform.
 
         *Filterable, sortable*.
         """,
     )
-    azimuth_angle = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Sensor azimuth angle in degrees.
-
-        *Filterable, sortable*.
-        """,
-    )
-    bits_per_pixel = ListAttribute(
-        TypedAttribute(float, coerce=True),
-        doc="list(float), optional: Average bits of data per pixel per band.",
-    )
-    bright_fraction = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Fraction of the image that has reflectance greater than .4 in the blue band.
+    description = TypedAttribute(
+        str,
+        doc="""str, optional: A description with further details on this blob.
 
-        *Filterable, sortable*.
-        """,
-    )
-    brightness_temperature_k1_k2 = ListAttribute(
-        ListAttribute(TypedAttribute(float, coerce=True)),
-        doc="""list(list(float), optional: radiance to brightness temperature
-        conversion coefficients.
+        The description can be up to 80,000 characters and is used by
+        :py:meth:`Search.find_text`.
 
-        Outer list indexed by ``Band.vendor_order``, inner lists are ``[k1, k2]`` or
-        empty if not applicable.
+        *Searchable*
         """,
     )
-    c6s_dlsr = ListAttribute(
-        ListAttribute(TypedAttribute(float, coerce=True)),
-        doc="list(list(float), optional: DLSR conversion coefficients.",
-    )
-    cloud_fraction = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Fraction of pixels which are obscured by clouds.
+    geometry = GeometryAttribute(
+        doc="""str or shapely.geometry.base.BaseGeometry, optional: Geometry representing the location for the blob.
 
-        *Filterable, sortable*.
-        """,
-    )
-    confidence_dlsr = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Confidence value for DLSR coefficients.
+        *Filterable*
 
-        *Filterable, sortable*.
-        """,
+        (use :py:meth:`BlobSearch.intersects
+        <descarteslabs.catalog.BlobSearch.intersects>` to search based on geometry)
+        """
     )
-    alt_cloud_fraction = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Fraction of pixels which are obscured by clouds.
-
-        This is as per an alternative algorithm.  See the product documentation in the
-        `Descartes Labs catalog <catalog.descarteslabs.com>`_ for more information.
+    expires = Timestamp(
+        doc="""str or datetime, optional: Timestamp when the blob should be expired and deleted.
 
         *Filterable, sortable*.
-        """,
+        """
     )
-    processing_pipeline_id = TypedAttribute(
+    href = TypedAttribute(
         str,
-        doc="""str, optional: Identifier for the pipeline that processed this image from raw data.
+        doc="""str, optional: Storage location for the blob.
 
-        *Filterable, sortable*.
+        This attribute may not be set by the end user.
         """,
     )
-    fill_fraction = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Fraction of this image which has data.
+    size_bytes = TypedAttribute(
+        int,
+        doc="""int, optional: Size of the blob in bytes.
 
         *Filterable, sortable*.
         """,
     )
-    incidence_angle = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Sensor incidence angle in degrees.
-
-        *Filterable, sortable*.
-        """,
+    hash = TypedAttribute(
+        str, doc="""str, optional: Content hash (MD5) for the blob."""
     )
-    radiance_gain_bias = ListAttribute(
-        ListAttribute(TypedAttribute(float, coerce=True)),
-        doc="""list(list(float), optional: radiance conversion gain and bias.
+    owners = ListAttribute(
+        TypedAttribute(str),
+        doc="""list(str), optional: User, group, or organization IDs that own this blob.
 
-        Outer list indexed by ``Band.vendor_order``, inner lists are ``[gain, bias]`` or
-        empty if not applicable.
-        """,
-    )
-    reflectance_gain_bias = ListAttribute(
-        ListAttribute(TypedAttribute(float, coerce=True)),
-        doc="""list(list(float), optional: reflectance conversion gain and bias.
+        Defaults to [``user:current_user``, ``org:current_org``].  The owner can edit,
+        delete, and change access to this blob.  :ref:`See this note <blob_note>`.
 
-        Outer list indexed by ``Band.vendor_order``, inner lists are ``[gain, bias]`` or
-        empty if not applicable.
+        *Filterable*.
         """,
     )
-    reflectance_scale = ListAttribute(
-        TypedAttribute(float, coerce=True),
-        doc="list(float), optional: Scale factors converting TOA radiances to TOA reflectances.",
-    )
-    roll_angle = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Applicable only to Landsat 8, roll angle in degrees.
+    readers = ListAttribute(
+        TypedAttribute(str),
+        doc="""list(str), optional: User, email, group, or organization IDs that can read this blob.
 
-        *Filterable, sortable*.
+        Will be empty by default.  This attribute is only available in full to the `owners`
+        of the blob.  :ref:`See this note <blob_note>`.
         """,
     )
-    solar_azimuth_angle = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Solar azimuth angle at capture time.
+    writers = ListAttribute(
+        TypedAttribute(str),
+        doc="""list(str), optional: User, group, or organization IDs that can edit this blob.
 
-        *Filterable, sortable*.
+        Writers will also have read permission.  Writers will be empty by default.
+        See note below.  This attribute is only available in full to the `owners` of the blob.
+        :ref:`See this note <blob_note>`.
         """,
     )
-    solar_elevation_angle = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Solar elevation angle at capture time.
 
-        *Filterable, sortable*.
-        """,
-    )
-    temperature_gain_bias = ListAttribute(
-        ListAttribute(TypedAttribute(float, coerce=True)),
-        doc="""list(list(float), optional: surface temperature conversion coefficients.
+    @classmethod
+    def namespace_id(cls, namespace_id, client=None):
+        """Generate a fully namespaced id.
 
-        Outer list indexed by ``Band.vendor_order``, inner lists are ``[gain, bias]`` or
-        empty if not applicable.
-        """,
-    )
-    view_angle = TypedAttribute(
-        float,
-        coerce=True,
-        doc="""float, optional: Sensor view angle in degrees.
+        Parameters
+        ----------
+        namespace_id : str or None
+            The unprefixed part of the id that you want prefixed.
+        client : CatalogClient, optional
+            A `CatalogClient` instance to use for requests to the Descartes Labs
+            catalog.  The
+            :py:meth:`~descarteslabs.catalog.CatalogClient.get_default_client` will
+            be used if not set.
 
-        *Filterable, sortable*.
-        """,
-    )
-    satellite_id = TypedAttribute(
-        str,
-        doc="""str, optional: Id of the capturing satellite/sensor among a constellation of many satellites.
+        Returns
+        -------
+        str
+            The fully namespaced id.
 
-        *Filterable, sortable*.
-        """,
-    )
+        Example
+        -------
+        >>> namespace = Blob.namespace_id("myproject") # doctest: +SKIP
+        'myorg:myproject' # doctest: +SKIP
+        """
+        if client is None:
+            client = CatalogClient.get_default_client()
+        org = client.auth.payload.get("org")
+        namespace = client.auth.namespace
+
+        if not namespace_id:
+            if org:
+                return f"{org}:{namespace}"
+            else:
+                return namespace
+        elif org:
+            if namespace_id == org or namespace_id.startswith(org + ":"):
+                return namespace_id
+            else:
+                return f"{org}:{namespace_id}"
+        elif namespace_id == namespace or namespace_id.startswith(namespace + ":"):
+            return namespace_id
+        else:
+            return f"{namespace}:{namespace_id}"
 
-    # Provider info
-    provider_id = TypedAttribute(
-        str,
-        doc="""str, optional: Id that uniquely ties this image to an entity as understood by the data provider.
+    @classmethod
+    def get(
+        cls,
+        id=None,
+        storage_type=StorageType.DATA,
+        namespace=None,
+        name=None,
+        client=None,
+        request_params=None,
+    ):
+        """Get an existing Blob from the Descartes Labs catalog.
 
-        *Filterable, sortable*.
-        """,
-    )
-    provider_url = TypedAttribute(
-        str,
-        doc="str, optional: An external (http) URL that has more details about the image",
-    )
-    preview_url = TypedAttribute(
-        str,
-        doc="""str, optional: An external (http) URL to a preview image.
+        If the Blob is found, it will be returned in the
+        `~descarteslabs.catalog.DocumentState.SAVED` state.  Subsequent changes will
+        put the instance in the `~descarteslabs.catalog.DocumentState.MODIFIED` state,
+        and you can use :py:meth:`save` to commit those changes and update the Descartes
+        Labs catalog object.  Also see the example for :py:meth:`save`.
+
+        Exactly one of the ``id`` and ``name`` parameters must be specified. If ``name``
+        is specified, it is used together with the ``storage_type`` and ``namespace``
+        parameters to form the corresponding ``id``.
 
-        This image could be inlined in a UI to show a preview for the image.
-        """,
-    )
-    preview_file = TypedAttribute(
-        str,
-        doc="""str, optional: A GCS URL with a georeferenced image.
+        Parameters
+        ----------
+        id : str, optional
+            The id of the object you are requesting. Required unless ``name`` is supplied.
+        storage_type : StorageType, optional
+            The storage type of the Blob you wish to retrieve. Defaults to ``data``. Ignored
+            unless ``name`` is specified.
+        namespace : str, optional
+            The namespace of the Blob you wish to retrieve. Defaults to the user's org name
+            (if any) plus the unique user hash. Ignored unless ``name`` is specified.
+        name : str, optional
+            The name of the Blob you wish to retrieve. Required if ``id`` is not specified.
+            May not be specified if ``id`` is specified.
+        client : CatalogClient, optional
+            A `CatalogClient` instance to use for requests to the Descartes Labs
+            catalog.  The
+            :py:meth:`~descarteslabs.catalog.CatalogClient.get_default_client` will
+            be used if not set.
 
-        Use a GCS URL (``gs://...```) with appropriate access permissions.  This
-        referenced image can be used to raster the image in a preview context, generally
-        low resolution.  It should be a 3-band (RBG) or a 4-band (RGBA) image suitable
-        for visual preview.  (It's not expected to conform to the bands of the
-        products.)
-        """,
-    )
+        Returns
+        -------
+        :py:class:`~descarteslabs.catalog.CatalogObject` or None
+            The object you requested, or ``None`` if an object with the given `id`
+            does not exist in the Descartes Labs catalog.
 
-    SUPPORTED_DATATYPES = (
-        "uint8",
-        "int16",
-        "uint16",
-        "int32",
-        "uint32",
-        "float32",
-        "float64",
-    )
+        Raises
+        ------
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
+            :ref:`Spurious exception <network_exceptions>` that can occur during a
+            network request.
+        """
+        if (not id and not name) or (id and name):
+            raise TypeError("Must specify exactly one of id or name parameters")
+        if not id:
+            id = f"{storage_type}/{Blob.namespace_id(namespace)}/{name}"
+        return super(cls, Blob).get(id)
 
     @classmethod
-    def search(cls, client=None):
-        """A search query for all images.
+    def search(cls, client=None, request_params=None):
+        """A search query for all blobs.
 
-        Return an `~descarteslabs.catalog.ImageSearch` instance for searching
-        images in the Descartes Labs catalog.  This instance extends the
+        Return an `~descarteslabs.catalog.BlobSearch` instance for searching
+        blobs in the Descartes Labs catalog.  This instance extends the
         :py:class:`~descarteslabs.catalog.Search` class with the
-        :py:meth:`~descarteslabs.catalog.ImageSearch.summary` and
-        :py:meth:`~descarteslabs.catalog.ImageSearch.summary_interval` methods
-        which return summary statistics about the images that match the search query.
+        :py:meth:`~descarteslabs.catalog.BlobSearch.summary` and
+        :py:meth:`~descarteslabs.catalog.BlobSearch.summary_interval` methods
+        which return summary statistics about the blobs that match the search query.
 
         Parameters
         ----------
         client : :class:`CatalogClient`, optional
             A `CatalogClient` instance to use for requests to the Descartes Labs
             catalog.
 
         Returns
         -------
-        :class:`~descarteslabs.catalog.ImageSearch`
-            An instance of the `~descarteslabs.catalog.ImageSearch` class
+        :class:`~descarteslabs.catalog.BlobSearch`
+            An instance of the `~descarteslabs.catalog.BlobSearch` class
 
         Example
         -------
-        >>> from descarteslabs.catalog import Image
-        >>> search = Image.search().limit(10)
+        >>> from descarteslabs.catalog import Blob
+        >>> search = Blob.search().limit(10)
         >>> for result in search: # doctest: +SKIP
         ...     print(result.name) # doctest: +SKIP
 
         """
-        from .search import ImageSearch
-
-        return ImageSearch(cls, client=client)
+        return BlobSearch(cls, client=client, request_params=request_params)
 
     @check_deleted
-    def upload(self, files, upload_options=None, overwrite=False):
-        """Uploads imagery from a file (or files).
+    def upload(self, file):
+        """Uploads storage blob from a file.
 
-        Uploads imagery from a file (or files) in GeoTIFF or JP2 format to be ingested
-        as an Image.
+        Uploads data from a file and creates the Blob.
 
-        The Image must be in the state `~descarteslabs.catalog.DocumentState.UNSAVED`.
-        The `product` or `product_id` attribute, the `name` attribute, and the
-        `acquired` attribute must all be set. If either the `cs_code` or `projection`
-        attributes is set (deprecated), it must agree with the projection defined in the file,
-        otherwise an upload error will occur during processing.
+        The Blob must be in the state `~descarteslabs.catalog.DocumentState.UNSAVED`.
+        The `storage_state`, `storage_type`, `namespace`, and the `name` attributes,
+        must all be set. If either the `size_bytes` and the `hash` attributes are set,
+        they must agree with the actual file to be uploaded, and will be validated
+        during the upload process.
+
+        On return, the Blob object will be updated to reflect the full state of the
+        new blob.
 
         Parameters
         ----------
-        files : str or io.IOBase or iterable of same
+        file : str or io.IOBase
             File or files to be uploaded.  Can be string with path to the file in the
-            local filesystem, or an opened file (``io.IOBase``), or an iterable of
-            either of these when multiple files make up the image.
-        upload_options : `~descarteslabs.catalog.ImageUploadOptions`, optional
-            Control of the upload process.
-        overwrite : bool, optional
-            If True, then permit overwriting of an existing image with the same id
-            in the catalog. Defaults to False. Note that in all cases, the image
-            object must have a state of `~descarteslabs.catalog.DocumentState.UNSAVED`.
+            local filesystem, or a file-like object (``io.IOBase``). If a file like
+            object and already open, must be binary mode and readable. Open file-like
+            objects remain open on return and must be closed by the caller.
 
         Returns
         -------
-        :py:class:`~descarteslabs.catalog.ImageUpload`
-            An `~descarteslabs.catalog.ImageUpload` instance which can
-            be used to check the status or wait on the asynchronous upload process to
-            complete.
+        Blob
+            The uploaded instance.
 
         Raises
         ------
         ValueError
             If any improper arguments are supplied.
         DeletedObjectError
-            If this image was deleted.
+            If this blob was deleted.
         """
-        from .image_upload import ImageUploadType, ImageUploadOptions
-
-        if not self.id:
-            raise ValueError("id field required")
-        if not self.acquired:
-            raise ValueError("acquired field required")
-        if self.cs_code or self.projection:
-            warnings.warn("cs_code and projection fields not permitted", FutureWarning)
-            # raise ValueError("cs_code and projection fields not permitted")
+        self.namespace = self.__class__.namespace_id(self.namespace)
+        if not self.name:
+            raise ValueError("name field required")
+        if not self.storage_state:
+            self.storage_state = StorageState.AVAILABLE
+        if not self.storage_type:
+            self.storage_type = StorageType.DATA
 
         if self.state != DocumentState.UNSAVED:
             raise ValueError(
-                "Image {} has been saved. Please use an unsaved image for uploading".format(
+                "Blob {} has been saved. Please use an unsaved blob for uploading".format(
                     self.id
                 )
             )
 
-        if not overwrite and Image.exists(self.id):
+        if isinstance(file, str):
+            file = io.open(file, "rb")
+            close = True
+        elif isinstance(file, io.IOBase):
+            close = file.closed
+            if close:
+                file = io.open(file.name, "rb")
+            elif not file.readable() or "b" not in file.mode:
+                raise ValueError("Invalid file is open but not readable or binary mode")
+        else:
+            raise ValueError("Invalid file value: must be string or IOBase")
+
+        try:
+            return self._do_upload(file)
+        finally:
+            if close:
+                file.close()
+
+    @check_deleted
+    def upload_data(self, data):
+        """Uploads storage blob from a bytes or str.
+
+        Uploads data from a string or bytes and creates the Blob.
+
+        The Blob must be in the state `~descarteslabs.catalog.DocumentState.UNSAVED`.
+        The `storage_state`, `storage_type`, `namespace`, and the `name` attributes,
+        must all be set. If either the `size_bytes` and the `hash` attributes are set,
+        they must agree with the actual data to be uploaded, and will be validated
+        during the upload process.
+
+        On return, the Blob object will be updated to reflect the full state of the
+        new blob.
+
+        Parameters
+        ----------
+        data : str or bytes
+            Data to be uploaded. A str will be default encoded to bytes.
+
+        Returns
+        -------
+        Blob
+            The uploaded instance.
+
+        Raises
+        ------
+        ValueError
+            If any improper arguments are supplied.
+        DeletedObjectError
+            If this blob was deleted.
+        """
+        self.namespace = self.__class__.namespace_id(self.namespace)
+        if not self.name:
+            raise ValueError("name field required")
+        if not self.storage_state:
+            self.storage_state = StorageState.AVAILABLE
+        if not self.storage_type:
+            self.storage_type = StorageType.DATA
+
+        if self.state != DocumentState.UNSAVED:
             raise ValueError(
-                "Image {} already exists in the catalog. Please either use a new image id or overwrite=True".format(
+                "Blob {} has been saved. Please use an unsaved blob for uploading".format(
                     self.id
                 )
             )
 
-        if self.product.state != DocumentState.SAVED:
-            raise ValueError(
-                "Product {} has not been saved. Please save before uploading images".format(
-                    self.product_id
-                )
-            )
+        if isinstance(data, str):
+            data = data.encode()
+        elif not isinstance(data, bytes):
+            raise ValueError("Invalid data value: must be string or bytes")
+
+        return self._do_upload(data)
+
+    # the upload implementation is broken out so it can be used from multiple methods
+    def _do_upload(self, src):
+        # import here for circular dependency
+        from .blob_upload import BlobUpload
 
-        # convert file to a list, validating and extracting file names
-        if isinstance(files, six.string_types) or isinstance(files, io.IOBase):
-            files = [files]
-        elif not isinstance(files, abc.Iterable):
-            raise ValueError(
-                "Invalid files value: must be string, IOBase, or iterable of the same"
-            )
-        filenames = []
-        for f in files:
-            if isinstance(f, six.string_types):
-                filenames.append(f)
-            elif isinstance(f, io.IOBase):
-                filenames.append(f.name)
-            else:
-                raise ValueError(
-                    "Invalid files value: must be string, IOBase, or iterable of the same"
-                )
-        if not filenames:
-            raise ValueError("Invalid files value has zero length")
+        # Request an upload url
+        upload = BlobUpload(client=self._client, storage=self)
 
-        if not upload_options:
-            upload_options = ImageUploadOptions()
+        upload.save()
 
-        upload_options.upload_type = ImageUploadType.FILE
-        upload_options.image_files = filenames
+        headers = {}
+        headers["content-type"] = "application/octet-stream"
+        if upload.storage.size_bytes:
+            headers["content-length"] = str(upload.storage.size_bytes)
+
+        # This should work but it doesn't. The header must be the base64
+        # encoding of the 16 binary MD5 checksum bytes. But the value
+        # that is is checked against by S3 is the hex-ified version of the
+        # 16 binary bytes. So even though they mean the same thing,
+        # they miscompare at S3 and the file upload fails.
+        # if upload.storage.hash:
+        #     headers["content-md5"] = upload.storage.hash
+
+        # do the upload
+        self._url_client.session.put(upload.resumable_url, data=src, headers=headers)
+
+        # save the blob
+        upload.storage.save(request_params={"upload_signature": upload.signature})
+
+        # replenish our state, like reload but no need to go to server.
+        # this will effectively wipe all current state & caching.
+        self._initialize(
+            saved=True,
+            **upload.storage._attributes,
+        )
 
-        return self._do_upload(files, upload_options)
+        return self
 
     @check_deleted
-    def upload_ndarray(
-        self,
-        ndarray,
-        upload_options=None,
-        raster_meta=None,
-        overviews=None,
-        overview_resampler=None,
-        overwrite=False,
-    ):
-        """Uploads imagery from an ndarray to be ingested as an Image.
+    def download(self, file, range=None):
+        """Downloads storage blob to a file.
 
-        The Image must be in the state `~descarteslabs.catalog.DocumentState.UNSAVED`.
-        The `product` or `product_id` attribute, the `name` attribute, and the
-        `acquired` attribute must all be set. Either (but not both) the `cs_code`
-        or `projection` attributes must be set, or the `raster_meta` parameter must be provided.
-        Similarly, either the `geotrans` attribute must be set or `raster_meta` must be provided.
-
-        Note that one of the spatial reference attributes (`cs_code` or
-        `projection`), or the `geotrans` attribute can be
-        specified explicitly in the image, or the `raster_meta` parameter can be
-        specified.  Likewise, `overviews` and `overview_resampler` can be
-        specified explicitly, or via the `upload_options` parameter.
+        Downloads data from the blob to a file.
 
+        The Blob must be in the state `~descarteslabs.catalog.DocumentState.SAVED`.
 
         Parameters
         ----------
-        ndarray : np.array
-            A numpy array with image data, either with 2 dimensions of shape
-            ``(x, y)`` for a single band or with 3 dimensions of shape
-            ``(band, x, y)`` for any number of bands.  If providing a 3d array
-            the first dimension must index the bands.  The ``dtype`` of the array must
-            also be one of the following:
-            [``uint8``, ``int8``, ``uint16``, ``int16``, ``uint32``, ``int32``,
-            ``float32``, ``float64``]
-        upload_options : :py:class:`~descarteslabs.catalog.ImageUploadOptions`, optional
-            Control of the upload process.
-        raster_meta : dict, optional
-            Metadata returned from the :meth:`Raster.ndarray()
-            <descarteslabs.client.services.raster.Raster.ndarray>` request which
-            generated the initial data for the `ndarray` being uploaded.  Specifying
-            `geotrans` and one of the spatial reference attributes (`cs_code` or
-            `projection`) is unnecessary in this case but will take precedence over
-            the value in `raster_meta`.
-        overviews : list(int), optional
-            Overview resolution magnification factors e.g.  [2, 4] would make two
-            overviews at 2x and 4x the native resolution.  Maximum number of overviews
-            allowed is 16.  Can also be set in the `upload_options` parameter.
-        overview_resampler : str, optional
-            Resampler algorithm to use when building overviews.  Controls how pixels
-            are combined to make lower res pixels in overviews.  Allowed resampler
-            algorithms are: [``nearest``, ``average``, ``gauss``, ``cubic``,
-            ``cubicspline``, ``lanczos``, ``average_mp``, ``average_magphase``,
-            ``mode``].  Can also be set in the `upload_options` parameter.
-        overwrite : bool, optional
-            If True, then permit overwriting of an existing image with the same id
-            in the catalog. Defaults to False. Note that in all cases, the image
-            object must have a state of `~descarteslabs.catalog.DocumentState.UNSAVED`.
+        file : str or io.IOBase
+            File or files to be uploaded.  Can be string with path to the file in the
+            local filesystem, or an file opened for writing (``io.IOBase``). If a file like
+            object and already open, must be binary mode and writable. Open file-like
+            objects remain open on return and must be closed by the caller.
+        range : str or list, optional
+            Range(s) of blob to be downloaded. Can either be a string in the standard
+            HTTP Range header format (e.g. "bytes=0-99"), or a list or tuple containing
+            one or two integers (e.g. ``(0, 99)``), or a list or tuple of the same
+            (e.g. ``((0, 99), (200-299))``). A list or tuple of one integer implies
+            no upper bound; in this case the integer can be negative, indicating the
+            count back from the end of the blob.
+
+        Returns
+        -------
+        str
+            The name of the downloaded file.
 
         Raises
         ------
         ValueError
             If any improper arguments are supplied.
         DeletedObjectError
-            If this image was deleted.
+            If this blob was deleted.
+        """
+        if self.state != DocumentState.SAVED:
+            raise ValueError("Blob {} has not been saved".format(self.id))
+
+        if isinstance(file, str):
+            file = io.open(file, "wb")
+            close = True
+        elif isinstance(file, io.IOBase):
+            close = file.closed
+            if close:
+                file = io.open(file.name, "wb")
+            elif not file.writable() or "b" not in file.mode:
+                raise ValueError("Invalid file is open but not writable or binary mode")
+        else:
+            raise ValueError("Invalid file value: must be string or IOBase")
+
+        return self._do_download(dest=file, range=range)
+
+    @check_deleted
+    def data(self, range=None):
+        """Downloads storage blob data.
+
+        Downloads data from the blob and returns as a bytes object.
+
+        The Blob must be in the state `~descarteslabs.catalog.DocumentState.SAVED`.
+
+        Parameters
+        ----------
+        range : str or list, optional
+            Range(s) of blob to be downloaded. Can either be a string in the standard
+            HTTP Range header format (e.g. "bytes=0-99"), or a list or tuple containing
+            one or two integers (e.g. ``(0, 99)``), or a list or tuple of the same
+            (e.g. ``((0, 99), (200-299))``). A list or tuple of one integer implies
+            no upper bound; in this case the integer can be negative, indicating the
+            count back from the end of the blob.
 
         Returns
         -------
-        :py:class:`~descarteslabs.catalog.ImageUpload`
-            An `~descarteslabs.catalog.ImageUpload` instance which can
-            be used to check the status or wait on the asynchronous upload process to
-            complete.
-        """
-        from .image_upload import ImageUploadType, ImageUploadOptions
-
-        if not self.id:
-            raise ValueError("id field required")
-        if not self.acquired:
-            raise ValueError("acquired field required")
-        if self.cs_code and self.projection:
-            warnings.warn(
-                "Only one of cs_code and projection fields permitted", FutureWarning,
-            )
-            # raise ValueError("only one of cs_code and projection fields permitted")
-
-        if self.state != DocumentState.UNSAVED:
-            raise ValueError(
-                "Image {} has been saved. Please use an unsaved image for uploading".format(
-                    self.id
-                )
-            )
+        bytes
+            The data retrieved from the Blob.
 
-        if not overwrite and Image.exists(self.id):
-            raise ValueError(
-                "Image {} already exists in the catalog. Please either use a new image id or overwrite=True".format(
-                    self.id
-                )
-            )
+        Raises
+        ------
+        ValueError
+            If any improper arguments are supplied.
+        DeletedObjectError
+            If this blob was deleted.
+        """
+        if self.state != DocumentState.SAVED:
+            raise ValueError("Blob {} has not been saved".format(self.id))
 
-        if self.product.state != DocumentState.SAVED:
-            raise ValueError(
-                "Product {} has not been saved. Please save before uploading images".format(
-                    self.product_id
-                )
-            )
+        return self._do_download(range=range)
 
-        if len(ndarray.shape) not in (2, 3):
-            raise ValueError(
-                "The array must have 2 dimensions (shape '(x, y)') or 3 dimensions with the band "
-                "axis in the first dimension (shape '(band, x, y)'). The given array has shape "
-                "'{}' instead.".format(ndarray.shape)
-            )
+    @check_deleted
+    def iter_data(self, chunk_size=None, range=None):
+        """Downloads storage blob data.
 
-        if len(ndarray.shape) == 3:
-            scale_factor = 5
-            scaled_band_dim = ndarray.shape[0] * scale_factor
-            if scaled_band_dim > ndarray.shape[1] or scaled_band_dim > ndarray.shape[2]:
-                warnings.warn(
-                    "The shape '{}' of the given 3d-array looks like it might not have the band "
-                    "axis as the first dimension. Verify that your array conforms to the shape "
-                    "'(band, x, y)'".format(ndarray.shape)
-                )
-            # v1 ingest expects (X,Y,bands)
-            ndarray = np.moveaxis(ndarray, 0, -1)
+        Downloads data from the blob and returns as an iterator (generator)
+        which will yield the data (as a bytes) in chunks. This enables the
+        processing of very large files.
 
-        if ndarray.dtype.name not in self.SUPPORTED_DATATYPES:
-            raise ValueError(
-                "The array has an unsupported data type {}. Only the following data types are supported: {}".format(
-                    ndarray.dtype.name, ",".join(self.SUPPORTED_DATATYPES)
-                )
-            )
+        The Blob must be in the state `~descarteslabs.catalog.DocumentState.SAVED`.
 
-        # default to raster_meta fields if not explicitly provided
-        if raster_meta:
-            if not self.geotrans:
-                self.geotrans = raster_meta.get("geoTransform")
-            if not self.cs_code and not self.projection:
-                # doesn't yet exist!
-                self.projection = raster_meta.get("coordinateSystem", {}).get("proj4")
-
-        if not self.geotrans:
-            raise ValueError("geotrans field or raster_meta parameter is required")
-        if not self.cs_code and not self.projection:
-            raise ValueError(
-                "cs_code or projection field is required if "
-                + "raster_meta parameter is not given"
-            )
+        Parameters
+        ----------
+        chunk_size : int, optional
+            Size of chunks over which to iterate. Default is whatever size chunks
+            are received.
+        range : str or list, optional
+            Range(s) of blob to be downloaded. Can either be a string in the standard
+            HTTP Range header format (e.g. "bytes=0-99"), or a list or tuple containing
+            one or two integers (e.g. ``(0, 99)``), or a list or tuple of the same
+            (e.g. ``((0, 99), (200-299))``). A list or tuple of one integer implies
+            no upper bound; in this case the integer can be negative, indicating the
+            count back from the end of the blob.
 
-        if not upload_options:
-            upload_options = ImageUploadOptions()
-        upload_options.upload_type = ImageUploadType.NDARRAY
-        if overviews:
-            upload_options.overviews = overviews
-        if overview_resampler:
-            upload_options.overview_resampler = overview_resampler
+        Returns
+        -------
+        generator
+            An iterator over the blob data.
 
-        upload_options.upload_size = ndarray.nbytes
+        Raises
+        ------
+        ValueError
+            If any improper arguments are supplied.
+        DeletedObjectError
+            If this blob was deleted.
+        """
+        if self.state != DocumentState.SAVED:
+            raise ValueError("Blob {} has not been saved".format(self.id))
 
-        with NamedTemporaryFile(delete=False) as tmp:
+        def generator(response):
             try:
-                np.save(tmp, ndarray, allow_pickle=False)
-
-                # From tempfile docs:
-                # Whether the name can be used to open the file a second time,
-                # while the named temporary file is still open, varies across
-                # platforms (it can be so used on Unix; it cannot on Windows
-                # NT or later)
-                # We close the underlying file object so _do_upload can open
-                # the path again in a cross platform compatible way.
-                # Cleanup is manual in the finally block.
-                tmp.close()
-                upload_options.image_files = [tmp.name]
-                return self._do_upload([tmp.name], upload_options)
+                yield from response.iter_content(chunk_size)
             finally:
-                os.unlink(tmp.name)
+                response.close()
+
+        return self._do_download(dest=generator, range=range)
+
+    @check_deleted
+    def iter_lines(self, decode_unicode=False, delimiter=None):
+        """Downloads storage blob data.
+
+        Downloads data from the blob and returns as an iterator (generator)
+        which will yield the data as text lines.  This enables the
+        processing of very large files.
 
-    def image_uploads(self):
-        """A search query for all uploads for this image created by this user.
+        The Blob must be in the state `~descarteslabs.catalog.DocumentState.SAVED`.
+        The data within the blob must represent encoded text.
+
+        .. note:: This method is not reentrant safe.
+
+        Parameters
+        ----------
+        decode_unicode : bool, optional
+            If true, then decode unicode in the incoming data and return
+            strings. Default is to return bytes.
+        delimiter : str or byte, optional
+            Delimiter for lines. Type depends on setting of `decode_unicode`.
+            Default is to use default line break sequence.
 
         Returns
         -------
-        :py:class:`~descarteslabs.catalog.Search`
-            A :py:class:`~descarteslabs.catalog.Search` instance configured to
-            find all uploads for this image.
-        """
-        from .image_upload import ImageUpload
-
-        return ImageUpload.search(client=self._client).filter(
-            (properties.product_id == self.product_id)
-            & (properties.image_id == self.id)
-        )
+        generator
+            An iterator over the blob byte or text lines, depending on
+            value of `decode_unicode`.
+
+        Raises
+        ------
+        ValueError
+            If any improper arguments are supplied.
+        DeletedObjectError
+            If this blob was deleted.
+        """
+        if self.state != DocumentState.SAVED:
+            raise ValueError("Blob {} has not been saved".format(self.id))
 
-    def _do_upload(self, files, upload_options):
-        from .image_upload import ImageUpload, ImageUploadStatus
+        def generator(response):
+            if decode_unicode:
+                # response will always claim to be application/octet-stream
+                response.encoding = "utf-8"
+            try:
+                yield from response.iter_lines(
+                    decode_unicode=decode_unicode, delimiter=delimiter
+                )
+            finally:
+                response.close()
 
-        upload = ImageUpload(
-            client=self._client, image=self, image_upload_options=upload_options
-        )
+        return self._do_download(dest=generator)
 
-        upload.save()
+    def _do_download(self, dest=None, range=None):
+        download = BlobDownload.get(id=self.id, client=self._client)
 
-        for file, upload_url in zip(files, upload.resumable_urls):
-            if isinstance(file, io.IOBase):
-                if "b" not in file.mode:
-                    file.close()
-                    file = io.open(file.name, "rb")
-                f = file
+        headers = {}
+        if self.hash:
+            headers["if-match"] = self.hash
+        if range:
+            if isinstance(range, str):
+                range_str = range
+            elif isinstance(range, (list, tuple)) and all(
+                map(lambda x: isinstance(x, int), range)
+            ):
+                if len(range) == 1:
+                    range_str = f"bytes={range[0]}"
+                elif len(range) == 2:
+                    range_str = f"bytes={range[0]}-{range[1]}"
+                else:
+                    ValueError("invalid range value")
             else:
-                f = io.open(file, "rb")
+                ValueError("invalid range value")
 
+            headers["range"] = range_str
+
+        r = self._url_client.session.get(
+            download.resumable_url, headers=headers, stream=True
+        )
+        r.raise_for_status()
+        if callable(dest):
+            # generator will close response
+            return dest(r)
+        else:
             try:
-                self._gcs_upload_service.session.put(upload_url, data=f)
+                if dest is None:
+                    return r.raw.read()
+                else:
+                    for chunk in r.iter_content(1048576):
+                        dest.write(chunk)
+                    return dest.name
             finally:
-                f.close()
+                r.close()
+
+
+class BlobCollection(Collection):
+    _item_type = Blob
 
-        upload.status = ImageUploadStatus.PENDING
-        upload.save()
 
-        return upload
+# handle circular references
+Blob._collection_type = BlobCollection
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/image_upload.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/image_upload.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,32 +1,47 @@
-from enum import Enum
-import time
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from concurrent.futures import TimeoutError
 import itertools
-import urllib3.exceptions
 import requests.exceptions
+import time
+import urllib3.exceptions
 import warnings
 
-from descarteslabs.client.exceptions import ServerError
+from strenum import StrEnum
+
+from descarteslabs.exceptions import ServerError
 
 from .catalog_base import CatalogObjectBase, check_deleted
 from .attributes import (
     Attribute,
     CatalogObjectReference,
     Timestamp,
     EnumAttribute,
     MappingAttribute,
     ListAttribute,
     TypedAttribute,
 )
 from .image import Image
+from .search import Search
 
-from concurrent.futures import TimeoutError
 
-
-class ImageUploadType(str, Enum):
+class ImageUploadType(StrEnum):
     """The type of upload data.
 
     Attributes
     ----------
     NDARRAY : enum
         An multidimensional, homogeneous array of fixed-size items representing one
         or more images.
@@ -34,15 +49,15 @@
         A file on disk containing one or more images.
     """
 
     NDARRAY = "ndarray"
     FILE = "file"
 
 
-class OverviewResampler(str, Enum):
+class OverviewResampler(StrEnum):
     """Allowed overview resampler algorithms.
 
     Attributes
     ----------
     NEAREST : enum
         Applies a nearest neighbour (simple sampling) resampler
     AVERAGE : enum
@@ -72,15 +87,15 @@
     CUBICSPLINE = "cubicspline"
     LANCZOS = "lanczos"
     AVERAGE_MP = "average_mp"
     AVERAGE_MAGPHASE = "average_magphase"
     MODE = "mode"
 
 
-class ImageUploadStatus(str, Enum):
+class ImageUploadStatus(StrEnum):
     """The status of the image upload operation.
 
     Attributes
     ----------
     TRANSFERRING : enum
         Upload has been initiated and file(s) are being transfered from
         the client to the platform.
@@ -100,15 +115,15 @@
     PENDING = "pending"
     RUNNING = "running"
     SUCCESS = "success"
     FAILURE = "failure"
     CANCELED = "canceled"
 
 
-class ImageUploadEventType(str, Enum):
+class ImageUploadEventType(StrEnum):
     """The type of the image upload event.
 
     Attributes
     ----------
     QUEUE : enum
         The transfer of the file(s) was completed, and the upload processing
         request has been issued.
@@ -137,15 +152,15 @@
     COMPLETE = "complete"
     ERROR = "error"
     TIMEOUT = "timeout"
     LOG = "log"
     USAGE = "usage"
 
 
-class ImageUploadEventSeverity(str, Enum):
+class ImageUploadEventSeverity(StrEnum):
     """The severity of an image upload event.
 
     The severity values duplicate the standard python logging package
     level names and have the same meaning.
 
     Attributes
     ----------
@@ -402,16 +417,14 @@
         ...     properties as p,
         ... )
         >>> search = ImageUpload.search().filter(p.status == ImageUploadStatus.FAILURE)
         >>> for result in search: # doctest: +SKIP
         ...     print(result) # doctest: +SKIP
 
         """
-        from .search import Search
-
         return Search(cls, client=client, includes=includes)
 
     def wait_for_completion(self, timeout=None, warn_transient_errors=True):
         """Wait for the upload to complete.
 
         Parameters
         ----------
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/named_catalog_base.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/named_catalog_base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,7 +1,21 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import re
 
 from .attributes import AttributeValidationError, CatalogObjectReference, TypedAttribute
 from .catalog_base import CatalogObject, _new_abstract_class
 from .product import Product
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/product.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/product.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,34 +1,45 @@
-import six
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import time
-from enum import Enum
 from concurrent.futures import TimeoutError
 
-from descarteslabs.common.property_filtering import GenericProperties
-from .catalog_base import (
-    CatalogObject,
-    CatalogClient,
-    check_deleted,
-    _new_abstract_class,
-)
+from strenum import StrEnum
+
+from ..common.collection import Collection
+from ..common.property_filtering import Properties
 from .attributes import (
+    BooleanAttribute,
+    ListAttribute,
     Resolution,
     Timestamp,
-    BooleanAttribute,
     TypedAttribute,
-    ListAttribute,
 )
-
-try:
-    import collections.abc as abc
-except ImportError:
-    import collections as abc
+from .catalog_base import (
+    CatalogClient,
+    CatalogObject,
+    _new_abstract_class,
+    check_deleted,
+)
+from .search import Search
 
 
-properties = GenericProperties()
+properties = Properties()
 
 
 class Product(CatalogObject):
     """A raster product that connects band information to imagery.
 
     Instantiating a product indicates that you want to create a *new* Descartes Labs
     catalog product.  If you instead want to retrieve an existing catalog product use
@@ -57,21 +68,38 @@
     Note
     ----
     The ``reader`` and ``writer`` IDs must be prefixed with ``email:``, ``user:``,
     ``group:`` or ``org:``.  The ``owner`` ID only accepts ``org:`` and ``user:``.
     Using ``org:`` as an ``owner`` will assign those privileges only to administrators
     for that organization; using ``org:`` as a ``reader`` or ``writer`` assigns those
     privileges to everyone in that organization.  The `readers` and `writers` attributes
-    are only visible to the `owners`, you will not see them otherwise.
+    are only visible in full to the `owners`. If you are a `reader` or a `writer` those
+    attributes will only display the element of those lists by which you are gaining
+    read or write access.
+
+    Any user with ``owner`` privileges is able to read, modify, or delete the product,
+    including reading and modifying the ``owners``, ``writers``, and ``readers`` attributes.
+    Any user with ``owner`` privileges can also create, read, modify, or delete bands
+    and images for the product.
+
+    Any user with ``writer`` privileges is able to read or modify the product, but not
+    delete the product. A ``writer`` may create, read or modify bands and images for the
+    product. A ``writer`` can read the product ``owners`` and can only read the entry
+    in the ``writers`` and/or ``readers`` by which they gain access to the product.
+
+    Any user with ``reader`` privileges is able to read the product, bands, and images.
+    A ``reader`` can read the product ``owners`` and can only read the entry
+    in the ``writers`` and/or ``readers`` by which they gain access to the product.
 
-    Also see `Sharing Resources </guides/sharing.html>`_.
+    Also see :doc:`Sharing Resources </guides/sharing>`.
     """
 
     _doc_type = "product"
     _url = "/products"
+    # _collection_type set below due to circular problems
 
     # Product Attributes
     name = TypedAttribute(
         str,
         doc="""str: The name of this product.
 
         This should not be confused with a band name or image name.  Unlike the band
@@ -88,14 +116,41 @@
 
         The description can be up to 80,000 characters and is used by
         :py:meth:`Search.find_text`.
 
         *Searchable*
         """,
     )
+    owners = ListAttribute(
+        TypedAttribute(str),
+        doc="""list(str), optional: User, group, or organization IDs that own this product.
+
+        Defaults to [``user:current_user``, ``org:current_org``].  The owner can edit,
+        delete, and change access to this product.  :ref:`See this note <product_note>`.
+
+        *Filterable*.
+        """,
+    )
+    readers = ListAttribute(
+        TypedAttribute(str),
+        doc="""list(str), optional: User, email, group, or organization IDs that can read this product.
+
+        Will be empty by default.  This attribute is only available in full to the `owners`
+        of the product.  :ref:`See this note <product_note>`.
+        """,
+    )
+    writers = ListAttribute(
+        TypedAttribute(str),
+        doc="""list(str), optional: User, group, or organization IDs that can edit this product.
+
+        Writers will also have read permission.  Writers will be empty by default.
+        See note below.  This attribute is only available in full to the `owners` of the product.
+        :ref:`See this note <product_note>`.
+        """,
+    )
     is_core = BooleanAttribute(
         doc="""bool, optional: Whether this is a Descartes Labs catalog core product.
 
         A core product is a product that is fully supported by Descartes Labs.  By
         default this value is ``False`` and you must have a special permission
         (``descarteslabs:core:create``) to set it to ``True``.
 
@@ -161,14 +216,32 @@
         doc="""list(str) or iterable: Which bands to use for RGBA display.
 
         This field defines the default bands that are used for display purposes.  There are
         four supported formats: ``["greyscale-or-class"]``, ``["greyscale-or-class", "alpha"]``,
         ``["red", "green", "blue"]``, and ``["red", "green", "blue", "alpha"]``.
         """,
     )
+    image_index_name = TypedAttribute(
+        str,
+        doc="""str: The name of the image index for this product.
+
+        This is an internal field, accessible to privileged users only.
+
+        *Filterable, sortable*.
+        """,
+    )
+    product_tier = TypedAttribute(
+        str,
+        doc="""str: Product tier for this product.
+
+        This field can be set by privileged users only.
+
+        *Filterable, sortable*.
+        """,
+    )
 
     def named_id(self, name):
         """Return the ~descarteslabs.catalog.NamedCatalogObject.id` for the given named catalog object.
 
         Parameters
         ----------
         name : str
@@ -179,15 +252,15 @@
         -------
         str
             The named catalog object id within this product.
         """
         return "{}:{}".format(self.id, name)
 
     @check_deleted
-    def get_band(self, name, client=None):
+    def get_band(self, name, client=None, request_params=None):
         """Retrieve the request band associated with this product by name.
 
         Parameters
         ----------
         name : str
             The name of the band to retrieve.
         client : CatalogClient, optional
@@ -201,18 +274,20 @@
         Band or None
             A derived class of `Band` that represents the requested band object if
             found, ``None`` if not found.
 
         """
         from .band import Band
 
-        return Band.get(self.named_id(name))
+        return Band.get(
+            self.named_id(name), request_params=request_params, client=client
+        )
 
     @check_deleted
-    def get_image(self, name, client=None):
+    def get_image(self, name, client=None, request_params=None):
         """Retrieve the request image associated with this product by name.
 
         Parameters
         ----------
         name : str
             The name of the image to retrieve.
         client : CatalogClient, optional
@@ -225,15 +300,17 @@
         -------
         ~descarteslabs.catalog.Image or None
             The requested image if found, or ``None`` if not found.
 
         """
         from .image import Image
 
-        return Image.get(self.named_id(name))
+        return Image.get(
+            self.named_id(name), request_params=request_params, client=client
+        )
 
     @check_deleted
     def delete_related_objects(self):
         """Delete all related bands and images for this product.
 
         Starts an asynchronous operation that deletes all bands and images associated
         with this product. If the product has a large number of associated images, this
@@ -248,15 +325,15 @@
 
         Raises
         ------
         ConflictError
             If a deletion process is already in progress.
         DeletedObjectError
             If this product was deleted.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
         r = self._client.session.post(
             "/products/{}/delete_related_objects".format(self.id),
             json={"data": {"type": "product_delete_task"}},
         )
@@ -277,134 +354,28 @@
         -------
         DeletionTaskStatus
 
         Raises
         ------
         DeletedObjectError
             If this product was deleted.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
         r = self._client.session.get(
             "/products/{}/delete_related_objects".format(self.id)
         )
         response = r.json()
-        return DeletionTaskStatus(id=self.id, **response["data"]["attributes"])
-
-    @check_deleted
-    def update_related_objects_permissions(
-        self, owners=None, readers=None, writers=None, inherit=False
-    ):
-        """Update the owners, readers, and/or writers for all related bands and images.
-
-        Starts an asynchronous operation that updates the owners, readers, and/or
-        writers of all bands and images associated with this product. If the product
-        has a large number of associated images, this operation could take several
-        minutes, or even hours.
-
-        Parameters
-        ----------
-        owners : str or iterable(str), optional
-            An empty list, a single owner or a list of owners; see
-            `~CatalogObject.owners`.  If None, ignored.
-        readers : str or iterable(str), optional
-            An empty list, a single reader or a list of readers; see
-            `~CatalogObject.readers`.  If None, ignored.
-        writers : str or iterable(str), optional
-            An empty list, a single writer or a list of writers; see
-            `~CatalogObject.writers`.  If None, ignored.
-        inherit : bool, optional
-            Whether to inherit the values from the product for owners, readers, and/or
-            writers that have not been set in this request.  By default, this value
-            is ``False`` and if a parameter is not set, it will not change the
-            corresponding attribute in the related objects.  When set to ``True``, and
-            a parameter is not set, it is inherited from the product and applied to
-            all related objects.  If `inherit` is ``False``, at least one of the other
-            parameters must be given.  If `inherit` is ``True``, all other parameters
-            are optional.
-
-        Returns
-        -------
-        UpdatePermissionsTaskStatus
-            Returns :py:class:`UpdatePermissionsTaskStatus` if update task was
-            successfully started and ``None`` if there were no related objects
-            to update.
-
-        Raises
-        ------
-        ConflictError
-            If an update task is already in progress.
-        DeletedObjectError
-            If this product was deleted.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
-            :ref:`Spurious exception <network_exceptions>` that can occur during a
-            network request.
-        """
-        attributes = {"owners": owners, "readers": readers, "writers": writers}
-        for name, parameter in attributes.items():
-            if parameter is not None:
-                if isinstance(parameter, six.string_types):
-                    attributes[name] = [parameter]
-                elif isinstance(parameter, abc.Iterable) and all(
-                    isinstance(value, six.string_types) for value in parameter
-                ):
-                    attributes[name] = list(parameter)
-                else:
-                    raise TypeError(
-                        "{} must be a string or iterable of strings".format(name)
-                    )
-        attributes["inherit"] = inherit
-
-        r = self._client.session.post(
-            "/products/{}/update_related_objects_acls".format(self.id),
-            json={"data": {"type": "product_update_acls", "attributes": attributes}},
-        )
-        if r.status_code == 201:
-            response = r.json()
-            return UpdatePermissionsTaskStatus(
-                id=self.id, _client=self._client, **response["data"]["attributes"]
-            )
-
-    @check_deleted
-    def get_update_permissions_status(self):
-        """Fetches the status of an update task.
-
-        Fetches the status of an update task started using
-        :py:meth:`update_related_objects_permissions`.
-
-        Returns
-        -------
-        UpdatePermissionsTaskStatus
-
-        Raises
-        ------
-        DeletedObjectError
-            If this product was deleted.
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
-            :ref:`Spurious exception <network_exceptions>` that can occur during a
-            network request.
-
-        Example
-        -------
-        >>> product = Product.get('product-id') # doctest: +SKIP
-        >>> product.update_related_objects_permissions() # doctest: +SKIP
-        >>> product.get_update_permissions_status() # doctest: +SKIP
-
-        """
-        r = self._client.session.get(
-            "/products/{}/update_related_objects_acls".format(self.id)
-        )
-        response = r.json()
-        return UpdatePermissionsTaskStatus(
+        return DeletionTaskStatus(
             id=self.id, _client=self._client, **response["data"]["attributes"]
         )
 
     @check_deleted
-    def bands(self):
+    def bands(self, request_params=None):
         """A search query for all bands for this product, sorted by default band
         ``sort_order``.
 
         Returns
         -------
         :py:class:`~descarteslabs.catalog.Search`
             A :py:class:`~descarteslabs.catalog.Search` instance configured to
@@ -415,47 +386,47 @@
         DeletedObjectError
             If this product was deleted.
 
         """
         from .band import Band
 
         return (
-            Band.search(client=self._client)
+            Band.search(client=self._client, request_params=request_params)
             .filter(properties.product_id == self.id)
             .sort("sort_order")
         )
 
     @check_deleted
-    def derived_bands(self):
+    def derived_bands(self, request_params=None):
         """A search query for all derived bands associated with this product.
 
         Returns
         -------
         :py:class:`~descarteslabs.catalog.Search`
             A :py:class:`~descarteslabs.catalog.Search` instance configured to
             find all derived bands for this product.
 
         Raises
         ------
         DeletedObjectError
             If this product was deleted.
 
         """
-        from .search import Search
         from .band import DerivedBand
 
         return Search(
             DerivedBand,
             url="{}/{}/relationships/{}".format(self._url, self.id, "derived_bands"),
             client=self._client,
             includes=False,
+            request_params=request_params,
         )
 
     @check_deleted
-    def images(self):
+    def images(self, request_params=None):
         """A search query for all images in this product.
 
         Returns
         -------
         :py:class:`~descarteslabs.catalog.Search`
             A :py:class:`~descarteslabs.catalog.Search` instance configured to
             find all images in this product.
@@ -464,15 +435,15 @@
         ------
         DeletedObjectError
             If this product was deleted.
 
         """
         from .image import Image
 
-        return Image.search(client=self._client).filter(
+        return Image.search(client=self._client, request_params=request_params).filter(
             properties.product_id == self.id
         )
 
     @check_deleted
     def image_uploads(self):
         """A search query for all uploads in this product created by this user.
 
@@ -526,15 +497,23 @@
         prefix = "{}:".format(org)
         if id_.startswith(prefix):
             return id_
 
         return "{}{}".format(prefix, id_)
 
 
-class TaskState(str, Enum):
+class ProductCollection(Collection):
+    _item_type = Product
+
+
+# handle circular references
+Product._collection_type = ProductCollection
+
+
+class TaskState(StrEnum):
     """The state of a task.
 
     Attributes
     ----------
     NEVERRAN : enum
         The operation was never invoked.
     RUNNING : enum
@@ -601,24 +580,24 @@
         return "\n".join(text)
 
     def reload(self):
         """Update the task information.
 
         Raises
         ------
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
         """
         r = self._client.session.get(self._url.format(self.product_id))
         response = r.json()
         new_values = response["data"]["attributes"]
 
         self.status = TaskState(new_values.pop("status"))
-        for (key, value) in new_values.items():
+        for key, value in new_values.items():
             setattr(self, key, value)
 
     def wait_for_completion(self, timeout=None):
         """Wait for the task to complete.
 
         Parameters
         ----------
@@ -680,41 +659,7 @@
     def __repr__(self):
         text = super(DeletionTaskStatus, self).__repr__()
 
         if self.objects_deleted:
             text += "\n  - {:,} objects deleted".format(self.objects_deleted)
 
         return text
-
-
-class UpdatePermissionsTaskStatus(TaskStatus):
-    """The asynchronous task status for updating related objects' access control permissions
-
-    Attributes
-    ----------
-    product_id : str
-        The id of the product for which this task is running.
-    status : TaskState
-        The state of the task as explained in `TaskState`.
-    start_datetime : datetime
-        The date and time at which the task started running.
-    duration_in_seconds : float
-        The duration of the task.
-    objects_updated : int
-        The number of object (a combination of bands or images) that were updated.
-    errors: list
-        In case the status is ``FAILED`` this will contain a list of errors
-        that were encountered.  In all other states this will not be set.
-    """
-
-    _task_name = "update permissions task"
-    _url = "/products/{}/update_related_objects_acls"
-
-    def __init__(self, objects_updated=None, **kwargs):
-        super(UpdatePermissionsTaskStatus, self).__init__(**kwargs)
-        self.objects_updated = objects_updated
-
-    def __repr__(self):
-        text = super(UpdatePermissionsTaskStatus, self).__repr__()
-        if self.objects_updated:
-            text += "\n  - {:,} objects updated".format(self.objects_updated)
-        return text
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/search.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/search.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,36 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from collections.abc import Mapping
 import copy
 import json
 import warnings
 
-from enum import Enum
+from strenum import StrEnum
 
 from .catalog_client import CatalogClient
-from descarteslabs.common.property_filtering.filtering import AndExpression
-from descarteslabs.common.property_filtering.filtering import Expression  # noqa: F401
+from ..common.property_filtering.filtering import AndExpression
+from ..common.property_filtering.filtering import Expression  # noqa: F401
+
+from .attributes import serialize_datetime
 
-from .attributes import parse_iso_datetime, serialize_datetime
+
+V1_COMPATIBILITY = "v1_compatibility"
 
 
 class Search(object):
     """A search request that iterates over its search results.
 
     You can narrow your search by using the following methods on the search object:
 
@@ -23,28 +41,32 @@
     Each method on a search instance returns a narrowed-down search object.  You obtain
     a search instance using the search() method on a catalog object class, for example
     `Product.search() <descarteslabs.catalog.Product.search>`, `Band.search()
     <descarteslabs.catalog.Band>` or `Image.search() <descarteslabs.catalog.Image>`.
 
     You must use the `Search` object as an ``iterator`` to get the results.  This will
     execute the search query and return a generator for iterating through the returned
-    results.  This might raise a `~descarteslabs.client.exceptions.BadRequestError`
+    results.  This might raise a `~descarteslabs.exceptions.BadRequestError`
     if any of the query parameters or filters are invalid.
 
     Example
     -------
     >>> from descarteslabs.catalog import Product, Search, properties as p
     >>> search = Search(Product).filter(p.start_datetime >= "2012-01-01")
     >>> list(search) # doctest: +SKIP
     """
 
-    def __init__(self, model, client=None, url=None, includes=True):
+    def __init__(
+        self, model, client=None, url=None, includes=True, request_params=None
+    ):
         self._url = url or model._url
         self._model_cls = model
         self._request_params = {}
+        if request_params:
+            self._request_params.update(request_params)
 
         self._filter_properties = None
         self._client = client or CatalogClient.get_default_client()
         self._limit = None
         self._use_includes = includes
 
     def limit(self, limit):
@@ -66,15 +88,15 @@
 
         return s
 
     def sort(self, field, ascending=True):
         """Sort the returned results by the given field.
 
         Multiple sort fields are not supported, so
-        Successive calls to `sort` will overwrite the previous sort parameter.
+        successive calls to `sort` will overwrite the previous sort parameter.
 
         Parameters
         ----------
         field : str
             The name of the field to sort by
         ascending : bool
             Sorts results in ascending order if True and descending order if False.
@@ -102,15 +124,15 @@
         ``and`` Boolean operator (``&``).
 
         Parameters
         ----------
         properties : Expression
             Expression used to filter objects in the search by their properties, built
             from :class:`properties
-            <descarteslabs.common.property_filtering.filtering.GenericProperties>`.
+            <descarteslabs.common.property_filtering.filtering.Properties>`.
             You can construct filter expressions using the ``==``, ``!=``, ``<``,
             ``>``, ``<=`` and ``>=`` operators as well as the
             :meth:`~descarteslabs.common.property_filtering.filtering.Property.in_`
             or
             :meth:`~descarteslabs.common.property_filtering.filtering.Property.any_of`
             method.  You cannot use the boolean keywords ``and`` and ``or`` because
             of Python language limitations; instead combine filter expressions using
@@ -188,39 +210,72 @@
     def _to_request(self):
         s = copy.deepcopy(self)
 
         if self._limit is not None:
             s._request_params["limit"] = self._limit
 
         filters = s._serialize_filters()
+        self._require_product_ids(filters)
         if filters:
             # urlencode encodes spaces in the json object which create an invalid filter value when
             # the server tries to parse it, so we have to remove spaces prior to encoding.
             s._request_params["filter"] = json.dumps(filters, separators=(",", ":"))
 
         if self._use_includes and self._model_cls._default_includes:
             s._request_params["include"] = ",".join(self._model_cls._default_includes)
 
         return self._url, s._request_params
 
+    def _require_product_ids(self, filters):
+        from .product import Product
+        from .band import DerivedBand
+        from .blob import Blob
+
+        if self._model_cls in (Product, DerivedBand, Blob):
+            return
+        if filters:
+            for filter in filters:
+                # will be either a simple product_id eq filter,
+                # or an "or" of all of the same.
+                if "or" in filter:
+                    ors = filter["or"]
+                    if ors and all(
+                        map(
+                            lambda x: isinstance(x, Mapping)
+                            and x.get("name") == "product_id"
+                            and x.get("op") == "eq",
+                            ors,
+                        )
+                    ):
+                        return
+                elif (
+                    isinstance(filter, Mapping)
+                    and filter.get("name") == "product_id"
+                    and filter.get("op") == "eq"
+                ):
+                    return
+        raise ValueError(
+            f"{self._model_cls.__name__} search requires filtering by product_id"
+        )
+
     def count(self):
         """Fetch the number of documents that match the search.
 
         Note that this may not be an exact count if searching within a geometry.
 
         Returns
         -------
         int
             Number of matching records
 
         Raises
         ------
         BadRequestError
             If any of the query parameters or filters are invalid
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> from descarteslabs.catalog import Band, Search, properties as p
         >>> search = Search(Band).filter(p.type=="spectral")
@@ -230,28 +285,47 @@
         # modify query to return 0 results, and just get the object count
         s = self.limit(0)
         url, params = s._to_request()
         r = self._client.session.put(url, json=params)
         response = r.json()
         return response["meta"]["count"]
 
+    def collect(self, **kwargs):
+        """
+        Execute the search query and return the appropriate collection.
+
+        Returns
+        -------
+        ~descarteslabs.common.collection.Collection
+            Collection of objects that match the type of document beng searched.
+
+        Raises
+        ------
+        BadRequestError
+            If any of the query parameters or filters are invalid
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
+            :ref:`Spurious exception <network_exceptions>` that can occur during a
+            network request.
+        """
+        return self._model_cls._collection_type(self, **kwargs)
+
     def __iter__(self):
         """
         Execute the search query and get a generator for iterating through the returned results
 
         Returns
         -------
         generator
-            Generator of objects that match the type of document being searched. Empty if no matching images found.
+            Generator of objects that match the type of document being searched. Empty if no matching documents found.
 
         Raises
         ------
         BadRequestError
             If any of the query parameters or filters are invalid
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> from descarteslabs.catalog import Product, Search, properties as p
         >>> search = Search(Product).filter(p.tags == "test")
@@ -273,15 +347,15 @@
                 model_class = self._model_cls._get_model_class(doc)
                 yield model_class(
                     id=doc["id"],
                     client=self._client,
                     _saved=True,
                     _relationships=doc.get("relationships"),
                     _related_objects=related_objects,
-                    **doc["attributes"]
+                    **doc["attributes"],
                 )
 
             next_link = response["links"].get("next")
             if next_link is not None:
                 # The WrappedSession always prepends the base url, so we need to trim it from
                 # this URL.
                 if not next_link.startswith(self._client.base_url):
@@ -302,15 +376,15 @@
             if k in ["_client"]:
                 setattr(result, k, v)
             else:
                 setattr(result, k, copy.deepcopy(v, memo))
         return result
 
 
-class Interval(str, Enum):
+class Interval(StrEnum):
     """An interval for the :py:meth:`ImageSearch.summary_interval` method.
 
     Attributes
     ----------
     YEAR : enum
         Aggregate on a yearly basis
     QUARTER : enum
@@ -332,15 +406,15 @@
     MONTH = "month"
     WEEK = "week"
     DAY = "day"
     HOUR = "hour"
     MINUTE = "minute"
 
 
-class AggregateDateField(str, Enum):
+class AggregateDateField(StrEnum):
     """A date field to use for aggragation for the :py:meth:`ImageSearch.summary_interval` method.
 
 
     Attributes
     ----------
     ACQUIRED : enum
         Aggregate on the `Image.acquired` field.
@@ -354,50 +428,66 @@
 
     ACQUIRED = "acquired"
     CREATED = "created"
     MODIFIED = "modified"
     PUBLISHED = "published"
 
 
-class ImageSearch(Search):
-    # Be aware that the `|` characters below add whitespace.  The first one is needed
-    # avoid the `Inheritance` section from appearing before the auto summary.
-    """A search request that iterates over its search results for images.
-
-    The `ImageSearch` is identical to `Search` but with a couple of summary methods:
-    :py:meth:`summary` and :py:meth:`summary_interval`; and an additional method
-    :py:meth:`intersects` for geometry.
-    """
+class GeoSearch(Search):
+    """A search request that supports an :py:meth:`intersects` method for searching
+    geometries."""
 
-    _unsupported_summary_params = ["sort"]
+    def __init__(
+        self, model, client=None, url=None, includes=True, request_params=None
+    ):
+        super(GeoSearch, self).__init__(
+            model, client, url, includes, request_params=request_params
+        )
+        self._intersects = None
 
     def intersects(self, geometry):
-        """Filter images to those that intersect the given geometry.
+        """Filter images or blobs to those that intersect the given geometry.
 
         Successive calls to `intersects` override the previous intersection
         geometry.
 
         Parameters
         ----------
-        geometry : shapely.geometry.base.BaseGeometry, geojson-like
-            Geometry that found images must intersect.
+        geometry : shapely.geometry.base.BaseGeometry, ~descarteslabs.common.geo.GeoContext, geojson-like Geometry that found images must intersect.
 
         Returns
         -------
         Search
-            A new instance of the :py:class:`~descarteslabs.catalog.ImageSearch`
+            A new instance of the :py:class:`~descarteslabs.catalog.GeoSearch`
             class that includes geometry filter.
-        """
+        """  # noqa: E501
         s = copy.deepcopy(self)
+        name, value = self._model_cls._serialize_filter_attribute("geometry", geometry)
         s._request_params["intersects"] = json.dumps(
-            self._model_cls._serialize_filter_attribute("geometry", geometry),
+            value,
             separators=(",", ":"),
         )
+        s._intersects = copy.deepcopy(geometry)
         return s
 
+
+class SummarySearchMixin(Search):
+    # Be aware that the `|` characters below add whitespace.  The first one is needed
+    # avoid the `Inheritance` section from appearing before the auto summary.
+    """A search request that add support for summary methods.
+
+    The `SummarySearch` is identical to `Search` but with a couple of summary methods:
+    :py:meth:`summary` and :py:meth:`summary_interval`.
+    """
+
+    _unsupported_summary_params = ["sort"]
+    # must be set in derived class
+    SummaryResult = None
+    DEFAULT_AGGREGATE_DATE_FIELD = None
+
     def _summary_request(self):
         # don't modify existing search params
         params = copy.deepcopy(self._request_params)
 
         for p in self._unsupported_summary_params:
             params.pop(p, None)
 
@@ -406,24 +496,24 @@
             # urlencode encodes spaces in the json object which create an invalid filter value when
             # the server tries to parse it, so we have to remove spaces prior to encoding.
             params["filter"] = json.dumps(filters, separators=(",", ":"))
 
         return params
 
     def summary(self):
-        """Get summary statistics about the current `ImageSearch` query.
+        """Get summary statistics about the current `Search` query.
 
         Returns
         -------
         SummaryResult
             The summary statistics as a `SummaryResult` object.
 
         Raises
         ------
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> from descarteslabs.catalog import Image, properties as p
         >>> search = Image.search().filter(
@@ -435,33 +525,34 @@
 
         s = copy.deepcopy(self)
         summary_url = s._url + "/summary/all"
 
         r = self._client.session.put(summary_url, json=self._summary_request())
         response = r.json()
 
-        return SummaryResult(**response["data"]["attributes"])
+        return self.SummaryResult(**response["data"]["attributes"])
 
     def summary_interval(
         self,
-        aggregate_date_field="acquired",
+        aggregate_date_field=None,
         interval="year",
         start_datetime=None,
         end_datetime=None,
     ):
         """Get summary statistics by specified datetime intervals about the current `ImageSearch` query.
 
         Parameters
         ----------
 
         aggregate_date_field : str or AggregateDateField, optional
             The date field to use for aggregating summary results over time.  Valid
             inputs are `~AggregateDateField.ACQUIRED`, `~AggregateDateField.CREATED`,
             `~AggregateDateField.MODIFIED`, `~AggregateDateField.PUBLISHED`.  The
-            default is `~AggregateDateField.ACQUIRED`.
+            default is `~AggregateDateField.ACQUIRED`. Field must be defined for
+            the class.
         interval : str or Interval, optional
             The time interval to use for aggregating summary results.  Valid inputs
             are `~Interval.YEAR`, `~Interval.QUARTER`, `~Interval.MONTH`,
             `~Interval.WEEK`, `~Interval.DAY`, `~Interval.HOUR`, `~Interval.MINUTE`.
             The default is `~Interval.YEAR`.
         start_datetime : str or datetime, optional
             Beginning of the date range over which to summarize data in ISO format.
@@ -478,15 +569,15 @@
         -------
         list(SummaryResult)
             The summary statistics for each interval, as a list of `SummaryResult`
             objects.
 
         Raises
         ------
-        ~descarteslabs.client.exceptions.ClientError or ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ClientError or ~descarteslabs.exceptions.ServerError
             :ref:`Spurious exception <network_exceptions>` that can occur during a
             network request.
 
         Example
         -------
         >>> from descarteslabs.catalog import Image, AggregateDateField, Interval, properties
         >>> search = (
@@ -495,15 +586,17 @@
         ... )
         >>> interval_results = search.summary_interval(
         ...         aggregate_date_field=AggregateDateField.ACQUIRED, interval=Interval.MONTH
         ... ) # doctest: +SKIP
         >>> print([(i.interval_start, i.count) for i in interval_results]) # doctest: +SKIP
         """
         s = copy.deepcopy(self)
-        summary_url = "{}/summary/{}/{}".format(s._url, aggregate_date_field, interval)
+        summary_url = "{}/summary/{}/{}".format(
+            s._url, aggregate_date_field or self.DEFAULT_AGGREGATE_DATE_FIELD, interval
+        )
 
         # The service will calculate start/end if not given
         if start_datetime is not None:
             if start_datetime:
                 s._request_params["_start"] = serialize_datetime(start_datetime)
             else:
                 s._request_params["_start"] = ""  # Unbounded
@@ -513,48 +606,8 @@
                 s._request_params["_end"] = serialize_datetime(end_datetime)
             else:
                 s._request_params["_end"] = ""  # Unbounded
 
         r = self._client.session.put(summary_url, json=s._summary_request())
         response = r.json()
 
-        return [SummaryResult(**d["attributes"]) for d in response["data"]]
-
-
-class SummaryResult(object):
-    """
-    The readonly data returned by :py:meth:`ImageSearch.summary` or
-    :py:meth:`ImageSearch.summary_interval`.
-
-    Attributes
-    ----------
-    count : int
-        Number of images in the summary.
-    bytes : int
-        Total number of bytes of data across all images in the summary.
-    products : list(str)
-        List of IDs for the products included in the summary.
-    interval_start: datetime
-        For interval summaries only, a datetime representing the start of the interval period.
-
-    """
-
-    def __init__(
-        self, count=None, bytes=None, products=None, interval_start=None, **kwargs
-    ):
-        self.count = count
-        self.bytes = bytes
-        self.products = products
-        self.interval_start = (
-            parse_iso_datetime(interval_start) if interval_start else None
-        )
-
-    def __repr__(self):
-        text = [
-            "\nSummary for {} images:".format(self.count),
-            " - Total bytes: {:,}".format(self.bytes),
-        ]
-        if self.products:
-            text.append(" - Products: {}".format(", ".join(self.products)))
-        if self.interval_start:
-            text.append(" - Interval start: {}".format(self.interval_start))
-        return "\n".join(text)
+        return [self.SummaryResult(**d["attributes"]) for d in response["data"]]
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_attributes.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_attributes.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,30 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import pytest
 import unittest
 import textwrap
 from copy import deepcopy
 from datetime import datetime
 from enum import Enum
 
+from strenum import StrEnum
+
 from ..catalog_base import CatalogObject
 from ..attributes import (
     Attribute,
     TypedAttribute,
     Timestamp,
     EnumAttribute,
     utc,
@@ -19,24 +35,31 @@
     File,
     AttributeValidationError,
     ExtraPropertiesAttribute,
 )
 from ..band import BandType
 
 
-class CountToThree(str, Enum):
+class CountToThree(StrEnum):
+    ONE = "One"
+    TWO = "Two"
+    THREE = "Three"
+
+
+class CountToThreeOldStyle(str, Enum):
     ONE = "One"
     TWO = "Two"
     THREE = "Three"
 
 
 class Nested(MappingAttribute):
     foo = Attribute()
     dt = Timestamp(mutable=False)
     en = EnumAttribute(CountToThree)
+    old = EnumAttribute(CountToThreeOldStyle)
 
 
 class Mapping(MappingAttribute):
     bar = Attribute()
     nested = Nested()
 
 
@@ -268,15 +291,14 @@
         )
 
     def test_mapping_hash(self):
         with pytest.raises(TypeError):
             hash(Mapping())
 
     def test_list_attributes(self):
-
         nested1 = Nested(foo="zap", dt="2019-02-01T00:00:00.0000Z", validate=False)
         nested2 = Nested(foo="zip", dt="2019-02-02T00:00:00.0000Z", validate=False)
 
         mapping1 = Mapping(nested=nested1)
         mapping2 = Mapping(nested=nested2)
         model_object = FakeCatalogObject(
             id="id", listmapping=[mapping1, mapping2], listattribute=[12]
@@ -305,15 +327,16 @@
     def test_typed_list_attributes(self):
         model_object = FakeCatalogObject(id="id", typedlistattribute=["string"])
 
         assert model_object.typedlistattribute[0] == "string"
 
         with pytest.raises(AttributeValidationError):
             FakeCatalogObject(
-                id="id", typedlistattribute=[12],
+                id="id",
+                typedlistattribute=[12],
             )
 
     def test_listattribute_change_tracking(self):
         nested1 = Nested(foo="zap", dt="2019-02-01T00:00:00.0000Z", validate=False)
         nested2 = Nested(foo="zip", dt="2019-02-02T00:00:00.0000Z", validate=False)
         mapping1 = Mapping(nested=nested1)
         mapping2 = Mapping(nested=nested2)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_band.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_band.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,37 +1,54 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import pytest
 import responses
 import textwrap
 
-from descarteslabs.client.exceptions import NotFoundError
+from descarteslabs.exceptions import NotFoundError
+
+from ...common.property_filtering import Properties
 
 from .base import ClientTestCase
 from ..attributes import AttributeValidationError, DocumentState
 from ..band import (
     Band,
     MaskBand,
     SpectralBand,
     DerivedBand,
     GenericBand,
     MicrowaveBand,
     ProcessingStepAttribute,
     DerivedParamsAttribute,
+    DataType,
 )
 from ..product import Product
 
 
 class TestBand(ClientTestCase):
     def test_create(self):
         s = SpectralBand(
             name="test", product_id="foo", physical_range=[0, 1], wavelength_nm_max=1200
         )
         assert "foo:test" == s.id
         assert "spectral" == s.type
         assert 1200 == s.wavelength_nm_max
-        assert [0.0, 1.0] == s.physical_range
+        assert (0.0, 1.0) == s.physical_range
         with pytest.raises(AttributeError):
             s.frequency  # Attribute from a different band type
 
         s = SpectralBand(name="test", product=Product(id="foo", _saved=True))
         assert "foo:test" == s.id
         assert "foo" == s.product_id
         assert "product_id" in s._modified
@@ -74,17 +91,14 @@
     @responses.activate
     def test_get_subtype(self):
         self.mock_response(
             responses.GET,
             {
                 "data": {
                     "attributes": {
-                        "readers": [],
-                        "writers": [],
-                        "owners": ["org:descarteslabs"],
                         "modified": "2019-06-11T23:31:33.714883Z",
                         "created": "2019-06-11T23:31:33.714883Z",
                         "name": "blue",
                         "product_id": "p1",
                         "type": "spectral",
                         "physical_range": [0.0, 1.0],
                         "wavelength_nm_min": 2000,
@@ -97,15 +111,15 @@
                 ],
                 "jsonapi": {"version": "1.0"},
             },
         )
 
         b = Band.get("p1:blue", client=self.client)
         assert isinstance(b, SpectralBand)
-        assert [0.0, 1.0] == b.physical_range
+        assert (0.0, 1.0) == b.physical_range
         assert 2000 == b.wavelength_nm_min
         assert "P1" == b.product.name
 
         b_repr = repr(b)
         match_str = """\
             SpectralBand: blue
               id: p1:blue
@@ -122,32 +136,26 @@
         self.mock_response(
             responses.PUT,
             {
                 "meta": {"count": 2},
                 "data": [
                     {
                         "attributes": {
-                            "readers": [],
-                            "writers": [],
-                            "owners": ["org:descarteslabs"],
                             "modified": "2019-06-11T23:31:33.714883Z",
                             "created": "2019-06-11T23:31:33.714883Z",
                             "name": "blue",
                             "product_id": "p1",
                             "type": "spectral",
                             "wavelength_nm_min": 2000,
                         },
                         "type": "band",
                         "id": "p1:blue",
                     },
                     {
                         "attributes": {
-                            "readers": [],
-                            "writers": [],
-                            "owners": ["org:descarteslabs"],
                             "modified": "2019-06-11T23:31:33.714883Z",
                             "created": "2019-06-11T23:31:33.714883Z",
                             "name": "alpha",
                             "product_id": "p1",
                             "type": "mask",
                         },
                         "type": "band",
@@ -155,15 +163,17 @@
                     },
                 ],
                 "links": {"self": "https://www.example.com/catalog/v2/bands"},
                 "jsonapi": {"version": "1.0"},
             },
         )
 
-        results = list(Band.search(client=self.client))
+        results = list(
+            Band.search(client=self.client).filter(Properties().product_id == "p1")
+        )
         assert 2 == len(results)
         assert isinstance(results[0], SpectralBand)
         assert isinstance(results[1], MaskBand)
 
     def test_vendor_band_name(self):
         s = SpectralBand(
             name="test",
@@ -282,14 +292,51 @@
                 "default": "toa_reflectance",
                 "toa_reflectance": [
                     ProcessingStepAttribute(function="fun", parameter="param", index=0)
                 ],
             },
         )
 
+        b = SpectralBand(
+            id=band_id,
+            processing_levels={
+                "default": "toa_reflectance",
+                "toa_reflectance": [
+                    {
+                        "function": "fun",
+                        "parameter": "param",
+                        "index": 0,
+                        "data_type": "Float64",
+                        "data_range": [0, 1],
+                        "display_range": [0, 0.4],
+                        "physical_range": [0, 1],
+                        "physical_range_unit": "reflectance",
+                    }
+                ],
+            },
+        )
+        self.assertEqual(
+            b.processing_levels,
+            {
+                "default": "toa_reflectance",
+                "toa_reflectance": [
+                    ProcessingStepAttribute(
+                        function="fun",
+                        parameter="param",
+                        index=0,
+                        data_type=DataType("Float64"),
+                        data_range=(0.0, 1.0),
+                        display_range=(0, 0.4),
+                        physical_range=(0.0, 1.0),
+                        physical_range_unit="reflectance",
+                    )
+                ],
+            },
+        )
+
         with pytest.raises(AttributeValidationError):
             SpectralBand(id=band_id, processing_levels={"default": 1})
 
         with pytest.raises(AttributeValidationError):
             SpectralBand(id=band_id, processing_levels=[])
 
         with pytest.raises(AttributeValidationError):
@@ -371,17 +418,14 @@
         }
 
         self.mock_response(
             responses.POST,
             {
                 "data": {
                     "attributes": {
-                        "readers": [],
-                        "writers": [],
-                        "owners": ["org:descarteslabs"],
                         "modified": "2019-06-11T23:31:33.714883Z",
                         "created": "2019-06-11T23:31:33.714883Z",
                         "name": "band",
                         "product_id": "some_product_id",
                         "type": "spectral",
                         "processing_levels": pl,
                     },
@@ -499,17 +543,14 @@
         }
 
         self.mock_response(
             responses.POST,
             {
                 "data": {
                     "attributes": {
-                        "readers": [],
-                        "writers": [],
-                        "owners": ["org:descarteslabs"],
                         "modified": "2019-06-11T23:31:33.714883Z",
                         "created": "2019-06-11T23:31:33.714883Z",
                         "name": "band",
                         "product_id": "some_product_id",
                         "type": "spectral",
                         "derived_params": dp,
                     },
@@ -551,15 +592,14 @@
     @responses.activate
     def test_get(self):
         self.mock_response(
             responses.GET,
             {
                 "data": {
                     "attributes": {
-                        "owners": ["org:descarteslabs"],
                         "description": None,
                         "extra_properties": {},
                         "tags": None,
                         "bands": ["blue"],
                         "data_range": [0.0, 255.0],
                         "data_type": "Byte",
                         "physical_range": None,
@@ -582,15 +622,14 @@
         self.mock_response(
             responses.PUT,
             {
                 "meta": {"count": 5},
                 "data": [
                     {
                         "attributes": {
-                            "owners": ["org:descarteslabs"],
                             "description": None,
                             "extra_properties": {},
                             "tags": None,
                             "bands": ["blue"],
                             "data_range": [0.0, 255.0],
                             "data_type": "Byte",
                             "physical_range": None,
@@ -598,15 +637,14 @@
                             "name": "derived:prod1:alpha",
                         },
                         "type": "derived_band",
                         "id": "derived:prod1:alpha",
                     },
                     {
                         "attributes": {
-                            "owners": ["org:descarteslabs"],
                             "description": None,
                             "extra_properties": {},
                             "tags": None,
                             "bands": ["blue"],
                             "data_range": [0.0, 255.0],
                             "data_type": "Byte",
                             "physical_range": None,
@@ -663,33 +701,30 @@
                     "type": "band",
                     "attributes": {
                         "nodata": None,
                         "created": "2020-01-09T16:46:20.094904Z",
                         "data_type": "Float32",
                         "wavelength_nm_fwhm": None,
                         "type": "spectral",
-                        "readers": [],
                         "wavelength_nm_center": None,
                         "display_range": [0.0, 255.0],
                         "file_index": 0,
                         "jpx_layer_index": 0,
                         "tags": [],
                         "wavelength_nm_max": None,
                         "band_index": 0,
                         "wavelength_nm_min": None,
                         "sort_order": 1,
                         "extra_properties": {},
                         "modified": "2020-01-09T16:46:20.094904Z",
                         "name": "b1",
                         "product_id": "p1",
                         "description": None,
-                        "owners": ["org:descarteslabs", "user:someone"],
                         "data_range": [0.0, 1962239500502.9294],
                         "resolution": None,
-                        "writers": [],
                     },
                     "relationships": {
                         "product": {"data": {"type": "product", "id": "p1"}}
                     },
                     "id": "p1:b1",
                 },
                 "included": [
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_catalog_base.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_catalog_base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,27 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import pytest
 import responses
-from six import assertCountEqual
 from datetime import datetime
 from pytz import utc
 
-from descarteslabs.client.exceptions import (
+from descarteslabs.exceptions import (
     NotFoundError,
     BadRequestError,
     ConflictError,
 )
 
 from .base import ClientTestCase
 from ..attributes import (
@@ -61,29 +74,25 @@
             OriginalCatalogObject.get("foo")
 
         with pytest.raises(TypeError):
             OriginalCatalogObject.get_many(["foo"])
 
     def test_constructor(self):
         c = CatalogObject(id="id")
-        assertCountEqual(
-            self,
+        self.assertCountEqual(
             list(c._attribute_types.keys()),
             [
                 "id",
-                "owners",
-                "writers",
-                "readers",
                 "created",
                 "modified",
                 "extra_properties",
                 "tags",
+                "v1_properties",
             ],
         )
-        assert c.owners is None
         assert c.is_modified
 
     def test_constructor_no_id(self):
         c = CatalogObject()
         assert c.id is None
         c.id = "id"
         assert "id" == c.id
@@ -92,71 +101,65 @@
         with pytest.raises(AttributeValidationError):
             c.id = "oh no"
 
     def test_set_get(self):
         c = CatalogObject(id={})
         assert not c.is_modified
 
-        c.owners = ["user", "org"]
-        assert c.owners == ["user", "org"]
+        c.tags = ["foo", "bar"]
+        assert c.tags == ["foo", "bar"]
         assert c.is_modified
 
     def test_create_non_attr(self):
         with pytest.raises(AttributeError):
             CatalogObject(foo="bad")
 
     def test_set_non_attr(self):
         c = CatalogObject(id={})
 
         with pytest.raises(AttributeError):
             c.foo = "bad"
 
     def test_serialize(self):
-        c = CatalogObject(id="id", owners=["user", "org"], readers=["public"])
-        assert c.readers == ["public"]
+        c = CatalogObject(id="id", tags=["foo", "bar"])
+        assert c.tags == ["foo", "bar"]
         assert c.is_modified
-        assert {"id", "owners", "readers"} == c._modified
+        assert {"id", "tags"} == c._modified
 
-        self.assertDictEqual(
-            c.serialize(), dict(owners=["user", "org"], readers=["public"])
-        )
+        self.assertDictEqual(c.serialize(), dict(tags=["foo", "bar"]))
 
         self.assertDictEqual(
             c.serialize(jsonapi_format=True),
             dict(
                 data=dict(
                     id="id",
                     type=None,
-                    attributes=dict(owners=["user", "org"], readers=["public"]),
+                    attributes=dict(tags=["foo", "bar"]),
                 )
             ),
         )
 
     def test_clear_modified_attributes(self):
-        c = CatalogObject(
-            id="id", owners=["user", "org"], readers=["public"], _saved=True
-        )
+        c = CatalogObject(id="id", tags=["foo", "bar"], _saved=True)
         assert not c.is_modified
-        c.owners = ["org"]
+        c.tags = ["baz"]
         assert c.is_modified
-        assert c.serialize(modified_only=True) == {"owners": ["org"]}
+        assert c.serialize(modified_only=True) == {"tags": ["baz"]}
 
         c._clear_modified_attributes()
         assert not c.is_modified
 
     def test_list_properties(self):
-        c = CatalogObject(id="foo1", owners=["foo"], tags=["something"], _saved=True)
+        c = CatalogObject(id="foo1", tags=["something"], _saved=True)
         assert not c.is_modified
 
-        c.owners.append("bar")
         c.tags.append("nothing")
 
         assert c.is_modified
         assert c.serialize(modified_only=True) == {
-            "owners": ["foo", "bar"],
             "tags": ["something", "nothing"],
         }
 
     @responses.activate
     def test_get(self):
         self.mock_response(
             responses.GET,
@@ -243,51 +246,51 @@
 
         foo.reload()
         assert foo.id == "foo1"
         assert foo.bar == "qux"
         assert foo.state == DocumentState.SAVED
 
     @responses.activate
-    def test_save_extra_attributes(self):
+    def test_save_request_params(self):
         self.mock_response(
             responses.POST,
             {
                 "jsonapi": {"version": "1.0"},
                 "data": {
                     "type": Foo._doc_type,
                     "id": "foo1",
                     "attributes": {"bar": "baz", "foo": "bar"},
                 },
             },
         )
 
         foo = Foo(id="foo1", client=self.client)
         foo.bar = "baz"
-        foo.save(extra_attributes={"foo": "bar"})
+        foo.save(request_params={"foo": "bar"})
         assert foo.state == DocumentState.SAVED
 
         body = self.get_request_body(0)
         assert {"bar": "baz", "foo": "bar"} == body["data"]["attributes"]
 
     @responses.activate
-    def test_save_update_extra_attributes(self):
+    def test_save_update_request_params(self):
         self.mock_response(
             responses.PATCH,
             {
                 "jsonapi": {"version": "1.0"},
                 "data": {
                     "type": Foo._doc_type,
                     "id": "foo1",
                     "attributes": {"bar": "baz", "foo": "bar"},
                 },
             },
         )
 
         foo = Foo(id="foo1", bar="baz", client=self.client, _saved=True)
-        foo.save(extra_attributes={"foo": "bar"})
+        foo.save(request_params={"foo": "bar"})
         assert foo.state == DocumentState.SAVED
 
         body = self.get_request_body(0)
         assert {"foo": "bar"} == body["data"]["attributes"]
 
     def test_equality(self):
         assert Foo(id="foo2") != Foo(id="foo1")
@@ -403,70 +406,62 @@
             instance.reload()
 
     def test_update(self):
         c = CatalogObject()
         assert not c.is_modified
         assert c.state == DocumentState.UNSAVED
 
-        c.update(owners=["owner"], writers=["writer"], tags=["tag"])
-        assert c.owners == ["owner"]
-        assert c.writers == ["writer"]
-        assert c.readers is None
+        c.update(tags=["tag"])
         assert c.tags == ["tag"]
         assert c.is_modified
 
     def test_update_immutable_attr(self):
         timestamp = datetime.now(utc)
         c = CatalogObject(id="id", created=timestamp, _saved=True)
         assert not c.is_modified
         assert c.state == DocumentState.SAVED
 
         with pytest.raises(AttributeValidationError):
-            c.update(owners=["owner"], writers=["writer"], created=["created"])
+            c.update(created=["created"])
 
-        assert c.owners is None
-        assert c.writers is None
         assert c.created == timestamp
         assert not c.is_modified
         assert c.state == DocumentState.SAVED
 
     def test_update_non_attr(self):
         c = CatalogObject()
         assert not c.is_modified
 
         with pytest.raises(AttributeError):
-            c.update(owners=["owner"], writers=["writer"], foo=["bar"])
+            c.update(tags=["foo"], foo=["bar"])
 
-        assert c.owners is None
-        assert c.writers is None
+        assert c.tags is None
         with pytest.raises(AttributeError):
             c.foo
         assert not c.is_modified
 
     def test_update_bad_value(self):
         c = CatalogObject(id="id")
         assert c._modified == set(("id",))
 
         with pytest.raises(AttributeValidationError):
-            c.update(owners=["owner"], writers="writer")
+            c.update(tags=123)
 
         assert c.id == "id"
-        assert c.owners is None
-        assert c.writers is None
+        assert c.tags is None
         assert c._modified == set(("id",))
 
     def test_update_ignore_errors(self):
         c = CatalogObject(id="id")
         assert c._modified == set(("id",))
 
-        c.update(owners=["owner"], writers="writer", ignore_errors=True)
+        c.update(tags=123, ignore_errors=True)
         assert c.id == "id"
-        assert c.owners == ["owner"]
-        assert c.writers is None
-        assert c._modified == set(("id", "owners"))
+        assert c.tags is None
+        assert c._modified == set(("id",))
 
     @responses.activate
     def test_update_deleted_object(self):
         self.mock_response(
             responses.DELETE,
             {
                 "meta": {"message": "Object successfully deleted"},
@@ -474,15 +469,15 @@
             },
         )
 
         c = Foo(id="id", _saved=True, client=self.client)
         c.delete()
 
         with pytest.raises(DeletedObjectError):
-            c.update(owners=["owner"], writers="writer")
+            c.update(tags=["foo"])
 
     @responses.activate
     def test_rewritten_errors(self):
         title = "Validation error"
 
         self.mock_response(
             responses.POST,
@@ -506,20 +501,18 @@
             assert False
         except BadRequestError as error:
             assert str(error) == "\n    {}: {}".format(
                 title, "Missing data for required field: name"
             )
 
     def test_update_no_changes(self):
-        c = CatalogObject(
-            id="id", owners=["owner"], writers=["writer"], tags=["tag"], _saved=True
-        )
+        c = CatalogObject(id="id", tags=["tag"], _saved=True)
         assert not c.is_modified
 
-        c.update(owners=["owner"], writers=["writer"], tags=["tag"])
+        c.update(tags=["tag"])
         assert not c.is_modified
 
     @responses.activate
     def test_get_or_create(self):
         self.mock_response(responses.GET, self.not_found_json, status=404)
 
         foo = Foo.get("foo1", client=self.client)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_image.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_product.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,557 +1,442 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# -*- coding: utf-8 -*-
 import pytest
-import json
-from mock import patch
 import responses
 import textwrap
-import datetime
-from tempfile import NamedTemporaryFile
-import os.path
 import warnings
 
-import shapely.geometry
-
-from pytz import utc
-
-import numpy as np
+from datetime import datetime
 
-from descarteslabs.common.shapely_support import shapely_to_geojson
+from descarteslabs.exceptions import BadRequestError
 
-from .base import ClientTestCase
-from ..attributes import (
-    AttributeValidationError,
-    ListAttribute,
-    MappingAttribute,
-    DocumentState,
-)
-from ..image import Image
+from .. import properties
+from ..attributes import AttributeValidationError
+from ..band import DerivedBand
+from ..catalog_base import DocumentState, DeletedObjectError
 from ..image_upload import ImageUploadStatus
-from ..product import Product
+from ..product import (
+    Product,
+    Resolution,
+    TaskState,
+    TaskStatus,
+    DeletionTaskStatus,
+)
+from .base import ClientTestCase
+
 
+class TestProduct(ClientTestCase):
+    def test_constructor(self):
+        p = Product(
+            id="p1", name="Test Product", start_datetime="2019-01-01", tags=["tag"]
+        )
+        assert p.id == "p1"
+        assert p.name == "Test Product"
+        assert p.tags == ["tag"]
+        assert p.state == DocumentState.UNSAVED
+
+    def test_repr_non_ascii(self):
+        p = Product(id="plieades", name="Pliades")
+        p_repr = repr(p)
+        match_str = """\
+            Product: Pliades
+              id: plieades
+            * Not up-to-date in the Descartes Labs catalog. Call `.save()` to save or update this record."""
+        assert p_repr.strip("\n") == textwrap.dedent(match_str)
+
+    def test_resolution(self):
+        p = Product(
+            id="p1",
+            name="Test Product",
+            resolution_min=Resolution(value=10.0, unit="meters"),
+            _saved=True,
+        )
+
+        assert isinstance(p.resolution_min, Resolution)
+        assert not p.is_modified
+
+        p.tags = ["tag"]
+        assert p.is_modified
+
+    def test_resolution_new(self):
+        p = Product(
+            id="p1",
+            name="Test Product",
+            resolution_min={"value": 10.0, "unit": "miles"},
+            _saved=True,
+        )
 
-class TestImage(ClientTestCase):
-    geometry = {
-        "type": "Polygon",
-        "coordinates": [
-            [
-                [-9.000262842437783, 46.9537091787344],
-                [-8.325270159894608, 46.95172107428039],
-                [-8.336543403548475, 46.925857032669434],
-                [-8.39987774007129, 46.7807657614384],
-                [-8.463235968271405, 46.63558741606639],
-                [-8.75144712554016, 45.96528086358922],
-                [-9.0002581299532, 45.9655511480415],
-                [-9.000262842437783, 46.9537091787344],
-            ]
-        ],
-    }
+        assert p.resolution_min.unit == "miles"
+        with pytest.raises(AttributeValidationError):
+            Resolution(value=15.0, unit="miles")
 
     @responses.activate
-    def test_get(self):
+    def test_list(self):
         self.mock_response(
-            responses.GET,
+            responses.PUT,
             {
-                "data": {
-                    "attributes": {
-                        "readers": [],
-                        "writers": [],
-                        "owners": ["org:descarteslabs"],
-                        "modified": "2019-06-11T23:31:33.714883Z",
-                        "created": "2019-06-11T23:31:33.714883Z",
-                        "name": "myimage",
-                        "product_id": "p1",
-                        "geometry": self.geometry,
-                        "c6s_dlsr": [],
-                    },
-                    "type": "image",
-                    "id": "p1:myimage",
-                },
-                "included": [
-                    {"attributes": {"name": "A product"}, "type": "product", "id": "p1"}
+                "meta": {"count": 1},
+                "data": [
+                    {
+                        "attributes": {
+                            "owners": ["org:descarteslabs"],
+                            "name": "My Test Product",
+                            "readers": [],
+                            "revisit_period_minutes_min": None,
+                            "revisit_period_minutes_max": None,
+                            "modified": "2019-06-10T18:48:13.066192Z",
+                            "created": "2019-06-10T18:48:13.066192Z",
+                            "start_datetime": "2019-01-01T00:00:00Z",
+                            "writers": [],
+                            "end_datetime": None,
+                            "description": None,
+                            "resolution_min": {"value": 10.0, "unit": "meters"},
+                        },
+                        "type": "product",
+                        "id": "descarteslabs:test",
+                    }
                 ],
                 "jsonapi": {"version": "1.0"},
+                "links": {"self": "https://example.com/catalog/v2/products"},
             },
         )
 
-        i = Image.get("p1:myimage", client=self.client)
-        assert "p1" == i.product.id
-        assert shapely.geometry.shape(self.geometry) == i.geometry
+        r = list(Product.search(client=self.client))
+        assert len(r) == 1
+        product = r[0]
+        assert responses.calls[0].request.url == self.url + "/products"
+        assert product.id == "descarteslabs:test"
+        assert isinstance(product.created, datetime)
+        assert isinstance(product.resolution_min, Resolution)
 
-        i_repr = repr(i)
-        match_str = """\
-            Image: myimage
-              id: p1:myimage
-              product: p1
-              created: Tue Jun 11 23:31:33 2019"""  # noqa
-        assert i_repr.strip("\n") == textwrap.dedent(match_str)
-
-    def test_set_geometry(self):
-        shape = shapely.geometry.shape(self.geometry)
-        i = Image(name="myimage", product_id="p1")
-        i.geometry = self.geometry
-        assert shape == i.geometry
+        with pytest.raises(AttributeValidationError):
+            product.created = "2018-06-10T18:48:13.066192Z"
 
-        i.geometry = shape
-        assert shape == i.geometry
+        assert isinstance(product.start_datetime, datetime)
 
-        with pytest.raises(AttributeValidationError):
-            i.geometry = {"type": "Polygon"}
-        with pytest.raises(AttributeValidationError):
-            i.geometry = 2
+    @responses.activate
+    def test_list_no_results(self):
+        self.mock_response(
+            responses.PUT,
+            {
+                "meta": {"count": 0},
+                "data": [],
+                "jsonapi": {"version": "1.0"},
+                "links": {"self": "https://example.com/catalog/v2/products"},
+            },
+        )
 
-    def test_serialize_geometry(self):
-        i = Image(name="myimage", product_id="p1", geometry=self.geometry)
-        assert shapely_to_geojson(i.geometry) == i.serialize()["geometry"]
+        r = list(Product.search(client=self.client))
+        assert r == []
 
     @responses.activate
-    def test_nanosecond_timestamp(self):
+    def test_save(self):
         self.mock_response(
-            responses.GET,
+            responses.POST,
             {
                 "data": {
                     "attributes": {
+                        "owners": ["org:descarteslabs"],
+                        "name": "My Test Product",
                         "readers": [],
+                        "revisit_period_minutes_min": None,
+                        "revisit_period_minutes_max": None,
+                        "modified": "2019-06-10T18:48:13.066192Z",
+                        "created": "2019-06-10T18:48:13.066192Z",
+                        "start_datetime": "2019-01-01T00:00:00Z",
                         "writers": [],
-                        "owners": ["org:descarteslabs"],
-                        "modified": "2019-06-11T23:31:33.714883Z",
-                        "created": "2019-06-11T23:31:33.714883Z",
-                        "name": "myimage",
-                        "product_id": "p1",
-                        "geometry": self.geometry,
-                        "acquired": "2019-08-20T08:08:16.123456789Z",
+                        "end_datetime": None,
+                        "description": None,
+                        "resolution_min": {"value": 10.0, "unit": "meters"},
                     },
-                    "type": "image",
-                    "id": "p1:myimage",
+                    "type": "product",
+                    "id": "descarteslabs:test",
                 },
-                "included": [
-                    {"attributes": {"name": "A product"}, "type": "product", "id": "p1"}
-                ],
                 "jsonapi": {"version": "1.0"},
             },
         )
 
-        i = Image.get("p1:myimage", client=self.client)
-        assert (
-            datetime.datetime.strptime(
-                "2019-08-20T08:08:16.123456Z", "%Y-%m-%dT%H:%M:%S.%fZ"
-            ).replace(tzinfo=utc)
-            == i.acquired
-        )
+        p = Product(id="p1", name="Test Product", client=self.client)
+        assert p.state == DocumentState.UNSAVED
+        p.save()
+        assert responses.calls[0].request.url == self.url + "/products"
+        assert p.state == DocumentState.SAVED
+        # id updated on initial save
+        assert "p1" != p.id
+        assert isinstance(p.start_datetime, datetime)
 
-    def test_search_intersects(self):
-        search = Image.search().intersects(self.geometry)
-        _, request_params = search._to_request()
-        assert self.geometry == json.loads(request_params["intersects"])
+    @responses.activate
+    def test_save_dupe(self):
+        self.mock_response(
+            responses.POST,
+            {
+                "errors": [
+                    {
+                        "status": "400",
+                        "detail": "A document with id `descarteslabs:p1` already exists.",
+                        "title": "Bad request",
+                    }
+                ],
+                "jsonapi": {"version": "1.0"},
+            },
+            status=400,
+        )
+        p = Product(id="p", name="Test Product", client=self.client)
+        with pytest.raises(BadRequestError):
+            p.save()
 
     @responses.activate
-    def test_files_attribute(self):
+    def test_an_update(self):
         self.mock_response(
             responses.GET,
             {
                 "data": {
-                    "type": "image",
-                    "relationships": {
-                        "product": {"data": {"type": "product", "id": "prod1"}}
-                    },
                     "attributes": {
-                        "readers": ["group:public", "group:beta"],
-                        "proj4": "+proj=utm +zone=29 +datum=WGS84 +units=m +no_defs ",
-                        "satellite_id": "LANDSAT_8",
-                        "product_id": "prod1",
-                        "files": [
-                            {
-                                "href": "gs://descartes-files/01.jp2",
-                                "size_bytes": 121091191,
-                                "hash": "c1fe6f604b0bf1e7265d06ed0379bf0c",
-                                "provider_href": None,
-                                "provider_id": None,
-                            },
-                            {
-                                "href": "gs://descartes-files/02.jp2",
-                                "size_bytes": 53718630,
-                                "hash": "37ea2fb38268875f7f473c52ba485bc6",
-                                "provider_href": None,
-                                "provider_id": None,
-                            },
-                        ],
-                        "name": "id1",
-                        "storage_state": "available",
-                        "extra_properties": {},
-                        "geometry": self.geometry,
-                        "geotrans": [330592.5, 15.0, 0.0, 8918707.5, 0.0, -15.0],
-                        "x_pixels": 18240,
                         "owners": ["org:descarteslabs"],
-                        "published": "2017-05-16T18:45:16Z",
-                        "acquired": "2017-05-16T14:07:26.108914Z",
-                        "created": "2017-05-21T00:51:08Z",
-                        "y_pixels": 18216,
+                        "name": "My Product",
+                        "readers": [],
+                        "modified": "2019-06-11T23:59:46.800792Z",
+                        "created": "2019-06-11T23:52:35.114938Z",
+                        "start_datetime": None,
+                        "writers": [],
+                        "end_datetime": None,
+                        "description": "A descriptive description",
                     },
-                    "id": "prod1:id1",
+                    "type": "product",
+                    "id": "descarteslabs:my-product",
                 },
-                "included": [
-                    {
-                        "type": "product",
-                        "attributes": {
-                            "readers": ["group:beta", "group:public"],
-                            "owners": ["org:descarteslabs"],
-                            "start_datetime": "2013-01-01T00:00:00Z",
-                        },
-                        "id": "prod1",
-                    }
-                ],
                 "jsonapi": {"version": "1.0"},
             },
         )
 
-        i = Image.get("p1:myimage", client=self.client)
-        assert len(i.files) == 2
-        assert isinstance(i.files, ListAttribute)
-        assert isinstance(i.files[0], MappingAttribute)
-
-        file0 = i.files[0]
-        assert file0.href == "gs://descartes-files/01.jp2"
-        assert i.state == DocumentState.SAVED
-
-        file0.href = "gs://new-bucket/file0.jp2"
-        assert i.state == DocumentState.MODIFIED
-
-        serialized = i.serialize(modified_only=True)
-        assert list(serialized.keys()) == ["files"]
-        assert serialized["files"] == [
-            {
-                "href": "gs://new-bucket/file0.jp2",
-                "size_bytes": 121091191,
-                "hash": "c1fe6f604b0bf1e7265d06ed0379bf0c",
-                "provider_href": None,
-                "provider_id": None,
-            },
-            {
-                "href": "gs://descartes-files/02.jp2",
-                "size_bytes": 53718630,
-                "hash": "37ea2fb38268875f7f473c52ba485bc6",
-                "provider_href": None,
-                "provider_id": None,
-            },
-        ]
-
-    @patch("descarteslabs.catalog.image.Image._gcs_upload_service")
-    @patch("descarteslabs.catalog.image_upload.ImageUpload._POLLING_INTERVALS", [1])
-    @responses.activate
-    def test_upload(self, upload_mock):
-        with NamedTemporaryFile(suffix=".tif", delete=False) as f:
-            try:
-                f.close()
-                # this is copied from the upload impl, should go away with new ingest
-                product_id = "p1"
-                image_name = "image"
-                image_id = "{}:{}".format(product_id, image_name)
-                upload_url = "https:www.fake.com/1"
+        p1 = Product.get("descarteslabs:my-product", client=self.client)
+        assert p1.state == DocumentState.SAVED
 
-                self.mock_response(
-                    responses.GET,
-                    {
-                        "data": {
-                            "attributes": {
-                                "readers": [],
-                                "writers": [],
-                                "owners": ["org:descarteslabs"],
-                                "modified": "2019-06-11T23:31:33.714883Z",
-                                "created": "2019-06-11T23:31:33.714883Z",
-                            },
-                            "type": "product",
-                            "id": product_id,
-                        },
-                        "jsonapi": {"version": "1.0"},
-                    },
-                )
-                self.mock_response(
-                    responses.HEAD,
-                    {
-                        "errors": [
-                            {
-                                "detail": "Object not found: {}".format(image_id),
-                                "status": "404",
-                                "title": "Object not found",
-                            }
-                        ],
-                        "jsonapi": {"version": "1.0"},
-                    },
-                    status=404,
-                )
-                self.mock_response(
-                    responses.POST,
-                    {
-                        "data": {
-                            "type": "image_upload",
-                            "id": "1",
-                            "attributes": {
-                                "created": "2019-01-02T03:04:05Z",
-                                "modified": "2019-01-02T03:04:05Z",
-                                "product_id": product_id,
-                                "image_id": image_id,
-                                "resumable_urls": [upload_url],
-                                "status": ImageUploadStatus.TRANSFERRING.value,
-                            },
-                        },
-                        "jsonapi": {"version": "1.0"},
-                    },
-                )
-                self.mock_response(
-                    responses.PATCH,
-                    {
-                        "data": {
-                            "type": "image_upload",
-                            "id": "1",
-                            "attributes": {
-                                "created": "2019-01-02T03:04:05Z",
-                                "modified": "2019-01-02T03:04:06Z",
-                                "product_id": product_id,
-                                "image_id": image_id,
-                                "status": ImageUploadStatus.PENDING.value,
-                            },
-                        },
-                        "jsonapi": {"version": "1.0"},
-                    },
-                )
-                self.mock_response(
-                    responses.GET,
-                    {
-                        "data": {
-                            "type": "image_upload",
-                            "id": "1",
-                            "attributes": {
-                                "created": "2019-01-02T03:04:05Z",
-                                "modified": "2019-01-02T03:04:06Z",
-                                "product_id": product_id,
-                                "image_id": image_id,
-                                "status": ImageUploadStatus.SUCCESS.value,
-                            },
-                        },
-                        "jsonapi": {"version": "1.0"},
-                    },
-                )
-                self.mock_response(
-                    responses.GET,
-                    {
-                        "data": {
-                            "attributes": {
-                                "readers": [],
-                                "writers": [],
-                                "owners": ["org:descarteslabs"],
-                                "modified": "2019-06-11T23:31:33.714883Z",
-                                "created": "2019-06-11T23:31:33.714883Z",
-                                "name": image_name,
-                                "product_id": product_id,
-                                "acquired": "2001-01-01T00:00:00Z",
-                                "geometry": self.geometry,
-                            },
-                            "type": "image",
-                            "id": image_id,
-                        },
-                        "jsonapi": {"version": "1.0"},
+        p1_repr = repr(p1)
+        match_str = """\
+            Product: My Product
+              id: descarteslabs:my-product
+              created: Tue Jun 11 23:52:35 2019"""
+        assert p1_repr.strip("\n") == textwrap.dedent(match_str)
+
+        p1.description = "An updated description"
+        assert p1.state == DocumentState.MODIFIED
+        self.mock_response(
+            responses.PATCH,
+            {
+                "data": {
+                    "attributes": {
+                        "owners": ["org:descarteslabs"],
+                        "name": "My Product",
+                        "readers": [],
+                        "modified": "2019-06-11T23:59:46.800792Z",
+                        "created": "2019-06-11T23:52:35.114938Z",
+                        "start_datetime": None,
+                        "writers": [],
+                        "end_datetime": None,
+                        "description": "An updated description",
                     },
-                )
+                    "type": "product",
+                    "id": "descarteslabs:my-product",
+                },
+                "jsonapi": {"version": "1.0"},
+            },
+        )
 
-                image = Image(
-                    name=image_name,
-                    product_id=product_id,
-                    acquired="2001-01-01",
-                    client=self.client,
-                )
-
-                upload = image.upload(f.name)
-            finally:
-                # Manual cleanup required for Windows compatibility
-                os.unlink(f.name)
+        p1_repr = repr(p1)
+        match_str = """\
+            Product: My Product
+              id: descarteslabs:my-product
+              created: Tue Jun 11 23:52:35 2019
+            * Not up-to-date in the Descartes Labs catalog. Call `.save()` to save or update this record."""
+
+        assert p1_repr.strip("\n") == textwrap.dedent(match_str)
+
+        p1.save()
+        assert self.get_request_body(1) == {
+            "data": {
+                "type": "product",
+                "id": "descarteslabs:my-product",
+                "attributes": {"description": "An updated description"},
+            }
+        }
 
-        assert image.state == DocumentState.UNSAVED
-        assert upload.id == "1"
-        assert upload.product_id == product_id
-        assert upload.image_id == image.id
-        assert upload.status == ImageUploadStatus.PENDING
-        upload_mock.session.put.assert_called_once()
-        assert upload_mock.session.put.call_args[0][0] == upload_url
+    @responses.activate
+    def test_delete(self):
+        p = Product(
+            id="descarteslabs:my-product",
+            name="My Product",
+            client=self.client,
+            _saved=True,
+        )
+        self.mock_response(
+            responses.DELETE,
+            {
+                "meta": {"message": "Object successfully deleted"},
+                "jsonapi": {"version": "1.0"},
+            },
+        )
 
-        upload.wait_for_completion(15)
+        p.delete()
+        assert p.state == DocumentState.DELETED
 
-        assert upload.status == ImageUploadStatus.SUCCESS
+    @responses.activate
+    def test_delete_non_existent(self):
+        p = Product(
+            id="ne-my-product", name="Non-existent", client=self.client, _saved=True
+        )
+        self.mock_response(responses.DELETE, self.not_found_json, status=404)
 
-        # when the new ingest is completed, we may implement the reload
-        # of the updated Image...
+        with pytest.raises(DeletedObjectError):
+            p.delete()
 
-    @patch("descarteslabs.catalog.image.Image._gcs_upload_service")
-    @patch("descarteslabs.catalog.image_upload.ImageUpload._POLLING_INTERVALS", [1])
     @responses.activate
-    def test_upload_multi_file(self, upload_mock):
-        with NamedTemporaryFile(suffix=".tif", delete=False) as f1:
-            with NamedTemporaryFile(suffix=".tif", delete=False) as f2:
-                try:
-                    f1.close()
-                    f2.close()
-                    # this is copied from the upload impl, should go away with new ingest
-                    product_id = "p1"
-                    image_name = "image"
-                    image_id = "{}:{}".format(product_id, image_name)
-                    upload_url1 = "https:www.fake.com/1"
-                    upload_url2 = "https:www.fake.com/2"
+    def test_exists(self):
+        # head request, no JSON is returned
+        self.mock_response(responses.HEAD, {})
+        assert Product.exists("my-id:id", client=self.client)
+        assert (
+            responses.calls[0].request.url
+            == "https://example.com/catalog/v2/products/my-id:id"
+        )
 
-                    self.mock_response(
-                        responses.GET,
-                        {
-                            "data": {
-                                "attributes": {
-                                    "readers": [],
-                                    "writers": [],
-                                    "owners": ["org:descarteslabs"],
-                                    "modified": "2019-06-11T23:31:33.714883Z",
-                                    "created": "2019-06-11T23:31:33.714883Z",
-                                },
-                                "type": "product",
-                                "id": product_id,
-                            },
-                            "jsonapi": {"version": "1.0"},
-                        },
-                    )
-                    self.mock_response(
-                        responses.HEAD,
-                        {
-                            "errors": [
-                                {
-                                    "detail": "Object not found: {}".format(image_id),
-                                    "status": "404",
-                                    "title": "Object not found",
-                                }
-                            ],
-                            "jsonapi": {"version": "1.0"},
-                        },
-                        status=404,
-                    )
-                    self.mock_response(
-                        responses.POST,
-                        {
-                            "data": {
-                                "type": "image_upload",
-                                "id": "1",
-                                "attributes": {
-                                    "created": "2019-01-02T03:04:05Z",
-                                    "modified": "2019-01-02T03:04:05Z",
-                                    "product_id": product_id,
-                                    "image_id": image_id,
-                                    "resumable_urls": [upload_url1, upload_url2],
-                                    "status": ImageUploadStatus.TRANSFERRING.value,
-                                },
-                            },
-                            "jsonapi": {"version": "1.0"},
-                        },
-                    )
-                    self.mock_response(
-                        responses.PATCH,
-                        {
-                            "data": {
-                                "type": "image_upload",
-                                "id": "1",
-                                "attributes": {
-                                    "created": "2019-01-02T03:04:05Z",
-                                    "modified": "2019-01-02T03:04:05Z",
-                                    "product_id": product_id,
-                                    "image_id": image_id,
-                                    "status": ImageUploadStatus.PENDING.value,
-                                },
-                            },
-                            "jsonapi": {"version": "1.0"},
-                        },
-                    )
-                    self.mock_response(
-                        responses.GET,
-                        {
-                            "data": {
-                                "type": "image_upload",
-                                "id": "1",
-                                "attributes": {
-                                    "created": "2019-01-02T03:04:05Z",
-                                    "modified": "2019-01-02T03:04:05Z",
-                                    "product_id": product_id,
-                                    "image_id": image_id,
-                                    "status": ImageUploadStatus.SUCCESS.value,
-                                },
-                            },
-                            "jsonapi": {"version": "1.0"},
-                        },
-                    )
-                    self.mock_response(
-                        responses.GET,
-                        {
-                            "data": {
-                                "attributes": {
-                                    "readers": [],
-                                    "writers": [],
-                                    "owners": ["org:descarteslabs"],
-                                    "modified": "2019-06-11T23:31:33.714883Z",
-                                    "created": "2019-06-11T23:31:33.714883Z",
-                                    "name": image_name,
-                                    "product_id": product_id,
-                                    "acquired": "2001-01-01T00:00:00Z",
-                                    "geometry": self.geometry,
-                                },
-                                "type": "image",
-                                "id": image_id,
-                            },
-                            "jsonapi": {"version": "1.0"},
-                        },
-                    )
+    @responses.activate
+    def test_exists_false(self):
+        self.mock_response(responses.HEAD, self.not_found_json, status=404)
+        assert not Product.exists("my-id:id", client=self.client)
+        assert (
+            responses.calls[0].request.url
+            == "https://example.com/catalog/v2/products/my-id:id"
+        )
 
-                    image = Image(
-                        name=image_name,
-                        product_id=product_id,
-                        acquired="2001-01-01",
-                        client=self.client,
-                    )
-
-                    upload = image.upload([f1.name, f2.name])
-                finally:
-                    # Manual cleanup required for Windows compatibility
-                    os.unlink(f1.name)
-                    os.unlink(f2.name)
+    @responses.activate
+    def test_get_unknown_attribute(self):
+        self.mock_response(
+            responses.GET,
+            {
+                "data": {
+                    "attributes": {
+                        "owners": ["org:descarteslabs"],
+                        "name": "My Product",
+                        "readers": [],
+                        "modified": "2019-06-11T23:59:46.800792Z",
+                        "created": "2019-06-11T23:52:35.114938Z",
+                        "start_datetime": None,
+                        "writers": [],
+                        "end_datetime": None,
+                        "description": "A descriptive description",
+                        "foobar": "unkown",
+                    },
+                    "type": "product",
+                    "id": "descarteslabs:my-product",
+                },
+                "jsonapi": {"version": "1.0"},
+            },
+        )
 
-        assert image.state == DocumentState.UNSAVED
-        assert upload.id == "1"
-        assert upload.product_id == product_id
-        assert upload.image_id == image.id
-        assert upload.status == ImageUploadStatus.PENDING
-        assert len(upload_mock.session.put.call_args_list) == 2
-        assert upload_mock.session.put.call_args_list[0][0][0] == upload_url1
-        assert upload_mock.session.put.call_args_list[1][0][0] == upload_url2
+        p = Product.get("descarteslabs:my-product", client=self.client)
+        assert not hasattr(p, "foobar")
 
-        upload.wait_for_completion(15)
+    @responses.activate
+    def test_create_product_delete_task(self):
+        p = Product(id="p1", name="Test Product", client=self.client)
+        self.mock_response(
+            responses.POST,
+            {
+                "data": {
+                    "attributes": {"status": "RUNNING"},
+                    "type": "product_delete_task",
+                    "id": "descarteslabs:test-product",
+                },
+                "jsonapi": {"version": "1.0"},
+            },
+            status=201,
+        )
+        r = p.delete_related_objects()
+        req = responses.calls[0].request
+        assert r.status == TaskState.RUNNING
+        assert (
+            req.url
+            == "https://example.com/catalog/v2/products/p1/delete_related_objects"
+        )
+        assert req.body == b'{"data": {"type": "product_delete_task"}}'
 
-        assert upload.status == ImageUploadStatus.SUCCESS
+    @responses.activate
+    def test_no_objects_to_delete(self):
+        p = Product(id="p1", name="Test Product", client=self.client)
+        self.mock_response(
+            responses.POST,
+            {
+                "errors": [
+                    {
+                        "status": "204",
+                        "detail": "A 'delete related objects' operation is not needed: p1",
+                        "title": "No related objects found",
+                    }
+                ],
+                "jsonapi": {"version": "1.0"},
+            },
+            status=204,
+        )
+        r = p.delete_related_objects()
+        assert not r
 
-        # when the new ingest is completed, we may implement the reload
-        # of the updated Image...
+    def test_abstract_status_class(self):
+        with pytest.raises(TypeError):
+            TaskStatus()
 
-    @patch("descarteslabs.catalog.Image._do_upload", return_value=True)
-    def test_upload_warnings(self, *mocks):
-        p = Product(id="p1", name="Test Product", client=self.client, _saved=True)
-        image = Image(id="p1:image", product=p, acquired="2012-05-06", projection="foo")
+    @responses.activate
+    def test_get_delete_status(self):
+        p = Product(id="p1", name="Test Product", client=self.client)
+        self.mock_response(
+            responses.GET,
+            {
+                "data": {
+                    "attributes": {
+                        "status": "SUCCESS",
+                        "start_datetime": "2019-08-10T00:10:17.528903Z",
+                        "errors": None,
+                        "duration_in_seconds": 0.36756521779382323,
+                        "objects_deleted": 2,
+                    },
+                    "type": "product_delete_task",
+                    "id": "p1",
+                },
+                "jsonapi": {"version": "1.0"},
+            },
+        )
+        r = p.get_delete_status()
+        assert r.status == TaskState.SUCCEEDED
+        assert isinstance(r, DeletionTaskStatus)
 
-        with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            image.upload("somefile")
-            assert 1 == len(w)
-            assert "cs_code" in str(w[0].message)
+        status_repr = repr(r)
+        match_str = """\
+            p1 delete task status: SUCCESS
+              - started: 2019-08-10T00:10:17.528903Z
+              - took 0.3676 seconds
+              - 2 objects deleted"""
+
+        assert status_repr.strip("\n") == textwrap.dedent(match_str)
 
-    @patch("descarteslabs.catalog.image.Image._gcs_upload_service")
-    @patch("descarteslabs.catalog.image_upload.ImageUpload._POLLING_INTERVALS", [1])
     @responses.activate
-    def test_upload_ndarray(self, upload_mock):
-        # this is copied from the upload impl, should go away with new ingest
+    def test_image_uploads(self):
         product_id = "p1"
-        image_name = "image"
-        image_id = "{}:{}".format(product_id, image_name)
-        upload_url = "https:www.fake.com/1"
 
         self.mock_response(
             responses.GET,
             {
                 "data": {
                     "attributes": {
                         "readers": [],
@@ -563,191 +448,339 @@
                     "type": "product",
                     "id": product_id,
                 },
                 "jsonapi": {"version": "1.0"},
             },
         )
         self.mock_response(
-            responses.HEAD,
+            responses.PUT,
             {
-                "errors": [
+                "meta": {"count": 1},
+                "data": [
                     {
-                        "detail": "Object not found: {}".format(image_id),
-                        "status": "404",
-                        "title": "Object not found",
-                    }
+                        "type": "image_upload",
+                        "id": "1",
+                        "attributes": {
+                            "created": "2020-01-01T00:00:00.000000Z",
+                            "modified": "2020-01-01T00:00:00.000000Z",
+                            "product_id": product_id,
+                            "image_id": product_id + ":image",
+                            "start_datetime": "2020-01-01T00:00:00Z",
+                            "end_datetime": "2020-01-01T00:00:00Z",
+                            "status": ImageUploadStatus.SUCCESS.value,
+                        },
+                    },
+                    {
+                        "type": "image_upload",
+                        "id": "2",
+                        "attributes": {
+                            "created": "2020-01-01T00:00:00.000000Z",
+                            "modified": "2020-01-01T00:00:00.000000Z",
+                            "product_id": product_id,
+                            "image_id": product_id + ":image2",
+                            "start_datetime": "2020-01-01T00:00:00Z",
+                            "end_datetime": "2020-01-01T00:00:00Z",
+                            "status": ImageUploadStatus.FAILURE.value,
+                        },
+                    },
                 ],
+                "links": {},
                 "jsonapi": {"version": "1.0"},
             },
-            status=404,
         )
+
+        product = Product.get(product_id, client=self.client)
+
+        uploads = list(product.image_uploads())
+
+        assert len(uploads) == 2
+        upload = uploads[0]
+        assert upload.id == "1"
+        assert upload.product_id == product_id
+        assert upload.image_id == product_id + ":image"
+        assert upload.status == ImageUploadStatus.SUCCESS
+        failed_upload = uploads[1]
+        assert failed_upload.id == "2"
+        assert failed_upload.image_id == product_id + ":image2"
+        assert failed_upload.status == ImageUploadStatus.FAILURE
+
+    @responses.activate
+    def test_derived_bands(self):
         self.mock_response(
-            responses.POST,
+            responses.PUT,
             {
-                "data": {
-                    "type": "image_upload",
-                    "id": "1",
-                    "attributes": {
-                        "created": "2019-01-02T03:04:05Z",
-                        "modified": "2019-01-02T03:04:05Z",
-                        "product_id": product_id,
-                        "image_id": image_id,
-                        "resumable_urls": [upload_url],
-                        "status": ImageUploadStatus.TRANSFERRING.value,
+                "data": [
+                    {
+                        "type": "derived_band",
+                        "attributes": {
+                            "owners": ["org:descarteslabs"],
+                            "writers": None,
+                            "data_range": [0.0, 255.0],
+                            "name": "derived:ndvi",
+                            "data_type": "Byte",
+                            "tags": None,
+                            "readers": ["group:descarteslabs:engineering"],
+                            "function_name": "test",
+                            "extra_properties": {},
+                            "description": None,
+                            "physical_range": None,
+                            "bands": ["red", "nir"],
+                        },
+                        "id": "derived:ndvi",
+                    },
+                    {
+                        "type": "derived_band",
+                        "attributes": {
+                            "owners": ["org:descarteslabs"],
+                            "writers": None,
+                            "data_range": [0.0, 255.0],
+                            "name": "green",
+                            "data_type": "Byte",
+                            "tags": None,
+                            "readers": ["group:descarteslabs:engineering"],
+                            "function_name": "test",
+                            "extra_properties": {},
+                            "description": None,
+                            "physical_range": None,
+                            "bands": ["blue"],
+                        },
+                        "id": "derived:rsqrt",
                     },
+                ],
+                "links": {
+                    "self": "https://www.example.com/catalog/v2/products/p1/relationships/derived_bands",
+                    "related": None,
+                    "first": "https://www.example.com/catalog/v2/products/p1/relationships/derived_bands",
                 },
                 "jsonapi": {"version": "1.0"},
             },
         )
+        p = Product(id="p1", name="Test Product", client=self.client, _saved=True)
+        derived_bands = list(p.derived_bands())
+        assert responses.calls[
+            0
+        ].request.url == "{}/products/{}/relationships/derived_bands".format(
+            self.url, p.id
+        )
+        assert len(derived_bands) == 2
+        assert isinstance(derived_bands[0], DerivedBand)
+
+    @responses.activate
+    def test_derived_bands_filters(self):
+        p = Product(id="p1", name="Test Product", client=self.client, _saved=True)
         self.mock_response(
-            responses.PATCH,
+            responses.PUT,
             {
-                "data": {
-                    "type": "image_upload",
-                    "id": "1",
-                    "attributes": {
-                        "created": "2019-01-02T03:04:05Z",
-                        "modified": "2019-01-02T03:04:05Z",
-                        "product_id": product_id,
-                        "image_id": image_id,
-                        "status": ImageUploadStatus.PENDING.value,
-                    },
+                "data": [
+                    {
+                        "type": "derived_band",
+                        "attributes": {
+                            "owners": ["org:descarteslabs"],
+                            "writers": None,
+                            "data_range": [0.0, 255.0],
+                            "name": "green",
+                            "data_type": "Byte",
+                            "tags": None,
+                            "readers": ["group:descarteslabs:engineering"],
+                            "function_name": "test",
+                            "extra_properties": {},
+                            "description": None,
+                            "physical_range": None,
+                            "bands": ["blue"],
+                        },
+                        "id": "derived:rsqrt",
+                    }
+                ],
+                "links": {
+                    "self": "https://www.example.com/catalog/v2/products/p1/relationships/derived_bands",
+                    "related": None,
+                    "first": "https://www.example.com/catalog/v2/products/p1/relationships/derived_bands",
                 },
                 "jsonapi": {"version": "1.0"},
             },
         )
+        s = p.derived_bands().filter(properties.name == "green")
+        filtered_derived_bands = list(s)
+        req = responses.calls[0].request
+        assert req.url == "{}/products/{}/relationships/derived_bands".format(
+            self.url, p.id
+        )
+        assert s._serialize_filters() == [{"op": "eq", "name": "name", "val": "green"}]
+        assert len(filtered_derived_bands) == 1
+
+    @responses.activate
+    def test_core_product(self):
+        product_id = "p1"
+
         self.mock_response(
-            responses.GET,
+            responses.POST,
             {
                 "data": {
-                    "type": "image_upload",
-                    "id": "1",
                     "attributes": {
-                        "product_id": product_id,
-                        "image_id": image_id,
-                        "status": ImageUploadStatus.SUCCESS.value,
+                        "readers": [],
+                        "writers": [],
+                        "owners": ["org:descarteslabs"],
+                        "modified": "2019-06-11T23:31:33.714883Z",
+                        "created": "2019-06-11T23:31:33.714883Z",
+                        "is_core": True,
+                        "product_tier": "standard",
                     },
+                    "type": "product",
+                    "id": "product_id",
                 },
                 "jsonapi": {"version": "1.0"},
             },
         )
+
+        product = Product(client=self.client)
+        product.id = product_id
+        product.is_core = "True"
+        product.product_tier = "standard"
+
+        self.assertEqual(
+            product.serialize(), {"is_core": True, "product_tier": "standard"}
+        )
+        product.save()
+        self.assertEqual(product.is_core, True)
+        self.assertEqual(product.product_tier, "standard")
+
+    def test_namespace_id(self):
+        class Client(object):
+            class auth(object):
+                namespace = "mynamespace"
+                payload = {"org": "descarteslabs"}
+
+        assert Product.namespace_id("foo", client=Client) == "descarteslabs:foo"
+        assert (
+            Product.namespace_id("descarteslabs:foo", client=Client)
+            == "descarteslabs:foo"
+        )
+        assert (
+            Product.namespace_id("descarteslabs:foo:bar:baz", client=Client)
+            == "descarteslabs:foo:bar:baz"
+        )
+
+        del Client.auth.payload["org"]
+
+        assert Product.namespace_id("foo", client=Client) == "mynamespace:foo"
+
+    def test_named_id(self):
+        p = Product(id="id1")
+        assert p.named_id("band1") == "id1:band1"
+
+    @responses.activate
+    def test_warnings(self):
         self.mock_response(
             responses.GET,
             {
                 "data": {
                     "attributes": {
                         "readers": [],
                         "writers": [],
                         "owners": ["org:descarteslabs"],
                         "modified": "2019-06-11T23:31:33.714883Z",
                         "created": "2019-06-11T23:31:33.714883Z",
-                        "name": image_name,
-                        "product_id": product_id,
-                        "acquired": "2001-01-01T00:00:00Z",
-                        "geometry": self.geometry,
+                        "is_core": False,
                     },
-                    "type": "image",
-                    "id": image_id,
+                    "type": "product",
+                    "id": "product_id",
+                },
+                "meta": {
+                    "warnings": [
+                        {
+                            "category": "FutureWarning",
+                            "message": "This is a test of a FutureWarning",
+                        },
+                        {
+                            "category": "SomeWarning",
+                            "message": "This is a test of a warning with a bad category",
+                        },
+                    ]
                 },
                 "jsonapi": {"version": "1.0"},
             },
         )
 
-        image = Image(
-            name=image_name,
-            product_id=product_id,
-            acquired="2001-01-01",
-            client=self.client,
-        )
-
-        ary = np.zeros((10, 10), dtype=np.dtype(np.uint16))
-        raster_meta = {
-            "geoTransform": [0, 0, 0, 0, 0, 0],
-            "coordinateSystem": {"proj4": "proj4 string"},
-        }
-        upload = image.upload_ndarray(ary, raster_meta=raster_meta)
+        with warnings.catch_warnings(record=True) as w:
+            warnings.simplefilter("always")
+            Product.get("product_id", client=self.client)
 
-        assert image.state == DocumentState.UNSAVED
-        assert upload.id == "1"
-        assert upload.product_id == product_id
-        assert upload.image_id == image.id
-        assert upload.status == ImageUploadStatus.PENDING
-        upload_mock.session.put.assert_called_once()
-        assert upload_mock.session.put.call_args[0][0] == upload_url
+        assert w[0].category is FutureWarning
+        assert str(w[0].message) == "This is a test of a FutureWarning"
+        assert w[1].category is UserWarning
         assert (
-            self.get_request_body(2)["data"]["attributes"]["image_upload_options"][
-                "upload_size"
-            ]
-            == 200
+            str(w[1].message)
+            == "SomeWarning: This is a test of a warning with a bad category"
         )
 
-        upload.wait_for_completion(15)
+    def test_extra_properties(self):
+        p = Product(id="id1", extra_properties={"one": "two"}, _saved=True)
+        assert p.extra_properties["one"] == "two"
+        assert not p.is_modified
+
+        p.extra_properties["three"] = "four"
+        assert p.extra_properties["one"] == "two"
+        assert p.extra_properties["three"] == "four"
+        assert p.is_modified
 
-        assert upload.status == ImageUploadStatus.SUCCESS
+        with self.assertRaises(AttributeValidationError):
+            p.extra_properties["five"] = object()
 
-    @patch("descarteslabs.catalog.Image._do_upload", return_value=True)
-    def test_upload_ndarray_shape(self, *mocks):
-        p = Product(id="p1", name="Test Product", client=self.client, _saved=True)
-        image = Image(
-            id="p1:image",
-            product=p,
-            acquired="2012-05-06",
-            geotrans=[42, 0, 0, 0, 0, 0],
-            projection="foo",
+    @responses.activate
+    def test_bad_warnings(self):
+        self.mock_response(
+            responses.GET,
+            {
+                "data": {
+                    "attributes": {
+                        "readers": [],
+                        "writers": [],
+                        "owners": ["org:descarteslabs"],
+                        "modified": "2019-06-11T23:31:33.714883Z",
+                        "created": "2019-06-11T23:31:33.714883Z",
+                        "is_core": False,
+                    },
+                    "type": "product",
+                    "id": "product_id",
+                },
+                "meta": {
+                    "warnings": [
+                        {
+                            "category": "FutureWarning",
+                            "bad_message": "This is a test of a FutureWarning",
+                        },
+                        "some_other_garbage",
+                    ]
+                },
+                "jsonapi": {"version": "1.0"},
+            },
         )
 
-        pytest.raises(ValueError, image.upload_ndarray, np.zeros((100,)))
-        pytest.raises(ValueError, image.upload_ndarray, np.zeros((100, 100, 1, 2)))
-
-        array = np.zeros((1, 100, 100))
-        with warnings.catch_warnings(record=True) as w:
-            image.upload_ndarray(array)
-            assert 0 == len(w)
-
-        array = np.zeros((100, 100))
-        with warnings.catch_warnings(record=True) as w:
-            image.upload_ndarray(array)
-            assert 0 == len(w)
-
-        array = np.zeros((100, 100, 1))
-        with warnings.catch_warnings(record=True) as w:
-            image.upload_ndarray(array)
-            assert 1 == len(w)
-
-        array = np.zeros((1, 100, 100))
-        image.cs_code = "FOO:1"
         with warnings.catch_warnings(record=True) as w:
             warnings.simplefilter("always")
-            image.upload_ndarray(array)
-            assert 1 == len(w)
-            assert "cs_code" in str(w[0].message)
+            p = Product.get("product_id", client=self.client)
+            assert isinstance(p, Product)
+            assert p.id == "product_id"
 
-    @patch("descarteslabs.catalog.Image._do_upload", return_value=True)
-    def test_upload_ndarray_dtype(self, *mocks):
-        p = Product(id="p1", name="Test Product", client=self.client, _saved=True)
-        image = Image(
-            id="p1:image",
-            product=p,
-            acquired="2012-05-06",
-            geotrans=[42, 0, 0, 0, 0, 0],
-            projection="foo",
-        )
+        assert len(w) == 0
 
-        pytest.raises(
-            ValueError, image.upload_ndarray, np.zeros((1, 100, 100), np.int8)
-        )
-        pytest.raises(
-            ValueError, image.upload_ndarray, np.zeros((1, 100, 100), np.int64)
-        )
-        pytest.raises(
-            ValueError, image.upload_ndarray, np.zeros((1, 100, 100), np.uint64)
-        )
+    @responses.activate
+    def test_deleted_band_image(self):
+        self.mock_response(responses.GET, self.not_found_json, status=404)
+        p = Product(id="p1", name="Product 1", client=self.client, _saved=True)
+        p.get_band("p1:b1", client=self.client)
+        p.get_image("p1:i1", client=self.client)
 
-    def test_upload_ndarray_bad_georef(self):
-        p = Product(id="p1", name="Test Product", client=self.client, _saved=True)
-        image = Image(
-            id="p1:image",
-            product=p,
-            acquired="2012-05-06",
-            geotrans=[42, 0, 0, 0, 0, 0],
-        )
-        pytest.raises(ValueError, image.upload_ndarray, np.zeros((100, 100)))
+    @responses.activate
+    def test_deleted(self):
+        self.mock_response(responses.POST, self.not_found_json, status=404)
+        self.mock_response(responses.GET, self.not_found_json, status=404)
+
+        p = Product(id="p1", name="Product 1", client=self.client, _saved=True)
+        with self.assertRaises(DeletedObjectError):
+            p.delete_related_objects()
+        assert p.state == DocumentState.DELETED
+
+        p = Product(id="p1", name="Product 1", client=self.client, _saved=True)
+        with self.assertRaises(DeletedObjectError):
+            p.get_delete_status()
+        assert p.state == DocumentState.DELETED
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_image_upload.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_image_upload.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,30 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import warnings
 import responses
-from mock import patch
+from unittest.mock import patch
 
 from datetime import datetime
 
 from .base import ClientTestCase
 from ..catalog_base import DocumentState
+from .. import image_upload as image_upload_module
 from ..image_upload import (
     ImageUpload,
     ImageUploadOptions,
     ImageUploadType,
     ImageUploadStatus,
     ImageUploadEventType,
     ImageUploadEventSeverity,
@@ -189,15 +204,18 @@
                 ],
                 "jsonapi": {"version": "1.0"},
             },
         )
 
         u = ImageUpload(
             image=Image(
-                name="image_name", product_id="product_id", acquired="2020-01-01"
+                name="image_name",
+                product_id="product_id",
+                acquired="2020-01-01",
+                client=self.client,
             ),
             image_upload_options=ImageUploadOptions(upload_type=ImageUploadType.FILE),
             client=self.client,
         )
         assert u.image_id == "product_id:image_name"
         assert u.image_upload_options.upload_type == ImageUploadType.FILE
         assert u.state == DocumentState.UNSAVED
@@ -232,15 +250,15 @@
         assert u.state == DocumentState.SAVED
         assert len(u.events) == 2
         assert u.events[1].event_datetime == datetime(2020, 1, 1, 0, 0, 0, tzinfo=utc)
         assert u.events[1].event_type == ImageUploadEventType.CANCEL
         assert u.events[1].severity == ImageUploadEventSeverity.INFO
 
     @responses.activate
-    @patch("descarteslabs.catalog.image_upload.ImageUpload._POLLING_INTERVALS", [1])
+    @patch.object(image_upload_module.ImageUpload, "_POLLING_INTERVALS", [1])
     def test_wait_for_completion(self):
         self.mock_response(
             responses.POST,
             {
                 "data": {
                     "type": "image_upload",
                     "id": "1",
@@ -453,15 +471,18 @@
                 },
                 "jsonapi": {"version": "1.0"},
             },
         )
 
         u = ImageUpload(
             image=Image(
-                name="image_name", product_id="product_id", acquired="2020-01-01"
+                name="image_name",
+                product_id="product_id",
+                acquired="2020-01-01",
+                client=self.client,
             ),
             image_upload_options=ImageUploadOptions(upload_type=ImageUploadType.FILE),
             client=self.client,
         )
         u.save()
         u.status = ImageUploadStatus.PENDING
         u.save()
@@ -480,15 +501,15 @@
         assert [e.event_type for e in u.events] == [
             ImageUploadEventType.QUEUE,
             ImageUploadEventType.RUN,
             ImageUploadEventType.COMPLETE,
         ]
 
     @responses.activate
-    @patch("descarteslabs.catalog.image_upload.ImageUpload._POLLING_INTERVALS", [1])
+    @patch.object(image_upload_module.ImageUpload, "_POLLING_INTERVALS", [1])
     def test_reload_failed(self):
         self.mock_response(
             responses.POST,
             {
                 "data": {
                     "type": "image_upload",
                     "id": "1",
@@ -584,15 +605,18 @@
                     },
                 ],
                 "jsonapi": {"version": "1.0"},
             },
         )
         u = ImageUpload(
             image=Image(
-                name="image_name", product_id="product_id", acquired="2020-01-01"
+                name="image_name",
+                product_id="product_id",
+                acquired="2020-01-01",
+                client=self.client,
             ),
             image_upload_options=ImageUploadOptions(upload_type=ImageUploadType.FILE),
             client=self.client,
         )
 
         u.save()
         assert u.status == ImageUploadStatus.PENDING
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_search.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_search.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,15 +1,33 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import responses
 import json
 import shapely.geometry
 
+from ...common.collection import Collection
+from ...common.geo import AOI
+from ...common.property_filtering import Properties
 from .base import ClientTestCase
 from .. import properties as p
 from ..search import Search
-from ..image import Image
+from ..image import Image, ImageSearch
+from ..image_collection import ImageCollection
 from ..attributes import DocumentState
 from ..product import Product
 
 
 class TestSearch(ClientTestCase):
     def setUp(self):
         super(TestSearch, self).setUp()
@@ -85,14 +103,65 @@
         # followed continuation token
         assert responses.calls[0].request.url == self.url + "/products"
         assert (
             responses.calls[1].request.url == self.url + "/products?continuation=.xxx"
         )
 
     @responses.activate
+    def test_search_collect(self):
+        assert self.search._to_request() == ("/products", {})
+        self.mock_response(
+            responses.PUT,
+            {
+                "meta": {"count": 1},
+                "data": [
+                    {
+                        "attributes": {
+                            "owners": ["org:descarteslabs"],
+                            "name": "My Product",
+                            "readers": [],
+                            "modified": "2019-06-12T20:31:48.542725Z",
+                            "created": "2019-06-12T20:31:48.542725Z",
+                            "start_datetime": None,
+                            "writers": [],
+                            "end_datetime": None,
+                            "description": "This is a test product",
+                        },
+                        "type": "product",
+                        "id": "descarteslabs:my-product",
+                    }
+                ],
+                "jsonapi": {"version": "1.0"},
+                "links": {
+                    "self": "https://example.com/catalog/v2/products",
+                    "next": "https://example.com/catalog/v2/products?continuation=.xxx",
+                },
+            },
+        )
+
+        self.mock_response(
+            responses.PUT,
+            {
+                "meta": {"count": 0},
+                "data": [],
+                "jsonapi": {"version": "1.0"},
+                "links": {"self": "https://example.com/catalog/v2/products"},
+            },
+        )
+        results = self.search.collect()
+        assert isinstance(results, Collection)
+        assert results._item_type == Product
+        assert len(results) == 1
+        # followed continuation token
+        assert responses.calls[0].request.url == self.url + "/products"
+        assert (
+            responses.calls[1].request.url == self.url + "/products?continuation=.xxx"
+        )
+
+    @responses.activate
     def test_count(self):
         self.mock_response(
             responses.PUT,
             {
                 "meta": {"count": 1},
                 "data": [],
                 "jsonapi": {"version": "1.0"},
@@ -283,24 +352,26 @@
         )
         filters = s._serialize_filters()
         assert filters[0]["val"] == geometry
 
     def test_filter_object(self):
         my_product = Product(id="my_product")
 
-        s = Search(Image, client=self.client)
+        s = ImageSearch(Image, client=self.client)
         s = s.filter(p.product == my_product)
         filters = s._serialize_filters()
         assert filters[0]["name"] == "product_id"
+        assert filters[0]["op"] == "eq"
         assert filters[0]["val"] == my_product.id
 
-        s = Search(Image, client=self.client)
+        s = ImageSearch(Image, client=self.client)
         s = s.filter(p.product != my_product)
         filters = s._serialize_filters()
         assert filters[0]["name"] == "product_id"
+        assert filters[0]["op"] == "ne"
         assert filters[0]["val"] == my_product.id
 
         # Not supported for <, <=, >, >=
 
     @responses.activate
     def test_filter_resolution(self):
         s = self.search.filter(p.resolution_min == 60)
@@ -367,9 +438,122 @@
             {"name": "tags", "val": "drone", "op": "eq"}
         ]
         assert request_params["limit"] == 10
         assert request_params["sort"] == "start_datetime"
         assert request_params["text"] == "test"
 
     def test_default_includes(self):
-        s = Search(Image, client=self.client)
-        assert s._to_request() == ("/images", {"include": "product"})
+        s = ImageSearch(Image, client=self.client).filter(
+            Properties().product_id == "p1"
+        )
+        assert s._to_request() == (
+            "/images",
+            {
+                "filter": '[{"op":"eq","name":"product_id","val":"p1"}]',
+                "include": "product",
+            },
+        )
+
+    @responses.activate
+    def test_search_image_collection(self):
+        my_product = Product(id="descarteslabs:my_product")
+        s = ImageSearch(Image, client=self.client)
+        s = s.filter(p.product == my_product)
+        aoi = {
+            "type": "Polygon",
+            "coordinates": (
+                (
+                    (-95.0, 42.0),
+                    (-94.0, 42.0),
+                    (-94.0, 41.0),
+                    (-95.0, 41.0),
+                    (-95.0, 42.0),
+                ),
+            ),
+        }
+        s = s.intersects(aoi)
+
+        self.mock_response(
+            responses.PUT,
+            {
+                "meta": {"count": 1},
+                "data": [
+                    {
+                        "attributes": {
+                            "name": "my-image",
+                            "product_id": "descarteslabs:my-product",
+                            "created": "2019-06-12T20:31:48.542725Z",
+                            "acquired": "2019-06-12T20:31:48.542725Z",
+                            "files": [
+                                {
+                                    "hash": "abcdefg0123456789",
+                                    "href": "gs://some-bucket/file.tif",
+                                    "size_bytes": 1,
+                                },
+                            ],
+                            "geometry": {
+                                "type": "Polygon",
+                                "coordinates": [
+                                    [
+                                        [-95.2989209, 42.7999878],
+                                        [-93.1167728, 42.3858464],
+                                        [-93.7138666, 40.703737],
+                                        [-95.8364984, 41.1150618],
+                                        [-95.2989209, 42.7999878],
+                                    ]
+                                ],
+                            },
+                        },
+                        "type": "image",
+                        "id": "descarteslabs:my-product:my-image",
+                    }
+                ],
+                "jsonapi": {"version": "1.0"},
+                "links": {
+                    "self": "https://example.com/catalog/v2/images",
+                },
+            },
+        )
+        # product bands request
+        self.mock_response(
+            responses.PUT,
+            {
+                "meta": {"count": 1},
+                "data": [
+                    {
+                        "attributes": {
+                            "name": "my-band",
+                            "product_id": "descarteslabs:my-product",
+                            "created": "2019-06-12T20:31:48.542725Z",
+                            "resolution": {"value": 30, "unit": "meters"},
+                            "type": "spectral",
+                        },
+                        "type": "band",
+                        "id": "descarteslabs:my-product:my-band",
+                    }
+                ],
+                "jsonapi": {"version": "1.0"},
+                "links": {
+                    "self": "https://example.com/catalog/v2/bands",
+                },
+            },
+        )
+        # product derived bands request
+        self.mock_response(
+            responses.PUT,
+            {
+                "meta": {"count": 0},
+                "data": [],
+                "jsonapi": {"version": "1.0"},
+                "links": {
+                    "self": "https://example.com/catalog/v2/derived_bands",
+                },
+            },
+        )
+        assert s._intersects == aoi
+
+        results = s.collect()
+        assert isinstance(results, ImageCollection)
+        assert results._item_type == Image
+        assert len(results) == 1
+        assert isinstance(results.geocontext, AOI)
+        assert results.geocontext.__geo_interface__ == aoi
```

### Comparing `descarteslabs-1.9.1/descarteslabs/catalog/tests/test_summary.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/test_summary.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,35 @@
-import pytest
-import responses
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import json
 import textwrap
 from datetime import datetime
-from six.moves.urllib.parse import urlparse
+from urllib.parse import urlparse
+
+import pytest
+import responses
 
 from .. import properties as p
 from ..image import Image
 from ..product import Product
-
 from .base import ClientTestCase
 
 
-public_token = "header.e30.signature"
-
-
 class TestImageSummary(ClientTestCase):
     def setUp(self):
         super(TestImageSummary, self).setUp()
         self.search = Image.search(client=self.client)
 
     def mock_response(self, method, json, status=200, **kwargs):
         responses.add(method, self.match_url, json=json, status=status, **kwargs)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/__init__.py` & `descarteslabs-2.0.0/descarteslabs/core/client/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,24 +11,24 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import sys
 import warnings
 
-if sys.version_info < (3, 6):
-    msg = "Python version {}.{} not supported by descarteslabs.client".format(
+if sys.version_info < (3, 7):
+    msg = "Python version {}.{} not supported by the descarteslabs client".format(
         sys.version_info.major, sys.version_info.minor
     )
     raise ImportError(msg)
 
-if sys.version_info < (3, 7):
+if sys.version_info < (3, 8):
     msg = "Support for Python version {}.{} has been deprecated and will be removed in a future version.".format(
         sys.version_info.major, sys.version_info.minor
     )
     warnings.warn(msg, FutureWarning)
 
-if sys.version_info >= (3, 9):
+if sys.version_info >= (3, 12):
     msg = "Python version {}.{} is not supported yet. You may encounter unexpected errors.".format(
         sys.version_info.major, sys.version_info.minor
     )
     warnings.warn(msg, FutureWarning)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/auth/__init__.py` & `descarteslabs-2.0.0/descarteslabs/auth/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/auth/auth.py` & `descarteslabs-2.0.0/descarteslabs/auth/auth.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,40 +16,82 @@
 import datetime
 import errno
 import json
 import os
 import random
 import stat
 import tempfile
+import threading
 import warnings
 from hashlib import sha1
 
-import requests
-import six
-import binascii
-from requests.adapters import HTTPAdapter
-from urllib3.util.retry import Retry
-
-from descarteslabs.client.exceptions import AuthError, OauthError
-from descarteslabs.common.threading.local import ThreadLocalWrapper
-
-DEFAULT_TOKEN_INFO_PATH = os.path.join(
-    os.path.expanduser("~"), ".descarteslabs", "token_info.json"
-)
+from descarteslabs.exceptions import AuthError, OauthError
+
+try:
+    # public client
+    from ..core.common.http import Retry, Session
+except ImportError:
+    # inside monorepo
+    from ..common.http import Retry, Session
+
+
+# copied from descarteslabs/common/threading/local.py, but we need
+# it standalone here to avoid any dependencies on our own packages
+# for client configuration purposes
+class ThreadLocalWrapper(object):
+    """
+    A wrapper around a thread-local object that gets created lazily in every
+    thread of every process via the given factory callable when it is
+    accessed. I.e., at most one instance per thread exists.
+
+    In contrast to standard thread-locals this is compatible with multiple
+    processes.
+    """
+
+    def __init__(self, factory):
+        self._factory = factory
+        self._create_local(os.getpid())
+
+    def get(self):
+        self._init_local()
+        if not hasattr(self._local, "wrapped"):
+            self._local.wrapped = self._factory()
+        return self._local.wrapped
+
+    def _init_local(self):
+        local_pid = os.getpid()
+        previous_pid = getattr(self._local, "_pid", None)
+        if previous_pid is None:
+            self._local._pid = local_pid
+        elif local_pid != previous_pid:
+            self._create_local(local_pid)
+
+    def _create_local(self, pid):
+        self._local = threading.local()
+        self._local._pid = pid
+
+
+DEFAULT_TOKEN_INFO_DIR = os.path.join(os.path.expanduser("~"), ".descarteslabs")
+DEFAULT_TOKEN_INFO_PATH = os.path.join(DEFAULT_TOKEN_INFO_DIR, "token_info.json")
+JWT_TOKEN_PREFIX = "jwt_token_"
 DESCARTESLABS_CLIENT_ID = "DESCARTESLABS_CLIENT_ID"
 DESCARTESLABS_CLIENT_SECRET = "DESCARTESLABS_CLIENT_SECRET"
 DESCARTESLABS_REFRESH_TOKEN = "DESCARTESLABS_REFRESH_TOKEN"
 DESCARTESLABS_TOKEN = "DESCARTESLABS_TOKEN"
+
 DESCARTESLABS_TOKEN_INFO_PATH = "DESCARTESLABS_TOKEN_INFO_PATH"
 
 
 def base64url_decode(input):
     """Helper method to base64url_decode a string.
-    Args:
-        input (str): A base64url_encoded string to decode.
+
+    Parameter
+    ---------
+    input : str
+        A base64url_encoded string to decode.
     """
     rem = len(input) % 4
     if rem > 0:
         input += b"=" * (4 - rem)
 
     return base64.urlsafe_b64decode(input)
 
@@ -62,28 +104,35 @@
         except OSError as ex:
             if ex.errno == errno.EEXIST:
                 pass
             else:
                 raise
 
 
+def get_default_domain():
+    # See if we know the environment we're in, and if so use the
+    # correct `iam_url`. Use a default if we don't know the environment
+    from descarteslabs.config import peek_settings
+
+    class DummyAuth:
+        payload = {}
+
+    return peek_settings().iam_url
+
+
 class Auth:
-    """
-    Authentication client used to authenticate with all Descartes Labs service APIs.
-    """
+    """Client used to authenticate with all Descartes Labs service APIs."""
 
     RETRY_CONFIG = Retry(
         total=5,
         backoff_factor=random.uniform(1, 10),
-        method_whitelist=frozenset(["GET", "POST"]),
+        allowed_methods=frozenset(["GET", "POST"]),
         status_forcelist=[429, 500, 502, 503, 504],
     )
 
-    ADAPTER = ThreadLocalWrapper(lambda: HTTPAdapter(max_retries=Auth.RETRY_CONFIG))
-
     AUTHORIZATION_ERROR = (
         "No valid authentication info found{}. "
         "See https://docs.descarteslabs.com/authentication.html."
     )
 
     KEY_CLIENT_ID = "client_id"
     KEY_CLIENT_SECRET = "client_secret"
@@ -106,77 +155,180 @@
         "_token",
         "_namespace",
         "RETRY_CONFIG",
     ]
 
     _default_token_info_path = object()  # Just any unique object
 
+    _instance = None  # the default Auth instance
+
     def __init__(
         self,
-        domain="https://accounts.descarteslabs.com",
+        domain=None,
         scope=None,
         leeway=500,
         token_info_path=_default_token_info_path,
         client_id=None,
         client_secret=None,
         jwt_token=None,
         refresh_token=None,
         retries=None,
         _suppress_warning=False,
     ):
-        """
-        Helps retrieve a JWT token from a client id and refresh token for cli usage.
+        """Retrieves a JWT access token from a client id and refresh token for cli usage.
+
+        By default and without arguments the credentials are retrieved from a
+        config file named ``token_info.json``. This file can be created by running
+        ``descarteslabs auth login`` from the command line.
+
+        You can change the default location by setting the environment variable
+        ``DESCARTESLABS_TOKEN_INFO_PATH``. Make sure you do this **before** running
+        ``descarteslabs auth login`` so the credentials will be saved to the file
+        specified in the environment variable, and when still set when instantiating
+        this class, the credentials will be read from that file.
+
+        To use a short-lived access token that will not be refreshed, either set the
+        environment variable ``DESCARTESLABS_TOKEN`` or use the ``jwt_token`` parameter.
+
+        To use a long-lived refresh token that will be refreshed, either set the
+        environment variables ``DESCARTESLABS_CLIENT_ID`` and
+        ``DESCARTESLABS_CLIENT_SECRET`` or use the parameters ``client_id`` and
+        ``client_secret``. This will retrieve an access token which will be cached
+        between instances for the same combination of client id and client secret.
+
+        If in addition to the client id and client secret you also specify a valid
+        short-lived access token, it will be used until it expires.
+
+        Note that the environment variable ``DESCARTESLABS_REFRESH_TOKEN`` is identical
+        to ``DESCARTESLABS_CLIENT_SECRET`` and the parameter ``refresh_token`` is
+        identical to ``client_secret``. Use one or the other but not both.
+
+        Although discouraged, it is possible to set one value as environment variable,
+        and pass the other value in as parameter. For example, one could set the
+        environment variable ``DESCARTESLABS_CLIENT_ID`` and only pass in the parameter
+        ``client_secret``.
+
+        If you also specify a ``token_info_path`` that indicates which file to
+        read the credentials from. If used by itself, it works the same as
+        ``DESCARTESLABS_TOKEN_INFO_PATH`` and assuming the file exists and contains
+        valid credentials, you could switch between accounts this way.
+
+        If you specify the ``token_info_path`` together with an additional
+        client id and client secret (whether retrieved through environment
+        variables or given using parameters), the given credentials will be
+        written to the given file. If this file already exists and contains
+        matching credentials, it will be used to retrieve the short-lived
+        access token and refreshes it when it expires. If the file already
+        exists and contains conflicting credentials, it will be overwritten
+        with the new credentials.
+
+        Parameters
+        ----------
+
+        domain : str, default ``descarteslabs.config.get_settings().IAM_URL``
+            The domain used for the credentials. You should normally never
+            change this.
+        scope : list(str), optional
+            The JWT access token fields to be included. You should normally
+            never have to use this.
+        leeway : int, default 500
+            The leeway is given in seconds and is used as a safety cushion
+            for the expiration. If the expiration falls within the leeway,
+            the JWT access token will be renewed.
+        token_info_path : str, default ``~/.descarteslabs/token_info.json``
+            Path to a JSON file holding the credentials. If not set and
+            credentials are provided through environment variables or through
+            parameters, this parameter will **not** be used. However, if no
+            credentials are provided through environment variables or through
+            parameters, it will default to ``~/.descarteslabs/token_info.json``
+            and credentials will be retrieved from that file if present. If
+            explicitly set to ``None``, credentials will never be retrieved
+            from file and **must** be provided through environment variables
+            or parameters.
+        client_id : str, optional
+            The JWT client id. If provided it will take precedence over the
+            corresponding environment variable, or the credentials retrieved through
+            the file specified in ``token_info_path``. If this parameter is provided,
+            you **must** either provide a ``client_secret`` or ``refresh_token`` (but not
+            both). Access tokens retrieved this way will be cached without revealing
+            the client secret.
+        client_secret : str, optional
+            The refresh token used to retrieve short-lived access tokens. If provided
+            it will take precedence over the corresponding environment variable, or the
+            credentials retrieved through the file specified in ``token_info_path``. If
+            this parameter is provided, you **must** also provide a client id either as
+            a parameter or through an environment variable. Access tokens retrieved this
+            way will be cached without revealing the client secret.
+        jwt_token : str, optional
+            A short-lived JWT access token. If valid and used without other parameters,
+            it will be used for access. If used with a client id, the access token must
+            match or it will be discarded. If the access token is discarded either
+            because it expired or didn't match the given client id, and no client secret
+            has been given, no new access token can be retrieved and access will be
+            denied. If used with both client id and client secret, the token will be
+            cached and updated as needed without revealing the client secret.
+        refresh_token : str, optional
+            Identical to the ``client_secret``. You can only specify one or the other,
+            or if specified both, they must match. The refresh token takes precedence
+            over the client secret.
+        retries : Retry or int, optional
+            The number of retries and backoff policy;
+            by default 5 retries with a random backoff policy between 1 and 10 seconds.
+
+        Raises
+        ------
+        UserWarning
+            In case the refresh token and client secret differ.
+            In case the defailt or given ``token_info_path`` cannot be found.
+            In case no credentials can be found.
+
+        Examples
+        --------
+        >>> import descarteslabs
+        >>> # Use default credentials obtained through 'descarteslabs auth login'
+        >>> auth = descarteslabs.auth.Auth()
+        >>> # Your Descartes Labs user id
+        >>> auth.namespace # doctest: +SKIP
+        'a54d88e06612d820bc3be72877c74f257b561b19'
+        >>> auth = descarteslabs.auth.Auth(
+        ...     client_id="ZOBAi4UROl5gKZIpxxlwOEfx8KpqXf2c",
+        ...     client_secret="b70B_ozH6CaV23WQ-toFQ8CaujGHDs-eC39QEJTRnZa9Z",
+        ... )
+        >>> auth.namespace # doctest: +SKIP
+        '67f21eb1040f978fe1da32e5e33501d0f4a604ac'
+        >>>
+        """
+
+        # The logic here is murky and changed over time. Initially, the logic would
+        # retrieve *any* of the information from *any* of the sources. This resulted in
+        # the `token_info.json` being overwritten when you would use a different refresh
+        # token set in the environment or passed in. This was changed to make a
+        # distinction between data that is provided through the environment or as
+        # arguments, versus the data that is retrieved from `token_info.json`. This still
+        # allows arbitrary combinations of data provided through the environment and
+        # passed in as arguments.
+
+        # In addition there are duplicate keys and arguments, which makes things even
+        # more unnecessarily complicated. For backward compatibility reasons we keep it
+        # as-is. Overall the core information consists of:
+        #     client_id:     The oauth application id.
+        #     client_secret: Same as refresh_token.
+        #     refresh_token: The oauth application refresh token. Refresh token has
+        #                    precedence over client_secret.
+        #     _token:        The short-lived jwt id token that can be generated from the
+        #                    refresh token if present.
+
+        self.token_info_path = token_info_path
 
-        If the `jwt_token` is provided or set in the environment, the `token_info_path`
-        is ignored and the stored auth information, if available, is not used.
-        The `client_id` and `client_secret` are optional.
-
-        If the `client_id` and `client_secret` are provided or set in the environment,
-        the `token_info_path` is ignored and the stored auth information, if available,
-        is not used. A new jwt token will be retrieved as needed.
-
-        If neither the `jwt_token` nor the `client_id` and `client_secret` are provided
-        or set in the environment, the stored auth information is retrieved from the
-        default `token_info_path` or given `token_info_path`.
-
-        :type domain: str, optional
-        :param domain: The endpoint for auth0;
-            ``https://accounts.descarteslabs.com`` by default
-        :type scope: list(str), optional
-        :param scope: The JWT fields to be included; ``None`` by default
-        :type leeway: int, optional
-        :param leeway: JWT expiration leeway; ``500`` seconds by default
-        :type token_info_path: str, optional
-        :param token_info_path: Path to a JSON file optionally holding auth information;
-            ``~/.descarteslabs/token_info.json`` by default;
-            if set to ``None`` the logic will not search for stored auth information
-        :type client_id: str, optional
-        :param client_id: JWT client id; ``None`` by default which means it will be
-            retrieved from the environment or stored auth info if available
-        :type client_secret: str, optional
-        :param client_secret: The refresh token; ``None`` by default which means it will
-            be retrieved from the environment or the stored auth info if available
-        :type jwt_token: str, optional
-        :param jwt_token: The JWT token, if we already have one; ``None`` by default
-            which means that the token will be retrieved dynamically
-        :type refresh_token: str, optional
-        :param refresh_token: The refresh token; You can either set
-            the `client_secret` or the `refresh_token`. If both are set, they should be
-            identical'; ``None`` by default which means it will
-            be retrieved from the the environment or stored auth info if available
-        :type retries: Retry or int, optional
-        :param retries: The number of retries and backoff policy;
-            by default 5 retries with a random backoff policy between 1 and 10 seconds
-        """
         if token_info_path is Auth._default_token_info_path:
-            token_info_path = os.environ.get(
+            token_info_path = None
+            self.token_info_path = os.environ.get(
                 DESCARTESLABS_TOKEN_INFO_PATH, DEFAULT_TOKEN_INFO_PATH
             )
 
-        self.token_info_path = token_info_path
         token_info = {}
 
         # First determine if we are getting our info from the args or environment
         self.client_id = next(
             (
                 x
                 for x in (
@@ -222,256 +374,320 @@
                     os.environ.get(DESCARTESLABS_TOKEN),
                 )
                 if x is not None
             ),
             None,
         )
 
-        # Only read the stored info if the user didn't pass in any information.
-        if (
-            self.client_id is not None
-            or self.client_secret is not None
-            or self.refresh_token is not None
-            or self._token is not None
-        ):
-            # The used passed in some info; don't touch the stored info!
-            self.token_info_path = None
+        # Make sure self.refresh_token is set
+        if not self.refresh_token:
+            self.refresh_token = self.client_secret
+
+        if self.client_id or self.refresh_token or self._token:
+            # Information is provided through the environment or as argument
+            if token_info_path:
+                # Explicit token_info.json file; see if we can use it...
+                if os.path.exists(self.token_info_path):
+                    token_info = self._read_token_info(self.token_info_path)
+
+                    if (
+                        not self._token
+                        and self.client_id == token_info.get(self.KEY_CLIENT_ID)
+                        and self.refresh_token == token_info.get(self.KEY_REFRESH_TOKEN)
+                    ):
+                        self._token = token_info.get(self.KEY_JWT_TOKEN)
+            elif self.refresh_token:
+                # Make the saved JWT token file unique to the refresh token
+                token = self.refresh_token
+                token_sha1 = sha1(token.encode("utf-8")).hexdigest()
+                self.token_info_path = os.path.join(
+                    DEFAULT_TOKEN_INFO_DIR, f"{JWT_TOKEN_PREFIX}{token_sha1}.json"
+                )
+
+                if self._token:
+                    self._write_token_info(
+                        self.token_info_path, {self.KEY_JWT_TOKEN: self._token}
+                    )
+                else:
+                    self._token = self._read_token_info(
+                        self.token_info_path, suppress_warning=True
+                    ).get(self.KEY_JWT_TOKEN)
         elif self.token_info_path:
-            # Info is missing; read the stored info
+            # All information comes from the cached token_info.json file
             token_info = self._read_token_info(self.token_info_path, _suppress_warning)
 
-            # Fill in the missing information
-            if self.client_id is None:
-                self.client_id = token_info.get(self.KEY_CLIENT_ID)
-
-            if self.client_secret is None:
-                self.client_secret = token_info.get(self.KEY_CLIENT_SECRET)
-
-            if self.refresh_token is None:
-                self.refresh_token = token_info.get(self.KEY_REFRESH_TOKEN)
-
-            if self._token is None:
-                self._token = next(
-                    (
-                        x
-                        for x in (
-                            token_info.get(self.KEY_ALT_JWT_TOKEN),
-                            token_info.get(self.KEY_JWT_TOKEN),
-                        )
-                        if x is not None
-                    ),
-                    None,
-                )
+            self.client_id = token_info.get(self.KEY_CLIENT_ID)
+            self.client_secret = token_info.get(self.KEY_CLIENT_SECRET)
+            self.refresh_token = token_info.get(self.KEY_REFRESH_TOKEN)
+            self._token = next(
+                (
+                    x
+                    for x in (
+                        token_info.get(self.KEY_ALT_JWT_TOKEN),
+                        token_info.get(self.KEY_JWT_TOKEN),
+                    )
+                    if x is not None
+                ),
+                None,
+            )
 
         # The refresh token and client secret should be identical if both set
-        if self.client_secret != self.refresh_token:
-            if self.client_secret is not None and self.refresh_token is not None:
-                warnings.warn(
-                    "Authentication token mismatch: "
-                    "client_secret and refresh_token values must match for authentication to work correctly. "
-                )
+        if (
+            self.client_secret
+            and self.refresh_token
+            and self.client_secret != self.refresh_token
+        ):
+            warnings.warn(
+                "Authentication token mismatch: both the client secret and the "
+                "refresh token are provided but differ in value; "
+                "the refresh token will be used for authentication.",
+                stacklevel=2,
+            )
 
-            # Make sure they're identical. Refresh token has precedence
-            if self.refresh_token is not None:
-                self.client_secret = self.refresh_token
-            elif self.client_secret is not None:
-                self.refresh_token = self.client_secret
+        # Make sure they're identical. Refresh token has precedence.
+        if self.refresh_token:
+            self.client_secret = self.refresh_token
+        elif self.client_secret:
+            self.refresh_token = self.client_secret
 
         self.scope = next(
             (x for x in (scope, token_info.get(self.KEY_SCOPE)) if x is not None), None
         )
 
-        if token_info:
-            # If the token was read from a path but environment variables were set,
-            # we may need to reset the token.
-            client_id_changed = (
-                token_info.get(self.KEY_CLIENT_ID, None) != self.client_id
-            )
-            client_secret_changed = (
-                token_info.get(self.KEY_CLIENT_SECRET, None) != self.client_secret
-            )
-            refresh_token_changed = (
-                token_info.get(self.KEY_REFRESH_TOKEN, None) != self.refresh_token
-            )
-
-            if client_id_changed or client_secret_changed or refresh_token_changed:
+        # Verify that the token is valid; otherwise clear it
+        if self._token:
+            try:
+                payload = self._get_payload(self._token)
+            except AuthError:
                 self._token = None
+            else:
+                if self._token_expired(payload) or (
+                    self.client_id and payload.get("aud") != self.client_id
+                ):
+                    self._token = None
 
-        if not _suppress_warning and self.client_id is None and self._token is None:
-            warnings.warn(self.AUTHORIZATION_ERROR.format(""))
+        if not _suppress_warning and not (
+            self._token or (self.client_id and self.refresh_token)
+        ):
+            # Won't authn if we don't have a token or a client_id/refresh_token pair
+            warnings.warn(self.AUTHORIZATION_ERROR.format(""), stacklevel=2)
 
         self._namespace = None
 
         if retries is None:
-            self._adapter = self.ADAPTER
-        else:
-            self.RETRY_CONFIG = retries
-            self._init_adapter()
+            retries = self.RETRY_CONFIG
 
+        self._retry_config = retries
         self._init_session()
-        self.domain = domain
         self.leeway = leeway
 
+        if domain is None:
+            domain = get_default_domain()
+
+        self.domain = domain
+
     @classmethod
     def from_environment_or_token_json(cls, **kwargs):
-        """
+        """Creates an Auth object from the given arguments.
+
         Creates an Auth object from the given arguments,
         environment variables, or stored credentials.
 
         See :py:class:`Auth` for details.
         """
         return Auth(**kwargs)
 
-    def _init_adapter(self):
-        self._adapter = ThreadLocalWrapper(
-            lambda: HTTPAdapter(max_retries=self.RETRY_CONFIG)
-        )
-
     def _init_session(self):
         # Sessions can't be shared across threads or processes because the underlying
         # SSL connection pool can't be shared. We create them thread-local to avoid
         # intractable exceptions when users naively share clients e.g. when using
         # multiprocessing.
         self._session = ThreadLocalWrapper(self.build_session)
 
+    def _token_expired(self, payload, leeway=0):
+        exp = payload.get("exp")
+
+        if exp is not None:
+            now = (
+                datetime.datetime.utcnow() - datetime.datetime(1970, 1, 1)
+            ).total_seconds()
+
+            return now + leeway > exp
+
+        return True  # Must have exp
+
     @property
     def token(self):
-        """
-        Gets the token.
+        """Gets the short-lived JWT access token.
 
-        :rtype: str
-        :return: The JWT token string.
-
-        :raises ~descarteslabs.client.exceptions.AuthError: Raised when
-            incomplete information has been provided.
-        :raises ~descarteslabs.client.exceptions.OauthError: Raised when
-            a token cannot be obtained or refreshed.
+        Returns
+        -------
+        str
+            The JWT token string.
+
+        Raises
+        ------
+        AuthError
+            Raised when incomplete credentials were provided.
+        OauthError
+            Raised when a token cannot be obtained or refreshed.
         """
         if self._token is None:
             self._get_token()
         else:  # might have token but could be close to expiration
-            exp = self.payload.get("exp")
+            payload = self._get_payload(self._token)
 
-            if exp is not None:
-                now = (
-                    datetime.datetime.utcnow() - datetime.datetime(1970, 1, 1)
-                ).total_seconds()
-                if now + self.leeway > exp:
-                    try:
-                        self._get_token()
-                    except AuthError as e:
-                        # Unable to refresh, raise if now > exp
-                        if now > exp:
-                            raise e
+            if self._token_expired(payload, self.leeway):
+                try:
+                    self._get_token()
+                except AuthError as e:
+                    # Unable to refresh, raise if truly expired
+                    if self._token_expired(payload):
+                        raise e
 
         return self._token
 
     @property
     def payload(self):
-        """
-        Gets the token payload.
+        """Gets the token payload.
 
-        :rtype: dict
-        :return: Dictionary containing the fields specified by scope, which may include:
+        Returns
+        -------
+        dict
+            Dictionary containing the fields specified by scope, which may include:
 
             .. highlight:: none
 
             ::
 
                 name:           The name of the user.
                 groups:         Groups to which the user belongs.
                 org:            The organization to which the user belongs.
                 email:          The email address of the user.
                 email_verified: True if the user's email has been verified.
                 sub:            The user identifier.
                 exp:            The expiration time of the token, in seconds since
                                 the start of the unix epoch.
 
-        :raises ~descarteslabs.client.exceptions.AuthError: Raised when
-            incomplete information has been provided.
-        :raises ~descarteslabs.client.exceptions.OauthError: Raised when
-            a token cannot be obtained or refreshed.
+        Raises
+        ------
+        AuthError
+            Raised when incomplete credentials were provided.
+        OauthError
+            Raised when a token cannot be obtained or refreshed.
         """
-        if self._token is None:
-            self._get_token()
+        return self._get_payload(self.token)
 
-        if isinstance(self._token, six.text_type):
-            token = self._token.encode("utf-8")
-        else:
-            token = self._token
+    @staticmethod
+    def _get_payload(token):
+        if isinstance(token, str):
+            token = token.encode("utf-8")
+
+        if isinstance(token, str):
+            token = token.encode("utf-8")
 
         try:
+            # Anything that goes wrong here means it's a bad token
             claims = token.split(b".")[1]
             return json.loads(base64url_decode(claims).decode("utf-8"))
-        except (
-            IndexError,
-            UnicodeDecodeError,
-            binascii.Error,
-            json.JSONDecodeError,
-        ) as e:
-            raise AuthError("Unable to read token: {}".format(e))
+        except Exception as e:
+            raise AuthError("Unable to read token {}: {}".format(token, e))
 
     @property
     def session(self):
-        """
-        Gets the request session used to communicate with the OAuth server.
-
-        :rtype: requests.Session
-        :return: Session object
-        """
         return self._session.get()
 
     def build_session(self):
-        session = requests.Session()
-        session.mount("https://", self.ADAPTER.get())
-        return session
+        return Session(self.domain, retries=self._retry_config)
+
+    @staticmethod
+    def get_default_auth():
+        """Retrieve the default Auth.
+
+        This Auth is used whenever you don't explicitly set the Auth
+        when creating clients, etc.
+        """
+        if Auth._instance is None:
+            Auth._instance = Auth()
+
+        return Auth._instance
+
+    @staticmethod
+    def set_default_auth(auth):
+        """Change the default Auth to the given Auth.
+
+        This is the Auth that will be used whenever you don't explicitly set the
+        Auth when creating clients, etc.
+        """
+        Auth._instance = auth
 
     @staticmethod
     def _read_token_info(path, suppress_warning=False):
+        if os.environ.get("DESCARTESLABS_NO_JWT_CACHE", "").lower() == "true":
+            return {}
+
         try:
             with open(path) as fp:
                 return json.load(fp)
-        except (IOError, ValueError) as e:
+        except Exception as e:
             if not suppress_warning:
                 warnings.warn(
                     "Unable to read token_info from {} with error {}.".format(
                         path, str(e)
-                    )
+                    ),
+                    stacklevel=3,
                 )
 
         return {}
 
     @staticmethod
     def _write_token_info(path, token_info):
         token_info_directory = os.path.dirname(path)
         temp_prefix = ".{}.".format(os.path.basename(path))
-        makedirs_if_not_exists(token_info_directory)
 
         fd = None
         temp_path = None
+        suppress_warning = False
 
         try:
+            if Auth.KEY_JWT_TOKEN in token_info:
+                token = token_info[Auth.KEY_JWT_TOKEN]
+
+                if isinstance(token, bytes):
+                    token_info[Auth.KEY_JWT_TOKEN] = token.decode("utf-8")
+
+            makedirs_if_not_exists(token_info_directory)
             fd, temp_path = tempfile.mkstemp(
                 prefix=temp_prefix, dir=token_info_directory
             )
 
-            with os.fdopen(fd, "w+") as fp:
-                json.dump(token_info, fp)
+            if JWT_TOKEN_PREFIX in path:
+                token_info = {Auth.KEY_JWT_TOKEN: token_info[Auth.KEY_JWT_TOKEN]}
+                suppress_warning = True
+
+            try:
+                with os.fdopen(fd, "w+") as fp:
+                    json.dump(token_info, fp)
+            finally:
+                fd = None  # Closed now
 
-            fd = None  # Closed now
             os.chmod(temp_path, stat.S_IRUSR | stat.S_IWUSR)
 
             try:
                 os.rename(temp_path, path)
             except FileExistsError:
                 # On windows remove the file first
                 os.remove(path)
                 os.rename(temp_path, path)
-        except IOError as e:
-            warnings.warn("Failed to save token: {}".format(e))
+        except Exception as e:
+            if not suppress_warning:
+                warnings.warn(
+                    "Failed to save token: {}".format(e),
+                    stacklevel=3,
+                )
         finally:
             if fd is not None:
                 os.close(fd)
 
             if temp_path is not None and os.path.exists(temp_path):
                 os.remove(temp_path)
 
@@ -481,15 +697,15 @@
 
         if self.client_secret is None and self.refresh_token is None:
             raise AuthError(
                 self.AUTHORIZATION_ERROR.format(" (no client_secret or refresh_token)")
             )
 
         if self.client_id in [
-            "ZOBAi4UROl5gKZIpxxlwOEfx8KpqXf2c"
+            "ZOBAi4UROl5gKZIpxxlwOEfx8KpqXf2c",
         ]:  # TODO(justin) remove legacy handling
             # TODO (justin) insert deprecation warning
             if self.scope is None:
                 scope = ["openid", "name", "groups", "org", "email"]
             else:
                 scope = self.scope
             params = {
@@ -506,15 +722,15 @@
                 self.KEY_GRANT_TYPE: "refresh_token",
                 self.KEY_REFRESH_TOKEN: self.refresh_token,
             }
 
             if self.scope is not None:
                 params[self.KEY_SCOPE] = " ".join(self.scope)
 
-        r = self.session.post(self.domain + "/token", json=params, timeout=timeout)
+        r = self.session.post("/token", json=params, timeout=timeout)
 
         if r.status_code != 200:
             raise OauthError("Could not retrieve token: {}".format(r.text.strip()))
 
         data = r.json()
         access_token = data.get("access_token")
         id_token = data.get("id_token")  # TODO(justin) remove legacy id_token usage
@@ -524,52 +740,62 @@
         elif id_token is not None:
             self._token = id_token
         else:
             raise OauthError("Could not retrieve token")
 
         token_info = {}
 
-        # If we read the token from the token_info_path, save it again
+        # Read the token from the token_info_path, and save it again
         if self.token_info_path:
-            token_info = self._read_token_info(self.token_info_path)
-
-            if not token_info:
-                return
+            token_info = self._read_token_info(
+                self.token_info_path, suppress_warning=True
+            )
 
-        token_info[self.KEY_JWT_TOKEN] = self._token
-        token_info.pop(self.KEY_ALT_JWT_TOKEN, None)  # Make sure the alt key is removed
+            if (
+                token_info.get(self.KEY_CLIENT_ID) != self.client_id
+                or token_info.get(self.KEY_CLIENT_SECRET) != self.client_secret
+            ):
+                # Not matching; better rewrite!
+                token_info = {
+                    self.KEY_CLIENT_ID: self.client_id,
+                    self.KEY_CLIENT_SECRET: self.client_secret,
+                    self.KEY_REFRESH_TOKEN: self.refresh_token,
+                }
 
-        if self.token_info_path:
+            token_info[self.KEY_JWT_TOKEN] = self._token
+            token_info.pop(self.KEY_ALT_JWT_TOKEN, None)  # Remove alt key
             self._write_token_info(self.token_info_path, token_info)
 
     @property
     def namespace(self):
-        """
-        Gets the user namespace.
-
-        :rtype: str
-        :return: The user namespace
+        """Gets the user namespace (the Descartes Labs used id).
 
-        :raises ~descarteslabs.client.exceptions.AuthError: Raised when
-            incomplete information has been provided.
-        :raises ~descarteslabs.client.exceptions.OauthError: Raised when
-            a token cannot be obtained or refreshed.
+        Returns
+        -------
+        str
+            The user namespace.
+
+        Raises
+        ------
+        AuthError
+            Raised when incomplete credentials were provided.
+        OauthError
+            Raised when a token cannot be obtained or refreshed.
         """
         if self._namespace is None:
             self._namespace = sha1(self.payload["sub"].encode("utf-8")).hexdigest()
         return self._namespace
 
     def __getstate__(self):
         return dict((attr, getattr(self, attr)) for attr in self.__attrs__)
 
     def __setstate__(self, state):
         for name, value in state.items():
             setattr(self, name, value)
 
-        self._init_adapter()
         self._init_session()
 
 
 if __name__ == "__main__":
-    auth = Auth()
+    auth = Auth.get_default_auth()
 
     print(auth.token)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/auth/cli.py` & `descarteslabs-2.0.0/descarteslabs/core/client/auth/cli.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,69 +1,71 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
-import os
-import json
-import six
 import binascii
-
-from six.moves import input
+import json
+import os
 from pprint import pprint
 
-from descarteslabs.client.auth.auth import (
-    Auth,
-    base64url_decode,
+from descarteslabs.auth.auth import (
     DEFAULT_TOKEN_INFO_PATH,
-    DESCARTESLABS_TOKEN_INFO_PATH,
     DESCARTESLABS_CLIENT_ID,
     DESCARTESLABS_CLIENT_SECRET,
     DESCARTESLABS_REFRESH_TOKEN,
+    DESCARTESLABS_TOKEN_INFO_PATH,
+    Auth,
+    base64url_decode,
 )
-from descarteslabs.client.version import __version__
 
+from ..version import __version__
+
+
+def get_default_domain():
+    from descarteslabs.auth.auth import get_default_domain as get_auth_domain
 
-LOGIN_URL = "https://iam.descarteslabs.com/auth/refresh_token"
+    return get_auth_domain()
 
 
 def auth_handler(args):
     auth = Auth(_suppress_warning=True)
+    login_url = f"{get_default_domain()}/auth/refresh_token"
 
     if args.command == "login":
-        print(f"Follow this link to login:\n\n    {LOGIN_URL}\n")
+        print(f"Follow this link to login:\n\n    {login_url}\n")
 
         while True:
             try:
                 s = input("...then come back here and paste the generated token: ")
 
                 if not s:
                     raise KeyboardInterrupt()
             except KeyboardInterrupt:
                 print("\nExiting without logging in")
                 break
 
-            if isinstance(s, six.text_type):
+            if isinstance(s, str):
                 s = s.encode("utf-8")
 
             if s:
                 retry_message = f"""
 You entered the wrong token. Please go to
 
-    {LOGIN_URL}
+    {login_url}
 
 to retrieve your token"""
 
                 try:
                     json_data = base64url_decode(s).decode("utf-8")
                 except (UnicodeDecodeError, binascii.Error):
                     print(retry_message)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/auth/tests/test_cli.py` & `descarteslabs-2.0.0/descarteslabs/core/client/auth/tests/test_cli.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# 2018-2020 Descartes Labs.
+# 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,18 +14,20 @@
 
 import binascii
 import builtins
 import json
 import os
 import sys
 import unittest
+from unittest.mock import patch
 
-from descarteslabs.client.exceptions import AuthError
-from descarteslabs.client.auth.cli import auth_handler
-from mock import patch
+from descarteslabs.exceptions import AuthError
+
+from .. import cli
+from ..cli import auth_handler
 
 
 class Args:
     command = "login"
 
 
 class Input:
@@ -104,16 +106,16 @@
 
 
 #
 # Note that the `open()` patch cannot be shared across tests.
 # Note that the environment must be cleaned in order to get
 # expected behavior (i.e. no credentials present).
 #
-@patch("descarteslabs.client.auth.auth.makedirs_if_not_exists")
-@patch("descarteslabs.client.auth.cli.os")
+@patch("descarteslabs.auth.auth.makedirs_if_not_exists")
+@patch("descarteslabs.auth.auth.get_default_domain", return_value="some_domain")
 class TestAuth(unittest.TestCase):
     def setUp(self):
         # Clean up the environment
         CLIENT_ID = "CLIENT_ID"
         CLIENT_SECRET = "CLIENT_SECRET"
 
         if CLIENT_ID in os.environ:
@@ -128,34 +130,34 @@
         if hasattr(self, "client_id"):
             os.environ["CLIENT_ID"] = self.client_id
 
         if hasattr(self, "client_secret"):
             os.environ["CLIENT_SECRET"] = self.client_secret
 
     # Test simple bad input
-    @patch("descarteslabs.client.auth.cli.input", Input("foo", "foo.bar"))
+    @patch.object(cli, "input", Input("foo", "foo.bar"))
     @patch("builtins.print", Print(None, UnicodeDecodeError, binascii.Error))
     @patch("builtins.open", Open(PAYLOAD))
     def test_invalid_token(self, *mocks):
         auth_handler(Args)
 
     # Test incorrect json
-    @patch("descarteslabs.client.auth.cli.input", Input("VGhpcyBpcyBhIHRlc3Q="))
+    @patch.object(cli, "input", Input("VGhpcyBpcyBhIHRlc3Q="))
     @patch("builtins.print", Print(None, json.JSONDecodeError))
     @patch("builtins.open", Open(PAYLOAD))
     def test_invalid_json(self, *mocks):
         auth_handler(Args)
 
     # Test incorrect character set. Base64encoded CP51932: This is  test
-    @patch("descarteslabs.client.auth.cli.input", Input("VGhpcyBpcyCh5yB0ZXN0"))
+    @patch.object(cli, "input", Input("VGhpcyBpcyCh5yB0ZXN0"))
     @patch("builtins.print", Print(None, UnicodeDecodeError))
     @patch("builtins.open", Open(PAYLOAD))
     def test_invalid_character(self, *mocks):
         auth_handler(Args)
 
     # Test incomplete json: {"test": "test"}
-    @patch("descarteslabs.client.auth.cli.input", Input("eyJ0ZXN0IjogInRlc3QifQ=="))
+    @patch.object(cli, "input", Input("eyJ0ZXN0IjogInRlc3QifQ=="))
     @patch("builtins.print", Print(None, None, None))
     @patch("builtins.open", Open(""))
     def test_incomplete_json(self, *mocks):
         with self.assertRaises(AuthError):
             auth_handler(Args)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/exceptions.py` & `descarteslabs-2.0.0/descarteslabs/exceptions.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 
 """Exceptions raised by HTTP clients."""
 
 
 class ClientError(Exception):
-    """ Base class for all client exceptions."""
+    """Base class for all client exceptions."""
 
     pass
 
 
 class AuthError(ClientError):
     """Authentication error, improperly supplied credentials."""
 
@@ -30,44 +30,76 @@
 
 class OauthError(AuthError):
     """Authentication error, failure from OAuth authentication service."""
 
     pass
 
 
+class ConfigError(Exception):
+    """Configuration error during initial configuration of the library."""
+
+    pass
+
+
 class ServerError(Exception):
     """Server or service failure."""
 
     status = 500
 
 
 class BadRequestError(ClientError):
-    """Client request with invalid or incorrect parameters."""
+    """Client request with incorrect parameters."""
 
     status = 400
 
 
+class ValidationError(BadRequestError):
+    """Client request with invalid parameters."""
+
+    status = 422
+
+
 class NotFoundError(ClientError):
     """Resource not found."""
 
     status = 404
 
 
 class ProxyAuthenticationRequiredError(ClientError):
-    """Client request needs proxy authentication."""
+    """Client request needs proxy authentication.
+
+    Attributes
+    ==========
+    status : int
+        The status code of the error response.
+    proxy_authenticate : Optional[str]
+        A `ProxyAuthenticate <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Proxy-Authenticate>`_
+        header if found in the response.
+    """
 
     status = 407
 
+    def __init__(self, message, proxy_authenticate=None) -> None:
+        super(ProxyAuthenticationRequiredError, self).__init__(message)
+
+        self.proxy_authenticate = proxy_authenticate
+
 
 class ConflictError(ClientError):
     """Client request conflicts with existing state."""
 
     status = 409
 
 
+class GoneError(ClientError):
+    """Client request to a URL which has been permanently removed."""
+
+    status = 410
+
+
 class RateLimitError(ClientError):
     """
     Client request exceeds rate limits.
 
     The retry_after member will contain any time limit returned
     in the response.
     """
@@ -93,7 +125,11 @@
     status = 449
 
 
 class GatewayTimeoutError(ServerError):
     """Timeout from the gateway after failing to route request to destination service."""
 
     status = 504
+
+
+class RequestCancellationError(ClientError):
+    """Client cancelled the request and no status or response was received."""
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/scripts/__init__.py` & `descarteslabs-2.0.0/descarteslabs/scenes/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,15 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+
+from descarteslabs.core.scenes import *  # noqa F401 F403
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/scripts/__main__.py` & `descarteslabs-2.0.0/descarteslabs/core/common/collection/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,17 @@
-#!/usr/bin/env python
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from descarteslabs.client.scripts.cli import parser, handle
+from .collection import Collection, Eacher
 
-
-def main():
-    try:
-        handle(parser.parse_args())
-    except Exception as e:
-        print("{}: {}".format(e.__class__.__name__, e))
-
-
-if __name__ == "__main__":
-    main()
+__all__ = ["Collection", "Eacher"]
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/scripts/cli.py` & `descarteslabs-2.0.0/descarteslabs/core/client/scripts/cli.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 #!/usr/bin/env python
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,18 +13,18 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 # flake8: noqa
 
 
 import argparse
-from descarteslabs.client.auth.cli import auth_handler
-from descarteslabs.client.services.metadata.cli import metadata_handler
-from descarteslabs.client.services.raster.cli import scales, raster_handler
-from descarteslabs.client.services.places.cli import places_handler
+from ..auth.cli import auth_handler
+from ..services.metadata.cli import metadata_handler
+from ..services.raster.cli import scales, raster_handler
+from ..version import __version__
 
 
 parser = argparse.ArgumentParser()
 subparsers = parser.add_subparsers(dest="group")
 
 # Auth Group
 auth_parser = subparsers.add_parser("auth")
@@ -59,56 +59,38 @@
 metadata_parser.add_argument("-offset", help="Number of items to skip (default 0)")
 metadata_parser.add_argument(
     "-bbox",
     help="Whether or not to use a bounding box filter (default: false)",
     action="store_true",
 )
 
-# Places Group
-places_parser = subparsers.add_parser("places")
-places_parser.add_argument(
-    "command",
-    choices=["find", "shape", "prefix", "placetypes"],
-    help="The action to take.",
-)
-places_parser.add_argument("argument", nargs="?")
-
-places_parser.add_argument("-url", help="The url of the service")
-places_parser.add_argument(
-    "-placetype", default=None, help="The placetype of the response"
-)
-places_parser.add_argument(
-    "-geom",
-    default="low",
-    choices=["low", "medium", "high", "None"],
-    help="Resolution of shape",
-)
-places_parser.add_argument("-output", default="geojson")
-
 # Raster Group
 raster_parser = subparsers.add_parser("raster")
 raster_parser.add_argument("inputs", type=str, nargs="+")
 raster_parser.add_argument("-bands", nargs="+", default=None, type=str)
 raster_parser.add_argument("-scales", default=None, type=scales, nargs="+")
 raster_parser.add_argument("-resolution", default=240, type=float)
 raster_parser.add_argument("-output_format", default="GTiff", type=str)
 raster_parser.add_argument("-data_type", default="UInt16", type=str)
 raster_parser.add_argument("-srs", default=None, type=str)
 raster_parser.add_argument("-place", default=None, type=str)
 raster_parser.add_argument("-outfile_basename", default=None, type=str)
 
+# Version
+auth_parser = subparsers.add_parser("version")
+
 
 def handle(args):
     if args.group == "auth":
         auth_handler(args)
     elif args.group == "metadata":
         metadata_handler(args)
-    elif args.group == "places":
-        places_handler(args)
     elif args.group == "raster":
         raster_handler(args)
+    elif args.group == "version":
+        print(__version__)
     else:
-        print("invalid command group")
+        print("invalid command: choose from 'auth', 'metadata', 'raster', 'version'")
 
 
 if __name__ == "__main__":
     handle(parser.parse_args())
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/scripts/tests/test_scripts.py` & `descarteslabs-2.0.0/descarteslabs/core/client/scripts/tests/test_scripts.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import unittest
-import mock
+from unittest import mock
 import os
-from six import StringIO
-from descarteslabs.client.scripts.cli import parser, handle
+from io import StringIO
+from ..cli import parser, handle
 import base64
 import json
 import pytest
 
 
 class TestScripts(unittest.TestCase):
     old_token = None
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/metadata/cli.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/cli.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 #!/usr/bin/env python
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/metadata/metadata.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/metadata.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,97 +1,98 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import json
-import os
 import itertools
-from six import string_types
-from descarteslabs.client.services.service import Service
-from descarteslabs.client.services.places import Places
-from descarteslabs.client.auth import Auth
-from descarteslabs.client.deprecation import check_deprecated_kwargs
-from descarteslabs.common.property_filtering.filtering import (
-    AndExpression,
-    GenericProperties,
-)
-from descarteslabs.common.dotdict import DotDict, DotList
-from descarteslabs.common.dltile import Tile
-from descarteslabs.common.shapely_support import shapely_to_geojson
 
+from ..service import Service
+from descarteslabs.auth import Auth
+from descarteslabs.config import get_settings
+from ...deprecation import deprecate
+from ....common import property_filtering
+from ....common.dotdict import DotDict, DotList
+from ....common.dltile import Tile
+from ....common.http.service import DefaultClientMixin
+from ....common.shapely_support import shapely_to_geojson
 
-class Metadata(Service):
+
+class Metadata(Service, DefaultClientMixin):
     """
     Image Metadata Service
 
     Any methods that take start and end timestamps accept most common date/time
     formats as a string. If no explicit timezone is given, the timestamp is assumed
     to be in UTC. For example ``'2012-06-01'`` means June 1st 2012 00:00 in UTC,
     ``'2012-06-01 00:00+02:00'`` means June 1st 2012 00:00 in GMT+2.
     """
 
     TIMEOUT = (9.5, 120)
 
-    properties = GenericProperties()
+    properties = property_filtering.Properties()
 
     def __init__(self, url=None, auth=None, retries=None):
         """
-        :param str url: A HTTP URL pointing to a version of the storage service
-            (defaults to current version)
+        :param str url: URL for the metadata service.  Only change
+            this if you are being asked to use a non-default Descartes Labs catalog.  If
+            not set, then ``descarteslabs.config.get_settings().METADATA_URL`` will be used.
         :param Auth auth: A custom user authentication (defaults to the user
             authenticated locally by token information on disk or by environment
             variables)
         :param urllib3.util.retry.Retry retries: A custom retry configuration
             used for all API requests (defaults to a reasonable amount of retries)
         """
         if auth is None:
-            auth = Auth()
+            auth = Auth.get_default_auth()
 
         if url is None:
-            url = os.environ.get(
-                "DESCARTESLABS_METADATA_URL",
-                "https://platform.descarteslabs.com/metadata/v1",
-            )
+            url = get_settings().metadata_url
 
         super(Metadata, self).__init__(url, auth=auth, retries=retries)
 
     def bands(
         self,
-        products=None,
+        products,
         limit=None,
         offset=None,
         wavelength=None,
         resolution=None,
         tags=None,
         bands=None,
         **kwargs
     ):
         """Search for imagery data bands that you have access to.
 
-        :param list(str) products: A list of product(s) to return bands for.
+        :param list(str) products: A list of product(s) to return bands for. May
+          not be empty.
         :param int limit: Number of results to return.
         :param int offset: Index to start at when returning results.
         :param float wavelength: A wavelength in nm e.g 700 that the band sensor must measure.
         :param int resolution: The resolution in meters per pixel e.g 30 of the data available in this band.
         :param list(str) tags: A list of tags that the band must have in its own tag list.
 
         :return: List of dicts containing at most `limit` bands. Empty if there are no
             bands matching query (e.g. product id not available).
         :rtype: DotList(DotDict)
         """
+        if not products:
+            raise ValueError(
+                "One or more products must be specified to search for bands"
+            )
+
         params = ["limit", "offset", "products", "wavelength", "resolution", "tags"]
 
         args = locals()
         kwargs = dict(
             kwargs,
             **{param: args[param] for param in params if args[param] is not None}
         )
@@ -132,43 +133,44 @@
         For a given image source id, return the available bands.
 
         :param str id_: A :class:`Metadata` image identifier.
 
         :return: A dictionary of band entries and their metadata.
         :rtype: DotDict
 
-        :raises ~descarteslabs.client.exceptions.NotFoundError: Raised if image id cannot
+        :raises ~descarteslabs.exceptions.NotFoundError: Raised if image id cannot
             be found.
 
         Example::
 
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> bands = Metadata().get_bands_by_id('landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1')
             >>> ndvi_info = bands['derived:ndvi'] # View NDVI band information
             >>> ndvi_info['physical_range']
             [-1.0, 1.0]
         """
         r = self.session.get("/bands/id/{}".format(id_))
 
         return DotDict(r.json())
 
     def get_bands_by_product(self, product_id):
         """
-        All bands (includig derived bands) available in a product.
+        All bands (including derived bands) available in a product.
 
         :param str product_id: A product identifier.
 
         :return: A dictionary mapping band ids to dictionaries of their metadata.
             Returns empty dict if product id not found.
         :rtype: DotDict
         """
         r = self.session.get("/bands/all/{}".format(product_id))
 
         return DotDict(r.json())
 
+    @deprecate(renamed={"band": "bands"})
     def products(
         self, bands=None, limit=None, offset=None, owner=None, text=None, **kwargs
     ):
         """Search products that are available on the platform.
 
         :param list(str) bands: Band name(s) e.g ["red", "nir"] to filter products by.
                                 Note that products must match all bands that are passed.
@@ -177,79 +179,97 @@
         :param str owner: Filter products by the owner's uuid.
         :param str text: Filter products by string match.
 
         :return: List of dicts containing at most `limit` products. Empty if no matching
             products are found.
         :rtype: DotList(DotDict)
         """
-        params = ["limit", "offset", "bands", "owner", "text"]
-
+        keys = ["limit", "offset", "bands", "owner", "text"]
         args = locals()
-        kwargs = dict(
-            kwargs,
-            **{param: args[param] for param in params if args[param] is not None}
-        )
-        check_deprecated_kwargs(kwargs, {"band": "bands"})
+        params = {key: args[key] for key in keys if args[key]}
 
-        r = self.session.post("/products/search", json=kwargs)
+        # sets minumum limit
+        params["limit"] = 1000 if limit is None else min(limit, 1000)
 
-        return DotList(r.json())
+        # Add parameters that were set to kwargs
+        kwargs = dict(kwargs, **params)
+
+        products = []
+        continuation_token = None
+        while limit is None or len(products) < limit:
+            if continuation_token:
+                kwargs["continuation_token"] = continuation_token
+
+            r = self.session.post("/products/search", json=kwargs)
+            continuation_token = r.headers.get("X-Continuation-Token")
+            paged_response = r.json()
+            products.extend(paged_response)
+            if not continuation_token or not paged_response:
+                break
+
+        return DotList(products[:limit])
 
     def available_products(self):
         """Get the list of product identifiers you have access to.
 
         :return: List of product ids
         :rtype: DotList
 
         Example::
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> products = Metadata().available_products()
             >>> products  # doctest: +SKIP
             ['landsat:LC08:PRE:TOAR']
         """
-        r = self.session.get("/products")
-
-        return DotList(r.json())
+        return DotList(p.id for p in self.products())
 
+    @deprecate(
+        renamed={
+            "product": "products",
+            "const_id": "const_ids",
+            "sat_id": "sat_ids",
+            "start_time": "start_datetime",
+            "end_time": "end_datetime",
+            "part": "interval",
+        },
+    )
     def summary(
         self,
-        products=None,
+        products,
         sat_ids=None,
         date="acquired",
         interval=None,
-        place=None,
         geom=None,
         start_datetime=None,
         end_datetime=None,
         cloud_fraction=None,
         cloud_fraction_0=None,
         fill_fraction=None,
         storage_state=None,
         q=None,
         pixels=None,
         dltile=None,
         **kwargs
     ):
         """Get a summary of the results for the specified spatio-temporal query.
 
-        :param list(str) products: Product identifier(s).
+        :param list(str) products: Product identifier(s). May not be empty.
         :param list(str) sat_ids: Satellite identifier(s).
         :param str date: The date field to use for search (e.g. `acquired`).
         :param str interval: Part of the date to aggregate over (e.g. `day`).
             The list of possibilites is:
 
             * ``year`` or ``y``
             * ``quarter``
             * ``month`` or ``M``
             * ``week`` or ``q``
             * ``day`` or ``d``
             * ``hour`` or ``h``
             * ``minute`` or ``m``
             * ``product``
-        :param str place: A slug identifier to be used as a region of interest.
         :param str geom: A GeoJSON or WKT region of interest or a Shapely shape object.
         :param str start_datetime: Desired starting timestamp, in any common format.
         :param str end_datetime: Desired ending timestamp, in any common format.
         :param float cloud_fraction: Maximum cloud fraction, calculated by data provider.
         :param float cloud_fraction_0: Maximum cloud fraction, calculated by cloud mask pixels.
         :param float fill_fraction: Minimum scene fill fraction, calculated as valid/total pixels.
         :param str storage_state: Filter results based on `storage_state` value. Allowed values are `"available"`,
@@ -263,15 +283,15 @@
 
         :return: Dictionary containing summary of products that match query. Empty products list
             if no matching products found.
         :rtype: DotDict
 
         Example::
 
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> iowa_geom = {
             ...     "coordinates": [[
             ...         [-96.498997, 42.560832],
             ...         [-95.765645, 40.585208],
             ...         [-91.729115, 40.61364],
             ...         [-91.391613, 40.384038],
             ...         [-90.952233, 40.954047],
@@ -310,49 +330,32 @@
                     'timestamp': 1467824400
                   }
                 ],
                 'pixels': 751782336,
                 'products': ['landsat:LC08:PRE:TOAR']
             }
         """
-        check_deprecated_kwargs(
-            kwargs,
-            {
-                "product": "products",
-                "const_id": "const_ids",
-                "sat_id": "sat_ids",
-                "start_time": "start_datetime",
-                "end_time": "end_datetime",
-                "part": "interval",
-            },
-        )
-
-        if place:
-            places = Places()
-            places.auth = self.auth
-            shape = places.shape(place, geom="low")
-            geom = json.dumps(shape["geometry"])
 
         if dltile is not None:
-            if isinstance(dltile, string_types):
+            if isinstance(dltile, str):
                 geom = Tile.from_key(dltile).geometry
             if isinstance(dltile, dict):
                 geom = dltile["geometry"]
 
         if isinstance(geom, dict):
             geom = json.dumps(geom)
 
         if sat_ids:
-            if isinstance(sat_ids, string_types):
+            if isinstance(sat_ids, str):
                 sat_ids = [sat_ids]
 
             kwargs["sat_ids"] = sat_ids
 
         if products:
-            if isinstance(products, string_types):
+            if isinstance(products, str):
                 products = [products]
 
             kwargs["products"] = products
 
         if date:
             kwargs["date"] = date
 
@@ -377,31 +380,42 @@
 
         if fill_fraction is not None:
             kwargs["fill_fraction"] = fill_fraction
 
         if q is not None:
             if not isinstance(q, list):
                 q = [q]
-            kwargs["query_expr"] = AndExpression(q).serialize()
+            kwargs["query_expr"] = property_filtering.filtering.AndExpression(
+                q
+            ).serialize()
 
         if pixels:
             kwargs["pixels"] = pixels
 
         if storage_state:
             kwargs["storage_state"] = storage_state
 
         r = self.session.post("/summary", json=kwargs)
         return DotDict(r.json())
 
+    @deprecate(
+        renamed={
+            "product": "products",
+            "const_id": "const_ids",
+            "sat_id": "sat_ids",
+            "start_time": "start_datetime",
+            "end_time": "end_datetime",
+        },
+        deprecated=["offset"],
+    )
     def paged_search(
         self,
-        products=None,
+        products,
         sat_ids=None,
         date="acquired",
-        place=None,
         geom=None,
         start_datetime=None,
         end_datetime=None,
         cloud_fraction=None,
         cloud_fraction_0=None,
         fill_fraction=None,
         storage_state=None,
@@ -417,18 +431,17 @@
     ):
         """
         Execute a metadata query in a paged manner, with up to 10,000 items per page.
 
         Most clients should use :py:func:`features` instead, which batch searches into smaller requests
         and handles the paging for you.
 
-        :param list(str) products: Product Identifier(s).
+        :param list(str) products: Product Identifier(s). May not be empty.
         :param list(str) sat_ids: Satellite identifier(s).
         :param str date: The date field to use for search (default is `acquired`).
-        :param str place: A slug identifier to be used as a region of interest.
         :param str geom: A GeoJSON or WKT region of interest or a Shapely shape object.
         :param str start_datetime: Desired starting timestamp, in any common format.
         :param str end_datetime: Desired ending timestamp, in any common format.
         :param float cloud_fraction: Maximum cloud fraction, calculated by data provider.
         :param float cloud_fraction_0: Maximum cloud fraction, calculated by cloud mask pixels.
         :param float fill_fraction: Minimum scene fill fraction, calculated as valid/total pixels.
         :param str storage_state: Filter results based on `storage_state` value. Allowed values are
@@ -447,51 +460,34 @@
         :param str continuation_token: None for new query, or the `properties.continuation_token` value from
             the returned FeatureCollection from a previous invocation of this method to page through a large
             result set.
 
         :return: GeoJSON ``FeatureCollection`` containing at most `limit` features.
         :rtype: DotDict
         """
-        check_deprecated_kwargs(
-            kwargs,
-            {
-                "product": "products",
-                "const_id": "const_ids",
-                "sat_id": "sat_ids",
-                "start_time": "start_datetime",
-                "end_time": "end_datetime",
-                "offset": None,
-            },
-        )
-
-        if place:
-            places = Places()
-            places.auth = self.auth
-            shape = places.shape(place, geom="low")
-            geom = json.dumps(shape["geometry"])
 
         if dltile is not None:
-            if isinstance(dltile, string_types):
+            if isinstance(dltile, str):
                 geom = Tile.from_key(dltile).geometry
             if isinstance(dltile, dict):
                 geom = dltile["geometry"]
 
         if isinstance(geom, dict):
             geom = json.dumps(geom)
 
         kwargs.update({"date": date, "limit": limit})
 
         if sat_ids:
-            if isinstance(sat_ids, string_types):
+            if isinstance(sat_ids, str):
                 sat_ids = [sat_ids]
 
             kwargs["sat_ids"] = sat_ids
 
         if products:
-            if isinstance(products, string_types):
+            if isinstance(products, str):
                 products = [products]
 
             kwargs["products"] = products
 
         if geom:
             geom = shapely_to_geojson(geom)
             kwargs["geom"] = geom
@@ -516,15 +512,17 @@
 
         if fields is not None:
             kwargs["fields"] = fields
 
         if q is not None:
             if not isinstance(q, list):
                 q = [q]
-            kwargs["query_expr"] = AndExpression(q).serialize()
+            kwargs["query_expr"] = property_filtering.filtering.AndExpression(
+                q
+            ).serialize()
 
         if sort_field is not None:
             kwargs["sort_field"] = sort_field
 
         if sort_order is not None:
             kwargs["sort_order"] = sort_order
 
@@ -539,20 +537,27 @@
         fc = {"type": "FeatureCollection", "features": r.json()}
 
         if "x-continuation-token" in r.headers:
             fc["properties"] = {"continuation_token": r.headers["x-continuation-token"]}
 
         return DotDict(fc)
 
+    @deprecate(
+        renamed={
+            "product": "products",
+            "sat_id": "sat_ids",
+            "start_time": "start_datetime",
+            "end_time": "end_datetime",
+        },
+    )
     def search(
         self,
-        products=None,
+        products,
         sat_ids=None,
         date="acquired",
-        place=None,
         geom=None,
         start_datetime=None,
         end_datetime=None,
         cloud_fraction=None,
         cloud_fraction_0=None,
         fill_fraction=None,
         storage_state=None,
@@ -566,18 +571,17 @@
         **kwargs
     ):
         """Search metadata given a spatio-temporal query. All parameters are
         optional.
 
         If performing a large query, consider using the iterator :py:func:`features` instead.
 
-        :param list(str) products: Product Identifier(s).
+        :param list(str) products: Product Identifier(s). May not be empty.
         :param list(str) sat_ids: Satellite identifier(s).
         :param str date: The date field to use for search (e.g. `acquired`).
-        :param str place: A slug identifier to be used as a region of interest.
         :param str geom: A GeoJSON or WKT region of interest.
         :param str start_datetime: Desired starting timestamp, in any common format.
         :param str end_datetime: Desired ending timestamp, in any common format.
         :param float cloud_fraction: Maximum cloud fraction, calculated by data provider.
         :param float cloud_fraction_0: Maximum cloud fraction, calculated by cloud mask pixels.
         :param float fill_fraction: Minimum scene fill fraction, calculated as valid/total pixels.
         :param str storage_state: Filter results based on `storage_state` value. Allowed values are
@@ -598,15 +602,15 @@
         :rtype: DotDict
 
         Note that as of release 0.16.0 the ``continuation_token`` token has been removed. Please use the
         :py:func:`paged_search` if you require this feature.
 
         Example::
 
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> iowa_geom = {
             ...     "coordinates": [[
             ...         [-96.498997, 42.560832],
             ...         [-95.765645, 40.585208],
             ...         [-91.729115, 40.61364],
             ...         [-91.391613, 40.384038],
             ...         [-90.952233, 40.954047],
@@ -629,15 +633,14 @@
             >>> len(scenes['features'])  # doctest: +SKIP
             2
         """
         features_iter = self.features(
             products=products,
             sat_ids=sat_ids,
             date=date,
-            place=place,
             geom=geom,
             start_datetime=start_datetime,
             end_datetime=end_datetime,
             cloud_fraction=cloud_fraction,
             cloud_fraction_0=cloud_fraction_0,
             fill_fraction=fill_fraction,
             storage_state=storage_state,
@@ -649,20 +652,27 @@
             randomize=randomize,
             batch_size=1000 if limit is None else min(limit, 1000),
             **kwargs
         )
         limited_features = itertools.islice(features_iter, limit)
         return DotDict(type="FeatureCollection", features=DotList(limited_features))
 
+    @deprecate(
+        renamed={
+            "product": "products",
+            "sat_id": "sat_ids",
+            "start_time": "start_datetime",
+            "end_time": "end_datetime",
+        },
+    )
     def ids(
         self,
-        products=None,
+        products,
         sat_ids=None,
         date="acquired",
-        place=None,
         geom=None,
         start_datetime=None,
         end_datetime=None,
         cloud_fraction=None,
         cloud_fraction_0=None,
         fill_fraction=None,
         storage_state=None,
@@ -673,18 +683,17 @@
         sort_order=None,
         randomize=None,
         **kwargs
     ):
         """Search metadata given a spatio-temporal query. All parameters are
         optional.
 
-        :param list(str) products: Products identifier(s).
+        :param list(str) products: Products identifier(s). May not be empty.
         :param list(str) sat_ids: Satellite identifier(s).
         :param str date: The date field to use for search (e.g. `acquired`).
-        :param str place: A slug identifier to be used as a region of interest.
         :param str geom: A GeoJSON or WKT region of interest.
         :param str start_datetime: Desired starting timestamp, in any common format.
         :param str end_datetime: Desired ending timestamp, in any common format.
         :param float cloud_fraction: Maximum cloud fraction, calculated by data provider.
         :param float cloud_fraction_0: Maximum cloud fraction, calculated by cloud mask pixels.
         :param float fill_fraction: Minimum scene fill fraction, calculated as valid/total pixels.
         :param str storage_state: Filter results based on `storage_state` value. Allowed values are
@@ -701,15 +710,15 @@
         :param bool randomize: Randomize the results. You may also use an `int` or `str` as an explicit seed.
 
         :return: List of image identifiers. Empty list if no matching images found.
         :rtype: DotList(str)
 
         Example::
 
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> iowa_geom = {
             ...     "coordinates": [[
             ...         [-96.498997, 42.560832],
             ...         [-95.765645, 40.585208],
             ...         [-91.729115, 40.61364],
             ...         [-91.391613, 40.384038],
             ...         [-90.952233, 40.954047],
@@ -733,15 +742,14 @@
             >>> ids  # doctest: +SKIP
             ['landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1', 'landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1']
         """
         result = self.search(
             sat_ids=sat_ids,
             products=products,
             date=date,
-            place=place,
             geom=geom,
             start_datetime=start_datetime,
             end_datetime=end_datetime,
             cloud_fraction=cloud_fraction,
             cloud_fraction_0=cloud_fraction_0,
             fill_fraction=fill_fraction,
             storage_state=storage_state,
@@ -753,20 +761,27 @@
             sort_order=sort_order,
             randomize=randomize,
             **kwargs
         )
 
         return DotList(feature["id"] for feature in result["features"])
 
+    @deprecate(
+        renamed={
+            "product": "products",
+            "sat_id": "sat_ids",
+            "start_time": "start_datetime",
+            "end_time": "end_datetime",
+        },
+    )
     def features(
         self,
-        products=None,
+        products,
         sat_ids=None,
         date="acquired",
-        place=None,
         geom=None,
         start_datetime=None,
         end_datetime=None,
         cloud_fraction=None,
         cloud_fraction_0=None,
         fill_fraction=None,
         storage_state=None,
@@ -784,15 +799,15 @@
         :param int batch_size: Number of features to fetch per request.
 
         :return: Generator of GeoJSON ``Feature`` objects. Empty if no matching images found.
         :rtype: generator
 
         Example::
 
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> features = Metadata().features(
             ...     "landsat:LC08:PRE:TOAR",
             ...     start_datetime='2016-01-01',
             ...     end_datetime="2016-03-01"
             ... )
             >>> total = 0
             >>> for f in features:
@@ -805,15 +820,14 @@
         continuation_token = None
 
         while True:
             result = self.paged_search(
                 sat_ids=sat_ids,
                 products=products,
                 date=date,
-                place=place,
                 geom=geom,
                 start_datetime=start_datetime,
                 end_datetime=end_datetime,
                 cloud_fraction=cloud_fraction,
                 cloud_fraction_0=cloud_fraction_0,
                 fill_fraction=fill_fraction,
                 storage_state=storage_state,
@@ -842,29 +856,29 @@
         """Get metadata of a single image.
 
         :param str image_id: Image identifier.
 
         :return: A dictionary of metadata for a single image.
         :rtype: DotDict
 
-        :raises ~descarteslabs.client.exceptions.NotFoundError: Raised if image id cannot
+        :raises ~descarteslabs.exceptions.NotFoundError: Raised if image id cannot
              be found.
 
         Example::
 
-            >>> from descarteslabs.client.services import Metadata
+            >>> from descarteslabs.client.services.metadata import Metadata
             >>> meta = Metadata().get('landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1')
             >>> keys = list(meta.keys())
             >>> keys.sort()
-            >>> keys
+            >>> keys  # doctest: +SKIP
             ['acquired', 'area', 'bits_per_pixel', 'bright_fraction', 'bucket',
              'cloud_fraction', 'cloud_fraction_0', 'confidence_dlsr', 'cs_code',
              'descartes_version', 'file_md5s', 'file_sizes', 'files', 'fill_fraction',
              'geolocation_accuracy', 'geometry', 'geotrans', 'id', 'identifier', 'key',
-             'owner_type', 'processed', 'product', 'proj4', 'projcs', 'published',
+             'modified', 'processed', 'product', 'proj4', 'projcs', 'published',
              'raster_size', 'reflectance_scale', 'roll_angle', 'sat_id',
              'solar_azimuth_angle', 'solar_elevation_angle', 'storage_state',
              'sw_version', 'terrain_correction', 'tile_id']
         """
         r = self.session.get("/get/{}".format(image_id))
         return DotDict(r.json())
 
@@ -876,15 +890,15 @@
         :param list(str) fields: Properties to return.
         :param bool ignore_not_found: For image id lookups that fail: if :py:obj:`True`, ignore;
                                       if :py:obj:`False`, raise :py:exc:`NotFoundError`. Default is :py:obj:`True`.
 
         :return: List of image metadata dicts.
         :rtype: DotList(DotDict)
 
-        :raises ~descarteslabs.client.exceptions.NotFoundError: Raised if an image id cannot
+        :raises ~descarteslabs.exceptions.NotFoundError: Raised if an image id cannot
              be found and ignore_not_found set to `False` (default is `True`)
         """
         kwargs["ids"] = ids
         kwargs["ignore_not_found"] = ignore_not_found
         if fields is not None:
             kwargs["fields"] = fields
 
@@ -895,40 +909,39 @@
         """Get information about a single product.
 
         :param str product_id: Product Identifier.
 
         :return: A dictionary with metadata for a single product.
         :rtype: DotDict
 
-        :raises ~descarteslabs.client.exceptions.NotFoundError: Raised if an product id
+        :raises ~descarteslabs.exceptions.NotFoundError: Raised if an product id
             cannot be found.
         """
         r = self.session.get("/products/{}".format(product_id))
         return DotDict(r.json())
 
     def get_band(self, band_id):
         """Get information about a single band.
 
         :param str band_id: Band Identifier.
 
         :return: A dictionary with metadata for a single band.
         :rtype: DotDict
 
-        :raises ~descarteslabs.client.exceptions.NotFoundError: Raised if an band id
+        :raises ~descarteslabs.exceptions.NotFoundError: Raised if an band id
             cannot be found.
         """
         r = self.session.get("/bands/{}".format(band_id))
         return DotDict(r.json())
 
     def get_derived_band(self, derived_band_id):
         """Get information about a single derived band.
 
         :param str derived_band_id: Derived band identifier.
 
         :return: A dictionary with metadata for a single derived band.
         :rtype: DotDict
 
-        :raises ~descarteslabs.client.exceptions.NotFoundError: Raised if an band id
-            cannot be found.
+        :raises ~descarteslabs.exceptions.NotFoundError: Raised if a band id cannot be found.
         """
         r = self.session.get("/bands/derived/{}".format(derived_band_id))
         return DotDict(r.json())
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/metadata/smoke_tests/test_metadata.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/metadata/tests/e2e/test_metadata.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,16 +11,16 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import itertools
 import unittest
 
-from descarteslabs.client.services.metadata import Metadata
-from descarteslabs.client.exceptions import NotFoundError
+from ... import Metadata
+from descarteslabs.exceptions import NotFoundError
 
 
 class TestMetadata(unittest.TestCase):
     instance = None
 
     @classmethod
     def setUpClass(cls):
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/places/__init__.py` & `descarteslabs-2.0.0/descarteslabs/core/client/exceptions.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,15 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from .places import Places
-
-
-__all__ = ["Places"]
+from descarteslabs.exceptions import *  # noqa 401
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/raster/cli.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/cli.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 #!/usr/bin/env python
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,25 +12,23 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import argparse
 import json
 
-import six
-
 from .raster import Raster
 
 
 def scales(s):
     if s.count(",") == 1:
-        mi, ma = six.moves.map(float, s.split(","))
+        mi, ma = map(float, s.split(","))
         return [mi, ma]
     elif s.count(",") == 3:
-        smi, sma, dmi, dma = six.moves.map(float, s.split(","))
+        smi, sma, dmi, dma = map(float, s.split(","))
         return [smi, sma, dmi, dma]
     else:
         raise argparse.ArgumentTypeError("Scales must be mi,ma or smi,sma,dmi,dma")
 
 
 def raster_handler(args):
     params = {
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/raster/geotiff_utils.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/geotiff_utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,14 +1,36 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from typing import List, Tuple, Union
 from enum import Enum
 import numpy as np
 from affine import Affine
 
 from tifffile import TiffWriter
 
+# Rasterio is used in `make_geotiffs` but ONLY if installed
+try:
+    import rasterio
+    from rasterio.crs import CRS
+except ImportError:
+    rasterio = None
+
+
 ##############################################################################
 # GeoTiff Tags
 ##############################################################################
 
 # Geotiff-specific data structure, see spec
 
 GeoKeyDirectory = List[int]
@@ -295,14 +317,79 @@
     if nodata is not None:
         nodata_str = str(nodata)
         tags.append((42113, 2, len(nodata_str), nodata_str, False))
     return tags
 
 
 def make_geotiff(outfile, chunk_iter, metadata, blosc_meta, compress, nodata):
+    if rasterio is not None:
+        make_rasterio_geotiff(
+            outfile, chunk_iter, metadata, blosc_meta, compress, nodata
+        )
+    else:
+        make_tifffile_geotiff(
+            outfile, chunk_iter, metadata, blosc_meta, compress, nodata
+        )
+
+
+def make_rasterio_geotiff(outfile, chunk_iter, metadata, blosc_meta, compress, nodata):
+    """Use rasterio to create a geotiff. Uses libgdal to write thus offering full functionality
+    and more likely to be compatible with the rest of the geospatial software ecosystem
+
+    :param outfile: string, path to output geotiff file.
+    :param chunk_iter: Iterator yielding "chunks", a 3D array of (rows, cols, bands) representing one
+        geotiff block. Streamed from the npz service. The order and length of the chunk sequence
+        must match that of the underlying blocks on disk. npz and all our tiff writers
+        agree on the correct order.
+    :param metadata: dict of image and per-band metdata
+    :param blosc_meta: dict of metadata describing the npz payload shape
+    :param compress: string, compression method to use when writing geotiff. Defaults to "LZW".
+        For rasterio geotiffs, accepts any of the algorithms supported by the
+        underlying GDAL shared library.
+    :param nodata: numeric, global value to represent masked (nodata) regions
+    """
+    geotiff_profile = make_geotiff_profile(metadata, blosc_meta)
+
+    if compress is None:
+        # Always default to lossless compression to save disk space.
+        compress = "LZW"
+
+    crs = CRS.from_proj4(metadata["coordinateSystem"]["proj4"])
+
+    with rasterio.open(
+        outfile, mode="w", compress=compress, nodata=nodata, crs=crs, **geotiff_profile
+    ) as dst:
+        for i, bandmeta in enumerate(metadata["bands"]):
+            dst.update_tags(i + 1, **bandmeta["description"])
+
+        # Windowed writing ensures that we never need more than one chunk in memory
+        # each "chunk" corresponds to a raster block (ie tile) by design
+        for chunk, (_, window) in zip(chunk_iter, dst.block_windows()):
+            # swap axis order from (rows, cols, bands) to (bands, rows, cols)
+            # single bands come back as 2d
+            arr = np.transpose(np.atleast_3d(chunk), [2, 0, 1])
+            dst.write(arr, window=window)
+
+
+def make_tifffile_geotiff(outfile, chunk_iter, metadata, blosc_meta, compress, nodata):
+    """
+    Use the tiffwriter which makes viable GeoTiffs but with limited optionality
+    specifically, they lack lossless compression
+
+    :param outfile: string, path to output geotiff file.
+    :param chunk_iter: Iterator yielding "chunks", a 3D array of (rows, cols, bands) representing one
+        geotiff block. Streamed from the npz service. The order and length of the chunk sequenmce
+        must match that of the underlying blocks on disk. npz and all our tiff writers
+        agree on the correct order.
+    :param metadata: dict of image and per-band metdata
+    :param blosc_meta: dict of metadata describing the npz payload shape
+    :param compress: string, compression method to use when writing geotiff.
+        Defaults to uncompressed. Also supports "JPEG" and "PNG".
+    :param nodata: numeric, global value to represent masked (nodata) regions
+    """
     geotiff_profile = make_geotiff_profile(metadata, blosc_meta)
     gkd, projcs, geogcs = parse_projection(metadata)
     mtp, mps = parse_transform(geotiff_profile["transform"])
     gdalinfo = make_gdalinfo(metadata)
     extra_tags = convert_to_geotiff_tags(
         gkd, mtp, mps, projcs, geogcs, gdalinfo, nodata
     )
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/raster/raster.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/raster.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,42 +1,45 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import json
-import logging
 import os
 import random
 import struct
 import time
+from collections.abc import Iterable
+from concurrent import futures
 
-from tqdm import tqdm
-from urllib3.exceptions import ProtocolError, IncompleteRead
+import blosc
+import numpy as np
+from descarteslabs.auth import Auth
+from descarteslabs.config import get_settings
+from descarteslabs.exceptions import ServerError
 from PIL import Image
+from tqdm import tqdm
+from urllib3.exceptions import IncompleteRead, ProtocolError
 
-from descarteslabs.client.addons import blosc, concurrent, numpy as np
-from descarteslabs.client.auth import Auth
-from descarteslabs.client.services.places import Places
-from descarteslabs.client.services.service.service import Service
-from descarteslabs.client.exceptions import ServerError
-from descarteslabs.common.dltile import Tile
-
+from ....common.dltile import Tile
+from ....common.http.service import DefaultClientMixin
+from ..service.service import Service
 from .geotiff_utils import make_geotiff
 
 DEFAULT_MAX_WORKERS = 8
+DEFAULT_MAX_RETRIES = 8
 
 
 def as_json_string(str_or_dict):
     if not str_or_dict:
         return str_or_dict
     elif isinstance(str_or_dict, dict):
         return json.dumps(str_or_dict)
@@ -70,17 +73,35 @@
             unit="B",
             disable=False if progress is True else None,
         )
         if progress is not False
         else None
     )
     for _ in range(metadata["chunks"]):
-        chunk_metadata = json.loads(data.readline().decode("utf-8").strip())
+        chunk_metadata_bytes = data.readline()
+        # the service instance may have gotten killed such that we
+        # see no transport error, but we do not get the complete
+        # chunk metadata. Handle all the variants as a retryable error.
+        # Note that although there are different paths to an exception,
+        # they all represent the same problem: we did not receive a
+        # complete and valid chunk metadata JSON dict.
+        errmsg = "Did not receive complete chunk metadata"
+        try:
+            chunk_metadata_str = chunk_metadata_bytes.decode("utf-8")
+        except UnicodeDecodeError:
+            # incomplete bytes don't decode
+            raise ServerError(errmsg)
+        try:
+            chunk_metadata = json.loads(chunk_metadata_str.strip())
+        except json.JSONDecodeError:
+            # incomplete JSON string doesn't decode (including empty string)
+            raise ServerError(errmsg)
 
         if "error" in chunk_metadata:
+            # The server encountered an error
             raise ServerError(chunk_metadata["error"])
 
         chunk = np.empty(chunk_metadata["shape"], dtype=output.dtype)
         raw_size, buffer = read_blosc_buffer(data)
 
         if raw_size != chunk.nbytes:
             raise ServerError(
@@ -149,15 +170,15 @@
                     raw_size, chunk.nbytes
                 )
             )
         blosc.decompress_ptr(buffer, chunk.__array_interface__["data"][0])
 
         mask_raw_size, mask_buffer = read_blosc_buffer(data)
         if nodata is not None:
-            mask_chunk = np.ma.empty(chunk_metadata["shape"], dtype=np.bool)
+            mask_chunk = np.ma.empty(chunk_metadata["shape"], dtype=bool)
             if mask_raw_size != mask_chunk.nbytes:
                 raise ServerError(
                     "Did not receive complete mask chunk (got {}, expected {})".format(
                         raw_size, chunk.nbytes
                     )
                 )
             blosc.decompress_ptr(mask_buffer, mask_chunk.__array_interface__["data"][0])
@@ -171,15 +192,15 @@
 
 def _retry(req, headers=None):
     # this provides a nominal 60 seconds of retry
     DELAY = 0.5
     MULTIPLIER = 2
     JITTER = 1.0
     MAX_DELAY = 30.0
-    MAX_RETRIES = 8
+    MAX_RETRIES = DEFAULT_MAX_RETRIES
 
     retry_count = 0
 
     # Should always be present outside of tests
     if headers is None:
         headers = {}
 
@@ -202,15 +223,15 @@
             # this is a variation on "Full Jitter" with JITTER as a tuning parameter.
             delay = min(DELAY * MULTIPLIER ** (retry_count - 1), MAX_DELAY)
             delay = random.uniform(1.0 - JITTER, 1.0) * delay
             time.sleep(delay)
         retry_count += 1
 
 
-class Raster(Service):
+class Raster(Service, DefaultClientMixin):
     """
     The Raster API retrieves data from the Descartes Labs Catalog. Direct use of
     the Raster API is not recommended. Consider using the Descartes Labs Scenes API instead.
     """
 
     # https://requests.readthedocs.io/en/master/user/advanced/#timeouts
     CONNECT_TIMEOUT = 9.5
@@ -220,83 +241,79 @@
 
     def __init__(self, url=None, auth=None):
         """The parent Service class implements authentication and exponential
         backoff/retry. Override the url parameter to use a different instance
         of the backing service.
         """
         if auth is None:
-            auth = Auth()
+            auth = Auth.get_default_auth()
 
         if url is None:
-            url = os.environ.get(
-                "DESCARTESLABS_RASTER_URL",
-                "https://platform.descarteslabs.com/raster/v2",
-            )
+            url = get_settings().raster_url
 
         super(Raster, self).__init__(url, auth=auth)
 
     def raster(
         self,
         inputs,
-        bands=None,
+        bands,
         scales=None,
         data_type=None,
         output_format="GTiff",
         srs=None,
         dimensions=None,
         resolution=None,
         bounds=None,
         bounds_srs=None,
         cutline=None,
-        place=None,
         align_pixels=False,
         resampler=None,
         dltile=None,
         processing_level=None,
         outfile_basename=None,
         headers=None,
         progress=None,
         nodata=None,
         _retry=_retry,
         **pass_through_params,
     ):
-        """Given a list of :class:`Metadata <descarteslabs.services.Metadata>` identifiers,
+        """Given a list of image identifiers,
         retrieve a translated and warped mosaic as an image file.
 
-        :param inputs: List of :class:`Metadata` identifiers.
+        :param inputs: Iterable of image identifiers.
         :param bands: List of requested bands. If the last item in the list is an alpha
             band (with data range `[0, 1]`) it affects rastering of all other bands:
             When rastering multiple images, they are combined image-by-image only where
             each respective image's alpha band is `1` (pixels where the alpha band is not
             `1` are "transparent" in the overlap between images). If a pixel is fully
             masked considering all combined alpha bands it will be `0` in all non-alpha
-            bands. Not specifying bands returns all bands in the product.
+            bands.
         :param scales: List of tuples specifying the scaling to be applied to each band.
             A tuple has 4 elements in the order ``(src_min, src_max, out_min, out_max)``,
             meaning values in the source range ``src_min`` to ``src_max`` will be scaled
             to the output range ``out_min`` to ``out_max``. A tuple with 2 elements
             ``(src_min, src_max)`` is also allowed, in which case the output range
             defaults to ``(0, 255)`` (a useful default for the common output type
             ``Byte``).  If no scaling is desired for a band, use ``None``.  This tuple
             format and behaviour is identical to GDAL's scales during translation.
             Example argument: ``[(0, 10000, 0, 127), (0, 1, 0, 1), (0, 10000)]`` - the first
             band will have source values 0-10000 scaled to 0-127, the second band will
             not be scaled, the third band will have 0-10000 scaled to 0-255.
         :param str output_format: Output format (one of ``GTiff``, ``PNG``, ``JPEG``).
+            The default is ``GTiff``.
         :param str data_type: Output data type (one of ``Byte``, ``UInt16``, ``Int16``,
             ``UInt32``, ``Int32``, ``Float32``, ``Float64``).
         :param str srs: Output spatial reference system definition understood by GDAL.
         :param float resolution: Desired resolution in output SRS units. Incompatible with
             `dimensions`
         :param tuple dimensions: Desired output (width, height) in pixels within which
             the raster should fit; i.e. the longer side of the raster will be min(dimensions).
             Incompatible with `resolution`.
         :param str cutline: A GeoJSON object to be used as a cutline, or WKT string.
                             GeoJSON coordinates must be in WGS84 lat-lon.
-        :param str place: A slug identifier to be used as a cutline.
         :param tuple bounds: ``(min_x, min_y, max_x, max_y)`` in target SRS.
         :param str bounds_srs:
             Override the coordinate system in which bounds are expressed.
             If not given, bounds are assumed to be expressed in the output SRS.
         :param bool align_pixels: Align pixels to the target coordinate system.
         :param str resampler: Resampling algorithm to be used during warping (``near``,
             ``bilinear``, ``cubic``, ``cubicsplice``, ``lanczos``, ``average``, ``mode``,
@@ -322,15 +339,14 @@
             bands=bands,
             scales=scales,
             data_type=data_type,
             srs=srs,
             resolution=resolution,
             dimensions=dimensions,
             cutline=cutline,
-            place=place,
             bounds=bounds,
             bounds_srs=bounds_srs,
             align_pixels=align_pixels,
             resampler=resampler,
             dltile=dltile,
             processing_level=processing_level,
             output_window=None,
@@ -358,15 +374,15 @@
             )
             metadata = json.loads(r.raw.readline().decode("utf-8").strip())
             blosc_meta = json.loads(r.raw.readline().decode("utf-8").strip())
 
             chunk_iter = yield_chunks(blosc_meta, r.raw, progress, nodata)
 
             if "id" not in metadata:
-                metadata["id"] = inputs[0]
+                metadata["id"] = params["ids"][0]
 
             try:
                 if output_format == "GTiff":
                     make_geotiff(
                         outfile, chunk_iter, metadata, blosc_meta, None, nodata
                     )
                 elif output_format == "JPEG":
@@ -395,22 +411,21 @@
             return (outfile, metadata)
 
         return _retry(retry_req, headers=headers)
 
     def ndarray(
         self,
         inputs,
-        bands=None,
+        bands,
         scales=None,
         data_type=None,
         srs=None,
         resolution=None,
         dimensions=None,
         cutline=None,
-        place=None,
         bounds=None,
         bounds_srs=None,
         align_pixels=False,
         resampler=None,
         order="image",
         dltile=None,
         processing_level=None,
@@ -419,22 +434,22 @@
         progress=None,
         masked=True,
         _retry=_retry,
         **pass_through_params,
     ):
         """Retrieve a raster as a NumPy array.
 
-        :param inputs: List of :class:`Metadata` identifiers.
+        :param inputs: List of image identifiers.
         :param bands: List of requested bands. If the last item in the list is an alpha
             band (with data range `[0, 1]`) it affects rastering of all other bands:
             When rastering multiple images, they are combined image-by-image only where
             each respective image's alpha band is `1` (pixels where the alpha band is not
             `1` are "transparent" in the overlap between images). If a pixel is fully
             masked considering all combined alpha bands it will be `0` in all non-alpha
-            bands. Not specifying bands returns all bands in the product.
+            bands.
         :param scales: List of tuples specifying the scaling to be applied to each band.
             A tuple has 4 elements in the order ``(src_min, src_max, out_min, out_max)``,
             meaning values in the source range ``src_min`` to ``src_max`` will be scaled
             to the output range ``out_min`` to ``out_max``. A tuple with 2 elements
             ``(src_min, src_max)`` is also allowed, in which case the output range
             defaults to ``(0, 255)`` (a useful default for the common output type
             ``Byte``).  If no scaling is desired for a band, use ``None``. This tuple
@@ -448,15 +463,14 @@
         :param float resolution: Desired resolution in output SRS units. Incompatible with
             `dimensions`
         :param tuple dimensions: Desired output (width, height) in pixels within which
             the raster should fit; i.e. the longer side of the raster will be min(dimensions).
             Incompatible with `resolution`.
         :param str cutline: A GeoJSON object to be used as a cutline, or WKT string.
                             GeoJSON coordinates must be in WGS84 lat-lon.
-        :param str place: A slug identifier to be used as a cutline.
         :param tuple bounds: ``(min_x, min_y, max_x, max_y)`` in target SRS.
         :param str bounds_srs:
             Override the coordinate system in which bounds are expressed.
             If not given, bounds are assumed to be expressed in the output SRS.
         :param bool align_pixels: Align pixels to the target coordinate system.
         :param str resampler: Resampling algorithm to be used during warping (``near``,
             ``bilinear``, ``cubic``, ``cubicsplice``, ``lanczos``, ``average``, ``mode``,
@@ -483,15 +497,14 @@
             bands=bands,
             scales=scales,
             data_type=data_type,
             srs=srs,
             resolution=resolution,
             dimensions=dimensions,
             cutline=cutline,
-            place=place,
             bounds=bounds,
             bounds_srs=bounds_srs,
             align_pixels=align_pixels,
             resampler=resampler,
             dltile=dltile,
             processing_level=processing_level,
             output_window=output_window,
@@ -529,25 +542,14 @@
         """
         Thread ndarray calls by id group, keeping the same `args` and
         `kwargs` for each raster.ndarray call.
         """
         max_workers = kwargs.pop(
             "max_workers", min(len(id_groups), DEFAULT_MAX_WORKERS)
         )
-        try:
-            futures = concurrent.futures
-        except ImportError:
-            logging.warning(
-                "Failed to import concurrent.futures. ndarray calls will be serial"
-            )
-            # Fallback to serial execution
-            for i, arr, meta in self._serial_ndarray(id_groups, *args, **kwargs):
-                yield i, arr, meta
-            return
-
         with futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
             future_ndarrays = {}
             for i, id_group in enumerate(id_groups):
                 future_ndarrays[
                     executor.submit(self.ndarray, id_group, *args, **kwargs)
                 ] = i
 
@@ -555,22 +557,21 @@
                 i = future_ndarrays[future]
                 arr, meta = future.result()
                 yield i, arr, meta
 
     def stack(
         self,
         inputs,
-        bands=None,
+        bands,
         scales=None,
         data_type="UInt16",
         srs=None,
         resolution=None,
         dimensions=None,
         cutline=None,
-        place=None,
         bounds=None,
         bounds_srs=None,
         align_pixels=False,
         resampler=None,
         order="image",
         dltile=None,
         processing_level=None,
@@ -583,26 +584,26 @@
 
         To ensure every raster in the stack has the same shape and covers the same
         spatial extent, you must either:
 
         * set ``dltile``, or
         * set [``resolution`` or ``dimensions``], ``srs``, and ``bounds``
 
-        :param inputs: List, or list of lists, of :class:`Metadata` identifiers.
+        :param inputs: Iterable, or Iterable of Iterables, of image identifiers.
             The stack will follow the same order as this list.
             Each element in the list is treated as a separate input to ``raster.ndarray``,
             so if a list of lists is given, each sublist's identifiers will be mosaiced together
             to become a single level in the stack.
         :param bands: List of requested bands. If the last item in the list is an alpha
             band (with data range `[0, 1]`) it affects rastering of all other bands:
             When rastering multiple images, they are combined image-by-image only where
             each respective image's alpha band is `1` (pixels where the alpha band is not
             `1` are "transparent" in the overlap between images). If a pixel is fully
             masked considering all combined alpha bands it will be `0` in all non-alpha
-            bands. Not specifying bands returns all bands in the product.
+            bands.
         :param scales: List of tuples specifying the scaling to be applied to each band.
             A tuple has 4 elements in the order ``(src_min, src_max, out_min, out_max)``,
             meaning values in the source range ``src_min`` to ``src_max`` will be scaled
             to the output range ``out_min`` to ``out_max``. A tuple with 2 elements
             ``(src_min, src_max)`` is also allowed, in which case the output range
             defaults to ``(0, 255)`` (a useful default for the common output type
             ``Byte``).  If no scaling is desired for a band, use ``None``. This tuple
@@ -616,15 +617,14 @@
         :param float resolution: Desired resolution in output SRS units. Incompatible with
             `dimensions`
         :param tuple dimensions: Desired output (width, height) in pixels within which
             the raster should fit; i.e. the longer side of the raster will be min(dimensions).
             Incompatible with `resolution`.
         :param str cutline: A GeoJSON object to be used as a cutline, or WKT string.
                             GeoJSON coordinates must be in WGS84 lat-lon.
-        :param str place: A slug identifier to be used as a cutline.
         :param tuple bounds: ``(min_x, min_y, max_x, max_y)`` in target SRS.
         :param str bounds_srs:
             Override the coordinate system in which bounds are expressed.
             If not given, bounds are assumed to be expressed in the output SRS.
         :param bool align_pixels: Align pixels to the target coordinate system.
         :param str resampler: Resampling algorithm to be used during warping (``near``,
             ``bilinear``, ``cubic``, ``cubicsplice``, ``lanczos``, ``average``, ``mode``,
@@ -648,40 +648,41 @@
               (or ``(scene, y, x, band)`` if ``order="gdal"``). The scenes in the outermost
               axis are in the same order as the list of identifiers given as ``inputs``.
             * ``metadata``: List[dict] of the rasterization metadata for each element in ``inputs``.
               As with the metadata returned by :meth:`ndarray` and :meth:`raster`, these dictionaries
               contain useful information about the raster, such as its geotransform matrix and WKT
               of its coordinate system, but there are no guarantees that certain keys will be present.
         """
-        if not isinstance(inputs, (list, tuple)):
+        if isinstance(inputs, str):
+            inputs = list(inputs)
+        if isinstance(inputs, (list, tuple)):
+            pass
+        elif isinstance(inputs, Iterable):
+            inputs = list(inputs)
+        else:
             raise TypeError(
-                "Inputs must be a list or tuple, instead got '{}'".format(type(inputs))
+                "Inputs must be a Iterable, instead got '{}'".format(type(inputs))
             )
 
         if dltile is None:
             if resolution is None and dimensions is None:
                 raise ValueError("Must set `resolution` or `dimensions`")
             if srs is None:
                 raise ValueError("Must set `srs`")
             if bounds is None:
                 raise ValueError("Must set `bounds`")
 
-        if place is not None:
-            shape = Places(auth=self.auth).shape(place, geom="low")
-            cutline = json.dumps(shape["geometry"])
-
         params = dict(
             bands=bands,
             scales=scales,
             data_type=data_type,
             srs=srs,
             resolution=resolution,
             dimensions=dimensions,
             cutline=cutline,
-            place=None,
             bounds=bounds,
             bounds_srs=bounds_srs,
             align_pixels=align_pixels,
             resampler=resampler,
             order=order,
             dltile=dltile,
             processing_level=processing_level,
@@ -723,36 +724,30 @@
         bands,
         scales,
         data_type,
         srs,
         resolution,
         dimensions,
         cutline,
-        place,
         bounds,
         bounds_srs,
         align_pixels,
         resampler,
         dltile,
         processing_level,
         output_window,
         pass_through_params,
     ):
-
         cutline = as_json_string(cutline)
 
-        if place is not None:
-            shape = Places(auth=self.auth).shape(place, geom="low")
-            cutline = json.dumps(shape["geometry"])
-
         if type(inputs) is str:
             inputs = [inputs]
 
         params = {
-            "ids": inputs,
+            "ids": list(inputs),
             "bands": bands,
             "scales": scales,
             "ot": data_type,
             "srs": srs,
             "resolution": resolution,
             "shape": cutline,
             "outputBounds": bounds,
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/raster/smoke_tests/iowa_geometry.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/e2e/iowa_geometry.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,21 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 iowa_geom = {
     "coordinates": [
         [
             [-94.015492, 40.573914],
             [-94.270456, 40.571531],
             [-94.594196, 40.57096],
             [-95.765645, 40.585208],
@@ -1113,9 +1127,9 @@
             [-92.686693, 40.589809],
             [-92.943472, 40.587762],
             [-93.260429, 40.580814],
             [-93.547578, 40.580407],
             [-94.015492, 40.573914],
         ]
     ],
-    "type": u"Polygon",
+    "type": "Polygon",
 }
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/raster/smoke_tests/test_raster.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/e2e/test_raster.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,26 +14,38 @@
 
 import os
 import tempfile
 import shutil
 import unittest
 import json
 import hashlib
+import sys
 
-from descarteslabs.client.addons import numpy as np
-from descarteslabs.client.services.raster import Raster
+import numpy as np
+
+from ...raster import Raster
 
 
 class TestRaster(unittest.TestCase):
     raster = None
     places = None
 
     @classmethod
     def setUpClass(cls):
         cls.raster = Raster()
+        # make sure we aren't testing with rasterio
+        cls.rasterio = None
+        if "rasterio" in sys.modules:
+            cls.rasterio = sys.modules["rasterio"]
+            del sys.modules["rasterio"]
+
+    @classmethod
+    def tearDownClass(cls):
+        # put back rasterio
+        sys.modules["rasterio"] = cls.rasterio
 
     def test_raster(self):
         filename, metadata = self.raster.raster(
             inputs=["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"],
             bands=["red", "green", "blue", "alpha"],
             resolution=960,
         )
@@ -269,15 +281,14 @@
         assert os.path.exists(filename)
         try:
             assert metadata is not None
         finally:
             os.unlink(filename)
 
     def test_geotiff_simple(self):
-
         input_id = "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"
 
         filename, metadata = self.raster.raster(
             inputs=[input_id],
             bands=["red"],
             resolution=960,
             output_format="GTiff",
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/raster/tests/test_raster.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/tests/test_raster_rasterio.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,39 +1,35 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import base64
 import json
 import re
-import pytest
+import time
 import unittest
 
-from descarteslabs.client.addons import blosc, numpy as np, ThirdParty
-from descarteslabs.client.auth import Auth
-import descarteslabs.client.services.raster.raster
-from descarteslabs.client.services.raster.raster import as_json_string, Raster
-
+import blosc
+import numpy as np
+import pytest
 import responses
+from descarteslabs.auth import Auth
 
-try:
-    import mock
-except ImportError:
-    from unittest import mock
+from ..raster import Raster, as_json_string
 
-public_token = "header.e30.signature"
 a_geometry = {
     "coordinates": (
         (
             (-95.66055514862535, 41.24469400862013),
             (-94.74931826062456, 41.26199387228942),
             (-94.76311013534223, 41.95357639323731),
             (-95.69397431605952, 41.93542085595837),
@@ -42,14 +38,28 @@
     ),
     "type": "Polygon",
 }
 
 
 class RasterTest(unittest.TestCase):
     def setUp(self):
+        payload = (
+            base64.b64encode(
+                json.dumps(
+                    {
+                        "aud": "ZOBAi4UROl5gKZIpxxlwOEfx8KpqXf2c",
+                        "exp": time.time() + 3600,
+                    }
+                ).encode()
+            )
+            .decode()
+            .strip("=")
+        )
+        public_token = f"header.{payload}.signature"
+
         self.url = "http://example.com/raster"
         self.raster = Raster(
             url=self.url, auth=Auth(jwt_token=public_token, token_info_path=None)
         )
         self.match_url = re.compile(self.url)
 
     def mock_response(self, method, json, status=200, **kwargs):
@@ -62,32 +72,34 @@
         array_ptr = array.__array_interface__["data"][0]
         blosc_data = blosc.compress_ptr(
             array_ptr, array.size, array.dtype.itemsize
         ).decode("utf-8")
 
         mask = np.zeros(array.shape[1:]).astype(bool)
         mask_ptr = mask.__array_interface__["data"][0]
-        mask_data = blosc.compress_ptr(
-            mask_ptr, mask.size, mask.dtype.itemsize
-        ).decode("utf-8")
+        mask_data = blosc.compress_ptr(mask_ptr, mask.size, mask.dtype.itemsize).decode(
+            "utf-8"
+        )
 
-        return "\n".join([
-            json.dumps(metadata),
-            json.dumps(array_meta),
-            json.dumps(chunk_meta),
-            blosc_data + mask_data,
-        ])
+        return "\n".join(
+            [
+                json.dumps(metadata),
+                json.dumps(array_meta),
+                json.dumps(chunk_meta),
+                blosc_data + mask_data,
+            ]
+        )
 
     @responses.activate
     def test_ndarray_blosc(self):
         expected_metadata = {"foo": "bar"}
         expected_array = np.zeros((1, 2, 2))
         content = self.create_blosc_response(expected_metadata, expected_array)
         self.mock_response(responses.POST, json=None, body=content, stream=True)
-        array, meta = self.raster.ndarray(["fakeid"])
+        array, meta = self.raster.ndarray(["fakeid"], bands=["red"])
         assert expected_metadata == meta
         np.testing.assert_array_equal(expected_array.transpose((1, 2, 0)), array)
 
     @responses.activate
     def do_stack(self, **stack_args):
         expected_metadata = {"foo": "bar"}
         expected_array = np.zeros((1, 2, 2))
@@ -97,27 +109,14 @@
             [["fakeid"], ["fakeid2"]], order="gdal", **stack_args
         )
 
         np.testing.assert_array_equal(expected_array, stack[0, :])
         np.testing.assert_array_equal(expected_array, stack[1, :])
         assert [expected_metadata] * 2 == meta
 
-    @mock.patch.object(
-        descarteslabs.client.services.raster.raster,
-        "concurrent",
-        ThirdParty("concurrent"),
-    )
-    def test_stack_serial_blosc(self):
-        self.do_stack(
-            resolution=60,
-            srs="EPSG:32615",
-            bounds=(277280.0, 4569600.0, 354080.0, 4646400.0),
-            bands=["red"],
-        )
-
     def test_stack_threaded_blosc(self):
         self.do_stack(
             resolution=60,
             srs="EPSG:32615",
             bounds=(277280.0, 4569600.0, 354080.0, 4646400.0),
             bands=["red"],
         )
@@ -134,23 +133,23 @@
             -94.74931826062456,
             41.95357639323731,
         )
         resolution = 960
         dimensions = (128, 128)
 
         with pytest.raises(ValueError):
-            self.raster.stack(keys)
+            self.raster.stack(keys, bands=["red"])
         with pytest.raises(ValueError):
-            self.raster.stack(keys, resolution=resolution)
+            self.raster.stack(keys, bands=["red"], resolution=resolution)
         with pytest.raises(ValueError):
-            self.raster.stack(keys, dimensions=dimensions)
+            self.raster.stack(keys, bands=["red"], dimensions=dimensions)
         with pytest.raises(ValueError):
-            self.raster.stack(keys, bounds=bounds)
+            self.raster.stack(keys, bands=["red"], bounds=bounds)
         with pytest.raises(ValueError):
-            self.raster.stack(keys, resolution=resolution, place=place)
+            self.raster.stack(keys, bands=["red"], resolution=resolution, place=place)
 
 
 class UtilitiesTest(unittest.TestCase):
     def test_as_json_string(self):
         d = {"a": "b"}
         truth = json.dumps(d)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/service/__init__.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/raster/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,31 +1,17 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from .service import (
-    Service,
-    Session,
-    JsonApiService,
-    JsonApiSession,
-    ThirdPartyService,
-    NotFoundError,
-)
+from .raster import Raster
 
-__all__ = [
-    "Service",
-    "Session",
-    "JsonApiService",
-    "JsonApiSession",
-    "ThirdPartyService",
-    "NotFoundError",
-]
+__all__ = ["Raster"]
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/service/service.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/service/service.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,248 +15,74 @@
 try:
     import builtins
 except ImportError:
     # Until we get rid of Python2 tests...
     builtins = __builtins__
 
 import itertools
+import json
 import os
 import platform
 import random
-import requests
 import sys
 import uuid
-import json
-
-from requests.adapters import HTTPAdapter
-from urllib3.util.retry import Retry
+from http import HTTPStatus
 from warnings import warn
 
-from descarteslabs.client.auth import Auth
-from descarteslabs.client.exceptions import (
-    ClientError,
-    ServerError,
-    BadRequestError,
-    NotFoundError,
-    RateLimitError,
-    ProxyAuthenticationRequiredError,
-    GatewayTimeoutError,
-    ConflictError,
-)
-from descarteslabs.client.version import __version__
-from descarteslabs.common.http.authorization import add_bearer
-from descarteslabs.common.threading.local import ThreadLocalWrapper
+from descarteslabs.auth import Auth
+from descarteslabs.exceptions import ClientError, ServerError
+
+from ....common.http import Retry, Session
+from ....common.http.authorization import add_bearer
+from ....common.threading.local import ThreadLocalWrapper
+from ...version import __version__
 
 
-class HttpMountProtocol(object):
+class HttpMountProtocol:
     HTTP = "http://"
     HTTPS = "https://"
 
 
-class HttpRequestMethod(object):
+class HttpRequestMethod:
     DELETE = "DELETE"
     GET = "GET"
     HEAD = "HEAD"
     OPTIONS = "OPTIONS"
     PATCH = "PATCH"
     POST = "POST"
     PUT = "PUT"
     TRACE = "TRACE"
 
 
-class HttpStatusCode(object):
-    Ok = 200
-    BadRequest = 400
-    NotFound = 404
-    ProxyAuthenticationRequired = 407
-    Conflict = 409
-    UnprocessableEntity = 422
-    TooManyRequests = 429
-    InternalServerError = 500
-    BadGateway = 502
-    ServiceUnavailable = 503
-    GatewayTimeout = 504
-
-
-class HttpHeaderKeys(object):
+class HttpHeaderKeys:
     Accept = "Accept"
     Authorization = "Authorization"
     ClientSession = "X-Client-Session"
     Conda = "X-Conda"
     ContentType = "Content-Type"
     Notebook = "X-Notebook"
     Platform = "X-Platform"
     Python = "X-Python"
     RequestGroup = "X-Request-Group"
     RetryAfter = "Retry-After"
     UserAgent = "User-Agent"
 
 
-class HttpHeaderValues(object):
+class HttpHeaderValues:
     ApplicationJson = "application/json"
     ApplicationVndApiJson = "application/vnd.api+json"
     ApplicationOctetStream = "application/octet-stream"
     DlPython = "dl-python"
 
 
-class Session(requests.Session):
-    """The HTTP Session that performs the actual HTTP request.
-
-    This is the base session that is used for all Descartes Labs HTTP calls which
-    itself is derived from `requests.Session
-    <https://requests.readthedocs.io/en/master/api/#requests.Session>`_.
-
-    You cannot control its instantiation, but you can derive from this class
-    and pass it as the class to use when you instantiate a :py:class:`Service`
-    or register it as the default session class using
-    :py:meth:`Service.set_default_session_class`.
-
-    Parameters
-    ----------
-    base_url: str
-        The URL prefix to use for communication with the Descartes Labs servers.
-    timeout: int or tuple(int, int)
-        See `requests timeouts
-        <https://requests.readthedocs.io/en/master/user/advanced/#timeouts>`_.
-    """
-
-    ATTR_BASE_URL = "base_url"
-    ATTR_HEADERS = "headers"
-    ATTR_TIMEOUT = "timeout"
-
-    # Adapts the custom pickling protocol of requests.Session
-    __attrs__ = requests.Session.__attrs__ + [ATTR_BASE_URL, ATTR_TIMEOUT]
-
-    def __init__(self, base_url, timeout=None):
-        self.base_url = base_url
-        self.timeout = timeout
-        super(Session, self).__init__()
-
-    def initialize(self):
-        """Initialize the :py:class:`Session` instance
-
-        You can override this method in a derived class to add your own initialization.
-        This method does nothing in the base class.
-        """
-
-        pass
-
-    def request(self, method, url, **kwargs):
-        """Sends an HTTP request and emits Descartes Labs specific errors.
-
-        Parameters
-        ----------
-        method: str
-            The HTTP method to use.
-        url: str
-            The URL to send the request to.
-        kwargs: dict
-            Additional arguments.  See `requests.request
-            <https://requests.readthedocs.io/en/master/api/#requests.request>`_.
-
-        Returns
-        -------
-        Response
-            A :py:class:`request.Response` object.
-
-        Raises
-        ------
-        BadRequestError
-            Either a 400 or 422 HTTP response status code was encountered.
-        NotFoundError
-            A 404 HTTP response status code was encountered.
-        ProxyAuthenticationRequiredError
-            A 407 HTTP response status code was encountered and the resulting
-            :py:meth:`handle_proxy_authentication` did not indicate that the
-            proxy authentication was handled.
-        ConflictError
-            A 409 HTTP response status code was encountered.
-        RateLimitError
-            A 429 HTTP response status code was encountered.
-        GatewayTimeoutError
-            A 504 HTTP response status code was encountered.
-        ~descarteslabs.client.exceptions.ServerError
-            Any HTTP response status code larger than 400 that was not covered above
-            is returned as a ServerError.  The original HTTP response status code
-            can be found in the attribute :py:attr:`original_status`.
-        """
-
-        if self.timeout and self.ATTR_TIMEOUT not in kwargs:
-            kwargs[self.ATTR_TIMEOUT] = self.timeout
-
-        if self.ATTR_HEADERS not in kwargs:
-            kwargs[self.ATTR_HEADERS] = {}
-
-        kwargs[self.ATTR_HEADERS][HttpHeaderKeys.RequestGroup] = uuid.uuid4().hex
-
-        resp = super(Session, self).request(method, self.base_url + url, **kwargs)
-
-        if (
-            resp.status_code >= HttpStatusCode.Ok
-            and resp.status_code < HttpStatusCode.BadRequest
-        ):
-            return resp
-        elif resp.status_code == HttpStatusCode.BadRequest:
-            raise BadRequestError(resp.text)
-        elif resp.status_code == HttpStatusCode.NotFound:
-            text = resp.text
-            if not text:
-                text = "{} {} {}".format(HttpStatusCode.NotFound, method, url)
-            raise NotFoundError(text)
-        elif resp.status_code == HttpStatusCode.ProxyAuthenticationRequired:
-            if not self.handle_proxy_authentication(method, url, **kwargs):
-                raise ProxyAuthenticationRequiredError()
-        elif resp.status_code == HttpStatusCode.Conflict:
-            raise ConflictError(resp.text)
-        elif resp.status_code == HttpStatusCode.UnprocessableEntity:
-            raise BadRequestError(resp.text)
-        elif resp.status_code == HttpStatusCode.TooManyRequests:
-            raise RateLimitError(
-                resp.text, retry_after=resp.headers.get(HttpHeaderKeys.RetryAfter)
-            )
-        elif resp.status_code == HttpStatusCode.GatewayTimeout:
-            raise GatewayTimeoutError(
-                "Your request timed out on the server. "
-                "Consider reducing the complexity of your request."
-            )
-        else:
-            # The whole error hierarchy has some problems.  Originally a ClientError
-            # could be thrown by our client libraries, but any HTTP error was a
-            # ServerError.  That changed and HTTP errors below 500 became ClientErrors.
-            # That means that this actually should be split in ClientError for
-            # status < 500 and ServerError for status >= 500, but that might break
-            # things.  So instead, we'll add the original status.
-            server_error = ServerError(resp.text)
-            server_error.original_status = resp.status_code
-            raise server_error
-
-    def handle_proxy_authentication(self, method, url, **kwargs):
-        """Handle proxy authentication when the HTTP request was denied.
-
-        This method can be overridden in a derived class.  By default a
-        :py:class:`~descarteslabs.client.exceptions.ProxyAuthenticationRequiredError`
-        will be raised.
-
-        Returns
-        -------
-        bool
-            Return True if the proxy authentication has been handled and no further
-            exception should be raised.  Return False if a
-            :py:class:`~descarteslabs.client.exceptions.ProxyAuthenticationRequiredError`
-            should be raised.
-        """
-
-        return False
-
-
 # For backward compatibility
 WrappedSession = Session
 
 
-class Service(object):
+class Service:
     """The default Descartes Labs HTTP Service used to communicate with its servers.
 
     This service has a default timeout and retry policy that retries HTTP requests
     depending on the timeout and HTTP status code that was returned.  This is based
     on the `requests timeouts
     <https://requests.readthedocs.io/en/master/user/advanced/#timeouts>`_
     and the `urllib3 retry object
@@ -278,18 +104,18 @@
     Parameters
     ----------
     url: str
         The URL prefix to use for communication with the Descartes Labs server.
     token: str, optional
         Deprecated.
     auth: Auth, optional
-        A Descartes Labs :py:class:`~descarteslabs.client.auth.Auth` instance.  If not
+        A Descartes Labs :py:class:`~descarteslabs.auth.Auth` instance.  If not
         provided, a default one will be instantiated.
     retries: int or urllib3.util.retry.Retry
-        If a number, it's the number of retries that will be attempled.  If a
+        If a number, it's the number of retries that will be attempted.  If a
         :py:class:`urllib3.util.retry.Retry` instance, it will determine the retry
         behavior.  If not provided, the default retry policy as described above will
         be used.
     session_class: class
         The session class to use when instantiating the session.  This must be a derived
         class from :py:class:`Session`.  If not provided, the default session class
         is used.  You can register a default session class with
@@ -322,26 +148,22 @@
                 HttpRequestMethod.PUT,
                 HttpRequestMethod.PATCH,
                 HttpRequestMethod.OPTIONS,
                 HttpRequestMethod.DELETE,
             ]
         ),
         status_forcelist=[
-            HttpStatusCode.InternalServerError,
-            HttpStatusCode.BadGateway,
-            HttpStatusCode.ServiceUnavailable,
-            HttpStatusCode.GatewayTimeout,
+            HTTPStatus.INTERNAL_SERVER_ERROR,
+            HTTPStatus.BAD_GATEWAY,
+            HTTPStatus.SERVICE_UNAVAILABLE,
+            HTTPStatus.GATEWAY_TIMEOUT,
         ],
         remove_headers_on_redirect=[],
     )
 
-    # We share an adapter (one per thread/process) among all clients to take advantage
-    # of the single underlying connection pool.
-    ADAPTER = ThreadLocalWrapper(lambda: HTTPAdapter(max_retries=Service.RETRY_CONFIG))
-
     _session_class = Session
 
     # List of attributes that will be included in state for pickling.
     # Subclasses can extend this attribute list.
     __attrs__ = ["auth", "base_url", "_session_class", "RETRY_CONFIG"]
 
     @classmethod
@@ -377,48 +199,41 @@
             class from :py:class:`Session`.
         """
 
         return cls._session_class
 
     def __init__(self, url, token=None, auth=None, retries=None, session_class=None):
         if auth is None:
-            auth = Auth()
+            auth = Auth.get_default_auth()
 
         if token is not None:
             warn(
                 "setting token at service level will be removed in future",
                 FutureWarning,
             )
             auth._token = token
 
         self.auth = auth
         self.base_url = url
 
         if retries is None:
-            self._adapter = self.ADAPTER
-        else:
-            self.RETRY_CONFIG = retries
-            self._init_adapter()
+            retries = Service.RETRY_CONFIG
+        self._retry_config = retries
 
         if session_class is not None:
             # Overwrite the default session class
             if not issubclass(session_class, Session):
                 raise TypeError(
                     "The session class must be a subclass of {}.".format(Session)
                 )
 
             self._session_class = session_class
 
         self._init_session()
 
-    def _init_adapter(self):
-        self._adapter = ThreadLocalWrapper(
-            lambda: HTTPAdapter(max_retries=self.RETRY_CONFIG)
-        )
-
     def _init_session(self):
         # Sessions can't be shared across threads or processes because the underlying
         # SSL connection pool can't be shared. We create them thread-local to avoid
         # intractable exceptions when users naively share clients e.g. when using
         # multiprocessing.
         self._session = ThreadLocalWrapper(self._build_session)
 
@@ -429,31 +244,28 @@
 
     @token.setter
     def token(self, token):
         """str: Deprecated"""
         self.auth._token = token
 
     @property
-    def session(self):
+    def session(self) -> Session:
         """Session: The session instance used by this service."""
         session = self._session.get()
         auth = add_bearer(self.token)
         if session.headers.get(HttpHeaderKeys.Authorization) != auth:
             session.headers[HttpHeaderKeys.Authorization] = auth
 
         return session
 
     def _build_session(self):
-        session = self._session_class(self.base_url, timeout=self.TIMEOUT)
+        session = self._session_class(
+            self.base_url, timeout=self.TIMEOUT, retries=self._retry_config
+        )
         session.initialize()
-
-        adapter = self._adapter.get()
-        session.mount(HttpMountProtocol.HTTPS, adapter)
-        session.mount(HttpMountProtocol.HTTP, adapter)
-
         session.headers.update(
             {
                 HttpHeaderKeys.ContentType: HttpHeaderValues.ApplicationJson,
                 HttpHeaderKeys.UserAgent: "{}/{}".format(
                     HttpHeaderValues.DlPython, __version__
                 ),
             }
@@ -484,15 +296,14 @@
     def __getstate__(self):
         return dict((attr, getattr(self, attr)) for attr in self.__attrs__)
 
     def __setstate__(self, state):
         for name, value in state.items():
             setattr(self, name, value)
 
-        self._init_adapter()
         self._init_session()
 
 
 class JsonApiSession(Session):
     """The HTTP Session that performs the actual JSONAPI HTTP request.
 
     You cannot control its instantiation, but you can derive from this class
@@ -559,27 +370,29 @@
         Response
             A :py:class:`request.Response` object.
 
         Raises
         ------
         BadRequestError
             Either a 400 or 422 HTTP response status code was encountered.
-        ~descarteslabs.client.exceptions.NotFoundError
+        ~descarteslabs.exceptions.NotFoundError
             A 404 HTTP response status code was encountered.
         ProxyAuthenticationRequiredError
-            A 407 HTTP response status code was encountered and the resulting
-            :py:meth:`~JsonApiSession.handle_proxy_authentication` did not indicate
-            that the proxy authentication was handled.
+            A 407 HTTP response status code was encountered indicating proxy
+            authentication was not handled or was invalid.
         ConflictError
             A 409 HTTP response status code was encountered.
+        ValidationError
+            A 422 HTTP response status code was encountered.
+            ValidationError extends BadRequestError for backward compatibility.
         RateLimitError
             A 429 HTTP response status code was encountered.
         GatewayTimeoutError
             A 504 HTTP response status code was encountered.
-        ~descarteslabs.client.exceptions.ServerError
+        ~descarteslabs.exceptions.ServerError
             Any HTTP response status code larger than 400 that was not covered above
             is returned as a ServerError.  The original HTTP response status code
             can be found in the attribute :py:attr:`original_status`.
 
         Note
         ----
         If :py:attr:`rewrite_errors` was set to ``True`` in the corresponding
@@ -598,32 +411,14 @@
             self._emit_warnings(resp.json())
         except Exception:
             # Really don't want to raise anything here
             pass
 
         return resp
 
-    def handle_proxy_authentication(self, method, url, **kwargs):
-        """Handle proxy authentication when the HTTP request was denied.
-
-        This method can be overridden in a derived class.  By default a
-        :py:class:`~descarteslabs.client.exceptions.ProxyAuthenticationRequiredError`
-        will be raised.
-
-        Returns
-        -------
-        bool
-            Return True if the proxy authentication has been handled and no further
-            exception should be raised.  Return False if a
-            :py:class:`~descarteslabs.client.exceptions.ProxyAuthenticationRequiredError`
-            should be raised.
-        """
-
-        return False
-
     def _emit_warnings(self, json_response):
         if (
             self.KEY_META not in json_response
             or self.KEY_WARNINGS not in json_response[self.KEY_META]
         ):
             return
 
@@ -650,34 +445,34 @@
 
         for arg in client_error.args:
             try:
                 errors = json.loads(arg)[self.KEY_ERRORS]
 
                 for error in errors:
                     line = ""
-                    seperator = ""
+                    separator = ""
 
                     if self.KEY_TITLE in error:
                         line += error[self.KEY_TITLE]
-                        seperator = ": "
+                        separator = ": "
                     elif self.KEY_STATUS in error:
                         line += error[self.KEY_STATUS]
-                        seperator = ": "
+                        separator = ": "
 
                     if self.KEY_DETAIL in error:
-                        line += seperator + error[self.KEY_DETAIL].strip(".")
-                        seperator = ": "
+                        line += separator + error[self.KEY_DETAIL].strip(".")
+                        separator = ": "
 
                     if self.KEY_SOURCE in error:
                         source = error[self.KEY_SOURCE]
                         if self.KEY_POINTER in source:
                             source = source[self.KEY_POINTER].split("/")[-1]
                         elif self.KEY_PARAMETER in source:
                             source = source[self.KEY_PARAMETER]
-                        line += seperator + source
+                        line += separator + source
 
                     if self.KEY_ID in error:
                         line += " ({})".format(error[self.KEY_ID])
 
                     if line:
                         message += "\n    " + line
 
@@ -695,15 +490,15 @@
                 return
 
         if message:
             client_error.args = (message,)
 
 
 class JsonApiService(Service):
-    """A JsonApi oriented default Descateslabs Labs HTTP Service.
+    """A JsonApi oriented default Descartes Labs HTTP Service.
 
     For details see the :py:class:`Service`.  This service adheres to the `JsonApi
     standard <https://jsonapi.org/format/>`_ and interprets responses as needed.
 
     This service uses the :py:class:`JsonApiSession` which provides some optional
     functionality.
 
@@ -716,18 +511,18 @@
         class from :py:class:`JsonApiSession`.  If not provided, the default session
         class is used.  You can register a default session class with
         :py:meth:`JsonApiService.set_default_session_class`.
     rewrite_errors: bool
         When set to ``True``, errors are rewritten to be more readable.  Each JsonApi
         error becomes a single line of error information without tags.
     auth: Auth, optional
-        A Descartes Labs :py:class:`~descarteslabs.client.auth.Auth` instance.  If not
+        A Descartes Labs :py:class:`~descarteslabs.auth.Auth` instance.  If not
         provided, a default one will be instantiated.
     retries: int or urllib3.util.retry.Retry If a number, it's the number of retries
-        that will be attempled.  If a :py:class:`urllib3.util.retry.Retry` instance,
+        that will be attempted.  If a :py:class:`urllib3.util.retry.Retry` instance,
         it will determine the retry behavior.  If not provided, the default retry
         policy as described above will be used.
 
     Raises
     ------
     TypeError
         If you try to use a session class that is not derived from
@@ -898,15 +693,15 @@
         """
 
         if ids_list is None:
             ids_list = itertools.repeat(None)
         else:
             if len(ids_list) != len(attributes_list):
                 raise ValueError(
-                    "Different number of resources given than IDs: {} vs {}".foramt(
+                    "Different number of resources given than IDs: {} vs {}".format(
                         len(attributes_list), len(ids_list)
                     )
                 )
         resources = []
         for attributes, id in zip(attributes_list, ids_list):
             resource = {
                 JsonApiService.KEY_TYPE: type,
@@ -914,15 +709,15 @@
             }
             if id is not None:
                 resource[JsonApiService.KEY_ID] = id
             resources.append(resource)
         return {JsonApiService.KEY_DATA: resources}
 
 
-class ThirdPartyService(object):
+class ThirdPartyService:
     """The default Descartes Labs HTTP Service used for 3rd party servers.
 
     This service has a default timeout and retry policy that retries HTTP requests
     depending on the timeout and HTTP status code that was returned.  This is based
     on the `requests timeouts
     <https://requests.readthedocs.io/en/master/user/advanced/#timeouts>`_
     and the `urllib3 retry object
@@ -972,26 +767,22 @@
                 HttpRequestMethod.POST,
                 HttpRequestMethod.PUT,
                 HttpRequestMethod.OPTIONS,
                 HttpRequestMethod.DELETE,
             ]
         ),
         status_forcelist=[
-            HttpStatusCode.TooManyRequests,
-            HttpStatusCode.InternalServerError,
-            HttpStatusCode.BadGateway,
-            HttpStatusCode.ServiceUnavailable,
-            HttpStatusCode.GatewayTimeout,
+            HTTPStatus.TOO_MANY_REQUESTS,
+            HTTPStatus.INTERNAL_SERVER_ERROR,
+            HTTPStatus.BAD_GATEWAY,
+            HTTPStatus.SERVICE_UNAVAILABLE,
+            HTTPStatus.GATEWAY_TIMEOUT,
         ],
     )
 
-    ADAPTER = ThreadLocalWrapper(
-        lambda: HTTPAdapter(max_retries=ThirdPartyService.RETRY_CONFIG)
-    )
-
     _session_class = Session
 
     @classmethod
     def set_default_session_class(cls, session_class=None):
         """Set the default session class for :py:class:`ThirdPartyService`.
 
         The default session is used for any :py:meth:`ThirdPartyService` that is
@@ -1035,25 +826,23 @@
                 )
 
             self._session_class = session_class
 
         self._session = ThreadLocalWrapper(self._build_session)
 
     @property
-    def session(self):
+    def session(self) -> Session:
         return self._session.get()
 
     def _build_session(self):
         session = self._session_class(self.base_url, timeout=self.TIMEOUT)
         session.initialize()
-
-        session.mount(HttpMountProtocol.HTTPS, self.ADAPTER.get())
         session.headers.update(
             {
-                HttpHeaderKeys.ContentType: HttpHeaderValues.ApplicationOctetStream,
+                # HttpHeaderKeys.ContentType: HttpHeaderValues.ApplicationOctetStream,
                 HttpHeaderKeys.UserAgent: "{}/{}".format(
                     HttpHeaderValues.DlPython, __version__
                 ),
             }
         )
 
         return session
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/services/service/tests/test_service.py` & `descarteslabs-2.0.0/descarteslabs/core/client/services/service/tests/test_service.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,38 +10,35 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import pickle
 import unittest
+from http import HTTPStatus
+from io import BytesIO
 
-import mock
-import descarteslabs
-from descarteslabs.client.exceptions import (
-    ProxyAuthenticationRequiredError,
-    BadRequestError,
-)
-from descarteslabs.client.services.service import (
+from unittest import mock
+import requests
+import responses
+import urllib3
+from descarteslabs.exceptions import BadRequestError, ProxyAuthenticationRequiredError
+
+from .....common.http.authorization import add_bearer
+from .....common.http import ProxyAuthentication
+from ....version import __version__
+from .. import (
     JsonApiService,
     JsonApiSession,
     Service,
     Session,
     ThirdPartyService,
+    service,
 )
-from descarteslabs.client.services.service.service import (
-    HttpHeaderKeys,
-    HttpHeaderValues,
-    HttpRequestMethod,
-    HttpStatusCode,
-    WrappedSession,
-    requests,
-)
-from descarteslabs.client.version import __version__
-from descarteslabs.common.http.authorization import add_bearer
+from ..service import HttpHeaderKeys, HttpHeaderValues, WrappedSession
 
 FAKE_URL = "http://localhost"
 FAKE_TOKEN = "foo.bar.sig"
 
 
 class TestService(unittest.TestCase):
     def test_session_token(self):
@@ -98,26 +95,26 @@
         session.request("POST", FAKE_URL)
 
         request.assert_called_once()
         assert "X-Request-Group" in request.call_args[1]["headers"]
 
     @mock.patch.object(requests.Session, "request")
     def test_request_group_header_conflict(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         args = "POST", FAKE_URL
         kwargs = dict(headers={"X-Request-Group": "f00"})
 
         session = WrappedSession("")
         session.request(*args, **kwargs)
         request.assert_called_once_with(*args, **kwargs)  # we do nothing here
 
     @mock.patch.object(requests.Session, "request")
     def test_request_group_header_no_conflict(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         session = WrappedSession("")
         session.request("POST", FAKE_URL, headers={"foo": "bar"})
 
         request.assert_called_once()
         assert "X-Request-Group" in request.call_args[1]["headers"]
 
@@ -130,131 +127,52 @@
         with self.assertRaises(TypeError):
             Service(
                 "foo", auth=mock.MagicMock(token=FAKE_TOKEN), session_class=MySession
             )
 
     @mock.patch.object(requests.Session, "request")
     def test_good_session(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         class MySession(Session):
             pass
 
         service = Service(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), session_class=MySession
         )
         service.session.get("bar")
 
         request.assert_called()
 
     @mock.patch.object(requests.Session, "request")
     def test_bad_json_session(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         class MySession(Session):
             pass
 
         with self.assertRaises(TypeError):
             JsonApiService(
                 "foo", auth=mock.MagicMock(token=FAKE_TOKEN), session_class=MySession
             )
 
     @mock.patch.object(requests.Session, "request")
     def test_good_json_session(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         class MySession(JsonApiSession):
             pass
 
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), session_class=MySession
         )
         service.session.get("bar")
 
         request.assert_called()
 
-    @mock.patch.object(requests.Session, "request")
-    def test_proxy_called(self, request):
-        request.return_value.status_code = HttpStatusCode.ProxyAuthenticationRequired
-
-        class MySession(Session):
-            handle_proxy_authentication_called = 0
-            handled = True
-
-            def handle_proxy_authentication(self, method, url, **kwargs):
-                MySession.handle_proxy_authentication_called += 1
-                assert method == HttpRequestMethod.GET
-                assert url == "bar"
-                return MySession.handled
-
-        service = Service(
-            "foo", auth=mock.MagicMock(token=FAKE_TOKEN), session_class=MySession
-        )
-        service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 1
-
-        MySession.handled = False
-        with self.assertRaises(ProxyAuthenticationRequiredError):
-            service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 2
-
-    @mock.patch.object(requests.Session, "request")
-    def test_proxy_called_jsonapi(self, request):
-        request.return_value.status_code = HttpStatusCode.ProxyAuthenticationRequired
-
-        class MySession(JsonApiSession):
-            handle_proxy_authentication_called = 0
-            handled = True
-
-            def handle_proxy_authentication(self, method, url, **kwargs):
-                MySession.handle_proxy_authentication_called += 1
-                assert method == HttpRequestMethod.GET
-                assert url == "bar"
-                return MySession.handled
-
-        service = JsonApiService(
-            "foo", auth=mock.MagicMock(token=FAKE_TOKEN), session_class=MySession
-        )
-        service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 1
-
-        MySession.handled = False
-        with self.assertRaises(ProxyAuthenticationRequiredError):
-            service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 2
-
-    @mock.patch.object(requests.Session, "request")
-    def test_proxy_called_thirdpary(self, request):
-        request.return_value.status_code = HttpStatusCode.ProxyAuthenticationRequired
-
-        class MySession(Session):
-            handle_proxy_authentication_called = 0
-            handled = True
-
-            def handle_proxy_authentication(self, method, url, **kwargs):
-                MySession.handle_proxy_authentication_called += 1
-                assert method == HttpRequestMethod.GET
-                assert url == "bar"
-                return MySession.handled
-
-        service = ThirdPartyService(session_class=MySession)
-        service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 1
-
-        MySession.handled = False
-        with self.assertRaises(ProxyAuthenticationRequiredError):
-            service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 2
-
 
 class TestJsonApiSession(unittest.TestCase):
     # A JSONAPI error can contain, amongst others, the following fields:
     #     status, title, detail, source
     # The source field can contain:
     #     pointer, parameter
     # When rewriting the error, it looks like
@@ -262,15 +180,15 @@
     #         link]
 
     @mock.patch.object(requests.Session, "request")
     def test_jsonapi_error(self, request):
         error_title = "Title"
         error_status = "Status"  # Should be ignored
 
-        request.return_value.status_code = HttpStatusCode.BadRequest
+        request.return_value.status_code = HTTPStatus.BAD_REQUEST
         request.return_value.text = (
             '{{"errors": [{{"title": "{}", "status": "{}"}}]}}'
         ).format(error_title, error_status)
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), rewrite_errors=True
         )
 
@@ -280,15 +198,15 @@
             assert e.args == ("\n    {}".format(error_title),)
 
     @mock.patch.object(requests.Session, "request")
     def test_jsonapi_error_with_detail(self, request):
         error_title = "Title"
         error_detail = "Description"
 
-        request.return_value.status_code = HttpStatusCode.BadRequest
+        request.return_value.status_code = HTTPStatus.BAD_REQUEST
         request.return_value.text = (
             '{{"errors": [{{"title": "{}", "detail": "{}"}}]}}'
         ).format(error_title, error_detail)
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), rewrite_errors=True
         )
 
@@ -298,15 +216,15 @@
             assert e.args == ("\n    {}: {}".format(error_title, error_detail),)
 
     @mock.patch.object(requests.Session, "request")
     def test_jsonapi_error_no_title(self, request):
         error_status = "Status"  # Should be used instead of the title
         error_detail = "Description"
 
-        request.return_value.status_code = HttpStatusCode.BadRequest
+        request.return_value.status_code = HTTPStatus.BAD_REQUEST
         request.return_value.text = (
             '{{"errors": [{{"status": "{}", "detail": "{}"}}]}}'
         ).format(error_status, error_detail)
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), rewrite_errors=True
         )
 
@@ -317,15 +235,15 @@
 
     @mock.patch.object(requests.Session, "request")
     def test_jsonapi_error_with_source(self, request):
         error_title = "Title"
         error_detail = "Detail"
         error_field = "Field"
 
-        request.return_value.status_code = HttpStatusCode.BadRequest
+        request.return_value.status_code = HTTPStatus.BAD_REQUEST
         request.return_value.text = (
             '{{"errors": [{{"title": "{}", "detail": "{}", "source": '
             '{{"pointer": "/path/to/{}"}}}}]}}'
         ).format(error_title, error_detail, error_field)
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), rewrite_errors=True
         )
@@ -339,15 +257,15 @@
 
     @mock.patch.object(requests.Session, "request")
     def test_jsonapi_error_with_id(self, request):
         error_title = "Title"
         error_detail = "Detail"
         error_id = "123"
 
-        request.return_value.status_code = HttpStatusCode.BadRequest
+        request.return_value.status_code = HTTPStatus.BAD_REQUEST
         request.return_value.text = (
             '{{"errors": [{{"title": "{}", "detail": "{}", "id": {}}}]}}'
         ).format(error_title, error_detail, error_id)
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), rewrite_errors=True
         )
 
@@ -360,15 +278,15 @@
 
     @mock.patch.object(requests.Session, "request")
     def test_jsonapi_error_with_link(self, request):
         error_title = "Title"
         error_detail = "Detail"
         error_href = "Href"
 
-        request.return_value.status_code = HttpStatusCode.BadRequest
+        request.return_value.status_code = HTTPStatus.BAD_REQUEST
         request.return_value.text = (
             '{{"errors": [{{"title": "{}", "detail": "{}", "links": '
             '{{"about": "{}"}}}}]}}'
         ).format(error_title, error_detail, error_href)
         service = JsonApiService(
             "foo", auth=mock.MagicMock(token=FAKE_TOKEN), rewrite_errors=True
         )
@@ -396,117 +314,76 @@
             assert e.args == (
                 "\n    {}: {}\n        {}".format(
                     error_title, error_detail, error_href
                 ),
             )
 
 
-class TestDefaultProxyClass(unittest.TestCase):
-    @mock.patch.object(requests.Session, "request")
-    def test_session_default_proxy(self, request):
-        request.return_value.status_code = HttpStatusCode.ProxyAuthenticationRequired
-
-        class MySession(Session):
-            handle_proxy_authentication_called = 0
-            handled = True
-
-            def handle_proxy_authentication(self, method, url, **kwargs):
-                MySession.handle_proxy_authentication_called += 1
-                assert method == HttpRequestMethod.GET
-                assert url == "bar"
-                return MySession.handled
-
-        Service.set_default_session_class(MySession)
-        service = Service("foo", auth=mock.MagicMock(token=FAKE_TOKEN))
-        service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 1
-
-        MySession.handled = False
-        with self.assertRaises(ProxyAuthenticationRequiredError):
-            service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 2
-
-        MySession.handled = True
-        ThirdPartyService.set_default_session_class(MySession)
-        service = ThirdPartyService()
-        service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 3
-
-        MySession.handled = False
-        with self.assertRaises(ProxyAuthenticationRequiredError):
-            service.session.get("bar")
-
-        assert MySession.handle_proxy_authentication_called == 4
-
-
 class TestWarningsClass(unittest.TestCase):
-    @mock.patch.object(descarteslabs.client.services.service.service, "warn")
+    @mock.patch.object(service, "warn")
     @mock.patch.object(requests.Session, "request")
     def test_session_deprecation_warning(self, request, warn):
         message = "Warning"
         cls = FutureWarning
 
         class result:
-            status_code = HttpStatusCode.Ok
+            status_code = HTTPStatus.OK
 
             def json(self):
                 return {
                     "meta": {
                         "warnings": [{"message": message, "category": cls.__name__}]
                     }
                 }
 
         request.side_effect = lambda *args, **kw: result()
         service = JsonApiService("foo", auth=mock.MagicMock(token=FAKE_TOKEN))
         service.session.get("bar")
         warn.assert_called_once_with(message, cls)
 
-    @mock.patch.object(descarteslabs.client.services.service.service, "warn")
+    @mock.patch.object(service, "warn")
     @mock.patch.object(requests.Session, "request")
     def test_session_my_warning(self, request, warn):
         message = "Warning"
         category = "MyCategory"
 
         class result:
-            status_code = HttpStatusCode.Ok
+            status_code = HTTPStatus.OK
 
             def json(self):
                 return {
                     "meta": {"warnings": [{"message": message, "category": category}]}
                 }
 
         request.side_effect = lambda *args, **kw: result()
         service = JsonApiService("foo", auth=mock.MagicMock(token=FAKE_TOKEN))
         service.session.get("bar")
         warn.assert_called_once_with("{}: {}".format(category, message), UserWarning)
 
-    @mock.patch.object(descarteslabs.client.services.service.service, "warn")
+    @mock.patch.object(service, "warn")
     @mock.patch.object(requests.Session, "request")
     def test_session_warning(self, request, warn):
         message = "Warning"
 
         class result:
-            status_code = HttpStatusCode.Ok
+            status_code = HTTPStatus.OK
 
             def json(self):
                 return {"meta": {"warnings": [{"message": message}]}}
 
         request.side_effect = lambda *args, **kw: result()
         service = JsonApiService("foo", auth=mock.MagicMock(token=FAKE_TOKEN))
         service.session.get("bar")
         warn.assert_called_once_with(message, UserWarning)
 
 
 class TestInitialize(unittest.TestCase):
     @mock.patch.object(requests.Session, "request")
     def test_initialize_session(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         class MySession(Session):
             initialize_called = 0
 
             def initialize(self):
                 MySession.initialize_called += 1
 
@@ -515,15 +392,15 @@
         )
         service.session.get("bar")
 
         assert MySession.initialize_called == 1
 
     @mock.patch.object(requests.Session, "request")
     def test_initialize_json_api_session(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         class MySession(JsonApiSession):
             initialize_called = 0
 
             def initialize(self):
                 MySession.initialize_called += 1
 
@@ -532,19 +409,166 @@
         )
         service.session.get("bar")
 
         assert MySession.initialize_called == 1
 
     @mock.patch.object(requests.Session, "request")
     def test_initialize_third_party_session(self, request):
-        request.return_value.status_code = HttpStatusCode.Ok
+        request.return_value.status_code = HTTPStatus.OK
 
         class MySession(Session):
             initialize_called = 0
 
             def initialize(self):
                 MySession.initialize_called += 1
 
         service = ThirdPartyService(session_class=MySession)
         service.session.get("bar")
 
         assert MySession.initialize_called == 1
+
+
+class TestProxyAuthHTTPS(unittest.TestCase):
+    url = "https://fake-service"
+    protocol = ProxyAuthentication.Protocol.HTTPS
+
+    def tearDown(self):
+        ProxyAuthentication.unregister()
+        ProxyAuthentication.clear_proxy()
+
+    @responses.activate
+    def test_requires_proxy_auth(self):
+        responses.add("GET", self.url + "/bar", status=407)
+
+        service = Service(self.url, auth=mock.MagicMock(token=FAKE_TOKEN))
+
+        with self.assertRaises(ProxyAuthenticationRequiredError):
+            service.session.get("/bar")
+
+    # responses hijacks the connection pool and bypasses our HTTPAdapter
+    # unfortunately we have to mock the pool manager here instead.
+    @mock.patch(
+        "urllib3.poolmanager.PoolManager._new_pool",
+    )
+    def test_no_proxy_headers_if_proxy_not_set(self, mock_conn):
+        mock_conn.return_value.urlopen.side_effect = [
+            urllib3.response.HTTPResponse(
+                status=200,
+                reason=None,
+                body=BytesIO(),
+                headers=[],
+                preload_content=False,
+            ),
+        ]
+
+        class MyProxyAuth(ProxyAuthentication):
+            def authorize(self, proxy: str, protocol: str) -> dict:
+                MyProxyAuth.proxy = proxy
+                MyProxyAuth.protocol = protocol
+
+                return {"header-1": "uh oh"}
+
+        ProxyAuthentication.register(MyProxyAuth)
+
+        service = Service(self.url, auth=mock.MagicMock(token=FAKE_TOKEN))
+        service.session.get("/bar")
+
+        assert not hasattr(MyProxyAuth, "proxy")
+        assert not hasattr(MyProxyAuth, "protocol")
+        assert mock_conn.called
+
+        _, kwargs = mock_conn.call_args
+
+        assert "_proxy" not in kwargs["request_context"]
+        assert "_proxy_headers" not in kwargs["request_context"]
+
+    @mock.patch(
+        "urllib3.poolmanager.PoolManager._new_pool",
+    )
+    def test_proxy_authentication(self, mock_conn):
+        mock_conn.return_value.urlopen.side_effect = [
+            urllib3.response.HTTPResponse(
+                status=200,
+                reason=None,
+                body=BytesIO(),
+                headers=[],
+                preload_content=False,
+            ),
+        ]
+
+        class MyProxyAuth(ProxyAuthentication):
+            def authorize(self, proxy: str, protocol: str) -> dict:
+                MyProxyAuth.proxy = proxy
+                MyProxyAuth.protocol = protocol
+
+                return {
+                    "Proxy-Authorization": "proxy-auth-value",
+                    "X-Test-Header": "another test header",
+                }
+
+        ProxyAuthentication.register(MyProxyAuth)
+        ProxyAuthentication.set_proxy("http://some-proxy.test")
+
+        service = Service(self.url, auth=mock.MagicMock(token=FAKE_TOKEN))
+        service.session.get("/bar")
+
+        assert MyProxyAuth.proxy == "http://some-proxy.test"
+        assert MyProxyAuth.protocol == self.protocol
+        assert mock_conn.called
+
+        args, kwargs = mock_conn.call_args
+        assert str(kwargs["request_context"]["_proxy"]) == "http://some-proxy.test:80"
+        assert kwargs["request_context"]["_proxy_headers"] == {
+            "Proxy-Authorization": "proxy-auth-value",
+            "X-Test-Header": "another test header",
+        }
+        assert kwargs["request_context"]["scheme"] == self.protocol
+        assert (
+            kwargs["request_context"]["port"] == 80
+            if self.protocol == ProxyAuthentication.Protocol.HTTP
+            else 443
+        )
+
+        # The request is tunneling it should be directed at the real service instead of
+        # the proxy
+        if self.protocol == ProxyAuthentication.Protocol.HTTPS:
+            assert kwargs["request_context"]["host"] == "fake-service"
+        else:
+            assert kwargs["request_context"]["host"] == "some-proxy.test"
+
+    def test_validates_authorize(self):
+        class MyProxyAuth(ProxyAuthentication):
+            def authorize(self, proxy: str, protocol: str) -> dict:
+                MyProxyAuth.called = True
+                return 10
+
+        ProxyAuthentication.register(MyProxyAuth)
+        ProxyAuthentication.set_proxy("http://some-proxy.test:8888")
+
+        with self.assertRaisesRegex(TypeError, "must return a dictionary"):
+            service = Service(self.url, auth=mock.MagicMock(token=FAKE_TOKEN))
+            service.session.get("/bar")
+            assert MyProxyAuth.called
+
+
+class TestProxyAuthHTTP(TestProxyAuthHTTPS):
+    url = "http://fake-service"
+    protocol = ProxyAuthentication.Protocol.HTTP
+
+    @responses.activate
+    def test_proxy_auth_required_headers(self):
+        responses.add(
+            "GET",
+            self.url + "/bar",
+            status=407,
+            headers={
+                "Proxy-Authenticate": "Basic",
+            },
+        )
+
+        service = Service(self.url, auth=mock.MagicMock(token=FAKE_TOKEN))
+
+        with self.assertRaises(ProxyAuthenticationRequiredError) as ctx:
+            service.session.get("/bar")
+
+        assert ctx.exception.status == 407
+        assert ctx.exception.proxy_authenticate == "Basic"
```

### Comparing `descarteslabs-1.9.1/descarteslabs/client/version.py` & `descarteslabs-2.0.0/descarteslabs/core/common/registry/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,15 +1,17 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-__version__ = "1.9.1"
+from .registry import registry
+
+__all__ = ["registry"]
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dltile/_tiling.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dltile/_tiling.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,23 @@
 """Implementation details for tile.Grid.tiles_from_shape"""
 
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import numpy as np
 import shapely.geometry as geo
 
 from .exceptions import InvalidShapeError
 from .utm import (
     UTM_MIN_LAT,
     UTM_MAX_LAT,
@@ -12,16 +26,16 @@
     FALSE_EASTING,
     lonlat_to_utm,
 )
 from .utils import utm_box_to_lonlat
 
 
 def _get_next_tiling(polygon, grid_width):
-    """ This function yields (zone, path, row) tuples corresponding to
-    all tiles over a shape, given grid_width (resolution*tilesize) in meters. """
+    """This function yields (zone, path, row) tuples corresponding to
+    all tiles over a shape, given grid_width (resolution*tilesize) in meters."""
 
     min_lon, min_lat, max_lon, max_lat = polygon.bounds
 
     if min_lon < -180.0:
         raise InvalidShapeError("Polygon goes beyond -180deg longitude")
 
     if max_lon > 180.0:
@@ -36,34 +50,50 @@
     yield from _tiling_method_appropriate_zones(polygon, grid_width)
 
 
 def _tiling_method_appropriate_zones(polygon, grid_width):
     """Chooses the most appropriate zones to tile a shape."""
     min_lon, _, max_lon, _ = polygon.bounds
     min_zone = max(1, 1 + np.floor((min_lon + 180.0) / 6.0).astype(int))
-    max_zone = 1 + min(60, 1 + np.floor((max_lon + 180.0) / 6.0).astype(int))  # exclusive range
+    max_zone = 1 + min(
+        60, 1 + np.floor((max_lon + 180.0) / 6.0).astype(int)
+    )  # exclusive range
 
     for zone in range(min_zone, max_zone):
         zone_min_lon = 6 * zone - 186.0
         zone_max_lon = 6 * zone - 180.0
         zone_box = geo.box(zone_min_lon, UTM_MIN_LAT, zone_max_lon, UTM_MAX_LAT)
 
         polygon_in_zone = polygon.intersection(zone_box)
 
-        if isinstance(polygon_in_zone, (geo.Polygon, geo.MultiPolygon)) and not polygon_in_zone.is_empty:
-            yield from _tile_zone(polygon_in_zone, grid_width, zone, zone_min_lon, zone_max_lon)
+        if (
+            isinstance(polygon_in_zone, (geo.Polygon, geo.MultiPolygon))
+            and not polygon_in_zone.is_empty
+        ):
+            yield from _tile_zone(
+                polygon_in_zone, grid_width, zone, zone_min_lon, zone_max_lon
+            )
 
         if isinstance(polygon_in_zone, geo.GeometryCollection):
             for shape in polygon_in_zone:
-                if isinstance(shape, (geo.Polygon, geo.MultiPolygon)) and not shape.is_empty:
-                    yield from _tile_zone(shape, grid_width, zone, zone_min_lon, zone_max_lon)
+                if (
+                    isinstance(shape, (geo.Polygon, geo.MultiPolygon))
+                    and not shape.is_empty
+                ):
+                    yield from _tile_zone(
+                        shape, grid_width, zone, zone_min_lon, zone_max_lon
+                    )
 
 
 def _tile_zone(polygon, grid_width, zone, zone_min_lon, zone_max_lon):
-    polygon_utm = lonlat_to_utm(polygon, zone=zone).buffer(0)
+    # buffer for utm zones curving away from latlon
+    _, quad_min_lat, _, quad_max_lat = polygon.bounds
+    b = 2000 * abs(quad_max_lat - quad_min_lat)
+
+    polygon_utm = lonlat_to_utm(polygon, zone=zone).buffer(b)
     min_east, min_north, max_east, max_north = polygon_utm.bounds
 
     min_east = max(min_east, UTM_MIN_EAST)
     max_east = min(max_east, UTM_MAX_EAST)
 
     min_path = int(np.floor((min_east - FALSE_EASTING) / grid_width))
     min_row = int(np.floor(min_north / grid_width))
@@ -85,67 +115,43 @@
         quadbox = geo.box(
             FALSE_EASTING + quad_min_path * grid_width,
             quad_min_row * grid_width,
             FALSE_EASTING + quad_max_path * grid_width,
             quad_max_row * grid_width,
         )
 
-        quad_min_lon, _, quad_max_lon, _ = utm_box_to_lonlat(quadbox, zone).bounds
+        quadbox_lonlat = utm_box_to_lonlat(quadbox, zone)
+        quad_min_lon, _, quad_max_lon, _ = quadbox_lonlat.bounds
         if quad_min_lon > zone_max_lon or quad_max_lon < zone_min_lon:
             continue
 
-        if quad_min_lon > zone_min_lon and quad_max_lon < zone_max_lon:
-            certainly_within_zone = True
-
         quad_h = quad_max_row - quad_min_row
         quad_w = quad_max_path - quad_min_path
 
         if quad_h <= 3 and quad_w <= 3:
             # Just do an exhaustive check when both dimensions are
             # less than 4 tiles across
             for row in range(quad_min_row, quad_max_row):
                 for path in range(quad_min_path, quad_max_path):
                     quadbox = geo.box(
                         FALSE_EASTING + path * grid_width,
                         row * grid_width,
                         FALSE_EASTING + (path + 1) * grid_width,
                         (row + 1) * grid_width,
                     )
-                    if quadbox.intersects(polygon_utm):
-                        if certainly_within_zone:
-                            yield zone, path, row
-                        else:
-                            (
-                                quad_min_lon,
-                                _,
-                                quad_max_lon,
-                                _,
-                            ) = utm_box_to_lonlat(quadbox, zone).bounds
-                            if quad_min_lon <= zone_max_lon and quad_max_lon >= zone_min_lon:
-                                yield zone, path, row
+                    quadbox_lonlat = utm_box_to_lonlat(quadbox, zone)
+                    if quadbox_lonlat.intersects(polygon):
+                        yield zone, path, row
 
-        elif quadbox.within(polygon_utm):
+        elif quadbox_lonlat.within(polygon):
             # If the quadbox is entirely within our polygon,
             # return all tiles in it
             for row in range(quad_min_row, quad_max_row):
                 for path in range(quad_min_path, quad_max_path):
-                    if certainly_within_zone:
-                        yield zone, path, row
-                    else:
-                        quadbox = geo.box(
-                            FALSE_EASTING + path * grid_width,
-                            row * grid_width,
-                            FALSE_EASTING + (path + 1) * grid_width,
-                            (row + 1) * grid_width,
-                        )
-                        quad_min_lon, _, quad_max_lon, _ = utm_box_to_lonlat(
-                            quadbox, zone
-                        ).bounds
-                        if quad_min_lon <= zone_max_lon and quad_max_lon >= zone_min_lon:
-                            yield zone, path, row
+                    yield zone, path, row
 
         elif quadbox.intersects(polygon_utm):
             quad_mid_path = int(np.floor((quad_max_path + quad_min_path) / 2))
             quad_mid_row = int(np.floor((quad_max_row + quad_min_row) / 2))
 
             if quad_h <= 1:
                 # Split the quad into two quads to check independently
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dltile/rasterize.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dltile/rasterize.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,21 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from collections import namedtuple
 import numpy as np
 import shapely.geometry as geo
 from typing import Sequence
 
 from .conversions import normalize_polygons, AnyShapes
 from .tile import Tile
@@ -14,18 +28,15 @@
     values: Sequence[int] = None,
     out: np.ndarray = None,
     mode="burn",
     dtype=np.byte,
     shape_coords="lonlat",
     all_touched=False,
 ) -> np.ndarray:
-    """ Rasterize a collection of lon,lat shapes onto a DLTile.
-    This is included in this directory's __init__.py, so you can import like:
-
-        from descarteslabs.commmon.dltile import rasterize_shape
+    """Rasterize a collection of lon,lat shapes onto a DLTile.
 
     Parameters
     ----------
 
     tile : Tile
         Defines the output raster geocontext
     shapes : AnyShapes
@@ -78,36 +89,33 @@
     if out is None:
         out = np.zeros((tile.tile_extent, tile.tile_extent), dtype=dtype)
 
     # Convert shapes to pixel coordinates
     tilebox = geo.box(0, 0, tile.tile_extent, tile.tile_extent)
     if shape_coords == "lonlat":
         shapes_rowcol = [
-            utm_to_rowcol(
-                lonlat_to_utm(shape, zone=tile.zone), tile=tile
-            ).intersection(tilebox)
+            utm_to_rowcol(lonlat_to_utm(shape, zone=tile.zone), tile=tile).intersection(
+                tilebox
+            )
             for shape in shapes
         ]
     elif shape_coords == "utm":
         shapes_rowcol = [
-            utm_to_rowcol(shape, tile=tile).intersection(tilebox)
-            for shape in shapes
+            utm_to_rowcol(shape, tile=tile).intersection(tilebox) for shape in shapes
         ]
     elif shape_coords == "rowcol":
         shapes_rowcol = [shape.intersection(tilebox) for shape in shapes]
     else:
         raise ValueError(
             "Parameter shape_coords of function rasterize_shape() must be one "
             "of 'lonlat', 'rowcol', or 'utm'."
         )
 
     # We use a quadtree algorithm to rasterize.
-    TreeNode = namedtuple(
-        "TreeNode", ("min_col", "min_row", "max_col", "max_row")
-    )
+    TreeNode = namedtuple("TreeNode", ("min_col", "min_row", "max_col", "max_row"))
     for shape_i, (shape, value) in enumerate(zip(shapes_rowcol, values)):
         nodes = [TreeNode(0, 0, tile.tile_extent, tile.tile_extent)]
         while len(nodes) > 0:
             node = nodes.pop()
             # "min_nodebox" is the smallest box we need to contain to cover all
             # pixels in the box. "max_nodebox" is the larger box we would need
             # to miss entirely in order to cover no pixels in the box.
@@ -145,33 +153,30 @@
                         if condition:
                             if mode == "burn":
                                 out[row, col] = value
                             elif mode == "add":
                                 out[row, col] += value
                             else:
                                 raise ValueError(
-                                    "Expected mode of 'burn' or 'add', got %s"
-                                    % mode
+                                    "Expected mode of 'burn' or 'add', got %s" % mode
                                 )
             elif shape.contains(min_nodebox):
                 # Apply to all pixels in box
                 if mode == "burn":
                     out[
                         node.min_row : node.max_row,
                         node.min_col : node.max_col,
                     ] = value
                 elif mode == "add":
                     out[
                         node.min_row : node.max_row,
                         node.min_col : node.max_col,
                     ] += value
                 else:
-                    raise ValueError(
-                        "Expected mode of 'burn' or 'add', got %s" % mode
-                    )
+                    raise ValueError("Expected mode of 'burn' or 'add', got %s" % mode)
             elif max_nodebox.disjoint(shape):
                 # No intersection, do nothing.
                 pass
             else:
                 # There is some intersection.
                 # Split node into child nodes
                 node_mid_row = int((node.max_row + node.min_row) / 2)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dltile/tests/test_dltiles.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dltile/tests/test_dltiles.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,48 +1,63 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import pytest
 from unittest import TestCase
 import numpy as np
 
 from ..tile import Tile, Grid
+from ..utm import lonlat_to_utm
 from ..exceptions import (
     InvalidLatLonError,
     InvalidRowColError,
     InvalidTileError,
     InvalidShapeError,
 )
 
 
 class TileTest(TestCase):
     """Tests Tile class"""
 
     def test_from_key_1(self):
-        key = '2048:16:30.2:15:3:80'
+        key = "2048:16:30.2:15:3:80"
         tile = Tile.from_key(key)
         assert tile.key == key
         assert tile.zone == 15
         assert tile.resolution == 30.2
         assert tile.tilesize == 2048
         assert tile.path == 3
         assert tile.row == 80
 
     def test_from_key_2(self):
-        key = '2048:16:30:15:-5:15'                 # no decimal in key
+        key = "2048:16:30:15:-5:15"  # no decimal in key
         tile = Tile.from_key(key)
-        assert tile.key == '2048:16:30.0:15:-5:15'  # decimal included
+        assert tile.key == "2048:16:30.0:15:-5:15"  # decimal included
         assert tile.resolution == 30
         assert tile.path == -5
         assert tile.row == 15
 
     def test_get_invalid_dlkey_1(self):
-        invalid_key = "2048:16:30.0:0:3:80"     # tilesize must be greater than zero
+        invalid_key = "2048:16:30.0:0:3:80"  # tilesize must be greater than zero
         with pytest.raises(InvalidTileError):
             Tile.from_key(invalid_key)
 
     def test_get_invalid_dlkey_2(self):
-        invalid_key = "blah:16:30.0:1:3:80"     # invalid type
+        invalid_key = "blah:16:30.0:1:3:80"  # invalid type
         with pytest.raises(InvalidTileError):
             Tile.from_key(invalid_key)
 
     def test_get_invalid_dlkey_3(self):
         invalid_key = "2048:16.4:30.0:15:3:80"  # pad must be int
         with pytest.raises(InvalidTileError):
             Tile.from_key(invalid_key)
@@ -70,31 +85,33 @@
         }
         new_resolution = 2
         new_pad = 13
         sub = 4
         lat, lon = 35.691544, -105.944183
 
         tile = Grid(**params).tile_from_lonlat(lon, lat)
-        tiles = [t for t in tile.subtile(sub, new_resolution=new_resolution, new_pad=new_pad)]
+        tiles = [
+            t for t in tile.subtile(sub, new_resolution=new_resolution, new_pad=new_pad)
+        ]
         assert len(tiles) == sub * sub
         for t in tiles:
             assert np.allclose(
                 t.tilesize * new_resolution * sub,
-                params["tilesize"] * params["resolution"]
+                params["tilesize"] * params["resolution"],
             )
             assert t.pad == new_pad
             assert t.resolution == new_resolution
 
     def test_dlkeys_subtile_error_1(self):
         params = {
             "resolution": 1,
             "tilesize": 1024,
             "pad": 0,
         }
-        sub = 11        # does not evenly divide tilesize
+        sub = 11  # does not evenly divide tilesize
         lat, lon = 35.691544, -105.944183
 
         tile = Grid(**params).tile_from_lonlat(lon, lat)
         with pytest.raises(InvalidTileError):
             [t for t in tile.subtile(sub)]
 
     def test_dlkeys_subtile_error_2(self):
@@ -104,27 +121,31 @@
             "pad": 0,
         }
         sub = 8
         lat, lon = 35.691544, -105.944183
 
         tile = Grid(**params).tile_from_lonlat(lon, lat)
         with pytest.raises(InvalidTileError):
-            [t for t in tile.subtile(sub, new_resolution=13)]   # does not divide
+            [t for t in tile.subtile(sub, new_resolution=13)]  # does not divide
 
     def test_rowcol_conversions(self):
         # get a polar tile
-        tile = Grid(tilesize=1000, resolution=1000, pad=0).tile_from_lonlat(lon=0.0, lat=90.0)
+        tile = Grid(tilesize=1000, resolution=1000, pad=0).tile_from_lonlat(
+            lon=0.0, lat=90.0
+        )
         x, y = 567, 133
         lon, lat = tile.rowcol_to_lonlat(x, y)
         row, col = tile.lonlat_to_rowcol(lon, lat)
         assert row == x
         assert col == y
 
     def test_invalid_rowcol(self):
-        tile = Grid(tilesize=1000, resolution=1000, pad=0).tile_from_lonlat(lon=0.0, lat=90.0)
+        tile = Grid(tilesize=1000, resolution=1000, pad=0).tile_from_lonlat(
+            lon=0.0, lat=90.0
+        )
         x, y = [1, 1, 2, 3, 5], [42]
         with pytest.raises(InvalidRowColError):
             lon, lat = tile.rowcol_to_lonlat(x, y)
 
     def test_assign(self):
         tile1 = Tile.from_key("2048:16:0.2:15:3:80")
         assert tile1.resolution == 0.2
@@ -144,30 +165,26 @@
     """Tests Grid class"""
 
     def test_make_invalid_grid(self):
         with pytest.raises(InvalidTileError):
             Grid(tilesize=0, resolution=1000, pad=0)
 
     def test_from_latlon(self):
-        params = {
-            "tilesize": 1,
-            "resolution": 1.5,
-            "pad": 99
-        }
+        params = {"tilesize": 1, "resolution": 1.5, "pad": 99}
         lat, lon = (61.91, 5.26)
         tile = Grid(**params).tile_from_lonlat(lon, lat)
         assert tile.tilesize == params["tilesize"]
         assert tile.pad == params["pad"]
         assert tile.tile_extent == params["tilesize"] + 2 * params["pad"]
         assert np.allclose(
             [
                 tile.polygon.centroid.xy[0][0],
                 tile.polygon.centroid.xy[1][0],
             ],
-            [lon, lat]
+            [lon, lat],
         )
 
     def test_dlkeys_from_invalid_latlon(self):
         lat, lon = -97.635, 212.723
         params = {"resolution": 60.0, "tilesize": 512, "pad": 0}
         with pytest.raises(InvalidLatLonError):
             Grid(**params).tile_from_lonlat(0, lat)
@@ -188,15 +205,15 @@
                 [-90.1897158, 44.2267595]]],
                 "type": "Polygon"}"""
 
         grid = Grid(**params)
         gen = grid.tiles_from_shape(shape)
         tiles = [tile for tile in gen]
         assert len(tiles) == len(set(tiles))
-        assert len(tiles) == 115
+        assert len(tiles) == 116
 
         est_ntiles = grid._estimate_ntiles_from_shape(shape)
         assert len(tiles) > (est_ntiles // 2)
         assert len(tiles) < (est_ntiles * 2)
 
     def test_tiles_from_shape_2(self):
         params = {
@@ -204,22 +221,25 @@
             "tilesize": 128,
             "pad": 8,
         }
         shape = {
             "type": "Feature",
             "geometry": {
                 "type": "Polygon",
-                "coordinates": [[
-                    [-122.51140471760839, 37.77130087547876],
-                    [-122.45475646845254, 37.77475476721895],
-                    [-122.45303985468301, 37.76657207194229],
-                    [-122.51057242081689, 37.763446782666094],
-                    [-122.51140471760839, 37.77130087547876]]
-                ]},
-            "properties": None
+                "coordinates": [
+                    [
+                        [-122.51140471760839, 37.77130087547876],
+                        [-122.45475646845254, 37.77475476721895],
+                        [-122.45303985468301, 37.76657207194229],
+                        [-122.51057242081689, 37.763446782666094],
+                        [-122.51140471760839, 37.77130087547876],
+                    ]
+                ],
+            },
+            "properties": None,
         }
 
         grid = Grid(**params)
         gen = Grid(**params).tiles_from_shape(shape)
         tiles = [tile for tile in gen]
         assert len(tiles) == len(set(tiles))
         assert len(tiles) == 325
@@ -234,22 +254,25 @@
             "tilesize": 128,
             "pad": 8,
         }
         feature = {
             "type": "Feature",
             "geometry": {
                 "type": "Polygon",
-                "coordinates": [[
-                    [-122.51140471760839, 37.77130087547876],
-                    [-122.45475646845254, 37.77475476721895],
-                    [-122.45303985468301, 37.76657207194229],
-                    [-122.51057242081689, 37.763446782666094],
-                    [-122.51140471760839, 37.77130087547876]]
-                ]},
-            "properties": None
+                "coordinates": [
+                    [
+                        [-122.51140471760839, 37.77130087547876],
+                        [-122.45475646845254, 37.77475476721895],
+                        [-122.45303985468301, 37.76657207194229],
+                        [-122.51057242081689, 37.763446782666094],
+                        [-122.51140471760839, 37.77130087547876],
+                    ]
+                ],
+            },
+            "properties": None,
         }
 
         # Any object with a __geo_interface__ property
         # e.g. wf.map.geocontext()
         class MockWfContext(object):
             @property
             def __geo_interface__(self):
@@ -269,17 +292,63 @@
 
     def test_dlkeys_from_invalid_shape(self):
         params = {
             "resolution": 30,
             "tilesize": 2048,
             "pad": 16,
         }
-        shape = {
-            "type": "Point",
-            "coordinates": [
-                -105.01621,
-                39.57422
-            ]
-        }
+        shape = {"type": "Point", "coordinates": [-105.01621, 39.57422]}
         with pytest.raises(InvalidShapeError):
             for t in Grid(**params).tiles_from_shape(shape):
                 pass
+
+    def test_dltiles_utm_buffering(self):
+        params = {
+            "resolution": 10.0,
+            "tilesize": 4096,
+            "pad": 0,
+        }
+
+        # extremely long and narrow strip which should cover
+        # most of the the known world
+        y_min, y_max = -66, 66
+        x_min, x_max = -98, -90
+
+        feature = {
+            "type": "FeatureCollection",
+            "features": [
+                {
+                    "type": "Feature",
+                    "geometry": {
+                        "type": "Polygon",
+                        "coordinates": [
+                            [
+                                [x_min, y_min],
+                                [x_max, y_min],
+                                [x_max, y_max],
+                                [x_min, y_max],
+                                [x_min, y_min],
+                            ]
+                        ],
+                    },
+                    "properties": {},
+                }
+            ],
+        }
+
+        gen = Grid(**params).tiles_from_shape(feature)
+
+        counter = 0
+        for tile in gen:
+            counter += 1
+            # simple check that all the tiles are in bounds
+            tx_min, ty_min, tx_max, ty_max = tile.polygon.bounds
+
+            if tx_max < x_min or tx_min > x_max or ty_min > y_max or ty_max < y_min:
+                raise InvalidLatLonError("tile outside bounds")
+
+        # simple check that coverage is greater than 100%
+        p = lonlat_to_utm([(x_min, y_min), (x_max, y_max)], ref_lon=x_min)
+        tile_area = (params["resolution"] * params["tilesize"]) ** 2
+        est_total_area = (p[1][0] - p[0][0]) * (p[1][1] - p[0][1])
+        ratio = (counter * tile_area) / est_total_area
+        assert ratio > 1
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dltile/tile.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dltile/tile.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,26 @@
 """In this file we define two classes: Grid, which describes a way to
 divide UTM zones in a grid, and Tile, which specifies a particular
 element in a grid."""
-import collections
+
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import collections.abc
 import numpy as np
 import re
 import shapely.geometry as geo
 from typing import Generator, Sequence, Tuple, Union
 
 from . import _tiling as _tiling
 from .conversions import normalize_polygons, AnyShapes
@@ -120,24 +135,28 @@
         ntiles = 0
         for s in shape:
             lat = s.centroid.xy[1][-1]
             m2 = 12321000000 * np.cos(lat * np.pi / 180)
             ntiles += (s.area * m2) // ((self.resolution * self.tilesize) ** 2)
         return int(ntiles)
 
-    def tiles_from_shape(self, shape: AnyShapes, keys_only=False) -> Generator[Union["Tile", str], None, None]:
+    def tiles_from_shape(
+        self, shape: AnyShapes, keys_only=False
+    ) -> Generator[Union["Tile", str], None, None]:
         """Yields tiles which cover the given shape. If zone is given, all
         tiles will come from one UTM zone. This puts everything on the same
         UTM grid, but comes with the trade-off of more area distortion the
         further from the given zone your shape is."""
         shape = normalize_polygons(shape)
 
-        key_set = set()   # remove duplicate tiles
+        key_set = set()  # remove duplicate tiles
         for polygon in shape:
-            for zone, path, row in _tiling._get_next_tiling(polygon, self.tilesize * self.resolution):
+            for zone, path, row in _tiling._get_next_tiling(
+                polygon, self.tilesize * self.resolution
+            ):
                 tile = Tile(self, zone=zone, path=path, row=row)
                 tile_key = str(tile)
                 if tile_key not in key_set:
                     key_set.add(tile_key)
                     if keys_only:
                         yield tile_key
                     else:
@@ -205,29 +224,31 @@
         return "%s:%s:%i:%i" % (
             repr(self.grid),
             zone,
             self.path,
             self.row,
         )
 
-    def assign(self, resolution: float = None, tilesize: int = None, pad: int = None) -> "Tile":
+    def assign(
+        self, resolution: float = None, tilesize: int = None, pad: int = None
+    ) -> "Tile":
         """Returns a new Tile with new resolution, tilesize, and / or pad (thus changing grid)
         while keeping the tile region (ignoring pad) the same. If both resolution
         and tilesize are specified, they must multiply to the same value as before."""
         new_grid = Grid(
             tilesize=self.tilesize if tilesize is None else tilesize,
             resolution=self.resolution if resolution is None else resolution,
             pad=self.pad if pad is None else pad,
         )
 
         if resolution is None:
             if tilesize is None and pad is None:
-                return self                 # change nothing
+                return self  # change nothing
         else:
-            if tilesize is not None:        # change resolution and tilesize, must check
+            if tilesize is not None:  # change resolution and tilesize, must check
                 if resolution * tilesize != self.resolution * self.tilesize:
                     raise InvalidTileError(
                         "New resolution and tilesize are not compatible"
                         "With the old resolution and tilesize"
                     )
 
         return Tile(new_grid, self.zone, self.path, self.row)
@@ -326,35 +347,37 @@
                 (x_min, y_min),
             ]
         )
         return geo.Polygon(utm_points)
 
     @property
     def polygon(self) -> geo.Polygon:
-        """ Shapely polygon """
+        """Shapely polygon"""
         x_min, y_min, x_max, y_max = self.utm_bounds
-        utm_points = np.array([
-            (x_min, y_min),
-            (x_max, y_min),
-            (x_max, y_max),
-            (x_min, y_max),
-            (x_min, y_min),
-        ])
+        utm_points = np.array(
+            [
+                (x_min, y_min),
+                (x_max, y_min),
+                (x_max, y_max),
+                (x_min, y_max),
+                (x_min, y_min),
+            ]
+        )
         lonlat_points = utm_to_lonlat(utm_points, zone=self.zone)
         return geo.Polygon(lonlat_points)
 
     @property
     def center(self) -> geo.Point:
-        """ Shapely centroid """
+        """Shapely centroid"""
         return self.polygon.centroid
 
     @property
     def epsg(self) -> int:
-        """ Returns the coordinate system's European Petroleum Survey Group
-        geodetic parameter database's standard code, as an integer. """
+        """Returns the coordinate system's European Petroleum Survey Group
+        geodetic parameter database's standard code, as an integer."""
         return 32600 + self.zone
 
     @property
     def proj4(self) -> str:
         return "+proj=utm +zone={} +datum=WGS84 +units=m +no_defs ".format(self.zone)
 
     @property
@@ -428,23 +451,23 @@
             size=[self.tile_extent, self.tile_extent],
             zone=self.zone,
             ti=self.path,
             tj=self.row,
             geotrans=self.geotransform,
             geoTransform=self.geotransform,
             wkt=self.srs,
-            proj4=self.proj4
+            proj4=self.proj4,
         )
         feature = self.feature
         feature["properties"] = properties
         return feature
 
     @property
     def feature(self) -> dict:
-        """ GeoJSON Feature """
+        """GeoJSON Feature"""
         return dict(
             type="Feature",
             geometry=self.polygon,
             properties={"tilekey": str(self)},
         )
 
     def lonlat_to_rowcol(
@@ -452,44 +475,40 @@
         lon: Union[float, Sequence[float]],
         lat: Union[float, Sequence[float]],
     ):
         """Convert lonlat coordinates to pixel coordinates"""
         if type(lon) != type(lat):
             raise InvalidLatLonError("lat and lon should have compatible types")
 
-        if isinstance(lon, (collections.Sequence, np.ndarray)):
+        if isinstance(lon, (collections.abc.Sequence, np.ndarray)):
             if len(lon) != len(lat):
                 raise InvalidLatLonError("lat and lon must be the same length")
 
             utm_coordinates = lonlat_to_utm(
                 np.stack((lon, lat), axis=-1), zone=self.zone
             )
-            return np.round(utm_to_rowcol(utm_coordinates, tile=self)).astype(int)
+            return np.floor(utm_to_rowcol(utm_coordinates, tile=self)).astype(int)
         else:
-            utm_coordinates = lonlat_to_utm(
-                np.array([(lon, lat)]), zone=self.zone
-            )
-            return np.round(utm_to_rowcol(utm_coordinates, tile=self)[0]).astype(int)
+            utm_coordinates = lonlat_to_utm(np.array([(lon, lat)]), zone=self.zone)
+            return np.floor(utm_to_rowcol(utm_coordinates, tile=self)[0]).astype(int)
 
     def rowcol_to_lonlat(
         self,
         row: Union[int, Sequence[int]],
         col: Union[int, Sequence[int]],
     ):
         """Convert pixel coordinates to lonlat coordinates"""
         if type(row) != type(col):
             raise InvalidRowColError("row and col should have compatible types")
 
-        if isinstance(row, (collections.Sequence, np.ndarray)):
+        if isinstance(row, (collections.abc.Sequence, np.ndarray)):
             if len(row) != len(col):
                 raise InvalidRowColError("row and col must be the same length")
 
-            utm_coordinates = rowcol_to_utm(
-                np.stack((row, col), axis=-1), tile=self
-            )
+            utm_coordinates = rowcol_to_utm(np.stack((row, col), axis=-1), tile=self)
             return utm_to_lonlat(utm_coordinates, zone=self.zone)
         else:
             utm_coordinates = rowcol_to_utm(np.array([(row, col)]), tile=self)
             return utm_to_lonlat(utm_coordinates, zone=self.zone)[0]
 
     def subtile(
         self,
@@ -536,29 +555,23 @@
         if not np.allclose(new_tilesize % 1, 0.0):
             raise InvalidTileError(
                 "The tile can only be subdivided if the subdivide * new tilesize * new resolution is "
                 "equal to the original tilesize * original resolution"
             )
         new_tilesize = int(new_tilesize)
 
-        grid = Grid(
-            resolution=new_resolution, tilesize=new_tilesize, pad=new_pad
-        )
+        grid = Grid(resolution=new_resolution, tilesize=new_tilesize, pad=new_pad)
 
         # Get the path, row of the lower-left corner subtile
         ll_path = self.path * subdivide
         ll_row = self.row * subdivide
 
         # Get the path, row of the upper-left corner subtile
         ul_path = ll_path
         ul_row = ll_row + subdivide - 1
 
         if row is not None:
-            return Tile(
-                grid=grid, zone=self.zone, path=ul_path + col, row=ul_row - row
-            )
+            return Tile(grid=grid, zone=self.zone, path=ul_path + col, row=ul_row - row)
 
         for j in range(subdivide):
             for i in range(subdivide):
-                yield Tile(
-                    grid=grid, zone=self.zone, path=ul_path + i, row=ul_row - j
-                )
+                yield Tile(grid=grid, zone=self.zone, path=ul_path + i, row=ul_row - j)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dltile/utils.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dltile/utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,19 +1,33 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import numpy as np
 import shapely.geometry as geo
 
 from .conversions import points_from_polygon
 from . import utm as utm
 
 
 def utm_box_to_lonlat(polygon: geo.Polygon, zone: int) -> geo.base.BaseGeometry:
-    """ Given a box (polygon with four corners) in UTM coordinates, return
+    """Given a box (polygon with four corners) in UTM coordinates, return
     a box in lonlat coordinates which behaves appropriately at the prime
     antimeridian and polar regions. This is used in tile.py to construct
-    appropriate tile boundaries. """
+    appropriate tile boundaries."""
     min_x, min_y, max_x, max_y = polygon.bounds
 
     polygon_lonlat = utm.utm_to_lonlat(polygon, zone)
     min_lon, min_lat, max_lon, max_lat = polygon_lonlat.bounds
 
     points_lonlat = np.array(points_from_polygon(polygon_lonlat)[0])
 
@@ -26,31 +40,27 @@
     wrap_north = polygon.touches(north_pole) or polygon.contains(north_pole)
     wrap_south = polygon.touches(south_pole) or polygon.contains(south_pole)
 
     if wrap_north or wrap_south:
         n_points, _ = points_lonlat.shape
 
         points_by_lon = np.sort(points_lonlat, axis=0)
-        wrapforward = points_by_lon[0, :][np.newaxis] + np.array(
-            [(360.0, 0.0)]
-        )
+        wrapforward = points_by_lon[0, :][np.newaxis] + np.array([(360.0, 0.0)])
         wrapback = points_by_lon[-1, :][np.newaxis] - np.array([(360.0, 0.0)])
 
         # Create a polygon that goes beyond 90deg latitude, then cut it down
         # to the real range of lonlat.
         if wrap_north:
             excessive_polygon = geo.Polygon(
                 np.concatenate(
                     (
                         wrapback,
                         points_by_lon,
                         wrapforward,
-                        np.array(
-                            [(wrapforward[0, 0], 91.0), (wrapback[0, 0], 91.0)]
-                        ),
+                        np.array([(wrapforward[0, 0], 91.0), (wrapback[0, 0], 91.0)]),
                     ),
                     axis=0,
                 )
             )
         else:  # wrap_south
             excessive_polygon = geo.Polygon(
                 np.concatenate(
@@ -64,17 +74,15 @@
                                 (wrapforward[0, 0], -91.0),
                             ]
                         ),
                     ),
                     axis=0,
                 )
             )
-        return excessive_polygon.intersection(
-            geo.box(-180.0, -90.0, 180.0, 90.0)
-        )
+        return excessive_polygon.intersection(geo.box(-180.0, -90.0, 180.0, 90.0))
 
     # A square in UTM coordinates which does not contain a pole can never
     # map to a polygon with longitude range greater than 180deg.
     # So because this polygon crosses the prime antimeridian, we know it
     # doesn't cross the prime meridian, and we can split it accordingly.
 
     wraps_prime_antimeridian = (
@@ -86,19 +94,15 @@
     lons = points_lonlat[:, 0]
     eastern_lons_mask = lons >= 0.0
     western_lons_mask = lons < 0.0
 
     western_points = points_lonlat.copy()
     western_points[eastern_lons_mask, 0] -= 360.0
     western_hemisphere = geo.box(-180.0, -90.0, 0.0, 90.0)
-    western_polygon = geo.Polygon(western_points).intersection(
-        western_hemisphere
-    )
+    western_polygon = geo.Polygon(western_points).intersection(western_hemisphere)
 
     eastern_points = points_lonlat.copy()
     eastern_points[western_lons_mask, 0] += 360.0
     eastern_hemisphere = geo.box(0.0, -90.0, 180.0, 90.0)
-    eastern_polygon = geo.Polygon(eastern_points).intersection(
-        eastern_hemisphere
-    )
+    eastern_polygon = geo.Polygon(eastern_points).intersection(eastern_hemisphere)
 
     return geo.MultiPolygon([western_polygon, eastern_polygon])
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dltile/utm.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dltile/utm.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,24 @@
 """ Descartes Labs utilities for our Universal Transverse Mercator (UTM)-based
 projection system. """
 
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 # The Descartes Labs projection system is slightly different from the
 # canonical UTM standard. Only North UTM zones are used, including for the
 # southern hemisphere; so there are no false northings. Also, the latitude
 # range is extended to the full +/-90 (instead of -80 to +84).
 
 from collections.abc import Sequence
 import json
@@ -30,19 +44,15 @@
 
 # usually written 'n'
 THIRD_FLATTENING = FLATTENING / (2 - FLATTENING)
 # Usually written 'A'
 RECTIFYING_RADIUS = (
     EARTH_MAJOR_AXIS
     / (1 + THIRD_FLATTENING)
-    * (
-        1.0
-        + 1.0 / 4.0 * THIRD_FLATTENING ** 2
-        + 1.0 / 64.0 * THIRD_FLATTENING ** 4
-    )
+    * (1.0 + 1.0 / 4.0 * THIRD_FLATTENING**2 + 1.0 / 64.0 * THIRD_FLATTENING**4)
 )
 
 # Numbers outside these ranges are surely outside their UTM zone
 # (but not strictly invalid)
 UTM_MIN_EAST = FALSE_EASTING - 334000
 UTM_MAX_EAST = FALSE_EASTING + 334000
 
@@ -95,31 +105,44 @@
             return json.dumps(geo.mapping(transformed_points))
 
         elif isinstance(points, dict):
             points = geo.shape(points)
             transformed_points = _transform(points, *args, **kwargs)
             return geo.mapping(transformed_points)
 
+        elif isinstance(points, geo.MultiPoint):
+            return geo.MultiPoint(
+                [_transform(geom, *args, **kwargs) for geom in points.geoms]
+            )
+
+        elif isinstance(points, geo.MultiLineString):
+            return geo.MultiLineString(
+                [_transform(geom, *args, **kwargs) for geom in points.geoms]
+            )
+
         elif isinstance(points, geo.MultiPolygon):
             return geo.MultiPolygon(
-                [_transform(polygon, *args, **kwargs) for polygon in points]
+                [_transform(geom, *args, **kwargs) for geom in points.geoms]
+            )
+
+        elif isinstance(points, geo.GeometryCollection):
+            return geo.GeometryCollection(
+                [_transform(geom, *args, **kwargs) for geom in points.geoms]
             )
 
         elif isinstance(points, Sequence):
             try:
                 if np.isfinite(points).all():
                     points = np.array(points, dtype=np.double)
                 else:
                     raise TypeError  # Catch
             except TypeError:
                 # The elements of this sequence could not become a numpy array,
                 # try instead to see if this is a list of polygons.
-                return [
-                    _transform(polygon, *args, **kwargs) for polygon in points
-                ]
+                return [_transform(polygon, *args, **kwargs) for polygon in points]
 
         elif isinstance(points, geo.Polygon):
             exterior_points, *interiors_points = points_from_polygon(points)
             return geo.Polygon(
                 _transform(exterior_points, *args, **kwargs),
                 holes=[
                     _transform(interior_points, *args, **kwargs)
@@ -142,15 +165,15 @@
         return transformed_points.reshape(shape).swapaxes(axis, -1)
 
     return _transform
 
 
 @coordinate_transform
 def lonlat_to_utm(points, zone=None, ref_lon=None):
-    """ Convert lon,lat points in a numpy array or shapely shape to UTM
+    """Convert lon,lat points in a numpy array or shapely shape to UTM
     coordinates in the given zone.
 
     Parameters
     ----------
 
     points: numpy array, shapely polygon/multipolygon, geojson, or array-like
         Points of WGS84 lon,lat coordinates
@@ -180,26 +203,26 @@
         zone = lon_to_zone(ref_lon)
 
     # These series expansion coefficients are sufficient to approximate the UTM
     # projection system to a precision of millimeters.
     n = THIRD_FLATTENING
     N = 2 * np.sqrt(n) / (1.0 + n)
 
-    a1 = 1.0 / 2.0 * n - 2.0 / 3.0 * n ** 2 + 5.0 / 16.0 * n ** 3
-    a2 = 13.0 / 48.0 * n ** 2 - 3.0 / 5.0 * n ** 3
-    a3 = 61.0 / 240.0 * n ** 3
+    a1 = 1.0 / 2.0 * n - 2.0 / 3.0 * n**2 + 5.0 / 16.0 * n**3
+    a2 = 13.0 / 48.0 * n**2 - 3.0 / 5.0 * n**3
+    a3 = 61.0 / 240.0 * n**3
 
     lon = points[:, 0]
     lat = points[:, 1]
     radlon = np.deg2rad(lon - 6.0 * zone + 183.0)
     radlat = np.deg2rad(lat)
 
     sinlat = np.sin(radlat)
     t = np.sinh(np.arctanh(sinlat) - N * np.arctanh(N * sinlat))
-    etap = np.arctanh(np.sin(radlon) / np.sqrt(1 + t ** 2))
+    etap = np.arctanh(np.sin(radlon) / np.sqrt(1 + t**2))
     xip = np.arctan(t / np.cos(radlon))
 
     easting = FALSE_EASTING + POINT_SCALE_FACTOR * RECTIFYING_RADIUS * (
         etap
         + a1 * np.cos(2 * xip) * np.sinh(2 * etap)
         + a2 * np.cos(4 * xip) * np.sinh(4 * etap)
         + a3 * np.cos(6 * xip) * np.sinh(6 * etap)
@@ -217,15 +240,15 @@
     )
 
     return np.stack((easting, northing), axis=-1)
 
 
 @coordinate_transform
 def utm_to_lonlat(points, zone):
-    """ Convert UTM points in a numpy array or shapely shape to lon,lat
+    """Convert UTM points in a numpy array or shapely shape to lon,lat
     coordinates in the given zone.
 
     Parameters
     ----------
 
     points: numpy array, shapely polygon/multipolygon, geojson, or array-like
         Points of x,y coordinates in the given UTM north zone
@@ -246,21 +269,21 @@
         When UTM zone is outside of 1 to 60 inclusive, or the numpy array
         axis does not have size==2.
     """
     # These series expansion coefficients are sufficient to approximate the UTM
     # projection system to a precision of millimeters.
     n = THIRD_FLATTENING
 
-    b1 = 1.0 / 2.0 * n - 2.0 / 3.0 * n ** 2 + 37.0 / 96.0 * n ** 3
-    b2 = 1.0 / 48.0 * n ** 2 + 1.0 / 15.0 * n ** 3
-    b3 = 17.0 / 480.0 * n ** 3
-
-    d1 = 2.0 * n - 2.0 / 3.0 * n ** 2 - 2.0 * n ** 3
-    d2 = 7.0 / 3.0 * n ** 2 - 8.0 / 5.0 * n ** 3
-    d3 = 56.0 / 15.0 * n ** 3
+    b1 = 1.0 / 2.0 * n - 2.0 / 3.0 * n**2 + 37.0 / 96.0 * n**3
+    b2 = 1.0 / 48.0 * n**2 + 1.0 / 15.0 * n**3
+    b3 = 17.0 / 480.0 * n**3
+
+    d1 = 2.0 * n - 2.0 / 3.0 * n**2 - 2.0 * n**3
+    d2 = 7.0 / 3.0 * n**2 - 8.0 / 5.0 * n**3
+    d3 = 56.0 / 15.0 * n**3
 
     easting = points[:, 0]
     northing = points[:, 1]
 
     xi = northing / (POINT_SCALE_FACTOR * RECTIFYING_RADIUS)
     eta = (easting - FALSE_EASTING) / (POINT_SCALE_FACTOR * RECTIFYING_RADIUS)
 
@@ -275,33 +298,28 @@
         + b2 * np.cos(4 * xi) * np.sinh(4 * eta)
         + b3 * np.cos(6 * xi) * np.sinh(6 * eta)
     )
 
     chi = np.arcsin(np.sin(xip) / np.cosh(etap))
 
     lat = np.rad2deg(
-        chi
-        + d1 * np.sin(2 * chi)
-        + d2 * np.sin(4 * chi)
-        + d3 * np.sin(6 * chi)
-    )
-    lon = (
-        6.0 * zone - 183.0 + np.rad2deg(np.arctan(np.sinh(etap) / np.cos(xip)))
+        chi + d1 * np.sin(2 * chi) + d2 * np.sin(4 * chi) + d3 * np.sin(6 * chi)
     )
+    lon = 6.0 * zone - 183.0 + np.rad2deg(np.arctan(np.sinh(etap) / np.cos(xip)))
 
     # Return all longitude outputs within the range -180.0, +180.0
     lon = (lon + 180.0) % 360.0 - 180.0
 
     return np.stack((lon, lat), axis=-1)
 
 
 @coordinate_transform
 def utm_to_rowcol(utm_points, tile):
-    """ Convert UTM points in an array of shape (?, 2) to row,col array indices
-    given a tile. """
+    """Convert UTM points in an array of shape (?, 2) to row,col array indices
+    given a tile."""
     if not utm_points.shape[1] == 2:
         raise ValueError(
             "Expected array of utm points of shape (?, 2), got %s"
             % str(utm_points.shape)
         )
 
     min_col = tile.tilesize * tile.path - tile.pad
@@ -314,25 +332,24 @@
     col = east / tile.resolution - min_col
 
     return np.stack((row, col), axis=-1)
 
 
 @coordinate_transform
 def rowcol_to_utm(indices, tile):
-    """ Convert row,col array indices in an array of shape (?, 2) to UTM
-    coordinates given a tile.  """
+    """Convert row,col array indices in an array of shape (?, 2) to UTM
+    coordinates given a tile."""
     if not indices.shape[1] == 2:
         raise ValueError(
-            "Expected array of utm points of shape (?, 2), got %s"
-            % str(indices.shape)
+            "Expected array of utm points of shape (?, 2), got %s" % str(indices.shape)
         )
 
     min_col = tile.tilesize * tile.path - tile.pad
     max_row = tile.tilesize * (tile.row + 1) + tile.pad
 
     row = indices[:, 0]
     col = indices[:, 1]
 
-    east = (col + min_col) * tile.resolution + FALSE_EASTING
-    north = (max_row - row) * tile.resolution
+    east = (col + min_col + 0.5) * tile.resolution + FALSE_EASTING
+    north = (max_row - row - 0.5) * tile.resolution
 
     return np.stack((east, north), axis=-1)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dotdict/dotdict.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dotdict/dotdict.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,7 +1,21 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import reprlib
 from itertools import islice
 
 
 class DotDict(dict):
     """
     Subclass of dict, with "dot" (attribute) access to keys,
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/dotdict/tests/test_dotdict.py` & `descarteslabs-2.0.0/descarteslabs/core/common/dotdict/tests/test_dotdict.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,31 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import unittest
 import pytest
 import textwrap
 import random
 import string
 import ast
 import json
-import six
-from descarteslabs.common.dotdict import DotDict, DotList, DotDict_items, DotDict_values
-from descarteslabs.common.dotdict.dotdict import IndentedRepr, idr, untruncated_idr
+
+from .. import DotDict, DotList, DotDict_items, DotDict_values
+from ..dotdict import IndentedRepr, idr, untruncated_idr
 
 
 class TestDotDict(unittest.TestCase):
     def test_from_dict(self):
         template = {"a": 1, "b": 2, "c": [0, -1]}
         d = DotDict(template)
         assert d == template
@@ -113,43 +127,28 @@
 
     def test_jsonable(self):
         d = DotDict(long=[[list(range(100))]])
         _ = d.long[0][0][0]  # force list to be converted to DotList  # noqa: F841
         from_json = json.loads(json.dumps(d))
         assert from_json == d
 
-    def test_six_iteritems(self):
-        d = DotDict({"a": 1, "subdict": {"x": 0, "z": -1}, "sublist": [{"y": "foo"}]})
-        iterator = six.iteritems(d)
-        assert not isinstance(iterator, list)
-        for k, v in iterator:
-            if isinstance(v, dict):
-                assert isinstance(v, DotDict)
-                v.foo = "bar"
-            if isinstance(v, list):
-                assert isinstance(v, DotList)
-                v.append(None)
-        assert d.subdict.foo == "bar"
-        assert d.sublist[1] is None
-
     def test_items(self):
         d = DotDict({"a": 1, "subdict": {"x": 0, "z": -1}, "sublist": [{"y": "foo"}]})
         items = d.items()
         assert isinstance(items, DotDict_items)
         for k, v in items:
             if isinstance(v, dict):
                 assert isinstance(v, DotDict)
                 v.foo = "bar"
             if isinstance(v, list):
                 assert isinstance(v, DotList)
                 v.append(None)
         assert d.subdict.foo == "bar"
         assert d.sublist[1] is None
 
-    @unittest.skipIf(six.PY2, "Dict view objects only exist in py3")
     def test_DotDict_view(self):
         d1 = DotDict({"a": 0, "b": 1})
         d2 = DotDict({"a": 0, "c": 2})
 
         items1 = d1.items()
         items2 = d2.items()
         assert len(items1) == 2
@@ -168,24 +167,14 @@
 
         with pytest.raises(TypeError):
             hash(items1)
 
         with pytest.raises(AttributeError):
             items1.foo()
 
-    def test_six_itervalues(self):
-        d = DotDict({"subdictA": {"x": 0}, "subdictB": {"x": 1}})
-        iterator = six.itervalues(d)
-        assert not isinstance(iterator, list)
-        for v in iterator:
-            assert isinstance(v.x, int)
-            v.foo = "bar"
-        assert d.subdictA.foo == "bar"
-        assert d.subdictB.foo == "bar"
-
     def test_values(self):
         d = DotDict({"subdictA": {"x": 0}, "subdictB": {"x": 1}})
         values = d.values()
         assert isinstance(values, DotDict_values)
         for v in values:
             assert isinstance(v.x, int)
             v.foo = "bar"
@@ -245,17 +234,15 @@
             )
 
     @classmethod
     def is_unboxed(cls, obj):
         if not isinstance(obj, (dict, list)):
             return True
         if isinstance(obj, dict):
-            return type(obj) is dict and all(
-                cls.is_unboxed(x) for x in six.itervalues(obj)
-            )
+            return type(obj) is dict and all(cls.is_unboxed(x) for x in obj.values())
         if isinstance(obj, list):
             return type(obj) is list and all(cls.is_unboxed(x) for x in obj)
 
     def test_basic(self):
         d = DotDict({"a": 1, "b": 2})
 
         unboxed = d.asdict()
@@ -269,15 +256,15 @@
         obj = DotList(DotDict(i=i) for i in range(10))
         unboxed = obj.aslist()
         assert type(unboxed) == list
         assert all(type(x) is dict for x in unboxed)
 
         obj = DotDict({i: DotList(range(i)) for i in range(10)})
         unboxed = obj.asdict()
-        assert all(type(x) is list for x in six.itervalues(unboxed))
+        assert all(type(x) is list for x in unboxed.values())
 
     def test_random_nested_container(self):
         obj = 0
         while isinstance(obj, int):
             obj = self.random_container()
 
         unboxed = obj.asdict() if isinstance(obj, DotDict) else obj.aslist()
@@ -331,24 +318,19 @@
 
 
 class TestIndentedRepr(unittest.TestCase):
     def test_idr_short(self):
         assert (
             idr.indent == 2
         ), "indented repr indent has changed, other tests will fail"
-        obj = [{u"key": 1.01, "bool": False, (1, (2, 3)): {"a", "b", "c"}}, [4, 5, 6]]
+        obj = [{"key": 1.01, "bool": False, (1, (2, 3)): {"a", "b", "c"}}, [4, 5, 6]]
         unicode_prefix = ""
         set_start = "{"
         set_end = "}"
 
-        if six.PY2:  # repr of sets and unicode changed from py2 to py3
-            unicode_prefix = "u"
-            set_start = "set(["
-            set_end = "])"
-
         output = idr.repr(obj)
 
         # The order is not guaranteed.  Look for individual lines.
         # Since the comma depends on the position, skip those.
         assert "[\n" in output
         assert "  {\n" in output
         assert "\n    {}'key': 1.01".format(unicode_prefix) in output
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/http/authorization.py` & `descarteslabs-2.0.0/descarteslabs/core/common/http/authorization.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,37 +1,49 @@
-import six
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 
 def add_bearer(token):
     """For use with Authorization headers, add "Bearer "."""
     if token:
-        return (u"Bearer " if isinstance(token, six.text_type) else b"Bearer ") + token
+        return ("Bearer " if isinstance(token, str) else b"Bearer ") + token
     else:
         return token
 
 
 def remove_bearer(token):
     """For use with Authorization headers, strip any "Bearer "."""
-    if isinstance(token, (six.text_type, six.binary_type)) and token.lower().startswith(
-        u"bearer " if isinstance(token, six.text_type) else b"bearer "
+    if isinstance(token, (str, bytes)) and token.lower().startswith(
+        "bearer " if isinstance(token, str) else b"bearer "
     ):
         return token[7:]
     else:
         return token
 
 
 def add_basic(token):
     """For use with Authorization headers, add "Basic "."""
     if token:
-        return (u"Basic " if isinstance(token, six.text_type) else b"Basic ") + token
+        return ("Basic " if isinstance(token, str) else b"Basic ") + token
     else:
         return token
 
 
 def remove_basic(token):
     """For use with Authorization headers, strip any "Basic "."""
-    if isinstance(token, (six.text_type, six.binary_type)) and token.lower().startswith(
-        u"basic " if isinstance(token, six.text_type) else b"basic "
+    if isinstance(token, (str, bytes)) and token.lower().startswith(
+        "basic " if isinstance(token, str) else b"basic "
     ):
         return token[6:]
     else:
         return token
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/property_filtering/filtering.py` & `descarteslabs-2.0.0/descarteslabs/core/common/property_filtering/filtering.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,26 +1,30 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
+import re
+
+
 class Expression(object):
-    """An expression for filtering a property against a value or set of values.
+    """An expression is the result of a filtering operation.
 
-    An expression contains a :py:class:`Property`, a comparison operator, and a value (or set of values):
+    An expression can contain a :py:class:`Property`, a comparison operator, and a
+    value (or set of values):
 
         | ``property`` ``operator`` ``value``
         | or
         | ``value`` ``operator`` ``property``
 
     where the operator can be
 
@@ -31,43 +35,57 @@
     * >
     * >=
 
     If the operator is ``<``, ``<=``, ``>`` or ``>=``, you can construct a range using
 
         ``value`` ``operator`` ``property`` ``operator`` ``value``
 
-    Expressions can be combined using the Boolean operators ``and`` or ``or``,
-    but due to language limitations
+    Expressions can be combined using the Boolean operators ``&`` and ``|`` to form
+    larger expressions. Due to language limitations
     the operator for ``and`` is expressed as ``&`` and the operator for ``or`` is
-    expressed as ``|``.
+    expressed as ``|``. Also, because of operator precedence, you must bracket
+    expressions with ``(`` and ``)`` to avoid unexpected behavior:
+
+        ``(`` ``property`` ``operator`` ``value`` ``)`` ``&`` ``(`` ``value`` ``operator`` ``property`` ``)``
+
+    In addition there is a method-like operator that can be used on a
+    property.
+
+    * :py:meth:`Property.any_of` or :meth:`Property.in_`
+
+    And a couple of properties that allow you to verify whether a property value has
+    been set or not. A property value is considered ``null`` when it's either set to
+    ``None`` or to the empty list ``[]`` in case of a list property. These are only
+    available for the Catalog Service.
 
-    In addition there are a couple of method-like operators that can be used on a
-    property:
+    * :py:attr:`Property.isnull`
+    * :py:attr:`Property.isnotnull`
 
-    * :meth:`~descarteslabs.common.property_filtering.filtering.Property.like`
-    * :meth:`~descarteslabs.common.property_filtering.filtering.Property.any_of` or
-      :meth:`~descarteslabs.common.property_filtering.filtering.Property.in_`
-
-    Example
-    -------
-    >>> from descarteslabs.common.property_filtering import GenericProperties
-    >>> p = GenericProperties()
+    Examples
+    --------
+    >>> from descarteslabs.common.property_filtering import Properties
+    >>> p = Properties()
     >>> e = p.foo == 5
     >>> type(e)
     <class 'descarteslabs.common.property_filtering.filtering.EqExpression'>
     >>> e = p.foo.any_of([1, 2, 3, 4, 5])
     >>> type(e)
     <class 'descarteslabs.common.property_filtering.filtering.OrExpression'>
     >>> e = 5 < p.foo < 10
     >>> type(e)
     <class 'descarteslabs.common.property_filtering.filtering.RangeExpression'>
     >>> e = (5 < p.foo < 10) & p.foo.any_of([1, 2, 3, 4, 5])
     >>> type(e)
     <class 'descarteslabs.common.property_filtering.filtering.AndExpression'>
-
+    >>> e = p.foo.isnotnull
+    >>> type(e)
+    <class 'descarteslabs.common.property_filtering.filtering.IsNotNullExpression'>
+    >>> e = p.foo.isnull
+    >>> type(e)
+    <class 'descarteslabs.common.property_filtering.filtering.IsNullExpression'>
     """
 
     def __and__(self, other):
         return AndExpression([self]) & other
 
     def __or__(self, other):
         return OrExpression([self]) | other
@@ -91,83 +109,201 @@
 
 # A second convention was added to allow for Catalog V2 object to be used
 # instead of the name for == and != operations, and to convert
 # that into the `id` field of the object.
 
 
 class EqExpression(Expression):
+    """Whether a property value is equal to the given value."""
+
     def __init__(self, name, value):
         self.name, self.value = self._convert_name_value_pair(name, value)
 
     def serialize(self):
         return {"eq": {self.name: self.value}}
 
     def jsonapi_serialize(self, model=None):
-        value = (
+        name, value = (
             model._serialize_filter_attribute(self.name, self.value)
             if model
-            else self.value
+            else (self.name, self.value)
         )
-        return {"op": "eq", "name": self.name, "val": value}
+        return {"op": "eq", "name": name, "val": value}
+
+    def evaluate(self, obj):
+        return getattr(obj, self.name) == self.value
 
 
 class NeExpression(Expression):
+    """Whether a property value is not equal to the given value."""
+
     def __init__(self, name, value):
         self.name, self.value = self._convert_name_value_pair(name, value)
 
     def serialize(self):
         return {"ne": {self.name: self.value}}
 
     def jsonapi_serialize(self, model=None):
-        value = (
+        name, value = (
             model._serialize_filter_attribute(self.name, self.value)
             if model
-            else self.value
+            else (self.name, self.value)
         )
-        return {"op": "ne", "name": self.name, "val": value}
+        return {"op": "ne", "name": name, "val": value}
+
+    def evaluate(self, obj):
+        return getattr(obj, self.name) != self.value
 
 
 class RangeExpression(Expression):
+    """Whether a property value is within the given range.
+
+    A range can have a single value that must be ``>``, ``>=``,
+    ``<`` or ``<=`` than the value of the property. If the range
+    has two values, the property value must be between the given
+    range values.
+    """
+
     def __init__(self, name, parts):
         self.name = name
         self.parts = parts
 
     def serialize(self):
         return {"range": {self.name: self.parts}}
 
     def jsonapi_serialize(self, model=None):
-        serialized = [
-            {
-                "name": self.name,
-                "op": op,
-                "val": model._serialize_filter_attribute(self.name, val)
+        serialized = []
+        for op, val in self.parts.items():
+            name, value = (
+                model._serialize_filter_attribute(self.name, val)
                 if model
-                else val,
-            }
-            for (op, val) in self.parts.items()
-        ]
+                else (self.name, val)
+            )
+            serialized.append({"name": name, "op": op, "val": value})
         return serialized[0] if len(serialized) == 1 else {"and": serialized}
 
+    def evaluate(self, obj):
+        result = True
+
+        for op, val in self.parts.items():
+            if op == "gte":
+                result = result and getattr(obj, self.name) >= val
+            elif op == "gt":
+                result = result and getattr(obj, self.name) > val
+            elif op == "lte":
+                result = result and getattr(obj, self.name) <= val
+            elif op == "lt":
+                result = result and getattr(obj, self.name) < val
+            else:
+                raise ValueError("Unknown operation")
+
+        return result
+
+
+class IsNullExpression(Expression):
+    """Whether a property value is ``None`` or ``[]``."""
+
+    def __init__(self, name):
+        self.name = name
+
+    def serialize(self):
+        raise TypeError("'isnull' expression is not supported")
+        # return {"isnull": self.name}
+
+    def jsonapi_serialize(self, model=None):
+        name = self.name
+
+        if model:
+            name, _ = model._serialize_filter_attribute(self.name, None)
+
+        return {"name": name, "op": "isnull"}
+
+    def evaluate(self, obj):
+        return getattr(obj, self.name) is None
+
+
+class IsNotNullExpression(Expression):
+    """Whether a property value is not ``None`` or ``[]``."""
+
+    def __init__(self, name):
+        self.name = name
+
+    def serialize(self):
+        raise TypeError("'isnotnull' expression is not supported")
+        # return {"isnotnull": self.name}
+
+    def jsonapi_serialize(self, model=None):
+        name = self.name
+
+        if model:
+            name, _ = model._serialize_filter_attribute(self.name, None)
+
+        return {"name": name, "op": "isnotnull"}
+
+    def evaluate(self, obj):
+        return getattr(obj, self.name) is not None
+
+
+class PrefixExpression(Expression):
+    """Whether a string property value starts with the given string prefix."""
+
+    def __init__(self, name, value):
+        self.name = name
+        self.value = value
+
+    def serialize(self):
+        return {"prefix": {self.name: self.value}}
+
+    def jsonapi_serialize(self, model=None):
+        if model:
+            name, _ = model._serialize_filter_attribute(self.name, None)
+
+        return {"op": "prefix", "name": name, "val": self.value}
+
+    def evaluate(self, obj):
+        return getattr(obj, self.name).startswith(self.value)
+
 
 class LikeExpression(Expression):
+    """Whether a property value matches the given wildcard expression.
+
+    The wildcard expression can contain ``%`` for zero or more characters and
+    ``_`` for a single character.
+
+    This can only be used in expressions for the ``Vector`` product.
+    """
+
     def __init__(self, name, value):
         self.name = name
         self.value = value
 
     def serialize(self):
         return {"like": {self.name: self.value}}
 
     def jsonapi_serialize(self, model=None):
-        value = (
-            model._serialize_attribute(self.name, self.value) if model else self.value
-        )
-        return {"name": self.name, "op": "ilike", "val": value}
+        # catalog does not support this, and at present this method
+        # is only used for Catalog V2. If it does start being used
+        # for something else, we'll have to generate the error server
+        # side
+        raise TypeError("'like' expression is not supported")
+        # name, value = (
+        #     model._serialize_filter_attribute(self.name, self.value)
+        #     if model
+        #     else (self.name, self.value)
+        # )
+        # return (name, {"name": name, "op": "ilike", "val": value})
+
+    def evaluate(self, obj):
+        expr = re.escape(self.value).replace("_", ".").replace("%", ".*")
+        return re.match(f"^{expr}$", getattr(obj, self.name)) is not None
 
 
 class AndExpression(object):
+    """``True`` if both expressions are ``True``, ``False`` otherwise."""
+
     def __init__(self, parts):
         self.parts = parts
 
     def __and__(self, other):
         if isinstance(other, AndExpression):
             self.parts.extend(other.parts)
             return self
@@ -184,16 +320,25 @@
 
     def serialize(self):
         return {"and": [x.serialize() for x in self.parts]}
 
     def jsonapi_serialize(self, model=None):
         return {"and": [part.jsonapi_serialize(model=model) for part in self.parts]}
 
+    def evaluate(self, obj):
+        for part in self.parts:
+            if not part.evaluate(obj):
+                return False
+
+        return True
+
 
 class OrExpression(object):
+    """``True`` if either expression is ``True``, ``False`` otherwise."""
+
     def __init__(self, parts):
         self.parts = parts
 
     def __or__(self, other):
         if isinstance(other, OrExpression):
             self.parts.extend(other.parts)
             return self
@@ -210,27 +355,51 @@
 
     def serialize(self):
         return {"or": [x.serialize() for x in self.parts]}
 
     def jsonapi_serialize(self, model=None):
         return {"or": [part.jsonapi_serialize(model=model) for part in self.parts]}
 
+    def evaluate(self, obj):
+        for part in self.parts:
+            if part.evaluate(obj):
+                return True
+
+        return False
+
 
 def range_expr(op):
     def f(self, other):
         # This is a hack to support compound comparisons
         # such as 10 < a < 20
         self.parts[op] = other
         return RangeExpression(self.name, self.parts.copy())
 
     return f
 
 
 class Property(object):
-    """A wrapper object for a single property"""
+    """A filter property that can be used in an expression.
+
+    Although you can generate filter properties by instantiating this class, a more
+    convenient method is to use a
+    :py:class:`~descarteslabs.common.property_filtering.filtering.Properties`
+    instance.
+    By referencing any attribute of a
+    :py:class:`~descarteslabs.common.property_filtering.filtering.Properties`
+    instance the corresponding filter property
+    will be created.
+
+    See :ref:`Properties Introduction <property_filtering>`
+    for a more detailed explanation.
+
+    Examples
+    --------
+    >>> e = Property("modified") > "2020-01-01"
+    """
 
     def __init__(self, name, parts=None):
         self.name = name
         self.parts = parts or {}
 
     __ge__ = range_expr("gte")
     __gt__ = range_expr("gt")
@@ -242,66 +411,111 @@
 
     def __ne__(self, other):
         return NeExpression(self.name, other)
 
     def __repr__(self):
         return "<Property {}>".format(self.name)
 
-    def like(self, other):
+    def prefix(self, prefix):
+        """Compare against a prefix string."""
+        return PrefixExpression(self.name, prefix)
+
+    startswith = prefix
+
+    def like(self, wildcard):
         """Compare against a wildcard string.
 
+        This can only be used in expressions for the ``Vector`` service.
         This allows for wildcards, e.g. ``like("bar%foo")`` where any
         string that starts with ``'bar'`` and ends with ``'foo'`` will be
         matched.
 
         This uses the SQL ``LIKE`` syntax with single character
         wildcard ``'_'`` and arbitrary character wildcard ``'%'``.
 
         To escape either of these wilcard characters prepend it
         with a backslash, which becomes a double backslash in the
         python string, i.e. use ``like("bar\\\\%foo")`` to match exactly
         ``'bar%foo'``.
         """
-        return LikeExpression(self.name, other)
+        return LikeExpression(self.name, wildcard)
+
+    def any_of(self, iterable):
+        """The property must have any of the given values.
 
-    def in_(self, iterable):
-        """
         Asserts that this property must have a value equal to one of the
         values in the given iterable. This can be thought of as behaving
         like an ``in`` expression in Python or an ``IN`` expression in SQL.
         """
-        return OrExpression([(self == item) for item in iterable])
-
-    any_of = in_
+        exprs = [(self == item) for item in iterable]
 
+        if len(exprs) > 1:
+            return OrExpression(exprs)
+        elif len(exprs) == 1:
+            return exprs[0]
+        else:
+            # technically we should return an expression that always evaluates false
+            # (to match python in operator on an empty sequence). But there's nothing
+            # we can do here to create such an expression, so instead error to the user
+            # since they surely didn't mean this.
+            raise ValueError("in_ expression requires at least one item")
+
+    in_ = any_of
+
+    @property
+    def isnull(self):
+        """Whether a property value is ``None`` or ``[]``.
 
-class Properties(object):
-    """A wrapper object to allow constructing filter expressions using properties"""
+        This can only be used in expressions for the ``Catalog`` service.
+        """
+        return IsNullExpression(self.name)
 
-    def __init__(self, *args):
-        self.props = args
+    @property
+    def isnotnull(self):
+        """Whether a property value is not ``None`` or ``[]``.
 
-    def __getattr__(self, attr):
-        if attr in self.props:
-            return Property(attr)
+        This can only be used in expressions for the ``Catalog`` service.
+        """
+        return IsNotNullExpression(self.name)
 
-        raise AttributeError("'Properties' object has no attribute '{}'".format(attr))
 
+class Properties(object):
+    """A wrapper object to construct filter properties by referencing instance attributes.
 
-class GenericProperties(object):
-    """A wrapper object to allow constructing filter expressions using properties.
+    By referring to any instance attribute, a corresponding property will be created.
+    The instance validates whether the generated property is in the list of property
+    names that this instance was created with.
+
+    See :ref:`Properties Introduction <property_filtering>`
+    for a more detailed explanation.
+
+    Parameters
+    ----------
+    name: str
+        The property names that are allowed, each as a positional parameter.
+
+    Examples
+    --------
+    >>> p = Properties("modified", "created")
+    >>> e = p.modified > "2020-01-01"
+    >>> e = p.deleted > "2020-01-01"  # doctest: +SKIP
+    Traceback (most recent call last):
+      ...
+    AttributeError: 'Properties' object has no attribute 'deleted'
+    >>>"""
 
-    You can construct filter expression using the ``==``, ``!=``, ``<``, ``>``,
-    ``<=`` and ``>=`` operators as well as the
-    :meth:`~descarteslabs.common.property_filtering.filtering.Property.like`
-    and :meth:`~descarteslabs.common.property_filtering.filtering.Property.in_`
-    or :meth:`~descarteslabs.common.property_filtering.filtering.Property.any_of`
-    method. You cannot use the boolean keywords ``and`` and ``or`` because of
-    Python language limitations; instead you can combine filter expressions
-    with ``&`` (boolean "and") and ``|`` (boolean "or").
-    """
+    def __init__(self, *args):
+        self.props = args
 
     def __getattr__(self, attr):
         # keep sphinx happy
         if attr == "__qualname__":
             return self.__class__.__qualname__
-        return Property(attr)
+
+        if not self.props:
+            # implement the old GenericProperties
+            return Property(attr)
+
+        if attr in self.props:
+            return Property(attr)
+
+        raise AttributeError("'Properties' object has no attribute '{}'".format(attr))
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/registry/registry.py` & `descarteslabs-2.0.0/descarteslabs/core/common/registry/registry.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,7 +1,21 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from typing import TypeVar, Optional, Mapping, Callable, Tuple
 
 K = TypeVar("K")
 V = TypeVar("V")
 
 
 def registry(
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/retry/retry.py` & `descarteslabs-2.0.0/descarteslabs/core/common/retry/retry.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,44 +1,57 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import datetime
 import functools
 import inspect
 import random
 import time
-
-import six
+from typing import Iterable
 
 _DEFAULT_RETRIES = 3
 _DEFAULT_DELAY_INITIAL = 0.1
 _DEFAULT_DELAY_MULTIPLIER = 2.0
 _DEFAULT_DELAY_MAXIMUM = 60
 _DEFAULT_DELAY_JITTER = (0, 1)
-_SAFE_VALID_ASSIGNMENTS = ("__doc__",)
 
 
 def _name_of_func(f):
     module = inspect.getmodule(f)
+
     if module is not None:
         module = module.__name__
     else:
         module = "<unknown>"
+
     return "{}.{}".format(module, getattr(f, "__name__", f))
 
 
 class Retry(object):
-    """
-    Retry class to wrap functions as a decorator or inline.
+    """Retry class to wrap functions as a decorator or inline.
 
     Example
     -------
 
     >>> import descarteslabs as dl
     >>> retry = dl.common.retry.Retry(
     ...     maximum=30,
     ...     retries=5,
-    ...     exceptions=(dl.client.exceptions.GatewayTimeoutError,)
+    ...     exceptions=(dl.exceptions.GatewayTimeoutError,)
     ... )
     >>> @retry
     ... def flaky(x):
     ...    return x
     >>> flaky("test")
     'test'
     >>> retry(lambda x: x)("test")
@@ -53,27 +66,32 @@
         blacklist=None,
         deadline=None,
         initial=_DEFAULT_DELAY_INITIAL,
         maximum=_DEFAULT_DELAY_MAXIMUM,
         jitter=_DEFAULT_DELAY_JITTER,
         multiplier=_DEFAULT_DELAY_MULTIPLIER,
     ):
-        """
-        Instantiate a Retry object that can be used to wrap a callable.
+        """Instantiate a Retry object that can be used to wrap a callable.
 
         Parameters
         ----------
         retries : int, optional
             The number of retries allowed.
         exceptions : tuple, optional
             A tuple of Exceptions that should always be retried.
         predicate : function, optional
-            A callable that takes an exception and returns true if retryable.
-            This can be used for cases where a generic exception with variable
-            attributes.
+            A callable that takes an exception and returns either a bool or a Tuple[bool, int].
+            If the bool value is true, the wrapped callable was determined to be retryable.
+            This can be used for cases with a generic exception with variable attributes.
+
+            If the return was a Tuple[bool, int], the int value will be used as the delay.
+            This can be used for cases where an exception should only be retried after some
+            variable amount of time.
+            This is typically used for handling `Retry-After` headers in which the server is
+            requesting the client wait for a specific amount of time.
         blacklist : tuple, optional
             A tuple of Exceptions that should never be retried.
         deadline : float, optional
             The deadline in seconds for retries.
         initial : float
             The amount of delay for the before the first retry.
         maximum : float
@@ -92,113 +110,119 @@
         self._deadline = deadline
         self._initial = initial
         self._maximum = maximum
         self._jitter = jitter
         self._multiplier = multiplier
 
     def __call__(self, func):
-        @_wraps(func)
+        @functools.wraps(func)
         def wrapper(*args, **kwargs):
             target = functools.partial(func, *args, **kwargs)
             delay_generator = truncated_delay_generator(
                 initial=self._initial,
                 maximum=self._maximum,
                 jitter=self._jitter,
                 multiplier=self._multiplier,
             )
 
             return self._retry(target, delay_generator)
 
         return wrapper
 
     def _retry(self, func, delay_generator):
-
         deadline = self._deadline_datetime(self._deadline)
-
         retries = self._retries
-
         previous_exceptions = []
 
-        for delay in delay_generator:
+        # delay generator can be a list and should
+        # be converted to an iterator to use with next
+        delay_generator = iter(delay_generator)
 
+        while True:
             try:
                 return func()
             except Exception as e:
-                self._handle_exception(e, previous_exceptions)
+                delay = self._handle_exception(e, previous_exceptions)
+
+            # predicate returned no delay use the generator
+            if delay is None:
+                try:
+                    delay = next(delay_generator)
+                except Exception:
+                    raise ValueError("Bad delay generator")
 
             # will raise RetryError if deadline or retries exceeded
             retries = self._check_retries(
                 retries, _name_of_func(func), deadline, previous_exceptions
             )
-
             time.sleep(delay)
-        else:
-            raise ValueError("Bad delay generator")
 
     def _handle_exception(self, exception, previous_exceptions):
-        if callable(self._predicate) and not self._predicate(exception):
-            raise
+        delay = None
+
+        if callable(self._predicate):
+            # a predicate can either return a bool
+            # or a an Iterable (tuple) containing a bool (if retryable) and a delay
+            retryable = self._predicate(exception)
+            if isinstance(retryable, Iterable):
+                retryable, delay, *_ = retryable
+
+            if not retryable:
+                raise
 
         if self._blacklist is not None and isinstance(exception, self._blacklist):
             raise
 
         if self._exceptions is not None and not isinstance(exception, self._exceptions):
             raise
 
         previous_exceptions.append(exception)
 
+        return delay
+
     def _check_retries(self, retries, name, deadline, previous_exceptions):
         # Raise RetryError if deadline exceeded
         if deadline is not None and deadline <= datetime.datetime.utcnow():
-            six.raise_from(
-                RetryError(
-                    "Deadline of {:.1f}s exceeded while calling {}".format(
-                        deadline, name
-                    ),
-                    previous_exceptions,
-                ),
-                previous_exceptions[-1],
-            )
+            raise RetryError(
+                "Deadline of {:.1f}s exceeded while calling {}".format(deadline, name),
+                previous_exceptions,
+            ) from previous_exceptions[-1]
 
         # Raise RetryError if retries exhausted
         if retries is not None and retries == 0:
-            six.raise_from(
-                RetryError(
-                    "Maximum retry attempts calling {}".format(name),
-                    previous_exceptions,
-                ),
-                previous_exceptions[-1],
-            )
+            raise RetryError(
+                "Maximum retry attempts calling {}".format(name),
+                previous_exceptions,
+            ) from previous_exceptions[-1]
 
         if retries is not None:
             retries -= 1
+
         return retries
 
     @staticmethod
     def _deadline_datetime(deadline):
         if deadline is None:
             return None
+
         return datetime.datetime.utcnow() + datetime.timedelta(seconds=deadline)
 
 
 class RetryError(Exception):
-    """
-    Error raised when the number of retries has been exhausted or the
-    deadline has passed.
-    """
+    """Error raised when the number of retries has been exhausted or the
+    deadline has passed."""
 
     def __init__(self, message, exceptions):
         super(RetryError, self).__init__(message)
         self.message = message
         self._exceptions = exceptions
 
     @property
     def exceptions(self):
-        """
-        Get a list of exceptions that occurred.
+        """Get a list of exceptions that occurred.
 
         Returns
         -------
         list
             The list of exceptions
         """
 
@@ -207,16 +231,15 @@
     def __str__(self):
         return "{}, exceptions: {}".format(self.message, self.exceptions)
 
 
 def truncated_delay_generator(
     initial=None, maximum=None, jitter=None, multiplier=_DEFAULT_DELAY_MULTIPLIER
 ):
-    """
-    A generator for truncated exponential delay.
+    """A generator for truncated exponential delay.
 
     Parameters
     ----------
     initial : float
         The amount of delay for the first generated value.
     maximum : float
         The maximum amount of delay.
@@ -237,18 +260,7 @@
 
         if maximum is not None:
             delay = min(delay, maximum)
 
         yield delay
 
         delay *= multiplier
-
-
-def _wraps(wrapped):
-    """
-    A helper that handles functions not having all attributes in Python 2.
-    """
-
-    if isinstance(wrapped, functools.partial) or not hasattr(wrapped, "__name__"):
-        return six.wraps(wrapped, assigned=_SAFE_VALID_ASSIGNMENTS)
-    else:
-        return six.wraps(wrapped)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/retry/tests/test_retry.py` & `descarteslabs-2.0.0/descarteslabs/core/common/retry/tests/test_retry.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,9 +1,25 @@
-import mock
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from unittest import mock
+
 import pytest
+
 from .. import Retry, RetryError, truncated_delay_generator
 from ..retry import _DEFAULT_DELAY_INITIAL
 
 
 class FakeException(Exception):
     pass
 
@@ -53,43 +69,48 @@
     second = next(delay_generator)
 
     assert first * multiplier == second
 
 
 def test__retry_exceptions():
     Retry(exceptions=(Exception,))._retry(
-        mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+        mock.Mock(side_effect=[FakeException, True]),
+        fake_delay_generator(),
     )
 
     with pytest.raises(FakeException):
         Retry(exceptions=(TypeError,))._retry(
-            mock.Mock(side_effect=[FakeException("")]), fake_delay_generator(),
+            mock.Mock(side_effect=[FakeException("")]),
+            fake_delay_generator(),
         )
 
 
 def test__retry_blacklist():
     Retry(blacklist=(TypeError,))._retry(
         mock.Mock(side_effect=[FakeException, ValueError, True]),
         fake_delay_generator(),
     )
 
     with pytest.raises(FakeException):
         Retry(blacklist=(FakeException,))._retry(
-            mock.Mock(side_effect=[FakeException("")]), fake_delay_generator(),
+            mock.Mock(side_effect=[FakeException("")]),
+            fake_delay_generator(),
         )
 
 
 def test__retry_retries():
     Retry(retries=1, exceptions=(FakeException,))._retry(
-        mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+        mock.Mock(side_effect=[FakeException, True]),
+        fake_delay_generator(),
     )
 
     with pytest.raises(RetryError) as exc_info:
         Retry(retries=0, exceptions=(FakeException,))._retry(
-            mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+            mock.Mock(side_effect=[FakeException, True]),
+            fake_delay_generator(),
         )
 
     assert len(exc_info.value.exceptions) == 1
 
     with pytest.raises(RetryError) as exc_info:
         Retry(retries=1, exceptions=(FakeException,))._retry(
             mock.Mock(side_effect=[FakeException, FakeException, True]),
@@ -97,51 +118,77 @@
         )
 
     assert len(exc_info.value.exceptions) == 2
 
 
 def test__retry_deadline():
     Retry(deadline=10, exceptions=(FakeException,))._retry(
-        mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+        mock.Mock(side_effect=[FakeException, True]),
+        fake_delay_generator(),
     )
 
     with pytest.raises(RetryError) as exc_info:
         Retry(deadline=0, exceptions=(FakeException,))._retry(
-            mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+            mock.Mock(side_effect=[FakeException, True]),
+            fake_delay_generator(),
         )
 
     assert len(exc_info.value.exceptions) == 1
 
 
+def test__retry_delay_from_predicate():
+    def noop_generator():
+        assert False, "noop delay generator called"
+
+        # this cannot be reached but yield is required to make this a generator
+        while True:
+            yield 0
+
+    Retry(predicate=lambda e: (True, 0))._retry(
+        mock.Mock(side_effect=[FakeException, FakeException, True]), noop_generator()
+    )
+
+
+def test__handle_exception_returns_delay():
+    delay = Retry(predicate=lambda e: True)._handle_exception(FakeException, [])
+    assert delay is None
+
+    delay = Retry(predicate=lambda e: (True, 10))._handle_exception(FakeException, [])
+    assert delay == 10
+
+
 def test_RetryError_message():
     with pytest.raises(
         RetryError,
-        match="^Maximum retry attempts calling descarteslabs.common.retry.tests.test_retry.fake_failing_func, exceptions: ",  # noqa
+        match="^Maximum retry attempts calling .*\.fake_failing_func, exceptions: ",  # noqa
     ):
         Retry(retries=0, exceptions=(Exception,))._retry(
-            fake_failing_func, fake_delay_generator(),
+            fake_failing_func,
+            fake_delay_generator(),
         )
 
 
 def test__retry_bad_delay_generator():
     with pytest.raises(ValueError):
         Retry()._retry(mock.Mock(side_effect=[FakeException]), [])
 
     with pytest.raises(ValueError):
         Retry()._retry(mock.Mock(side_effect=[FakeException]), [0])
 
 
 def test__retry_predicate():
     Retry(predicate=lambda e: True)._retry(
-        mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+        mock.Mock(side_effect=[FakeException, True]),
+        fake_delay_generator(),
     )
 
     with pytest.raises(FakeException):
         Retry(predicate=lambda e: False)._retry(
-            mock.Mock(side_effect=[FakeException, True]), fake_delay_generator(),
+            mock.Mock(side_effect=[FakeException, True]),
+            fake_delay_generator(),
         )
 
 
 def test_RetryError():
     exceptions = [FakeException("")]
     assert exceptions == RetryError("message", exceptions).exceptions
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/shapely_support/__init__.py` & `descarteslabs-2.0.0/descarteslabs/core/common/shapely_support/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,24 @@
-try:
-    # only after py3.4
-    import collections.abc as abc
-except ImportError:
-    import collections as abc
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
+import collections.abc as abc
 import geojson
 import shapely.geometry
-import six
 
 
 def shapely_to_geojson(geometry):
     """Converts a Shapely Shape geometry to a GeoJSON geometry"""
     if hasattr(geometry, "__geo_interface__"):
         geometry = shapely.geometry.mapping(geometry)
     return geometry
@@ -25,22 +33,19 @@
     if isinstance(geometry, shapely.geometry.base.BaseGeometry):
         return geometry
 
     if not isinstance(geometry, abc.Mapping):
         try:
             geometry = geometry.__geo_interface__
         except AttributeError:
-            six.raise_from(
-                TypeError(
-                    "geometry object is not a GeoJSON dict, nor has a `__geo_interface__`: {}".format(
-                        geometry
-                    )
-                ),
-                None,
-            )
+            raise TypeError(
+                "geometry object is not a GeoJSON dict, nor has a `__geo_interface__`: {}".format(
+                    geometry
+                )
+            ) from None
 
     geoj = as_geojson_geometry(geometry)
     try:
         shape = shapely.geometry.shape(geoj)
     except Exception:
         raise ValueError(
             "Could not interpret this geometry as a Shapely shape: {}".format(geometry)
@@ -118,22 +123,19 @@
 
         if len(bounds) != 4:
             raise ValueError(
                 "Bounds must a sequence of (minx, miny, maxx, maxy), "
                 "got sequence of length {}".format(len(bounds))
             )
     except TypeError:
-        six.raise_from(
-            TypeError(
-                "Bounds must a sequence of (minx, miny, maxx, maxy), got {}".format(
-                    type(bounds)
-                )
-            ),
-            None,
-        )
+        raise TypeError(
+            "Bounds must a sequence of (minx, miny, maxx, maxy), got {}".format(
+                type(bounds)
+            )
+        ) from None
 
     if bounds[0] >= bounds[2]:
         raise ValueError(
             "minx >= maxx in given bounds, should be (minx, miny, maxx, maxy)"
         )
     if bounds[1] >= bounds[3]:
         raise ValueError(
```

### Comparing `descarteslabs-1.9.1/descarteslabs/common/tasks/futuretask.py` & `descarteslabs-2.0.0/descarteslabs/core/common/client/attributes.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,290 +1,278 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import pickle
-import json
-import time
+from datetime import datetime, timezone
+from typing import TYPE_CHECKING, Callable, Type, TypeVar, Union
 
-from descarteslabs.client.exceptions import NotFoundError
-from descarteslabs.client.services.storage import Storage
+if TYPE_CHECKING:
+    from .document import Document
 
+T = TypeVar("T")
 
-class TransientResultError(Exception):
-    """
-    Raised when attempting to access results for a task that hasn't
-    completed.
-    """
 
-    def __init__(self, message="Result not yet ready"):
-        super(Exception, self).__init__(message)
-
-
-class TimeoutError(Exception):
-    """
-    Raised when attempting to access results for a task that hasn't
-    completed.
-    """
-
-    def __init__(self, message="Timeout exceeded"):
-        super(Exception, self).__init__(message)
-
-
-class ResultType(object):
-    """
-    Possible types of return values for a function.
-    """
-
-    JSON = "json"
-    LEGACY_PICKLE = "pickle"
-
-
-class FutureTask(object):
-    """
-    A submitted task which may or may not have completed yet. Accessing any
-    attributes only available on a completed task (for example `result`)
-    blocks until the task completes.
-    """
-
-    COMPLETION_POLL_INTERVAL_SECONDS = 3
-    SUCCESS = "SUCCESS"
-    FAILURE = "FAILURE"
-
-    def __init__(self, guid, tuid, client=None, args=None, kwargs=None):
-        self.guid = guid
-        self.tuid = tuid
-        if client is None:
-            from descarteslabs.client.services.tasks import Tasks  # circular import
-
-            client = Tasks()
-
-        self.client = client
-        self.args = args
-        self.kwargs = kwargs
-        self._is_return_value_loaded = False
-        self._return_value = None
-        self._task_result = None
-        self._is_log_loaded = False
-        self._log = None
-        self._json_arguments = None
-
-    def get_result(self, wait=False, timeout=None):
-        """
-        Attempt to load the result for this task. After returning from this
-        method without an exception raised, the return value for the task is
-        available through the :attr:`result` property.
-
-        :param bool wait: Whether to wait for the task to complete or raise
-            a :exc:`~descarteslabs.common.tasks.futuretask.TransientResultError`
-            if the task hasnt completed yet.
-        :param int timeout: How long to wait for the task to complete, or
-            :const:`None` to wait indefinitely.
-        """
-        if self._task_result is None:
-            start = time.time()
+class Attribute(object):
+    """An attribute defined on a Document."""
+
+    def __init__(
+        self,
+        type: Type[T] = None,
+        default: Union[T, Callable] = None,
+        doc: str = None,
+        mutable: bool = True,
+        readonly: bool = False,
+        sticky: bool = False,
+    ):
+        """Defines a document attribute.
+
+        Examples
+        --------
+        .. code::
+
+            class MyDocument(Document):
+                id: id = Attribute(readonly=True)
+                name: str = Attribute(str)
+                set_once: str = Attribute(str, mutable=False)
+
+            doc = MyDocument(name="test", set_once="can only be set once")
+            doc.set_once = "error"
+
+        Parameters
+        ----------
+        default : Any, Callable, None
+            The default value for the attribute when no value is defined.
+            If a callable is provided, it will be called once when the attribute is first
+            fetched.
+        doc : str, None
+            Sets the doc string for the attribute.
+        mutable : bool, True
+            If not set, the attribute will be immutable and can only be set once.
+        readonly : bool, False
+            If set, the attribute cannot be modified by the user.
+            This is designed for attributes set and managed exclusively by the server.
+        sticky : bool, False
+            If set, the attribute exists on the client only.
+            This attribute will be ignored when set by the server.
+        """
+
+        if sticky and readonly:
+            raise ValueError("Using sticky and readonly together does not make sense.")
+
+        self.type = type
+        self.default = default
+        self.mutable = mutable
+        self.readonly = readonly
+        self.sticky = sticky
+
+        if doc is None and type:
+            doc = type.__doc__
+
+        doc_modifiers = []
+
+        if not self.mutable:
+            doc_modifiers.append(
+                "The attribute is `immutable` and cannot be modified once set."
+            )
 
-            while timeout is None or (time.time() - start) < timeout:
-                try:
-                    self._task_result = self.client.get_task_result(
-                        self.guid, self.tuid, include=["stacktrace"]
-                    )
-                except NotFoundError:
-                    if not wait:
-                        raise TransientResultError()
-                else:
-                    break
+        if self.readonly:
+            doc_modifiers.append("The attribute is `readonly` and cannot be modified.")
 
-                time.sleep(self.COMPLETION_POLL_INTERVAL_SECONDS)
-            else:
-                raise TimeoutError()
+        doc = "{}: {}".format(self._doc_type, doc)
 
-    def _result_attribute(self, attribute_name, default=None):
-        self.get_result(wait=True)
+        if doc_modifiers:
+            doc += "\n\n" + "\n\n".join(doc_modifiers)
 
-        return self._task_result.get(attribute_name, default)
+        self.__doc__ = doc
 
     @property
-    def ready(self):
-        """
-        Property indicating whether the task has completed
+    def _doc_type(self) -> str:
+        return "{} or {}".format(self.type.__name__, self.default)
 
-        :rtype: bool
-        :return: True if the upload task has completed and status is available, otherwise False.
-        """
-        try:
-            self.get_result(wait=False)
-            return True
-        except TransientResultError:
-            return False
+    def __set_name__(self, owner, name):
+        """Called when an attribute is defined on a document."""
+        if not hasattr(owner, "_attributes"):
+            setattr(owner, "_attributes", dict())
 
-    @property
-    def result(self):
-        """
-        Property indicating the return value of the function for this completed task.
+        if not hasattr(owner, "_modified"):
+            setattr(owner, "_modified", set())
 
-        :rtype: json or pickled type
-        :return: The return value of the function for this completed task.
-        """
-        if not self.is_success:
-            return None
-
-        if not self._is_return_value_loaded:
-            if self._task_result.result_size_bytes > 0:
-                return_value = Storage().get(
-                    self._task_result.result_key, storage_type="result"
-                )
-                result_type = self._task_result.get(
-                    "result_type", ResultType.LEGACY_PICKLE
-                )
-                if result_type == ResultType.JSON:
-                    self._return_value = json.loads(return_value.decode("utf-8"))
-                elif result_type == ResultType.LEGACY_PICKLE:
-                    return_value = pickle.loads(return_value)
-
-                    if isinstance(return_value, dict):
-                        # For backwards-compatibility reasons (the old dlrun client requires it),
-                        # results to be pickled have always been wrapped in a dictionary. However,
-                        # all clients since version 0.10.0 ignore all the dictionary items except
-                        # for 'result', and all clients have always extracted the 'result' element.
-                        # In order for the service to remain compatible with older clients, we
-                        # must continue to do this even though it is wasteful.
-                        self._return_value = return_value["result"]
-                    else:
-                        # for the above reason, this code will likely never be reached.
-                        self._return_value = return_value
-                else:
-                    raise RuntimeError(
-                        "Unknown result type: %s - update your tasks client"
-                    )
-            else:
-                self._return_value = None
-
-            self._is_return_value_loaded = True
+        self.name = name
 
-        return self._return_value
-
-    @property
-    def log(self):
-        """
-        Property indicating the log output for this completed task.
+    def __get__(self, instance: "Document", owner) -> T:
+        """Called when an attribute value is accessed.
 
-        :rtype: str
-        :return: The log output
+        If no value is defined for the attribute, the default will be applied.
         """
-        self.get_result(wait=True)
+        # Instance will be None if accessed as a class property
+        # this occurs when generating documentation with Sphinx.
+        # In this case, return the attribute instance for documentation.
+        if instance is None:
+            return self
 
-        if not self._is_log_loaded and self._task_result.get("log_size_bytes", 1) > 0:
-            try:
-                self._log = Storage().get(
-                    self._task_result.result_key, storage_type="logs"
-                )
-            except NotFoundError:
-                self._log = None
+        if self.name not in instance._attributes:
+            if callable(self.default):
+                default = self.default()
+            else:
+                default = self.default
 
-            self._is_log_loaded = True
+            instance._attributes[self.name] = self.deserialize(default)
 
-        return self._log
+        return instance._attributes.get(self.name)
 
-    @property
-    def peak_memory_usage(self):
-        """
-        Property indicating the peak memory usage for this completed task, in bytes.
+    def __set__(self, instance: "Document", value, force: bool = False):
+        """Called when attribute is set to a given value.
 
-        :rtype: int
-        :return: The peak memory usage
-        """
-        return self._result_attribute("peak_memory_usage")
+        Values will be deserialized to the type defined in the attribute.
+        Additionally, the attribute will be marked as modified.
 
-    @property
-    def runtime(self):
+        Parameters
+        ----------
+        force : bool, False
+            When force is set, the value is assumed to be from the server.
+            In this case, `mutable` and `readonly` are ignored and `sticky` is respected.
         """
-        Property indicating the time spent executing the function for this task,
-        in seconds.
+        if force and self.sticky:
+            return
 
-        :rtype: int
-        :return: The time spent executing the function
-        """
-        return self._result_attribute("runtime")
+        if not force:
+            self._raise_immutable("set", instance)
 
-    @property
-    def status(self):
-        """
-        Property indicating the status (:const:`SUCCESS` or :const`FAILURE`) for
-        this completed task.
+        if self.type and value is not None:
+            value = self.deserialize(value)
 
-        :rtype: str
-        :return: The status for this completed task.
-        """
-        return self._result_attribute("status")
+        # Only update the value if it has changed
+        if (self.name not in instance._attributes and value is None) or (
+            instance._attributes.get(self.name) == value
+        ):
+            return
 
-    @property
-    def is_success(self):
-        """
-        Did this task succeeed?
+        # It is being set by the server, it is no longer modified
+        if force:
+            instance._modified.discard(self.name)
+        else:
+            instance._modified.add(self.name)
 
-        :rtype: bool
-        :return: Whether this task succeeded.
-        """
-        return self.status == FutureTask.SUCCESS
+        instance._attributes[self.name] = value
 
-    @property
-    def exception_name(self):
-        """
-        Property indicating the name of the exception raised during the function
-        execution, if any
+    def __delete__(self, instance: "Document", force: bool = False):
+        """Called when an attribute is deleted."""
+        if not force:
+            self._raise_immutable("delete", instance)
+
+        instance._attributes.pop(self.name, None)
+
+    def _raise_immutable(self, operation: str, instance: "Document"):
+        """Raises an error when an attribute cannot be modified."""
+        if self.readonly:
+            raise ValueError(
+                "Unable to {} readonly attribute '{}'".format(operation, self.name)
+            )
 
-        :rtype: str
-        :return: The name of the exception or :const:`None`
-        """
-        return self._result_attribute("exception_name")
+        if not self.mutable and (
+            instance is None or instance._attributes.get(self.name, None)
+        ):
+            raise ValueError(
+                "Unable to {} immutable attribute '{}'".format(operation, self.name)
+            )
 
-    exception = exception_name
+    def deserialize(self, value) -> T:
+        """Deserializes a value to the type in the attribute."""
+        if value is None or isinstance(value, self.type):
+            return value
 
-    @property
-    def stacktrace(self):
-        """
-        Property indicating the stacktrace of the exception raised during the function
-        execution, if any.
-
-        :rtype: str
-        :return: The stacktrace of the exception or :const:`None`
-        """
-        return self._result_attribute("stacktrace")
+        try:
+            return self.type(value)
+        except (ValueError, TypeError) as e:
+            raise ValueError(f"Unable to assign {type(value)} to type {self.type}: {e}")
+
+    def serialize(self, value):
+        """Serializes a value to a JSON encodable type."""
+        return value
+
+
+class DatetimeAttribute(Attribute):
+    """Represents a datetime attribute on a document."""
+
+    def __init__(
+        self,
+        timezone=None,
+        remote_timezone=timezone.utc,
+        default: Union[T, Callable] = None,
+        mutable: bool = True,
+        readonly: bool = False,
+        sticky: bool = False,
+        **extra,
+    ):
+        """Defines a datetime attribute.
+
+        Parameters
+        ----------
+        timezone : timezone, None
+            The timezone the client would like dates to be in.
+            By default, this will used the timezone defined by the user's machine.
+        remote_timezone : timezone, timezone.utc
+            The timezone the server will return dates in.
+            By default, this is assumed to be UTC.
+        default : Any, Callable, None
+            The default value for the attribute when no value is defined.
+            If a callable is provided, it will be called once when the attribute is first
+            fetched.
+        mutable : bool, True
+            If not set, the attribute will be immutable and can only be set once.
+        readonly : bool, False
+            If set, the attribute cannot be modified by the user.
+            This is designed for attributes set and managed exclusively by the server.
+        sticky : bool, False
+            If set, the attribute exists on the client only.
+            This attribute will be ignored when set by the server.
+        """
+        self.timezone = timezone
+        self.remote_timezone = remote_timezone
+
+        super().__init__(
+            type=datetime,
+            default=default,
+            mutable=mutable,
+            readonly=readonly,
+            sticky=sticky,
+            **extra,
+        )
+
+    def deserialize(self, value: str) -> T:
+        """Deserialize a server datetime."""
+        if value is None:
+            return None
 
-    traceback = stacktrace
+        if isinstance(value, (int, float)):
+            value = datetime.fromtimestamp(value, tz=self.remote_timezone)
 
-    @property
-    def failure_type(self):
-        """
-        The type of failure if this task did not succeed.
+        if isinstance(value, str):
+            if value.endswith("Z"):
+                value = value[:-1] + "+00:00"
 
-        :rtype: str
-        :return: The failure type
-        """
-        return self._result_attribute("failure_type")
+            value = datetime.fromisoformat(value)
 
-    def __eq__(self, other):
-        return self.guid == other.guid and self.tuid == other.tuid
+        if isinstance(value, datetime):
+            if not value.tzinfo:
+                value.replace(tzinfo=self.remote_timezone)
 
-    def __repr__(self):
-        s = "Task\n"
-        if self.ready:
-            s += "\tStatus: {}\n".format(self._task_result.status)
-            s += "\tMemory usage (MiB): {:.2f}\n".format(
-                self._task_result.peak_memory_usage / (1024 * 1024.0)
-            )
-            s += "\tRuntime (s): {}\n".format(self._task_result.runtime)
+            return value.astimezone(tz=self.timezone)
         else:
-            s += "\tStatus: Pending\n"
+            raise ValueError("Expected iso formatted date or unix timestamp")
+
+    def serialize(self, value: datetime):
+        """Serialize a datetime in local time to server time in iso format."""
+        if value is None:
+            return value
 
-        return s
+        return value.astimezone(tz=self.remote_timezone).isoformat()
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/__init__.py` & `descarteslabs-2.0.0/descarteslabs/core/scenes/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,26 +9,40 @@
 * :doc:`SceneCollection <docs/scenecollection>`: conveniently work with Scenes in aggregate
 * :doc:`search <docs/search>`: search for Scenes
 * :doc:`display <docs/display>`: display ndarrays with matplotlib
 
 It's available under ``descarteslabs.scenes``.
 """
 
-from .geocontext import AOI, DLTile, XYZTile, GeoContext
-from ._display import display, save_image
-from ._search import search
+from ..common.geo import AOI, DLTile, XYZTile, GeoContext
+from ..common.collection import Collection
+from ..common.display import display, save_image
+from .search_api import (
+    get_product,
+    get_band,
+    get_derived_band,
+    search,
+    search_products,
+    search_bands,
+    search_derived_bands,
+)
 from .scene import Scene
-from .collection import Collection
 from .scenecollection import SceneCollection
 
 __all__ = [
     "Scene",
     "SceneCollection",
     "Collection",
     "AOI",
     "DLTile",
     "XYZTile",
     "GeoContext",
     "search",
+    "get_product",
+    "get_band",
+    "get_derived_band",
+    "search_products",
+    "search_bands",
+    "search_derived_bands",
     "display",
     "save_image",
 ]
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/_display.py` & `descarteslabs-2.0.0/descarteslabs/core/common/display/_display.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,17 +13,57 @@
 # limitations under the License.
 
 """
 Displays ndarrays as images, but is easier to use and more flexible than matplotlib's ``imshow``.
 """
 
 from __future__ import division
-import six
 
-import descarteslabs.client.addons
+import math
+
+import numpy as np
+from strenum import StrEnum
+
+
+def _import_matplotlib_pyplot():
+    try:
+        import matplotlib
+    except ImportError:
+        raise ImportError("The matplotlib package is required for displaying images.")
+    try:
+        # a change in matplotlib at some point causes certain runtime failures
+        # unless these are previously imported
+        import matplotlib.backends
+        import matplotlib.backends.backend_agg  # noqa F401
+    except ImportError:
+        pass
+    try:
+        import matplotlib.pyplot
+    except RuntimeError as e:
+        if matplotlib.get_backend() == "MacOSX":
+            raise RuntimeError(
+                "Python is not installed as a framework; the Mac OS X backend will not work.\n"
+                "To resolve this, *before* calling dl.scenes.display(), execute this code:\n\n"
+                "import matplotlib\n"
+                "matplotlib.use('TkAgg')\n"
+                "import matplotlib.pyplot as plt\n\n"
+                "In an interactive session, you'll have to restart your Python interpreter first."
+            )
+        else:
+            raise e
+    return matplotlib
+
+
+class LayoutDirection(StrEnum):
+    left_to_right = "left-to-right"
+    top_to_bottom = "top-to-bottom"
+
+    @classmethod
+    def directions(cls):
+        return [attr for attr in dir(cls) if not attr.startswith("_")]
 
 
 def display(*imgs, **kwargs):
     """
     Display 2D and 3D ndarrays as images with matplotlib.
 
     The ndarrays must either be 2D, or 3D with 1 or 3 bands.
@@ -31,15 +71,15 @@
 
     Unlike matplotlib's ``imshow``, arrays can be any dtype;
     internally, each is normalized to the range [0..1].
 
     Parameters
     ----------
     *imgs: 1 or more ndarrays
-        When multiple images are given, each is displayed on its own row.
+        When multiple images are given, each is displayed on its own row by default.
     bands_axis: int, default 0
         Axis which contains bands in each array.
     title: str, or sequence of str; optional
         Title for each image. If a sequence, must be the same length as ``imgs``.
     size: int, default 10
         Length, in inches, to display the longer side of each image.
     robust: bool, default True
@@ -59,14 +99,23 @@
     colormap: str, default None
         The name of a Colormap registered with matplotlib. Some commonly used
         built-in options are 'plasma', 'magma', 'viridis', 'inferno'. See
         https://matplotlib.org/users/colormaps.html for more options.
 
         To use a Colormap, the input images must have a single band. The Colormap
         will be ignored for images with more than one band.
+    figsize: tuple(int), default (size, (size / ncols) * nrows)
+        Width, height in inches.
+    nrows: int, default is the number of images
+        Number of rows if there are multiple images.
+    ncols: int, default 1
+        Number of columns if there are multiple images.
+    layout_direction: str, default "left-to-right"
+        If ncols is greated than 1, it determines whether the layout is left-to-right
+        for the images, or top-to-bottom.
 
     Raises
     ------
     ImportError
         If matplotlib is not installed.
     """
     _display_or_save(None, *imgs, **kwargs)
@@ -85,34 +134,52 @@
     filename: str
         The name and extension of the image to be saved.
 
     """
     _display_or_save(filename, *imgs, **kwargs)
 
 
+def _flatten(axs, left_to_right=True):
+    # Flatten the images into a single stream
+    if left_to_right:
+        for axcol in axs:
+            for ax in axcol:
+                yield ax
+    else:
+        # top to bottom
+        for col in range(len(axs[0])):
+            for axcol in axs:
+                yield axcol[col]
+
+
 def _display_or_save(filename, *imgs, **kwargs):
     if len(imgs) == 0:
         return
 
     bands_axis = kwargs.pop("bands_axis", 0)
     titles = kwargs.pop("title", None)
     size = kwargs.pop("size", 10)
     robust = kwargs.pop("robust", True)
     interpolation = kwargs.pop("interpolation", "bilinear")
     colormap_name = kwargs.pop("colormap", None)
+    figsize = kwargs.pop("figsize", None)
+    nrows = kwargs.pop("nrows", None)
+    ncols = kwargs.pop("ncols", 1)
+    layout_direction = LayoutDirection(
+        kwargs.pop("layoutdirection", LayoutDirection.left_to_right)
+    )
 
     if len(kwargs) > 0:
         raise TypeError(
             "Unexpected keyword arguments for display: {}".format(
-                ", ".join(six.iterkeys(kwargs))
+                ", ".join(kwargs.keys())
             )
         )
 
-    np = descarteslabs.client.addons.numpy
-    matplotlib = descarteslabs.client.addons.import_matplotlib_pyplot()
+    matplotlib = _import_matplotlib_pyplot()
     plt = matplotlib.pyplot
 
     if len(imgs) == 1:
         if isinstance(imgs[0], (list, tuple)):
             raise TypeError(
                 "To display a sequence of images, unpack it: `display(*images_list)`"
             )
@@ -121,30 +188,35 @@
                 "To display a 4D ndarray (image stack), unpack it: `display(*stack)`"
             )
 
     # TODO: facet grid
     # TODO: leaves huge gaps between images that aren't very square
     # would need to calculate figsize better based on shapes of each img
     # or use seaborn?
-    figsize = (size, size * len(imgs))
-    fig, axs = plt.subplots(len(imgs), 1, figsize=figsize, squeeze=False)
+    if nrows is None:
+        nrows = math.ceil(len(imgs) / ncols)
+
+    if figsize is None:
+        figsize = size, (size / ncols) * nrows
+
+    fig, axs = plt.subplots(nrows, ncols, figsize=figsize, squeeze=False)
 
     if isinstance(titles, (list, tuple, np.ndarray)):
         if len(titles) != len(imgs):
             raise ValueError("Different number of titles given than images")
     else:
         titles = [titles] * len(imgs)
 
     colormap = None
     if colormap_name:
         colormap = plt.cm.get_cmap(colormap_name)
 
-    for ax, img, title in zip(axs, imgs, titles):
-        ax = ax[0]
-
+    for ax, img, title in zip(
+        _flatten(axs, layout_direction == LayoutDirection.left_to_right), imgs, titles
+    ):
         if not isinstance(img, np.ndarray):
             raise TypeError("Expected ndarray, instead got {}".format(type(img)))
 
         if len(img.shape) not in (2, 3):
             raise NotImplementedError(
                 "Can only display 2D or 3D arrays, not shape {}".format(img.shape)
             )
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/_scaling.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/scaling.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,15 +1,30 @@
-import six
-from enum import Enum
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 try:
     from collections import abc
 except ImportError:
     import collections as abc
 
+from strenum import StrEnum
+
+from .band import BandType
+
 # supported data types.
 # values must be ordered from smallest to largest, and
 # (arbitrarily) unsigned before signed, integer before float
 valid_data_types = ("Byte", "UInt16", "Int16", "UInt32", "Int32", "Float32", "Float64")
 
 # supported upcasts for each data type
 valid_data_type_casts = {
@@ -33,87 +48,47 @@
     # for floats, this is our default output range,
     # and does not imply the range a float can contain.
     "Float32": [0.0, 1.0],
     "Float64": [0.0, 1.0],
 }
 
 
-class ScalingMode(Enum):
+class ScalingMode(StrEnum):
     RAW = "raw"
     DISPLAY = "display"
     AUTO = "auto"
     PHYSICAL = "physical"
 
 
-class BandType(Enum):
-    SPECTRAL = "spectral"
-    MASK = "mask"
-    CLASS = "class"
-    OTHER = "other"
-    # v1 compatibility
-    DERIVED = "other"
-
-
 class BandScale(object):
     # An explanation for the `mode` and `mode_is_implied` properties of BandScales:
     #
     # A non-implied mode (`mode_is_implied=False`) is when the user has explicitly
     # stated a mode, e.g. "display", "physical", etc. If two bands specify different
     # incompatible modes, this is an error on the part of the user (however "auto"
     # and "display" are fungible). Thus you see `check_mode` raising an error.
     #
     # An implied mode (`mode_is_implied=True` is when the user has not explicitly
     # stated a mode, and instead we are inferring it from the tuple. This is guesswork,
     # and if two different bands imply two incompatible modes, it is not an error but
     # rather a case in which we cannot determine a mode.
     #
-    # Both are used in order to determine which possible input range to use (`default_range` or
+    # Both are used in order to determine which possible input range to use (`display_range` or
     # `data_range`), which possible output range to use (range of the data type, `physical_range`,
     # or [0, 255]), and how to default the output data type. AN explicit mode is stronger, and
     # the implied mode is never consulted unless there is no explicit mode.
 
     def __init__(self, name, properties, mode, mode_is_implied):
         """
         Construct a BandScale instance from band properties and scale specification.
 
         Will raise ValueError for any bad input.
         """
         self.name = name
-        self._properties = {
-            k: properties.get(k)
-            for k in ("type", "dtype", "data_range", "default_range", "physical_range")
-            if k in properties
-        }
-        # ensure required fields are available:
-        if "type" not in self._properties:
-            # handle a derived band
-            if name.startswith("derived:"):
-                self._properties["type"] = BandType.OTHER.value
-            else:
-                raise ValueError(
-                    "Invalid properties for band '{}' is missing 'type' field".format(
-                        name
-                    )
-                )
-        if "dtype" not in self._properties:
-            raise ValueError(
-                "Invalid properties for band '{}' is missing 'dtype' field".format(name)
-            )
-        if "data_range" not in self._properties:
-            raise ValueError(
-                "Invalid properties for band '{}' is missing 'data_range' field".format(
-                    name
-                )
-            )
-        # default_range isn't always populated
-        if "default_range" not in self._properties:
-            self._properties["default_range"] = self._properties["data_range"]
-        # physical_range isn't populated for mask and class types
-        if "physical_range" not in self._properties:
-            self._properties["physical_range"] = self._properties["data_range"]
+        self._properties = properties
         self.mode = mode
         self.mode_is_implied = mode_is_implied
 
     def __getattr__(self, attr):
         if attr in self._properties:
             return self._properties[attr]
         raise AttributeError(
@@ -155,25 +130,32 @@
         if self.mode == ScalingMode.RAW:
             return None
         elif self.mode == ScalingMode.AUTO:
             # this is handled by GDAL itself
             return ()
         elif self.mode == ScalingMode.DISPLAY:
             # 255.99 from GDAL
-            return tuple(self.default_range + [0, 255.99 if ofloat else 255])
+            return tuple(self.display_range) + (0, 255.99 if ofloat else 255)
         elif self.mode == ScalingMode.PHYSICAL:
-            return tuple(self.data_range + self.physical_range)
+            # avoid common no-op
+            if self.data_range == self.physical_range:
+                return None
+            else:
+                return tuple(self.data_range + self.physical_range)
+        else:
+            # shouldn't get here but be explicit
+            return None
 
 
 class TupleBandScale(BandScale):
     def __init__(self, name, properties, value):
         is_pct = []
         is_float = []
         for t in value:
-            if isinstance(t, six.string_types):
+            if isinstance(t, str):
                 if not t.endswith("%"):
                     raise ValueError(
                         "Invalid scaling tuple value '{}' for band '{}' is not a percentage string".format(
                             t, name
                         )
                     )
                 try:
@@ -221,30 +203,30 @@
                 None if self._is_pct[2] else self._tuple[2],
                 None if self._is_pct[3] else self._tuple[3],
             ]
         else:
             return [0, 255]
 
     def get_scale(self, mode, data_type):
-        ifloat = self.dtype.startswith("Float")
+        ifloat = self.data_type.startswith("Float")
         ofloat = data_type.startswith("Float")
         if len(self._tuple) == 0:
             # GDAL handles this
             return ()
         else:
             # generate default ranges
             if mode == ScalingMode.RAW:
-                irange = data_type_ranges[self.dtype]
+                irange = data_type_ranges[self.data_type]
                 # not sure about this; GDAL always uses 0, 255
                 orange = data_type_ranges[data_type]
             elif mode == ScalingMode.PHYSICAL:
                 irange = self.data_range
                 orange = self.physical_range
             else:
-                irange = self.default_range
+                irange = self.display_range
                 orange = [0.0, 255.99]  # from GDAL, works for integer also
             if len(self._tuple) == 2:
                 scale = (self._tuple[0], self._tuple[1], orange[0], orange[1])
             else:
                 scale = self._tuple
             # apply any percentage calculations across the tuple
             return tuple(
@@ -261,33 +243,22 @@
     """
     Create a BandScale instance appropriate for the scale value.
 
     Raises ValueError on invalid input.
     """
     if value is None:
         return NoBandScale(name, properties)
-    elif isinstance(value, six.string_types):
+    elif isinstance(value, str):
         try:
             mode = ScalingMode(value)
         except ValueError:
             raise ValueError(
                 "Invalid scaling mode '{}' for band '{}'".format(value, name)
             )
-        if name.startswith("derived:"):
-            band_type = BandType.OTHER
-        else:
-            try:
-                band_type = BandType(properties["type"])
-            except ValueError:
-                raise ValueError(
-                    "Invalid band type '{}' for band '{}'".format(
-                        properties["type"], name
-                    )
-                )
-        if band_type in (BandType.MASK, BandType.CLASS):
+        if properties["band_type"] in (BandType.MASK, BandType.CLASS):
             # do not scale these automatically, and make mode weak default
             return NoBandScale(name, properties, mode)
         else:
             return AutomaticBandScale(name, properties, mode)
     elif isinstance(value, (list, tuple)):
         if len(value) not in (0, 2, 4):
             raise ValueError(
@@ -305,32 +276,26 @@
     Will raise ValueError for any invalid input.
     """
     scales = []
     # handle four types of values permitted for scaling parameter
     if scaling is None:
         # no scaling
         scales = None
-    elif isinstance(scaling, six.string_types):
+    elif isinstance(scaling, str):
         # automatic mode for all
         for band in bands:
             scales.append(make_band_scale(band, properties[band], scaling))
     elif isinstance(scaling, abc.Mapping):
         # dictionary like mapping for looking up bands and band types
         for band in bands:
             # None is an allowed value, so don't use get()
             if band in scaling:
                 bscale = scaling[band]
             else:
-                try:
-                    band_type = BandType(properties[band]["type"])
-                except ValueError:
-                    raise ValueError(
-                        "Invalid band type '{}' for band '{}'".format(band_type, band)
-                    )
-                if band_type in (BandType.MASK, BandType.CLASS):
+                if properties[band]["band_type"] in (BandType.MASK, BandType.CLASS):
                     bscale = None
                 else:
                     bscale = scaling.get("default_", None)
             scales.append(make_band_scale(band, properties[band], bscale))
     elif isinstance(scaling, abc.Iterable):
         # list, tuple, etc.
         for i, bscale in enumerate(scaling):
@@ -352,15 +317,15 @@
     """
     If the scaling parameter is an iterable (list), add a
     None on the end to match an alpha band which has been
     added to the end of the band list by the caller.
     """
     if (
         scaling is None
-        or isinstance(scaling, six.string_types)
+        or isinstance(scaling, str)
         or isinstance(scaling, abc.Mapping)
         or not isinstance(scaling, abc.Iterable)
     ):
         return scaling
     return list(scaling) + [None]
 
 
@@ -413,19 +378,113 @@
     for dt in valid_data_types:
         rmin, rmax = data_type_ranges[dt]
         if (min is None or min >= rmin) and (max is not None and max <= rmax):
             return dt
     return "Float64"
 
 
+def resolve_processing_level(processing_level, processing_levels, depth=0):
+    """
+    Resolve a processing_level through any aliases to the processing steps.
+
+    Returns list of processing steps, or None if not found.
+
+    Raises ValueError on bad processing levels definitions, although this
+    is really a problem with the metadata, not anything here.
+    """
+    if depth >= 10:
+        # infinite loop, problem with band definitions
+        raise ValueError("Processing levels contains infinite loop")
+    if not processing_level:
+        processing_level = "default"
+    result = processing_levels.get(processing_level)
+
+    if result is None:
+        if depth > 0:
+            # dangling alias, problem with band definitions
+            raise ValueError(
+                f"Processing levels contains dangling alias {processing_level}"
+            )
+        # unknown but not an error
+        return None
+
+    if isinstance(result, str):
+        # alias
+        return resolve_processing_level(result, processing_levels, depth=depth + 1)
+
+    # a real processing level definition
+    return result
+
+
+def properties_for_band(name, band, processing_level):
+    """
+    Gather up relevant properties for the band, applying processing level and defaults.
+    """
+    # DerivedBand has no type field but treat as generic
+    band_type = getattr(band, "type", BandType.GENERIC)
+
+    # defaults on band base properties are real legacy
+    data_type = band.data_type or "UInt16"
+    data_range = band.data_range or [0, 10000]
+    # these are not required, some band types don't have them
+    display_range = None
+    try:
+        display_range = band.display_range
+    except AttributeError:
+        pass
+    if not display_range:
+        display_range = data_range
+    physical_range = None
+    try:
+        physical_range = band.physical_range
+    except AttributeError:
+        pass
+    if not physical_range:
+        physical_range = data_range
+
+    processing_levels = getattr(band, "processing_levels", None)
+    if not processing_levels:
+        # not an error for legacy or mask and class bands
+        if (
+            processing_level
+            and processing_level not in ("default", "toa", "surface")
+            and band_type not in (BandType.MASK, BandType.CLASS)
+        ):
+            raise ValueError(
+                f"Unknown processing_level value {processing_level} for band {name}"
+            )
+    else:
+        processing_level_steps = resolve_processing_level(
+            processing_level, processing_levels
+        )
+        if processing_level_steps:
+            step = processing_level_steps[-1]
+            # processing levels are always Float64 by default, except "dlsr" is special
+            # and always uses the underlying raw band's definitions
+            if step.function != "dlsr":
+                data_type = step.data_type or "Float64"
+                # this is a somewhat arbitrary default (good for reflectance)
+                data_range = step.data_range or data_type_ranges.get(data_type)
+                display_range = step.display_range or data_range
+                physical_range = step.physical_range or data_range
+    return {
+        "name": name,
+        "band_type": band_type,
+        "data_type": data_type,
+        "data_range": data_range,
+        "display_range": display_range,
+        "physical_range": physical_range,
+    }
+
+
 def calc_pct(value, bounds, is_float):
     """
     Helper function to calculate a scaling tuple value from a percentage.
     """
-    if isinstance(value, six.string_types):
+    if isinstance(value, str):
         value = float(value[:-1]) * (bounds[1] - bounds[0]) / 100.0 + bounds[0]
     return value if is_float else int(value)
 
 
 def check_modes(scales, implied=False):
     """
     Checks for and returns any combined mode settings.
@@ -475,43 +534,49 @@
     output_min = min(min_list) if min_list else None
     output_max = max(max_list) if max_list else None
     if output_min is None and output_max is None:
         return None
     return data_type_from_range(output_min, output_max, is_float)
 
 
-def scaling_parameters(properties, bands, scaling, data_type):
+def scaling_parameters(properties, bands, processing_level, scaling, data_type):
     """
     Determine GDAL-style band scaling parameters.
 
     properties is the "bands" dictionary from a product.
 
     returns scales, data_type where scales is either a None or a list of tuples and Nones,
     and data_type is the target GDAL data type.
     """
-    # validate bands
+    # validate bands and resolve properties
+    band_properties = {}
     for band in bands:
         if band not in properties:
             message = "Invalid bands: band '{}' is not available".format(band)
             if "derived:{}".format(band) in properties:
                 message += ", did you mean 'derived:{}'?".format(band)
             raise ValueError(message)
+        band_properties[band] = properties_for_band(
+            band, properties[band], processing_level
+        )
 
     # validate data_type
     if data_type is not None and data_type not in valid_data_types:
-        raise ValueError("Invalid data_type value {}")
+        raise ValueError(f"Invalid data_type value {data_type}")
 
     # handle this common case quickly
     if scaling is None:
         if data_type is None:
-            data_type = common_data_type([properties[band]["dtype"] for band in bands])
+            data_type = common_data_type(
+                [band_properties[band]["data_type"] for band in bands]
+            )
         return scaling, data_type
 
     # get list of BandScales, validates scaling possibly throwing ValueError
-    scales = parse_scaling(properties, bands, scaling)
+    scales = parse_scaling(band_properties, bands, scaling)
 
     # at this point everything is validated, except possible conflicts between
     # specifications for individual bands.
 
     # check any explicit modes, will raise error on conflict
     mode = check_modes(scales)
 
@@ -533,69 +598,81 @@
             mode = ScalingMode.DISPLAY
         elif data_type == "Float32" or data_type == "Float64":
             mode = ScalingMode.PHYSICAL
         else:
             mode = ScalingMode.RAW
     elif data_type is None:
         if mode == ScalingMode.RAW:
-            data_type = common_data_type([properties[band]["dtype"] for band in bands])
+            data_type = common_data_type(
+                [band_properties[band]["data_type"] for band in bands]
+            )
         elif mode == ScalingMode.PHYSICAL:
             data_type = "Float64"
         else:
             data_type = "Byte"
 
     # now take a pass to determine complete scaling for each band
     scales = [bscale.get_scale(mode, data_type) for bscale in scales]
 
+    # simplify no scaling
+    if all([s is None for s in scales]):
+        scales = None
+
     return scales, data_type
 
 
-def multiproduct_scaling_parameters(properties, bands, scaling, data_type):
+def multiproduct_scaling_parameters(
+    properties, bands, processing_level, scaling, data_type
+):
     """
     Determine GDAL-style band scaling parameters.
 
     properties is the dictionary keyed by the product id with values of the "bands" dictionary from that product.
     bands must already be validated.
 
     returns scales, data_type where scales is either a None or a list of tuples and Nones,
     and data_type is the target GDAL data type.
     """
     # validate bands
+    product_band_properties = {}
     for band in bands:
         for product in properties:
             if band not in properties[product]:
                 message = (
                     "Invalid bands: band '{}' is not available in product '{}'".format(
                         band, product
                     )
                 )
                 if "derived:{}".format(band) in properties[product]:
                     message += ", did you mean 'derived:{}'?".format(band)
                 raise ValueError(message)
+            product_band_properties.setdefault(product, {})[band] = properties_for_band(
+                band, properties[product][band], processing_level
+            )
 
     # validate data_type
     if data_type is not None and data_type not in valid_data_types:
         raise ValueError("Invalid data_type value {}")
 
     # handle this common case quickly
     if scaling is None:
         if data_type is None:
             data_type = common_data_type(
                 [
-                    properties[product][band]["dtype"]
-                    for band in bands
-                    for product in properties
+                    product_band_properties[product][band]["data_type"]
+                    for product in product_band_properties
+                    for band in product_band_properties[product]
                 ]
             )
         return scaling, data_type
 
     # loop over all products and bands, get list of BandScales, validates scaling possibly throwing ValueError
     scales = []
-    for product in properties:
-        scales.extend(parse_scaling(properties[product], bands, scaling))
+    for product in product_band_properties:
+        scales.extend(parse_scaling(product_band_properties[product], bands, scaling))
 
     # at this point everything is validated, except possible conflicts between
     # specifications for individual bands. This will be checked below.
 
     # check any explicit modes, will raise error on conflict
     mode = check_modes(scales)
 
@@ -619,31 +696,31 @@
             mode = ScalingMode.PHYSICAL
         else:
             mode = ScalingMode.RAW
     elif data_type is None:
         if mode == ScalingMode.RAW:
             data_type = common_data_type(
                 [
-                    properties[product][band]["dtype"]
-                    for band in bands
-                    for product in properties
+                    product_band_properties[product][band]["data_type"]
+                    for product in product_band_properties
+                    for band in product_band_properties[product]
                 ]
             )
         elif mode == ScalingMode.PHYSICAL:
             data_type = "Float64"
         else:
             data_type = "Byte"
 
     # now take a pass to determine complete scaling for each product*band
     scales = [bscale.get_scale(mode, data_type) for bscale in scales]
 
     # verify the resulting scale parameters for each band is the same across
     # all products
-    products = [product for product in properties]
-    for i in range(1, len(properties)):
+    products = [product for product in product_band_properties]
+    for i in range(1, len(product_band_properties)):
         for j in range(len(bands)):
             if scales[i * len(bands) + j] != scales[j]:
                 raise ValueError(
                     "Invalid scaling incompatible bands for band '{}' in products '{}' and '{}'".format(
                         bands[i], products[0], products[i]
                     )
                 )
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/collection.py` & `descarteslabs-2.0.0/descarteslabs/core/common/collection/collection.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,29 +14,37 @@
 
 """
 A list-based sequence with helper methods, which serves as the base class for `SceneCollection`.
 """
 
 import itertools
 import collections
-import six
+
+from ...client.deprecation import deprecate
+from ...common.property_filtering.filtering import Expression
 
 
 # TODO: maybe subclass collections.UserList?
 class Collection(object):
     """
     List-based sequence with convenience methods for mapping and filtering,
     and NumPy-style fancy indexing
     """
 
     def __init__(self, iterable=None):
         if iterable is None:
             self._list = []
         else:
             self._list = list(iterable)
+            item_type = getattr(self, "_item_type", None)
+            if item_type is not None:
+                if not all(map(lambda i: isinstance(i, item_type), self._list)):
+                    raise ValueError(
+                        f"item is not of required type {item_type.__name__}"
+                    )
 
     def __getitem__(self, idx):
         """
         self[start:stop:step] <--> Collection(list(self[start:stop:step]))
         self[<list>] <--> Collection(self[i] for i in <list>)
         Can slice like a normal list, or with a list of indices to select
         """
@@ -51,32 +59,38 @@
                 return self._list[idx]
 
     def __setitem__(self, idx, item):
         """
         Can assign a scalar, or a list of equal length to the slice,
         to any valid slice (including an list of indices)
         """
-
+        item_type = getattr(self, "_item_type", None)
         if isinstance(idx, (list, slice)) or type(idx).__name__ == "ndarray":
             if isinstance(idx, slice):
                 idx = list(range(*idx.indices(len(self))))
-            if isinstance(item, six.string_types) or not isinstance(
+            if isinstance(item, str) or not isinstance(
                 item, collections.abc.Sequence
             ):  # if scalar
                 item = [item] * len(idx)
             item = list(item)
             if len(idx) != len(item):
                 raise ValueError(
                     "Cannot assign {} items to a slice {} items long".format(
                         len(item), len(idx)
                     )
                 )
             for i, x in zip(idx, item):
+                if item_type is not None and not isinstance(x, item_type):
+                    raise ValueError(
+                        f"item is not of required type {item_type.__name__}"
+                    )
                 self._list[i] = x
         else:
+            if item_type is not None and not isinstance(x, item_type):
+                raise ValueError(f"item is not of required type {item_type.__name__}")
             self._list[idx] = item
 
     def __iter__(self):
         return iter(self._list)
 
     def __reversed__(self):
         return reversed(self._list)
@@ -92,37 +106,43 @@
 
     def __repr__(self):
         return "{}({})".format(self.__class__.__name__, repr(self._list))
 
     def _cast_and_copy_attrs_to(self, other):
         # used to copy over any attrs a subclass may have set
         other = self.__class__(other)
-        for k, v in six.iteritems(self.__dict__):
+        for k, v in self.__dict__.items():
             if k != "_list":
                 setattr(other, k, v)
         return other
 
     @property
     def each(self):
         """
         Any operations chained onto
-        :attr:`~descarteslabs.scenes.collection.Collection.each` (attribute access,
+        :attr:`~descarteslabs.common.collection.Collection.each` (attribute access,
         item access, and calls) are applied to each item in the
-        :class:`~descarteslabs.scenes.collection.Collection`.
+        :class:`~descarteslabs.common.collection.Collection`.
+
+        Yields
+        ------
+        Any
+            The result of an item with all operations following
+            :attr:`~descarteslabs.common.collection.Collection.each` applied to it.
 
         Notes
         -----
-            * Add :meth:`~descarteslabs.scenes.collection.Eacher.combine`
-              at the end of the operations chain to combine the results into a
-              list by default, or any container type passed into
-              :meth:`~descarteslabs.scenes.collection.Eacher.combine`
-            * Use
-              :meth:`pipe(f, *args, **kwargs) <descarteslabs.scenes.collection.Eacher.pipe>`
-              to yield ``f(x, *args, **kwargs)`` for each item ``x`` yielded by the
-              preceeding operations chain
+        * Add :meth:`~descarteslabs.common.collection.Eacher.combine`
+          at the end of the operations chain to combine the results into a
+          list by default, or any container type passed into
+          :meth:`~descarteslabs.common.collection.Eacher.combine`
+        * Use
+          :meth:`pipe(f, *args, **kwargs) <descarteslabs.common.collection.Eacher.pipe>`
+          to yield ``f(x, *args, **kwargs)`` for each item ``x`` yielded by the
+          preceeding operations chain
 
         Examples
         --------
         >>> c = Collection(["one", "two", "three", "four"])
         >>> for x in c.each.capitalize():
         ...     print(x)
         One
@@ -137,42 +157,99 @@
         >>> c.each.capitalize().pipe(len)
         3
         3
         5
         4
         >>> list(c.each.capitalize().pipe(len).combine(set))
         [3, 4, 5]
-
-        Yields
-        ------
-            item with all operations following :attr:`~descarteslabs.scenes.collection.Collection.each` applied to it
-
         """
         return Eacher(iter(self._list))
 
     def map(self, f):
-        "Returns a :class:`~descarteslabs.scenes.collection.Collection` of ``f`` applied to each item"
+        """Returns a :class:`~descarteslabs.common.collection.Collection` of ``f`` applied to each item.
+
+        Parameters
+        ----------
+        f : callable
+            Apply function ``f`` to each element of the collection and return the result
+            as a collection.
+
+        Returns
+        -------
+        Collection
+            A collection with the results of the function ``f`` applied to each element
+            of the original collection.
+        """
 
         res = (f(x) for x in self._list)
-        return self._cast_and_copy_attrs_to(res)
+        item_type = getattr(self, "_item_type", None)
+        if item_type is None or all(map(lambda i: isinstance(i, item_type), res)):
+            return self._cast_and_copy_attrs_to(res)
+        else:
+            return Collection(res)
 
     def filter(self, predicate):
-        "Returns a :class:`~descarteslabs.scenes.collection.Collection` of items for which ``predicate(item)`` is True"
+        """Returns a :class:`~descarteslabs.common.collection.Collection` filtered by predicate.
+
+        Predicate can either be a ``callable`` or an
+        :py:class:`~descarteslabs.common.property_filtering.filtering.Expression`
+        from :ref:`property_filtering`.
+
+        If the predicate is a ``callable``, :py:meth:`filter` will return all items
+        for which ``predicate(item)`` is ``True``.
+
+        If the predicate is an
+        :py:class:`~descarteslabs.common.property_filtering.filtering.Expression`,
+        :py:meth:`filter` will return all items
+        for which ``predicate.evaluate(item)`` is ``True``.
+
+        Parameters
+        ----------
+        predicate : callable or Expression
+            Either a callable or a :ref:`property_filtering` `Expression` which is
+            called or evaluated for each item in the list.
+
+        Returns
+        -------
+        Collection
+            A new collection with only those items for which the predicate returned
+            or evaluated to ``True``.
+        """
+
+        if isinstance(predicate, Expression):
+            res = (x for x in self._list if predicate.evaluate(x))
+        else:
+            res = (x for x in self._list if predicate(x))
 
-        res = (x for x in self._list if predicate(x))
         return self._cast_and_copy_attrs_to(res)
 
     def sorted(self, *predicates, **reverse):
         """
-        Returns a :class:`~descarteslabs.scenes.collection.Collection`,
+        Returns a :class:`~descarteslabs.common.collection.Collection`,
         sorted by predicates in ascending order.
 
         Each predicate can be a key function, or a string of dot-chained attributes
         to use as sort keys. The reverse flag returns results in descending order.
 
+        Parameters
+        ----------
+        predicates : callable or str
+            Any positional arguments are predicates. If the predicate is a string,
+            it denotes an attribute for each element, potentially with levels separated
+            by a dot. If the predicate is a callable, it must return the value to sort
+            by for each given element.
+        reverse : bool
+            The sort is ascending by default, by setting ``reverse`` to
+            ``True``, the sort will be descending.
+
+        Returns
+        -------
+        Collection
+            The sorted collection.
+
         Examples
         --------
         >>> import collections
         >>> FooBar = collections.namedtuple("FooBar", ["foo", "bar"])
         >>> X = collections.namedtuple("X", "x")
         >>> c = Collection([FooBar(1, X("one")), FooBar(2, X("two")), FooBar(3, X("three"))])
 
@@ -181,36 +258,76 @@
         >>> c.sorted("bar.x")
         Collection([FooBar(foo=1, bar=X(x='one')), FooBar(foo=3, bar=X(x='three')), FooBar(foo=2, bar=X(x='two'))])
         """
 
         if len(predicates) == 0:
             raise TypeError("No predicate(s) given to sorted")
         predicates = [
-            self._str_to_predicate(p) if isinstance(p, six.string_types) else p
-            for p in predicates
+            self._str_to_predicate(p) if isinstance(p, str) else p for p in predicates
         ]
         if len(predicates) == 1:
             predicate = predicates[0]
         else:
 
             def predicate(v):
                 return tuple(p(v) for p in predicates)
 
         res = sorted(self, key=predicate, **reverse)
         return self._cast_and_copy_attrs_to(res)
 
-    def groupby(self, *predicates):
+    def sort(self, field, ascending=True):
+        """
+        Returns a :class:`~descarteslabs.common.collection.Collection`,
+        sorted by the given field and direction.
+
+        Parameters
+        ----------
+        field : str
+            The name of the field to sort by
+        ascending : bool
+            Sorts results in ascending order if True (the default),
+            and in descending order if False.
+
+        Returns
+        -------
+        Collection
+            The sorted collection.
+
+        Example
+        -------
+        >>> from descarteslabs.catalog import Product
+        >>> collection = Product.search().collect() # doctest: +SKIP
+        >>> sorted_collection = collection.sort("created", ascending=False) # doctest: +SKIP
+        >>> sorted_collection # doctest: +SKIP
         """
+        return self.sorted(field, reverse=not ascending)
+
+    def groupby(self, *predicates):
+        """Groups items by predicates.
+
         Groups items by predicates and yields tuple of ``(group, items)``
         for each group, where ``items`` is a
-        :class:`~descarteslabs.scenes.collection.Collection`.
+        :class:`~descarteslabs.common.collection.Collection`.
 
         Each predicate can be a key function, or a string of dot-chained attributes
         to use as sort keys.
 
+        Parameters
+        ----------
+        predicates : callable or str
+            Any positional arguments are predicates. If the predicate is a string,
+            it denotes an attribute for each element, potentially with levels separated
+            by a dot. If the predicate is a callable, it must return the value to sort
+            by for each given element.
+
+        Yields
+        ------
+        Tuple[str, Collection]
+            A tuple of ``(group, Collection)`` for each group.
+
         Examples
         --------
         >>> import collections
         >>> FooBar = collections.namedtuple("FooBar", ["foo", "bar"])
         >>> c = Collection([FooBar("a", True), FooBar("b", False), FooBar("a", False)])
 
         >>> for group, items in c.groupby("foo"):
@@ -228,35 +345,60 @@
         True
         Collection([FooBar(foo='a', bar=True)])
         """
 
         if len(predicates) == 0:
             raise TypeError("No predicate(s) given to groupby")
         predicates = [
-            self._str_to_predicate(p) if isinstance(p, six.string_types) else p
-            for p in predicates
+            self._str_to_predicate(p) if isinstance(p, str) else p for p in predicates
         ]
         if len(predicates) == 1:
             predicate = predicates[0]
         else:
 
             def predicate(v):
                 return tuple(p(v) for p in predicates)
 
         ordered = self.sorted(predicate)
         for group, items in itertools.groupby(ordered, predicate):
             yield group, self._cast_and_copy_attrs_to(items)
 
     def append(self, x):
-        "Append x to the end of this :class:`~descarteslabs.scenes.collection.Collection`"
+        """Append x to the end of this :class:`~descarteslabs.common.collection.Collection`.
+
+        The type of the item must match the type of the collection.
+
+        Parameters
+        ----------
+        x : Any
+            Add an item to the collection
+        """
+
+        item_type = getattr(self, "_item_type", None)
+        if item_type is not None and not isinstance(x, item_type):
+            raise ValueError(f"item is not of required type {item_type.__name__}")
 
         self._list.append(x)
 
     def extend(self, x):
-        "Extend this :class:`~descarteslabs.scenes.collection.Collection` by appending elements from the iterable"
+        """Extend this :class:`~descarteslabs.common.collection.Collection` by appending elements from the iterable.
+
+        The type of the items in the list must all match the type of the collection.
+
+        Parameters
+        ----------
+        x : List[Any]
+            Extend a collection with the items from the list.
+        """
+
+        item_type = getattr(self, "_item_type", None)
+        if item_type is not None and not all(
+            map(lambda i: isinstance(i, item_type), x)
+        ):
+            raise ValueError(f"item is not of required type {item_type.__name__}")
 
         self._list.extend(x)
 
     @staticmethod
     def _str_to_predicate(string):
         attrs = string.split(".")
 
@@ -285,21 +427,27 @@
 
     def __getitem__(self, idx):
         return Eacher(x[idx] for x in self)
 
     def __call__(self, *args, **kwargs):
         return Eacher(x(*args, **kwargs) for x in self)
 
-    def combine(self, collection=list):
-        "``self.combine(collection) <--> collection(iter(self))``"
+    @deprecate(renamed={"collection": "op"})
+    def combine(self, op=list):
+        "self.combine(collection) <--> op(iter(self))"
+
+        return op(iter(self))
+
+    def collect(self, collection=Collection):
+        "self.collect(collection) <--> collection(iter(self))"
 
         return collection(iter(self))
 
     def pipe(self, callable, *args, **kwargs):
-        "``self.pipe(f, *args, **kwargs) <--> f(x, *args, **kwargs) for x in self``"
+        "self.pipe(f, *args, **kwargs) <--> f(x, *args, **kwargs) for x in self"
 
         return Eacher(callable(x, *args, **kwargs) for x in self)
 
     def __repr__(self):
         max_length = 8
         objs = list(itertools.islice(self, max_length))
         try:
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/geocontext.py` & `descarteslabs-2.0.0/descarteslabs/core/common/geo/geocontext.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,61 +1,40 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""
-Datasets in the Descartes Labs catalog have many different resolutions and
-projections. In two different images, even covering the same place on Earth,
-the pixels ``(i, j)`` usually correspond to two different points on the ground.
-
-GeoContexts are a way to ensure multiple images from different sources
-are **spatially compatible**---that is, they all have the same shape
-(same width and height, in pixels), and the same pixel in each image
-corresponds to the same area on Earth.
-
-They do this by simply capturing all the spatial parameters that affect how
-imagery is rasterized---namely output resolution, coordinate reference system,
-and bounding box---in one object that can be passed into different method calls.
-In typical use, these contexts are created for you with reasonable defaults,
-so you only need to understand the different parameters when you need more control.
-
-The different subclasses of `GeoContext` implement different
-functionality.
-
-* `AOI` clips to arbitrary geometry, and lets you specify any output resolution
-  and projection.
-* `DLTile` helps you split large regions up into a grid of any spacing and
-  resolution, and represents a single tile in that grid, in UTM projection.
-"""
-
 
 import copy
-import shapely.geometry
-import six
 import threading
 import warnings
 import math
 
-from six.moves import reprlib
+import reprlib
+import mercantile
+import shapely.geometry
 
-from descarteslabs.client.addons import mercantile
-from descarteslabs.common import shapely_support
-from descarteslabs.common.dltile import Tile, Grid
+from .. import shapely_support
+from ..dltile import Tile, Grid
 
-from . import _helpers
+from .utils import (
+    is_geographic_crs,
+    is_wgs84_crs,
+    polygon_from_bounds,
+    valid_latlon_bounds,
+)
 
 EARTH_CIRCUMFERENCE_WGS84 = 2 * math.pi * 6378137
 
 
 class GeoContext(object):
     """
     Specifies spatial parameters to use when loading a raster
@@ -64,55 +43,88 @@
     Two Scenes loaded with the same GeoContext will result in images
     with the same shape (in pixels), covering the same spatial extent,
     regardless of the dimensions or projection of the original data.
 
     Specifically, a fully-defined GeoContext specifies:
 
     * geometry to use as a cutline (WGS84), and/or bounds
-    * resolution (m)
+    * resolution (m) or a shape defining the extent in pixels
     * EPSG code of the output coordinate reference system
     * whether to align pixels to the output CRS
       (see docstring for `AOI.align_pixels` for more information)
 
     GeoContexts are immutable.
     """
 
-    __slots__ = "_geometry_lock_"
+    __slots__ = (
+        "_geometry_lock_",
+        "_all_touched",
+    )
     # slots *suffixed* with an underscore will be ignored by `__eq__` and `__repr__`.
     # a double-underscore prefix would be more conventional, but that actually breaks as a slot name.
 
-    def __init__(self):
+    def __init__(self, all_touched=False):
+        """
+        Parameters
+        ----------
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
+        """
+
         # Shapely objects are not thread-safe, due to the way the underlying GEOS library is used.
         # Specifically, accessing `__geo_interface__` on the same geometry across threads
-        # can cause bizzare exceptions. This makes `raster_params` and `__geo_interface__` thread-unsafe,
-        # which becomes an issue in `SceneCollection.stack` or `download`.
+        # can cause bizzare exceptions. This makes `raster_params` and `__geo_interface__` thread-unsafe.
         # Subclasses of GeoContext can use this lock to ensure `self._geometry.__geo_interface__`
         # is accessed from at most 1 thread at a time.
         self._geometry_lock_ = threading.Lock()
+        self._all_touched = bool(all_touched)
 
     def __getstate__(self):
-        # Lock objects shouldn't be pickled or deepcopied
+        # Lock objects shouldn't be pickled or deepcopied, but recursively get all the other slots
         return {
             attr: getattr(self, attr)
-            for attr in self.__slots__
+            for s in self.__class__.__mro__
+            for attr in getattr(s, "__slots__", [])
             if not attr.endswith("_")
         }
 
     def __setstate__(self, state):
-        for attr, val in six.iteritems(state):
+        for attr, val in state.items():
             setattr(self, attr, val)
         self._geometry_lock_ = threading.Lock()
 
     @property
+    def all_touched(self):
+        """
+        bool: If True, this ensures that any source pixel which intersects the
+        GeoContext contributes to the raster result.
+
+        Normally this mode is not enabled, and its use is strongly discouraged.
+        However, it can be useful when the AOI is smaller than a source pixel,
+        which under many situations will return no result at all (i.e. entirely
+        masked).
+        """
+        return self._all_touched
+
+    @property
     def raster_params(self):
         """
         dict: The properties of this GeoContext,
         as keyword arguments to use for `Raster.ndarray` or `Raster.raster`.
         """
-        raise NotImplementedError
+
+        raster_params = {}
+        if self.all_touched:
+            raster_params["cutline_all_touched"] = True
+
+        return raster_params
 
     def __eq__(self, other):
         """
         Two GeoContexts are equal only if they are the same type,
         and every property is equal.
         """
         if not isinstance(other, self.__class__):
@@ -125,23 +137,24 @@
         return True
 
     def __repr__(self):
         classname = self.__class__.__name__
         delim = ",\n" + " " * (len(classname) + 1)
         props = delim.join(
             "{}={}".format(attr.lstrip("_"), reprlib.repr(getattr(self, attr)))
-            for attr in self.__slots__
+            for s in self.__class__.__mro__
+            for attr in getattr(s, "__slots__", [])
             if not attr.endswith("_")
         )
         return "{}({})".format(classname, props)
 
 
 class AOI(GeoContext):
     """
-    A GeoContext that clips scenes to a geometry, and/or to square bounds,
+    A GeoContext that clips imagery to a geometry, and/or to square bounds,
     with any output resolution and CRS.
 
     Examples
     --------
 
     .. code-block:: python
 
@@ -163,85 +176,108 @@
     )
 
     def __init__(
         self,
         geometry=None,
         resolution=None,
         crs=None,
-        align_pixels=True,
+        align_pixels=None,
         bounds=None,
         bounds_crs="EPSG:4326",
         shape=None,
+        all_touched=False,
     ):
         """
         Parameters
         ----------
         geometry: GeoJSON-like dict, object with ``__geo_interface__``; optional
-            Clip scenes to this geometry.
+            When searching, filter for elements which intersect this geometry.
+            When rastering, clip imagery to this geometry.
             Coordinates must be WGS84 (lat-lon).
-            If :const:`None`, scenes will just be clipped to
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`.
+            If :const:`None`, imagery will just be clipped to
+            :py:attr:`~descarteslabs.common.gecontext.AOI.bounds`.
         resolution: float, optional
-            Distance, in units of the CRS, that the edge of each pixel
-            represents on the ground.
+            Distance, in native units of the CRS, that the edge of each pixel
+            represents on the ground. Do not assume this to always be either
+            degrees or meters.
             Can only specify one of `resolution` and `shape`.
         crs: str, optional
-            Coordinate Reference System into which scenes will be projected,
+            Coordinate Reference System into which imagery will be projected,
             expressed as an EPSG code (like :const:`EPSG:4326`), a PROJ.4 definition,
-            or an OGC CRS Well-Known Text string
-        align_pixels: bool, optional, default True
-            If True, this ensures that, in different Scenes rasterized
+            or an OGC CRS Well-Known Text string.
+        align_pixels: bool, optional, default True if resolution is not None
+            If :const:`True`, this ensures that, in different images rasterized
             with this same AOI GeoContext, pixels ``(i, j)`` correspond
             to the same area in space. This is accomplished by snapping the
             coordinates of the origin (top-left corner of top-left pixel)
-            to a non-fractional interval of `resolution`.
+            to a non-fractional interval of `resolution`. Note that in cases
+            where `shape` has been specified, this may lead to the resulting
+            image being one pixel larger in each dimension, so the the entire
+            bounds is included.
 
-            If `align_pixels` is False, when using scenes with different
-            native resolutions and/or projections, pixels at the same indicies
+            If `align_pixels` is :const:`False`, when using imagery with different
+            native resolutions and/or projections, pixels at the same indices
             can be misaligned by a fraction of `resolution`
             (i.e. correspond to *slighly* different coordinates in space).
 
             However, this requires warping of the original image, which can be
             undesireable when you want to work with the original data in its
             native resolution and projection.
         bounds: 4-tuple, optional
-            Clip scenes to these ``(min_x, min_y, max_x, max_y)`` bounds,
-            expressed in :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds_crs`
+            Clip imagery to these ``(min_x, min_y, max_x, max_y)`` bounds,
+            expressed in :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds_crs`
             (which defaults to WGS84 lat-lon).
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`
+            :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`
             are automatically computed from `geometry` if not specified.
             Otherwise,
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds` are required.
+            :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds` are required.
         bounds_crs: str, optional, default "EPSG:4326"
             The Coordinate Reference System of the
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`,
+            :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`,
             given as an EPSG code (like :const:`EPSG:4326`), a PROJ.4 definition,
             or an OGC CRS Well-Known Text string.
         shape: 2-tuple, optional
             ``(rows, columns)``, in pixels, the output raster should fit within;
             the longer side of the raster will be min(shape).
-            Can only specify one of `resolution` and `shape`.
+            Can only specify one of `resolution` and `shape`. Note that when
+            `align_pixels` is :const:`True`, the actual resulting raster may
+            be one pixel larger in each direction.
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
         """
 
-        super(AOI, self).__init__()
+        super(AOI, self).__init__(all_touched=all_touched)
 
         if bounds is None and geometry is not None:
             bounds = "update"
 
         # If no bounds were given, use the bounds of the geometry
-        self._assign(geometry, resolution, crs, align_pixels, bounds, bounds_crs, shape)
+        self._assign(
+            geometry,
+            resolution,
+            crs,
+            align_pixels,
+            bounds,
+            bounds_crs,
+            shape,
+            "unchanged",
+        )
         self._validate()
 
     @property
     def geometry(self):
         """
-        shapely geometry: Clip scenes to this geometry
+        shapely geometry: Clip imagery to this geometry
         Coordinates must be WGS84 (lat-lon).
-        If :const:`None`, scenes will just be clipped to
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`.
+        If :const:`None`, imagery will just be clipped to
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`.
         """
 
         return self._geometry
 
     @property
     def resolution(self):
         """
@@ -250,58 +286,62 @@
         """
 
         return self._resolution
 
     @property
     def crs(self):
         """
-        str: Coordinate reference system into which scenes will be projected,
+        str: Coordinate reference system into which imagery will be projected,
         expressed as an EPSG code (like :const:`EPSG:4326`), a PROJ.4 definition,
         or an OGC CRS Well-Known Text string.
         """
 
         return self._crs
 
     @property
     def align_pixels(self):
         """
-        bool: If True, this ensures that, in different
-        `Scenes <descarteslabs.scenes.scene.Scene>` rasterized with
+        bool: If True, this ensures that, in different images rasterized with
         this same AOI GeoContext, pixels ``(i, j)`` correspond to the
         same area in space. This is accomplished by snapping the coordinates of
         the origin (top-left corner of top-left pixel) to a non-fractional
-        interval of `resolution`.
+        interval of `resolution`. Note that in cases where `shape` has been
+        specified, this may lead to the resulting image being one pixel larger
+        in each dimension, so the the entire bounds is included.
 
-        If `align_pixels` is False, when using scenes with different native
+        If `align_pixels` is False, when using imagery with different native
         resolutions and/or projections, pixels at the same indicies can be
         misaligned by a fraction of ``resolution`` (i.e. correspond to *slighly*
         different coordinates in space).
 
         However, this requires warping of the original image, which can be
         undesireable when you want to work with the original data in its native
         resolution and projection.
         """
 
-        return self._align_pixels
+        if self._align_pixels is None:
+            return self._resolution is not None
+        else:
+            return self._align_pixels
 
     @property
     def bounds(self):
         """
-        tuple: Clip scenes to these ``(min_x, min_y, max_x, max_y)`` bounds,
+        tuple: Clip imagery to these ``(min_x, min_y, max_x, max_y)`` bounds,
         expressed in the coordinate reference system in
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds_crs`.
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds_crs`.
         """
 
         return self._bounds
 
     @property
     def bounds_crs(self):
         """
         str: The coordinate reference system of the
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`,
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`,
         given as an EPSG code (like :const:`EPSG:4326`), a PROJ.4 definition,
         or an OGC CRS Well-Known Text string.
         """
 
         return self._bounds_crs
 
     @property
@@ -318,74 +358,75 @@
         """
         dict: The properties of this `AOI`,
         as keyword arguments to use for
         :class:`~descarteslabs.client.services.raster.raster.Raster.ndarray` or
         :class:`~descarteslabs.client.services.raster.raster.Raster.raster`.
 
         Raises ValueError if
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`, `crs`,
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds_crs`,
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`, `crs`,
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds_crs`,
         `resolution`, or `align_pixels` is :const:`None`.
         """
 
         # Ensure that there can be no ambiguity: every parameter must be specified,
         # so every raster call using this context will return spatially equivalent data
         if self._bounds is None:
             raise ValueError("AOI must have bounds specified")
         if self._bounds_crs is None:
             raise ValueError("AOI must have bounds_crs specified")
         if self._crs is None:
             raise ValueError("AOI must have CRS specified")
         if self._resolution is None and self._shape is None:
             raise ValueError("AOI must have one of resolution or shape specified")
-        if self._align_pixels is None:
-            raise ValueError("AOI must have align_pixels specified")
+        # align_pixels will always be True or False based on resolution
+        # all_touched doesn't affect the spatial equivalence
 
         with self._geometry_lock_:
             # see comment in `GeoContext.__init__` for why we need to prevent
             # parallel access to `self._geometry.__geo_interface__`
             cutline = (
                 self._geometry.__geo_interface__ if self._geometry is not None else None
             )
 
         dimensions = (
             (self._shape[1], self._shape[0]) if self._shape is not None else None
         )
 
         return {
+            **super().raster_params,
             "cutline": cutline,
             "resolution": self._resolution,
             "srs": self._crs,
             "bounds_srs": self._bounds_crs,
-            "align_pixels": self._align_pixels,
+            "align_pixels": self.align_pixels,
             "bounds": self._bounds,
             "dimensions": dimensions,
         }
 
     @property
     def __geo_interface__(self):
         """
-        dict: :py:attr:`~descarteslabs.scenes.geocontext.AOI.geometry` as a GeoJSON Geometry dict,
+        dict: :py:attr:`~descarteslabs.common.geo.geocontext.AOI.geometry` as a GeoJSON Geometry dict,
         otherwise
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`
         as a GeoJSON Polygon dict if
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.geometry` is
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.geometry` is
         :const:`None` and
-        :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds_crs`
+        :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds_crs`
         is :const:`EPSG:4326`, otherwise
         raises :exc:`RuntimeError`.
         """
 
         if self._geometry is not None:
             with self._geometry_lock_:
                 # see comment in `GeoContext.__init__` for why we need to prevent
                 # parallel access to `self._geometry.__geo_interface__`
                 return self._geometry.__geo_interface__
-        elif self._bounds is not None and _helpers.is_wgs84_crs(self._bounds_crs):
-            return _helpers.polygon_from_bounds(self._bounds)
+        elif self._bounds is not None and is_wgs84_crs(self._bounds_crs):
+            return polygon_from_bounds(self._bounds)
         else:
             raise RuntimeError(
                 "AOI GeoContext must have a geometry set, or bounds set and a WGS84 `bounds_crs`, "
                 "to have a __geo_interface__"
             )
 
     def assign(
@@ -393,98 +434,125 @@
         geometry="unchanged",
         resolution="unchanged",
         crs="unchanged",
         align_pixels="unchanged",
         bounds="unchanged",
         bounds_crs="unchanged",
         shape="unchanged",
+        all_touched="unchanged",
     ):
         """
         Return a copy of the AOI with the given values assigned.
 
         Note
         ----
             If you are assigning a new geometry and want bounds to updated as
             well, use ``bounds="update"``. This will also change
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds_crs`
+            :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds_crs`
             to :const:`EPSG:4326`, since the geometry's coordinates are in WGS84
             decimal degrees, so the new bounds determined from those coordinates
             must be in that CRS as well.
 
             If you assign
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`
+            :py:attr:`~descarteslabs.common.geo.geocontext.AOI.geometry`
             without changing
-            :py:attr:`~descarteslabs.scenes.geocontext.AOI.bounds`,
+            :py:attr:`~descarteslabs.common.geo.geocontext.AOI.bounds`,
             the new AOI GeoContext will produce rasters with the same
             shape and covering the same spatial area as the old one, just with
             pixels masked out that fall outside your new geometry.
 
         Returns
         -------
         new : `AOI`
         """
 
         new = copy.deepcopy(self)
-        new._assign(geometry, resolution, crs, align_pixels, bounds, bounds_crs, shape)
+        new._assign(
+            geometry,
+            resolution,
+            crs,
+            align_pixels,
+            bounds,
+            bounds_crs,
+            shape,
+            all_touched,
+        )
         new._validate()
         return new
 
     def _validate(self):
+        # validate shape
+        if self._shape is not None:
+            if not isinstance(self._shape, (list, tuple)) or len(self._shape) != 2:
+                raise TypeError("Shape must be a tuple of (rows, columns) in pixels")
+
+        # validate resolution
+        if self._resolution is not None:
+            if not isinstance(self._resolution, (int, float)):
+                raise TypeError(
+                    "Resolution must be an int or float, got type '{}'".format(
+                        type(self._resolution).__name__
+                    )
+                )
+            if self._resolution <= 0:
+                raise ValueError("Resolution must be greater than zero")
+
+        # can't set both resolution and shape
+        if self._resolution is not None and self._shape is not None:
+            raise ValueError("Cannot set both resolution and shape")
+
         # test that bounds are sane
         if self._bounds is not None:
             shapely_support.check_valid_bounds(self._bounds)
 
         # rough check that bounds values actually make sense for bounds_crs
         if self._bounds_crs is not None and self._bounds is not None:
-            valid_latlon_bounds = _helpers.valid_latlon_bounds(self._bounds)
-            if _helpers.is_geographic_crs(self._bounds_crs):
-                if not valid_latlon_bounds:
+            is_geographic, lon_wrap = is_geographic_crs(
+                self._bounds_crs, with_lon_wrap=True
+            )
+            if is_geographic:
+                # some whole-globe products are funky around the dateline. Try
+                # to allow up to a 1/2 pixel slop there. This will generally only
+                # occur with AOIs created automatically from Image properties.
+                if self._resolution and self._crs and is_geographic_crs(self._crs):
+                    tol = self._resolution / 2
+                elif self._shape is not None:
+                    tol = (
+                        max(
+                            (self._bounds[2] - self._bounds[0]) / self._shape[1],
+                            (self._bounds[3] - self._bounds[1]) / self._shape[0],
+                        )
+                        / 2
+                    )
+                else:
+                    tol = 0.001
+                if not valid_latlon_bounds(self._bounds, tol, lon_wrap=lon_wrap):
                     raise ValueError(
                         "Bounds must be in lat-lon coordinates, "
                         "but the given bounds are outside [-90, 90] for y or [-180, 180] for x."
                     )
             else:
-                if valid_latlon_bounds:
+                if valid_latlon_bounds(self._bounds):
                     # Warn that bounds are probably in the wrong CRS.
                     # But we can't be sure without a proper tool for working with CRSs,
                     # since bounds that look like valid lat-lon coords
                     # *could* be valid in a different CRS, though unlikely.
                     warnings.warn(
                         "You might have the wrong `bounds_crs` set.\n"
                         "Bounds appear to be in lat-lon decimal degrees, but the `bounds_crs` "
                         "does not seem to be a geographic coordinate reference system "
                         "(i.e. its units are not degrees, but meters, feet, etc.).\n\n"
                         "If this is unexpected, set `bounds_crs='EPSG:4326'`."
                     )
 
-        # validate shape
-        if self._shape is not None:
-            if not isinstance(self._shape, (list, tuple)) or len(self._shape) != 2:
-                raise TypeError("Shape must be a tuple of (rows, columns) in pixels")
-
-        # validate resolution
-        if self._resolution is not None:
-            if not isinstance(self._resolution, (int, float)):
-                raise TypeError(
-                    "Resolution must be an int or float, got type '{}'".format(
-                        type(self._resolution).__name__
-                    )
-                )
-            if self._resolution <= 0:
-                raise ValueError("Resolution must be greater than zero")
-
-        # can't set both resolution and shape
-        if self._resolution is not None and self._shape is not None:
-            raise ValueError("Cannot set both resolution and shape")
-
         # check that bounds and geometry actually intersect (if bounds in wgs84)
         if (
             self._geometry is not None
             and self._bounds is not None
-            and _helpers.is_wgs84_crs(self._bounds_crs)
+            and is_wgs84_crs(self._bounds_crs)
         ):
             bounds_shp = shapely.geometry.box(*self._bounds)
             if not bounds_shp.intersects(self._geometry):
                 raise ValueError(
                     "Geometry and bounds do not intersect. This would result in all data being masked. "
                     "If you're assigning new geometry, assign new bounds as well "
                     "(use `bounds='update'` to use the bounds of the new geometry)."
@@ -495,29 +563,35 @@
 
         # This most often happens when switching from a projected to a geodetic CRS (i.e. UTM to WGS84)
         # and not updating the (units of the) resolution accordingly, so you now have, say,
         # 30 decimal degrees as your resolution. Probably not what you meant.
 
         # TODO: better way of checking equivalence between CRSs than string equality
         if (
-            self._crs is not None
+            not self._all_touched
+            and self._crs is not None
             and self._resolution is not None
             and self._bounds is not None
             and self._bounds_crs == self._crs
         ):
             crs_width = self._bounds[2] - self._bounds[0]
             crs_height = self._bounds[3] - self._bounds[1]
             msg = (
                 "Output raster's {dim} ({dim_len:.4f}) is smaller than its resolution "
                 "({res:.4f}), meaning it would be less than one pixel {dim_adj}.\n"
                 "Remember that resolution is specified in units of the output CRS, "
                 "which are not necessarily meters."
             )
-            if _helpers.is_geographic_crs(self._crs):
+            if is_geographic_crs(self._crs):
                 msg += "\nSince your CRS is in lat-lon coordinates, resolution must be given in decimal degrees."
+            msg += (
+                "\nIf you are intending to raster an area smaller than the source imagery resolution, then you"
+                "should set an appropriate value of resolution, shape, or all_touched=True on the supplied AOI"
+                " to signal your intentions."
+            )
 
             if crs_width < self._resolution:
                 raise ValueError(
                     msg.format(
                         dim="width",
                         dim_len=crs_width,
                         res=self._resolution,
@@ -531,15 +605,23 @@
                         dim_len=crs_height,
                         res=self._resolution,
                         dim_adj="tall",
                     )
                 )
 
     def _assign(
-        self, geometry, resolution, crs, align_pixels, bounds, bounds_crs, shape
+        self,
+        geometry,
+        resolution,
+        crs,
+        align_pixels,
+        bounds,
+        bounds_crs,
+        shape,
+        all_touched,
     ):
         # we use "unchanged" as a sentinel value, because None is a valid thing to set attributes to.
         if geometry is not None and geometry != "unchanged":
             geometry = shapely_support.geometry_like_to_shapely(geometry)
 
         if bounds is not None and bounds != "unchanged":
             if bounds == "update":
@@ -563,40 +645,49 @@
                     )
             else:
                 bounds = tuple(bounds)
 
         if geometry != "unchanged":
             self._geometry = geometry
         if resolution != "unchanged":
+            # To avoid breaking existing code, avoid a conflict with shape.
+            # getattr() to handle pre-init cases.
+            if (
+                getattr(self, "_resolution", None) is None
+                and getattr(self, "_shape", None) is not None
+            ):
+                self._shape = None
             self._resolution = resolution
         if crs != "unchanged":
             self._crs = crs
         if align_pixels != "unchanged":
             self._align_pixels = align_pixels
         if bounds != "unchanged":
             self._bounds = bounds
         if bounds_crs != "unchanged":
             self._bounds_crs = bounds_crs
         if shape != "unchanged":
             self._shape = shape
+        if all_touched != "unchanged":
+            self._all_touched = bool(all_touched)
 
 
 class DLTile(GeoContext):
     """
-    A GeoContext that clips and projects
-    :class:`Scenes <descarteslabs.scenes.scene.Scene>` to a single DLTile.
+    A GeoContext that clips and projects imagery to a single DLTile.
 
     DLTiles allow you to define a grid of arbitrary spacing, resolution,
     and overlap that can cover the globe.
+
     DLTiles are always in a UTM projection.
 
     Example
     -------
     >>> import descarteslabs as dl
-    >>> from descarteslabs.scenes import DLTile
+    >>> from descarteslabs.geo import DLTile
     >>> tile = DLTile.from_latlon(
     ...    lat=35.691,
     ...    lon=-105.944,
     ...    tilesize=512,
     ...    resolution=10,
     ...    pad=0
     ... )
@@ -636,22 +727,34 @@
         "_ti",
         "_tj",
         "_geotrans",
         "_proj4",
         "_wkt",
     )
 
-    def __init__(self, dltile_dict):
+    def __init__(self, dltile_dict, all_touched=False):
         """
         Constructs a DLTile from a parameter dictionary.
-        It is preferred to use the `DLTile.from_latlon`, `DLTile.from_shape`,
-        or `DLTile.from_key` class methods to construct a DLTile GeoContext.
+        It is preferred to use the
+        :meth:`DLTile.from_latlon, :meth:`DLTile.from_shape`, or :meth:`DLTile.from_key`
+        class methods to construct a DLTile GeoContext.
+
+        Parameters
+        ----------
+        dltile_dict: Dict[Str, Any]
+            Dictionary for the tile.
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
         """
 
-        super(DLTile, self).__init__()
+        super(DLTile, self).__init__(all_touched=all_touched)
 
         if isinstance(dltile_dict["geometry"], shapely.geometry.polygon.Polygon):
             self._geometry = dltile_dict["geometry"]
         else:
             self._geometry = shapely.geometry.shape(dltile_dict["geometry"])
 
         properties = dltile_dict["properties"]
@@ -668,15 +771,15 @@
 
         # these properties may not be present
         self._geotrans = properties.get("geotrans", None)
         self._proj4 = properties.get("proj4", None)
         self._wkt = properties.get("wkt", None)
 
     @classmethod
-    def from_latlon(cls, lat, lon, resolution, tilesize, pad):
+    def from_latlon(cls, lat, lon, resolution, tilesize, pad, all_touched=False):
         """
         Return a DLTile GeoContext that covers a latitude/longitude.
 
         Where the point falls within the tile will vary, depending on the point
         and tiling parameters.
 
         Parameters
@@ -688,22 +791,28 @@
         resolution : float
             Distance, in meters, that the edge of each pixel represents on the ground
         tilesize : int
             Length of each side of the tile, in pixels
         pad : int
             Number of extra pixels by which each side of the tile is buffered.
             This determines the number of pixels by which two tiles overlap.
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
 
         Returns
         -------
         tile : DLTile
 
         Example
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> # make a tile with total size 100, centered on lat, lon
         >>> # total tilesize == tilesize + 2 * pad
         >>> params = {
         ...    "lat": 30.0131,
         ...    "lon": 31.2089,
         ...    "resolution": 10,
         ...    "tilesize": 2,
@@ -712,24 +821,22 @@
         >>> tile = DLTile.from_latlon(**params)
         >>> tile.key
         '2:49:10.0:36:-8637:166079'
         >>> tile.geometry.centroid.xy  # doctest: +SKIP
         (array('d', [31.20899205942612]), array('d', [30.013121672688087]))
         """
 
-        grid = Grid(
-            resolution=resolution,
-            tilesize=tilesize,
-            pad=pad
-        )
+        grid = Grid(resolution=resolution, tilesize=tilesize, pad=pad)
         tile = grid.tile_from_lonlat(lat=lat, lon=lon)
-        return cls(tile.geocontext)
+        return cls(tile.geocontext, all_touched=all_touched)
 
     @classmethod
-    def from_shape(cls, shape, resolution, tilesize, pad, keys_only=False):
+    def from_shape(
+        cls, shape, resolution, tilesize, pad, keys_only=False, all_touched=False
+    ):
         """
         Return a list of DLTiles that intersect the given geometry.
 
         Parameters
         ----------
         shape : GeoJSON-like
             A GeoJSON dict, or object with a ``__geo_interface__``. Must be in
@@ -740,22 +847,28 @@
             Length of each side of the tile, in pixels.
         pad : int
             Number of extra pixels by which each side of the tile is buffered.
             This determines the number of pixels by which two tiles overlap.
         keys_only : bool, default False
             Whether to return DLTile objects or only DLTile keys. Set to True when
             returning a large number of tiles and you do not need the full objects.
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
 
         Returns
         -------
         tiles : List[DLTile] or List[Str]
 
         Example
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> shape = {
         ... "type":"Feature",
         ... "geometry":{
         ...     "type":"Polygon",
         ...     "coordinates":[[
         ...            [-122.51140471760839,37.77130087547876],
         ...            [-122.45475646845254,37.77475476721895],
@@ -770,35 +883,33 @@
         ...    tilesize=500,
         ...    pad=0,
         ... )
         >>> len(tiles)
         31
         """
 
-        grid = Grid(
-            resolution=resolution,
-            tilesize=tilesize,
-            pad=pad
-        )
+        grid = Grid(resolution=resolution, tilesize=tilesize, pad=pad)
 
         if grid._estimate_ntiles_from_shape(shape) > 50000:
             warnings.warn(
                 "DLTile.from_shape will return a large number of tiles. "
                 "Consider using DLTile.iter_from_shape instead."
             )
 
         tiles = grid.tiles_from_shape(shape=shape, keys_only=keys_only)
         if keys_only:
             result = [tile for tile in tiles]
         else:
-            result = [cls(tile.geocontext) for tile in tiles]
+            result = [cls(tile.geocontext, all_touched=all_touched) for tile in tiles]
         return result
 
     @classmethod
-    def iter_from_shape(cls, shape, resolution, tilesize, pad, keys_only=False):
+    def iter_from_shape(
+        cls, shape, resolution, tilesize, pad, keys_only=False, all_touched=False
+    ):
         """
         Return a iterator for DLTiles that intersect the given geometry.
 
         Parameters
         ----------
         shape : GeoJSON-like
             A GeoJSON dict, or object with a ``__geo_interface__``. Must be in
@@ -809,22 +920,28 @@
             Length of each side of the tile, in pixels.
         pad : int
             Number of extra pixels by which each side of the tile is buffered.
             This determines the number of pixels by which two tiles overlap.
         keys_only : bool, default False
             Whether to return DLTile objects or only DLTile keys. Set to True when
             returning a large number of tiles and you do not need the full objects.
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
 
         Returns
         -------
         Iterator of DLTiles or str
 
         Example
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> shape = {
         ... "type":"Feature",
         ... "geometry":{
         ...     "type":"Polygon",
         ...     "coordinates":[[
         ...            [-122.51140471760839,37.77130087547876],
         ...            [-122.45475646845254,37.77475476721895],
@@ -841,43 +958,45 @@
         ...    keys_only=True
         ... )
         >>> tiles = [tile for tile in gen]  # doctest: +SKIP
         >>> tiles[0]                        # doctest: +SKIP
         '500:0:1.0:10:94:8359'
         """
 
-        grid = Grid(
-            resolution=resolution,
-            tilesize=tilesize,
-            pad=pad
-        )
+        grid = Grid(resolution=resolution, tilesize=tilesize, pad=pad)
         tiles = grid.tiles_from_shape(shape=shape, keys_only=keys_only)
         for tile in tiles:
             if keys_only:
                 yield tile
             else:
-                yield cls(tile.geocontext)
+                yield cls(tile.geocontext, all_touched=all_touched)
 
     @classmethod
-    def from_key(cls, dltile_key):
+    def from_key(cls, dltile_key, all_touched=False):
         """
         Return a DLTile GeoContext from a DLTile key.
 
         Parameters
         ----------
         dltile_key : str
             DLTile key, e.g. '128:16:960.0:15:-1:37'
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
 
         Returns
         -------
         tile: DLTile
 
         Example
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> tile = DLTile.from_key("2048:16:30.0:15:3:80")
         >>> tile            # doctest: +SKIP
         DLTile(key='2048:16:30.0:15:3:80',
                resolution=30.0,
                tilesize=2048,
                pad=16,
                crs='EPSG:32615',
@@ -888,15 +1007,15 @@
                ti=3,
                tj=80,
                geotrans=[
         ...
         """
 
         tile = Tile.from_key(dltile_key)
-        return cls(tile.geocontext)
+        return cls(tile.geocontext, all_touched=all_touched)
 
     def subtile(self, subdivide, resolution=None, pad=None, keys_only=False):
         """
         Return an iterator for new DLTiles that subdivide this tile.
 
         The DLtile will be sub-divided into subdivide^2 total sub-tiles each with a side length
         of tile_size / subdivide. The resulting sub-tile size must be an integer.
@@ -919,15 +1038,15 @@
 
         Returns
         -------
         Iterator over DLTiles or str
 
         Example:
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> tile = DLTile.from_key("2048:0:30.0:15:3:80")
         >>> tiles = [tile for tile in tile.subtile(8)]
         >>> len(tiles)
         64
         >>> tiles[0].tilesize
         256
         """
@@ -938,15 +1057,15 @@
             new_pad=pad,
         )
 
         for tile in subtiles:
             if keys_only:
                 yield tile.key
             else:
-                yield DLTile(tile.geocontext)
+                yield DLTile(tile.geocontext, all_touched=self.all_touched)
 
     def rowcol_to_latlon(self, row, col):
         """
         Convert pixel coordinates to lat, lon coordinates
 
         Parameters
         ----------
@@ -958,18 +1077,18 @@
         Returns
         -------
         coords : List[Tuple[float], Tuple[float]]
             List with the first element the latitude values and the second element longitude values
 
         Example
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> tile = DLTile.from_key("2048:0:30.0:15:3:80")
         >>> tile.rowcol_to_latlon(row=56, col=1111)
-        [(44.89479253978484,), (-90.24352536949974,)]
+        [(44.894653081367544,), (-90.24334206726267,)]
         """
 
         lonlat = Tile.from_key(self.key).rowcol_to_lonlat(row=row, col=col)
         lonlat = lonlat.tolist()
         if isinstance(lonlat[0], (int, float)):
             result = [(lonlat[1],), (lonlat[0],)]
         else:
@@ -991,54 +1110,60 @@
         Returns
         -------
         coords: List[Tuple[int] Tuple[int]]
             Tuple with the first element the row values and the second element column values
 
         Example
         -------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> tile = DLTile.from_key("2048:0:30.0:15:3:80")
         >>> tile.latlon_to_rowcol(lat=44.8, lon=-90.2)
-        [(403,), (1238,)]
+        [(403,), (1237,)]
         """
 
         rowcol = Tile.from_key(self.key).lonlat_to_rowcol(lat=lat, lon=lon)
         rowcol = rowcol.tolist()
         if isinstance(rowcol[0], (int, float)):
             result = [(rowcol[0],), (rowcol[1],)]
         else:
             result = list(zip(*rowcol))
         return result
 
-    def assign(self, pad):
+    def assign(self, pad="unchanged", all_touched="unchanged"):
         """
-        Return a copy of the DLTile with the pad value modified.
+        Return a copy of the DLTile with the pad and/or all_touched value modified.
 
         Parameters
         ----------
-        pad : int
+        pad : int, default "unchanged"
             New pad value
+        all_touched : bool, default "unchanged"
+            New all_touched value
 
         Returns
         -------
         tile : DLTile
 
         Example:
         --------
-        >>> from descarteslabs.scenes import DLTile
+        >>> from descarteslabs.geo import DLTile
         >>> tile = DLTile.from_key("2048:16:30.0:15:3:80")
         >>> tile.pad
         16
         >>> tile = tile.assign(123)
         >>> tile.pad
         123
         """
 
-        tile = Tile.from_key(self.key).assign(pad=pad)
-        return DLTile(tile.geocontext)
+        tile = Tile.from_key(self.key)
+        if pad != "unchanged":
+            tile = tile.assign(pad=pad)
+        if all_touched == "unchanged":
+            all_touched = self.all_touched
+        return DLTile(tile.geocontext, all_touched=all_touched)
 
     @property
     def key(self):
         """
         str: The DLTile's key, which encodes the tiling parameters,
         and which number in the grid this tile is.
         """
@@ -1078,35 +1203,35 @@
         """
 
         return self._pad
 
     @property
     def crs(self):
         """
-        str: Coordinate reference system into which scenes will be projected.
+        str: Coordinate reference system into which imagery will be projected.
         For DLTiles, this is always a UTM projection, given as an EPSG code.
         """
 
         return self._crs
 
     @property
     def bounds(self):
         """
         tuple: The ``(min_x, min_y, max_x, max_y)`` of the area covered by
         this DLTile, in the UTM coordinate reference system given in
-        :py:attr:`~descarteslabs.scenes.geocontext.DLTile.bounds_crs`.
+        :py:attr:`~descarteslabs.common.geo.geocontext.DLTile.bounds_crs`.
         """
 
         return self._bounds
 
     @property
     def bounds_crs(self):
         """
         str: The coordinate reference system of the
-        :py:attr:`~descarteslabs.scenes.geocontext.DLTile.bounds`,
+        :py:attr:`~descarteslabs.common.geo.geocontext.DLTile.bounds`,
         given as an EPSG code (like :const:`EPSG:32615`).
         A DLTile's CRS is always UTM.
         """
 
         return self._bounds_crs
 
     @property
@@ -1140,21 +1265,22 @@
     def raster_params(self):
         """
         dict: The properties of this DLTile,
         as keyword arguments to use for `Raster.ndarray` or `Raster.raster`.
         """
 
         return {
+            **super().raster_params,
             "dltile": self._key,
-            "align_pixels": False
             # QUESTION: shouldn't align_pixels be True?
             # based on the GDAL documentation for `-tap`, seems like that should be true
             # to ensure that pixels of images with different resolutions/projections
             # are aligned with the same dltile. otherwise, pixel (0,0) in 1 image could be at
             # different coordinates than the other
+            "align_pixels": False,
         }
 
     @property
     def geotrans(self):
         """
         tuple: The 6-tuple GDAL geotrans for this DLTile in the shape
         ``(a, b, c, d, e, f)`` where
@@ -1182,50 +1308,54 @@
     def wkt(self):
         """str: OGC Well-Known Text definition for this DLTile's coordinate reference system"""
 
         return self._wkt
 
     @property
     def __geo_interface__(self):
-        """dict: :py:attr:`~descarteslabs.scenes.geocontext.DLTile.geometry` as a GeoJSON Polygon"""
+        """dict: :py:attr:`~descarteslabs.common.geo.geocontext.DLTile.geometry` as a GeoJSON Polygon"""
 
         with self._geometry_lock_:
             # see comment in `GeoContext.__init__` for why we need to prevent
             # parallel access to `self._geometry.__geo_interface__`
             return self._geometry.__geo_interface__
 
 
 class XYZTile(GeoContext):
     """
     A GeoContext for XYZ tiles, such as those used in web maps.
 
     The tiles are always 256x256 pixels, in the spherical Mercator
     or "Web Mercator" coordinate reference system (:const:`EPSG:3857`).
-
-    Requires the optional ``mercantile`` package.
     """
 
     __slots__ = ("_x", "_y", "_z")
 
-    def __init__(self, x, y, z):
+    def __init__(self, x, y, z, all_touched=False):
         """
         Parameters
         ----------
         x: int
             X-index of the tile (increases going east)
         y: int
             Y-index of the tile (increases going south)
         z: int
             Zoom level of the tile
+        all_touched: bool, default False
+            If True, this ensures that any source pixel which intersects the
+            AOI GeoContext contributes to the raster result. Normally this mode is
+            not enabled, and its use is strongly discouraged. However, it can be
+            useful when the AOI is smaller than a source pixel, which under many
+            situations will return no result at all (i.e. entirely masked).
         """
 
         self._x = x
         self._y = y
         self._z = z
-        super(XYZTile, self).__init__()
+        super(XYZTile, self).__init__(all_touched=all_touched)
 
     @property
     def x(self):
         "int: X-index of the tile (increases going east)"
 
         return self._x
 
@@ -1270,25 +1400,25 @@
         """
 
         return tuple(mercantile.xy_bounds(self._x, self._y, self._z))
 
     @property
     def crs(self):
         """
-        str: Coordinate reference system into which scenes will be projected.
+        str: Coordinate reference system into which common.geo will be projected.
         Always :const:`EPSG:3857` (spherical Mercator, aka "Web Mercator")
         """
 
         return "EPSG:3857"
 
     @property
     def bounds_crs(self):
         """
         str: The coordinate reference system of the
-        :py:attr:`~descarteslabs.scenes.geocontext.XYZTile.bounds`.
+        :py:attr:`~descarteslabs.common.geo.geocontext.XYZTile.bounds`.
         Always :const:`EPSG:3857` (spherical Mercator, aka "Web Mercator")
         """
 
         return "EPSG:3857"
 
     @property
     def tilesize(self):
@@ -1305,25 +1435,26 @@
         spherical Mercator ("Web Mercator", EPSG:3857) projection.
         """
         num_tiles = 1 << self.z
         return EARTH_CIRCUMFERENCE_WGS84 / num_tiles / self.tilesize
 
     @property
     def __geo_interface__(self):
-        "dict: :py:attr:`~descarteslabs.scenes.geocontext.XYZTile.geometry` as a GeoJSON Polygon"
+        "dict: :py:attr:`~descarteslabs.common.geo.geocontext.XYZTile.geometry` as a GeoJSON Polygon"
 
         return self.geometry.__geo_interface__
 
     @property
     def raster_params(self):
         """
         dict: The properties of this XYZTile,
         as keyword arguments to use for `Raster.ndarray` or `Raster.raster`.
         """
 
         return {
+            **super().raster_params,
             "bounds": self.bounds,
             "srs": self.crs,
             "bounds_srs": self.bounds_crs,
             "align_pixels": False,
             "resolution": self.resolution,
         }
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/scene.py` & `descarteslabs-2.0.0/descarteslabs/core/scenes/scene.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,81 +22,131 @@
 >>> ctx  # a default GeoContext to use when loading raster data from this Scene  # doctest: +SKIP
 AOI(geometry=None,
     resolution=15.0,
     crs='EPSG:32615',
     align_pixels=False,
     bounds=(258292.5, 4503907.5, 493732.5, 4743307.5),
     bounds_crs='EPSG:32615',
-    shape=None)
+    shape=None,
+    all_touched=False)
 >>> scene.properties.id  # doctest: +SKIP
 'landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1'
 >>> scene.properties.date  # doctest: +SKIP
-datetime.datetime(2016, 7, 6, 16, 59, 42, 753476)
+datetime.datetime(2016, 7, 6, 16, 59, 42, 753476, tzinfo=<UTC>)
 >>> scene.properties.bands.red.resolution  # doctest: +SKIP
 15
 >>> arr = scene.ndarray("red green blue", ctx.assign(resolution=120.))  # doctest: +SKIP
 >>> type(arr)  # doctest: +SKIP
 <class 'numpy.ma.core.MaskedArray'>
 >>> arr.shape  # doctest: +SKIP
 (3, 1995, 1962)
 """
 
-from __future__ import division
-import six
-import json
-import datetime
-import warnings
-
-import shapely.geometry
-from affine import Affine
-
-from descarteslabs.client.addons import numpy as np
-
-from descarteslabs.client.services.raster import Raster
-from descarteslabs.client.services.metadata import Metadata
-from descarteslabs.client.exceptions import NotFoundError, BadRequestError
-from descarteslabs.common.dotdict import DotDict
-from descarteslabs.common import shapely_support
-
-from . import geocontext
-from . import _download
-from ._helpers import cached_bands_by_product
-from . import _scaling
-
-
-def _strptime_helper(s):
-    formats = [
-        "%Y-%m-%dT%H:%M:%S.%fZ",
-        "%Y-%m-%dT%H:%M:%SZ",
-        "%Y-%m-%dT%H:%M:%S.%f+00:00",
-        "%Y-%m-%dT%H:%M:%S+00:00",
-        "%Y-%m-%dT%H:%M:%S",
-    ]
+from descarteslabs.exceptions import NotFoundError
+from ..client.deprecation import deprecate
+from ..catalog import Image
+from ..common.dotdict import DotDict
+
+from .helpers import REQUEST_PARAMS, cached_bands_by_product
+
+
+# more or less like a DotDict but delegates everything to the underlying image
+# most importantly, it is lazy about retrieving bands
+class _PropertiesAccessor(object):
+    def __init__(self, image):
+        self.__dict__["_image"] = image
+
+    # The following three properties are not part of the metadata model,
+    # but instead were computed and added to the metadata dict by the old
+    # Scenes constructor. We implement them via @property here instead
+    # as all but `bands` are lightweight, and `bands` is best deferred until
+    # actually needed.
+    @property
+    def bands(self):
+        return DotDict(
+            cached_bands_by_product(self._image.product_id, self._image._client)
+        )
+
+    @property
+    def crs(self):
+        return self._image.cs_code or self._image.projection
 
-    for fmt in formats:
+    @property
+    def date(self):
+        return self._image.acquired
+
+    def get(self, key, default=None):
         try:
-            return datetime.datetime.strptime(s, fmt)
-        except ValueError:
-            pass
+            return getattr(self, key)
+        except AttributeError:
+            return default
+
+    def __getitem__(self, key):
+        try:
+            return getattr(self, key)
+        except AttributeError:
+            raise KeyError(key) from None
+
+    def __setitem__(self, key, value):
+        raise TypeError("Properties are read-only")
+
+    def __delitem__(self, key):
+        raise TypeError("Properties are read-only")
+
+    def __getattr__(self, attr):
+        try:
+            return DotDict._box(self._image.v1_properties[attr])
+        except KeyError:
+            raise AttributeError(attr) from None
+
+    def __setattr__(self, attr, value):
+        raise TypeError("Properties are read-only")
+
+    def __delattr__(self, attr):
+        raise TypeError("Properties are read-only")
+
+    def __iter__(self):
+        for k in self._image.v1_properties.keys():
+            yield k
+        yield "date"
+        yield "crs"
+        yield "bands"
+
+    def __dir__(self):
+        return super(_PropertiesAccessor, self).__dir__() + list(
+            self._image.v1_properties.keys()
+        )
 
-    return None
+    def keys(self):
+        return self.__iter__()
+
+    def values(self):
+        for k, v in self.items():
+            yield v
+
+    def items(self):
+        for kv in DotDict(self._image.v1_properties.items()):
+            yield kv
+        yield ("date", self.date)
+        yield ("crs", self.crs)
+        yield ("bands", self.bands)
 
 
 class Scene(object):
     """
     Object holding metadata about a single scene in the Descartes Labs catalog.
 
     A Scene is structured like a GeoJSON Feature, with geometry and properties.
 
     Attributes
     ----------
     geometry : shapely.geometry.Polygon
         The region the scene's data covers, in WGS84 (lat-lon) coordinates,
         represented as a Shapely polygon.
-    properties : DotDict
+    properties : DotDict-like
         Metadata about the scene. Some fields will vary between products,
         but these will be present:
 
         * ``id`` : str
             Descartes Labs ID of this scene
         * ``crs`` : str
             Native coordinate reference system of the scene,
@@ -146,224 +196,153 @@
                 Central wavelength captured by the sensor in this band
             * ``wavelength_max``
                 Maximum wavelength captured by the sensor in this band
             * ``wavelength_unit``
                 Units of the wavelength fields, such as ``"nm"``
     """
 
-    def __init__(self, scene_dict, bands_dict):
+    def __init__(self, image: Image):
         """
-        ``__init__`` instantiates a Scene from a dict returned by `Metadata.search`
-        and `Metadata.get_bands_by_id`.
+        ``__init__`` instantiates a Scene by wrapping a `descarteslabs.catalog.Image` instead.
 
-        It's preferred to use `Scene.from_id` or `scenes.search <scenes._search.search>` instead.
+        It's preferred to use `Scene.from_id` or `scenes.search <scenes.search_api.search>` instead.
         """
+        if not isinstance(image, Image):
+            ValueError("image must be a descarteslabs.catalog.Image")
+        self._image = image
 
-        self.geometry = shapely.geometry.shape(scene_dict["geometry"])
-        properties = scene_dict["properties"]
-        properties["id"] = scene_dict["id"]
-        properties["bands"] = self._scenes_bands_dict(bands_dict)
-        properties["crs"] = (
-            properties.pop("cs_code")
-            if "cs_code" in properties
-            else properties.get("proj4")
-        )
+    @property
+    def geometry(self):
+        return self._image.geometry
 
-        if "acquired" in properties:
-            properties["date"] = _strptime_helper(properties["acquired"])
-        else:
-            properties["date"] = None
+    @property
+    def properties(self):
+        return _PropertiesAccessor(self._image)
 
-        self.properties = properties
+    @property
+    def __geo_interface__(self):
+        return self.geometry.__geo_interface__
 
     @classmethod
-    def from_id(cls, scene_id, metadata_client=None):
+    @deprecate(removed=["metadata_client"])
+    def from_id(cls, scene_id):
         """
         Return the metadata for a Descartes Labs scene ID as a Scene object.
 
-        Also returns a :class:`~descarteslabs.scenes.geocontext.GeoContext`
+        Also returns a :class:`~descarteslabs.common.geo.geocontext.GeoContext`
         for loading the Scene's original, unwarped data.
 
         Parameters
         ----------
         scene_id: str
             Descartes Labs scene ID,
             e.g. "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"
-        metadata_client : Metadata, optional
-            Unneeded in general use; lets you use a specific client instance
-            with non-default auth and parameters.
 
         Returns
         -------
         scene: Scene
             Scene instance with metadata loaded from the Descartes Labs catalog
         ctx: AOI
-            A :class:`~descarteslabs.scenes.geocontext.GeoContext` for loading this Scene's original data.
+            A :class:`~descarteslabs.common.geo.geocontext.GeoContext` for loading this Scene's original data.
             The defaults used are described in `Scene.default_ctx`.
 
         Example
         -------
         >>> import descarteslabs as dl
         >>> scene, ctx = dl.scenes.Scene.from_id("landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1")  # doctest: +SKIP
         >>> ctx  # doctest: +SKIP
         AOI(geometry=None,
             resolution=15.0,
             crs='EPSG:32615',
             align_pixels=False,
             bounds=(348592.5, 4345567.5, 581632.5, 4582807.5),
             bounds_crs='EPSG:32615',
-            shape=None)
+            shape=None.
+            all_touched=True)
         >>> scene.properties.date  # doctest: +SKIP
-        datetime.datetime(2016, 7, 15, 16, 53, 59, 495435)
+        datetime.datetime(2016, 7, 15, 16, 53, 59, 495435, tzinfo=<UTC>)
 
         Raises
         ------
         NotFoundError
             If the ``scene_id`` cannot be found in the Descartes Labs catalog
         """
 
-        if metadata_client is None:
-            metadata_client = Metadata()
-
-        metadata = metadata_client.get(scene_id)
-        metadata = {
-            "type": "Feature",
-            "geometry": metadata.pop("geometry"),
-            "id": metadata.pop("id"),
-            "key": metadata.pop("key"),
-            "properties": metadata,
-        }
-
-        bands = cached_bands_by_product(
-            metadata["properties"]["product"], metadata_client
-        )
-        scene = cls(metadata, bands)
-
-        return scene, scene.default_ctx()
+        image = Image.get(scene_id, request_params=REQUEST_PARAMS)
+        if image is None:
+            raise NotFoundError("Scene {scene_id} not found")
+        return cls(image), image.geocontext
 
     def default_ctx(self):
         """
-        Return an :class:`AOI GeoContext <descarteslabs.scenes.geocontext.AOI>`
+        Return an :class:`AOI GeoContext <descarteslabs.common.geo.geocontext.AOI>`
         for loading this Scene's original, unwarped data.
 
         These defaults are used:
 
         * resolution: resolution determined from the Scene's ``geotrans``
         * crs: native CRS of the Scene (often, a UTM CRS)
         * bounds: bounds determined from the Scene's ``geotrans`` and ``raster_size``
         * bounds_crs: native CRS of the Scene
         * align_pixels: False, to prevent interpolation snapping pixels to a new grid
         * geometry: None
 
         .. note::
 
-            Using this :class:`~descarteslabs.scenes.geocontext.GeoContext` will only
+            Using this :class:`~descarteslabs.common.geo.geocontext.GeoContext` will only
             return original, unwarped data if the Scene is axis-aligned ("north-up")
             within the CRS. If its ``geotrans`` applies a rotation, a warning will be raised.
             In that case, use `Raster.ndarray` or `Raster.raster` to retrieve
-            original data. (The :class:`~descarteslabs.scenes.geocontext.GeoContext`
+            original data. (The :class:`~descarteslabs.common.geo.geocontext.GeoContext`
             paradigm requires bounds for consistentcy, which are inherently axis-aligned.)
 
         Returns
         -------
         ctx: AOI
         """
-
-        resolution = None
-        bounds = None
-        bounds_crs = None
-        crs = self.properties.get("crs")
-
-        geotrans = self.properties.get("geotrans")
-        if geotrans is not None:
-            geotrans = Affine.from_gdal(*geotrans)
-            if not geotrans.is_rectilinear:
-                # NOTE: this may still be an insufficient check for some CRSs, i.e. polar stereographic?
-                warnings.warn(
-                    "The GeoContext will *not* return this Scene's original data, "
-                    "since it's rotated compared to the grid of the CRS. "
-                    "The array will be 'north-up', with the data rotated within it, "
-                    "and extra empty pixels padded around the side(s). "
-                    "To get the original, unrotated data, you must use the Raster API: "
-                    "`dl.raster.ndarray(scene.properties.id, ...)`."
-                )
-
-            scaling1, scaling2 = geotrans._scaling
-            if scaling1 == scaling2:
-                resolution = scaling1
-            else:
-                # if pixels aren't square (unlikely), we won't just pick a resolution---user has to figure that out.
-                warnings.warn(
-                    "Scene has non-square pixels, so no single resolution can be assigned. "
-                    "Use `shape` instead for more predictable results."
-                )
-
-            raster_size = self.properties.get("raster_size")
-            if raster_size is not None:
-                cols, rows = raster_size
-                # upper-left, upper-right, lower-left, lower-right in pixel coordinates
-                pixel_corners = [(0, 0), (cols, 0), (0, rows), (cols, rows)]
-                geo_corners = [geotrans * corner for corner in pixel_corners]
-                xs, ys = zip(*geo_corners)
-                bounds = (min(xs), min(ys), max(xs), max(ys))
-                bounds_crs = crs
-
-        return geocontext.AOI(
-            geometry=None,
-            resolution=resolution,
-            bounds=bounds,
-            bounds_crs=bounds_crs,
-            crs=crs,
-            align_pixels=False,
-        )
+        return self._image.geocontext
 
     def coverage(self, geom):
         """
         The fraction of a geometry-like object covered by this Scene's geometry.
 
         Parameters
         ----------
-        geom : GeoJSON-like dict, :class:`~descarteslabs.scenes.geocontext.GeoContext`, or object with __geo_interface__
+        geom : GeoJSON-like dict, :class:`~descarteslabs.common.geo.geocontext.GeoContext`, or object with __geo_interface__  # noqa: E501
             Geometry to which to compare this Scene's geometry
 
         Returns
         -------
         coverage: float
             The fraction of ``geom``'s area that overlaps with this Scene,
             between 0 and 1.
 
         Example
         -------
         >>> import descarteslabs as dl
         >>> scene, ctx = dl.scenes.Scene.from_id("landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1")  # doctest: +SKIP
         >>> scene.coverage(scene.geometry.buffer(1))  # doctest: +SKIP
-        0.8
+        0.258370644415335
         """
+        return self._image.coverage(geom)
 
-        if isinstance(geom, geocontext.GeoContext):
-            shape = geom.geometry
-        else:
-            shape = shapely_support.geometry_like_to_shapely(geom)
-
-        intersection = shape.intersection(self.geometry)
-        return intersection.area / shape.area
-
+    @deprecate(removed=["raster_client"])
     def ndarray(
         self,
         bands,
         ctx,
         mask_nodata=True,
         mask_alpha=None,
         bands_axis=0,
         raster_info=False,
         resampler="near",
         processing_level=None,
         scaling=None,
         data_type=None,
-        raster_client=None,
+        progress=None,
     ):
         """
         Load bands from this scene as an ndarray, optionally masking invalid data.
 
         If the selected bands have different data types the resulting ndarray
         has the most general of those data types. This table defines which data types
         can be cast to which more general data types:
@@ -381,16 +360,16 @@
         bands : str or Sequence[str]
             Band names to load. Can be a single string of band names
             separated by spaces (``"red green blue derived:ndvi"``),
             or a sequence of band names (``["red", "green", "blue", "derived:ndvi"]``).
             Names must be keys in ``self.properties.bands``.
             If the alpha band is requested, it must be last in the list
             to reduce rasterization errors.
-        ctx : :class:`~descarteslabs.scenes.geocontext.GeoContext`
-            A :class:`~descarteslabs.scenes.geocontext.GeoContext` to use when loading this Scene
+        ctx : :class:`~descarteslabs.common.geo.geocontext.GeoContext`
+            A :class:`~descarteslabs.common.geo.geocontext.GeoContext` to use when loading this Scene
         mask_nodata : bool, default True
             Whether to mask out values in each band that equal
             that band's ``nodata`` sentinel value.
         mask_alpha : bool or str or None, default None
             Whether to mask pixels in all bands where the alpha band of the scene is 0.
             Provide a string to use an alternate band name for masking.
             If the alpha band is available and ``mask_alpha`` is None, ``mask_alpha``
@@ -412,23 +391,26 @@
         resampler : str, default "near"
             Algorithm used to interpolate pixel values when scaling and transforming
             the image to its new resolution or CRS. Possible values are
             ``near`` (nearest-neighbor), ``bilinear``, ``cubic``, ``cubicsplice``,
             ``lanczos``, ``average``, ``mode``, ``max``, ``min``, ``med``, ``q1``, ``q3``.
         processing_level : str, optional
             How the processing level of the underlying data should be adjusted. Possible
-            values are ``toa`` (top of atmosphere) and ``surface``. For products that
-            support it, ``surface`` applies Descartes Labs' general surface reflectance
-            algorithm to the output.
+            values depend on the product and bands in use. Legacy products support
+            ``toa`` (top of atmosphere) and in some cases ``surface``. Consult the
+            available ``processing_levels`` in the product bands to understand what
+            is available.
         scaling : None, str, list, dict
             Band scaling specification. Please see :meth:`scaling_parameters` for a full
             description of this parameter.
         data_type : None, str
             Output data type. Please see :meth:`scaling_parameters` for a full
             description of this parameter.
+        progress : None, bool
+            Controls display of a progress bar.
         raster_client : Raster, optional
             Unneeded in general use; lets you use a specific client instance
             with non-default auth and parameters.
 
         Returns
         -------
         arr : ndarray
@@ -458,141 +440,57 @@
             If band names are not given or are invalid.
             If the requested bands have incompatible dtypes.
         NotFoundError
             If a Scene's ID cannot be found in the Descartes Labs catalog
         BadRequestError
             If the Descartes Labs Platform is given invalid parameters
         """
-        if raster_client is None:
-            raster_client = Raster()
-
-        if not (-3 < bands_axis < 3):
-            raise ValueError(
-                "Invalid bands_axis; axis {} would not exist in a 3D array".format(
-                    bands_axis
-                )
-            )
-
-        bands = self._bands_to_list(bands)
-        self_bands = self.properties["bands"]
-
-        scales, dtype = _scaling.scaling_parameters(
-            self_bands, bands, scaling, data_type
-        )
-
-        mask_nodata = bool(mask_nodata)
-
-        alpha_band_name = "alpha"
-        if isinstance(mask_alpha, six.string_types):
-            alpha_band_name = mask_alpha
-            mask_alpha = True
-        elif mask_alpha is None:
-            # if user does not set mask_alpha, only attempt to mask_alpha if
-            # alpha band is exists in the scene.
-            mask_alpha = self.has_alpha(alpha_band_name)
-        elif type(mask_alpha) is not bool:
-            raise ValueError("'mask_alpha' must be None, a band name, or a bool.")
-
-        drop_alpha = False
-        if mask_alpha:
-            if not self.has_alpha(alpha_band_name):
-                raise ValueError(
-                    "Cannot mask alpha: no {} band for the product '{}'. "
-                    "Try setting 'mask_alpha=False'.".format(
-                        alpha_band_name, self.properties["product"]
-                    )
-                )
-            try:
-                alpha_i = bands.index(alpha_band_name)
-            except ValueError:
-                bands.append(alpha_band_name)
-                drop_alpha = True
-            else:
-                if alpha_i != len(bands) - 1:
-                    raise ValueError(
-                        "Alpha must be the last band in order to reduce rasterization errors"
-                    )
-
-        raster_params = ctx.raster_params
-        full_raster_args = dict(
-            inputs=self.properties["id"],
-            order="gdal",
-            bands=bands,
-            scales=scales,
-            data_type=dtype,
-            resampler=resampler,
-            processing_level=processing_level,
-            masked=mask_nodata or mask_alpha,
+        return self._image.ndarray(
+            bands,
+            geocontext=ctx,
             mask_nodata=mask_nodata,
             mask_alpha=mask_alpha,
-            drop_alpha=drop_alpha,
-            **raster_params
+            bands_axis=bands_axis,
+            raster_info=raster_info,
+            resampler=resampler,
+            processing_level=processing_level,
+            scaling=scaling,
+            data_type=data_type,
+            progress=progress,
         )
 
-        try:
-            arr, info = raster_client.ndarray(**full_raster_args)
-
-        except NotFoundError:
-            six.raise_from(
-                NotFoundError(
-                    "'{}' does not exist in the Descartes catalog".format(
-                        self.properties["id"]
-                    )
-                ),
-                None,
-            )
-        except BadRequestError as e:
-            msg = (
-                "Error with request:\n"
-                "{err}\n"
-                "For reference, dl.Raster.ndarray was called with these arguments:\n"
-                "{args}"
-            )
-            msg = msg.format(err=e, args=json.dumps(full_raster_args, indent=2))
-            six.raise_from(BadRequestError(msg), None)
-
-        if len(arr.shape) == 2:
-            # if only 1 band requested, still return a 3d array
-            arr = arr[np.newaxis]
-
-        if bands_axis != 0:
-            arr = np.moveaxis(arr, 0, bands_axis)
-        if raster_info:
-            return arr, info
-        else:
-            return arr
-
     def has_alpha(self, alpha_band_name):
-        return alpha_band_name in self.properties["bands"]
+        return alpha_band_name in self.properties.bands
 
+    @deprecate(removed=["raster_client"])
     def download(
         self,
         bands,
         ctx,
         dest=None,
         format="tif",
         resampler="near",
         processing_level=None,
         scaling=None,
         data_type=None,
         nodata=None,
-        raster_client=None,
+        progress=None,
     ):
         """
         Save bands from this scene as a GeoTIFF, PNG, or JPEG, writing to a path.
 
         Parameters
         ----------
         bands : str or Sequence[str]
             Band names to load. Can be a single string of band names
             separated by spaces (``"red green blue derived:ndvi"``),
             or a sequence of band names (``["red", "green", "blue", "derived:ndvi"]``).
             Names must be keys in ``self.properties.bands``.
-        ctx : :class:`~descarteslabs.scenes.geocontext.GeoContext`
-            A :class:`~descarteslabs.scenes.geocontext.GeoContext` to use when loading this Scene
+        ctx : :class:`~descarteslabs.common.geo.geocontext.GeoContext`
+            A :class:`~descarteslabs.common.geo.geocontext.GeoContext` to use when loading this Scene
         dest : str or path-like object, default None
             Where to write the image file.
 
             * If None (default), it's written to an image file of the given ``format``
               in the current directory, named by the Scene's ID and requested bands,
               like ``"sentinel-2:L1C:2018-08-10_10TGK_68_S2A_v1-red-green-blue.tif"``
             * If a string or path-like object, it's written to that path.
@@ -611,28 +509,28 @@
         resampler : str, default "near"
             Algorithm used to interpolate pixel values when scaling and transforming
             the image to its new resolution or SRS. Possible values are
             ``near`` (nearest-neighbor), ``bilinear``, ``cubic``, ``cubicsplice``,
             ``lanczos``, ``average``, ``mode``, ``max``, ``min``, ``med``, ``q1``, ``q3``.
         processing_level : str, optional
             How the processing level of the underlying data should be adjusted. Possible
-            values are ``toa`` (top of atmosphere) and ``surface``. For products that
-            support it, ``surface`` applies Descartes Labs' general surface reflectance
-            algorithm to the output.
+            values depend on the product and bands in use. Legacy products support
+            ``toa`` (top of atmosphere) and in some cases ``surface``. Consult the
+            available ``processing_levels`` in the product bands to understand what
+            is available.
         scaling : None, str, list, dict
             Band scaling specification. Please see :meth:`scaling_parameters` for a full
             description of this parameter.
         data_type : None, str
             Output data type. Please see :meth:`scaling_parameters` for a full
             description of this parameter.
         nodata : None, number
             NODATA value for a geotiff file. Will be assigned to any masked pixels.
-        raster_client : Raster, optional
-            Unneeded in general use; lets you use a specific client instance
-            with non-default auth and parameters.
+        progress : None, bool
+            Controls display of a progress bar.
 
         Returns
         -------
         path : str or None
             If ``dest`` is None or a path, the path where the image file was written is returned.
             If ``dest`` is file-like, nothing is returned.
 
@@ -640,17 +538,17 @@
         -------
         >>> import descarteslabs as dl
         >>> scene, ctx = dl.scenes.Scene.from_id("landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1")  # doctest: +SKIP
         >>> scene.download("red green blue", ctx.assign(resolution=120.))  # doctest: +SKIP
         "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1_red-green-blue.tif"
         >>> import os
         >>> os.listdir(".")  # doctest: +SKIP
-        ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1_red-green-blue.tif"]
+        ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1-red-green-blue.tif"]
         >>> scene.download(
-        ...     "nir swir1",
+        ...     "red green blue",
         ...     ctx,
         ...     "rasters/{ctx.resolution}-{scene.properties.id}.jpg".format(ctx=ctx, scene=scene)
         ... )  # doctest: +SKIP
         "rasters/15-landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1.tif"
 
         Raises
         ------
@@ -660,34 +558,30 @@
             If the requested bands have incompatible dtypes.
             If ``format`` is invalid, or the path has an invalid extension.
         NotFoundError
             If a Scene's ID cannot be found in the Descartes Labs catalog
         BadRequestError
             If the Descartes Labs Platform is given invalid parameters
         """
-        bands = self._bands_to_list(bands)
-        scales, dtype = _scaling.scaling_parameters(
-            self.properties["bands"], bands, scaling, data_type
-        )
-
-        return _download._download(
-            inputs=[self.properties["id"]],
-            bands_list=bands,
-            ctx=ctx,
-            dtype=dtype,
+        return self._image.download(
+            bands,
+            geocontext=ctx,
             dest=dest,
             format=format,
             resampler=resampler,
             processing_level=processing_level,
-            scales=scales,
+            scaling=scaling,
+            data_type=data_type,
             nodata=nodata,
-            raster_client=raster_client,
+            progress=progress,
         )
 
-    def scaling_parameters(self, bands, scaling=None, data_type=None):
+    def scaling_parameters(
+        self, bands, processing_level=None, scaling=None, data_type=None
+    ):
         """
         Computes fully defaulted scaling parameters and output data_type
         from provided specifications.
 
         This method makes accessible the scales and data_type parameters
         which will be generated and passed to the Raster API by methods
         such as :meth:`ndarray` and :meth:`download`. It is provided
@@ -695,14 +589,20 @@
         ``scaling`` and ``data_type`` parameters will be handled by
         those methods. It would not usually be used in a normal workflow.
 
         Parameters
         ----------
         bands : list
             List of bands to be scaled.
+        processing_level : str, optional
+            How the processing level of the underlying data should be adjusted. Possible
+            values depend on the product and bands in use. Legacy products support
+            ``toa`` (top of atmosphere) and in some cases ``surface``. Consult the
+            available ``processing_levels`` in the product bands to understand what
+            is available.
         scaling : None or str or list or dict, default None
             Supplied scaling specification, see below.
         data_type : None or str, default None
             Result data type desired, as a standard data type string (e.g.
             ``"Byte"``, ``"Uint16"``, or ``"Float64"``). If not specified,
             will be deduced from the ``scaling`` specification. Typically
             this is left unset and the appropriate type will be determined
@@ -837,29 +737,21 @@
             parameter.
 
         See Also
         --------
         :doc:`Scenes Guide </guides/scenes>` : This contains many examples of the use of
         the ``scaling`` and ``data_type`` parameters.
         """
-        bands = self._bands_to_list(bands)
-        return _scaling.scaling_parameters(
-            self.properties["bands"], bands, scaling, data_type
+        return self._image.scaling_parameters(
+            bands, processing_level, scaling, data_type
         )
 
-    @property
-    def __geo_interface__(self):
-        # QUESTION: this returns a Geometry, should it be a Feature and include properties?
-        try:
-            return self.geometry.__geo_interface__
-        except AttributeError:
-            return self.geometry
-
-    def _dict(self):
-        return dict(geometry=self.__geo_interface__, properties=self.properties)
+    # not sure this is even needed?
+    # def _dict(self):
+    #     return dict(geometry=self.__geo_interface__, properties=DotDict({k: v for k, v in self.properties})
 
     def __repr__(self):
         parts = [
             'Scene "{}"'.format(self.properties.get("id")),
             '  * Product: "{}"'.format(self.properties.get("product")),
             '  * CRS: "{}"'.format(self.properties.get("crs")),
         ]
@@ -883,15 +775,15 @@
                     "{data_range}",
                     "-> {physical_range}",
                     'in units "{data_unit}"',
                 ]
 
                 band_lines = []
                 # QUESTION(gabe): should there be a canonical ordering to bands? (see GH #973)
-                for bandname, band in six.iteritems(bands):
+                for bandname, band in bands.items():
                     band_line = "    * " + bandname
                     band_parts = []
 
                     for format_string in part_format_strings:
                         try:
                             # If the named field in `format_string` is missing from `band`,
                             # `format_string.format(**band)` will fail with a KeyError, which we catch.
@@ -902,34 +794,7 @@
                     if len(band_parts) > 0:
                         band_line = band_line + ": " + " ".join(band_parts)
                     band_lines.append(band_line)
 
                 if len(band_lines) > 0:
                     parts += ["  * Bands:"] + band_lines
         return "\n".join(parts)
-
-    @staticmethod
-    def _bands_to_list(bands):
-        if isinstance(bands, six.string_types):
-            return bands.split(" ")
-        if not isinstance(bands, (list, tuple)):
-            raise TypeError(
-                "Expected list or tuple of band names, instead got {}".format(
-                    type(bands)
-                )
-            )
-        if len(bands) == 0:
-            raise ValueError("No bands specified to load")
-        return list(bands)
-
-    @staticmethod
-    def _scenes_bands_dict(metadata_bands):
-        """
-        Convert bands dict from metadata client ({id: band_meta})
-        to {<name, or ID if derived>: band_meta}
-        """
-        return DotDict(
-            {
-                id if id.startswith("derived") else meta["name"]: meta
-                for id, meta in six.iteritems(metadata_bands)
-            }
-        )
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/tests/mock_data.py` & `descarteslabs-2.0.0/descarteslabs/core/catalog/tests/mock_data.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,199 +1,1083 @@
-from descarteslabs.common.dotdict import DotDict
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from datetime import datetime
 import json
 import numpy as np
+import shapely.geometry
+
+from ...catalog import *
 
 # flake8: noqa: E501
 
 # this file contains mock data for the Metadata and Raster services, extracted from the production
 # services, which is shared across multiple tests in this directory.
 
-METADATA = {
-    "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1": '{"acquired": "2016-07-06T16:59:42.753476Z", "cs_code": "EPSG:32615", "product": "landsat:LC08:PRE:TOAR", "bits_per_pixel": [0.836, 1.767, 0.804], "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "cloud_fraction": 0.5646, "solar_azimuth_angle": 131.36710631, "bright_fraction": 0.2848, "file_sizes": [49721086, 43577223], "area": 35619.4, "terrain_correction": "L1T", "cloud_fraction_0": 0.3264, "ction": 0.6319, "raster_size": [15696, 15960], "reflectance_scale": [0.1781, 0.1746, 0.1907, 0.2252, 0.3711, 1.4732, 4.5285, 0.903, 0.1999], "files": ["2016-07-06_027031_L8_432.jp2", "2016-07-06_027031_L8_567_19a.jp2"], "geolocation_accuracy": 4.958, "solar_elevation_angle": 64.12277058, "confidence_dlsr": 1.0, "descartes_version": "hedj-landsat-0.9.7.4", "key": "meta_LC80270312016188_v1", "roll_angle": -0.001, "tile_id": "027031", "sw_version": "LPGS_2.6.2", "identifier": "LC80270312016188LGN00.tar.bz", "projcs": "WGS 84 / UTM zone 15N", "geometry": {"type": "Polygon", "coordinates": [[[-95.2989209, 42.7999878], [-93.1167728, 42.3858464], [-93.7138666, 40.703737], [-95.8364984, 41.1150618], [-95.2989209, 42.7999878]]]}, "bucket": ["gs://descartes-l8/", "gs://descartes-l8/"], "file_md5s": ["5b12fa74275aee3234428fc996429256", "efb979aeda1b2fbd58fd689f84540165"], "processed": 1468251918, "published": "2016-07-06T23:11:30Z", "sat_id": "LANDSAT_8", "geotrans": [258292.5, 15.0, 0.0, 4743307.5, 0.0, -15.0]}',  # noqa
-    "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1": '{"acquired": "2016-07-15T16:53:59.495435Z", "cs_code": "EPSG:32615", "product": "landsat:LC08:PRE:TOAR", "bits_per_pixel": [1.022, 2.61, 0.804], "id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "cloud_fraction": 0.1705, "solar_azimuth_angle": 129.79642888, "bright_fraction": 0.0571, "file_sizes": [60751671, 56534564], "area": 35599.3, "terrain_correction": "L1T", "cloud_fraction_0": 0.0947, "ction": 0.6439, "raster_size": [15536, 15816], "reflectance_scale": [0.1786, 0.1751, 0.1913, 0.2258, 0.3721, 1.4773, 4.5414, 0.9055, 0.2005], "files": ["2016-07-15_026032_L8_432.jp2", "2016-07-15_026032_L8_567_19a.jp2"], "geolocation_accuracy": 4.269, "solar_elevation_angle": 63.72682179, "confidence_dlsr": 1.0, "descartes_version": "hedj-landsat-0.9.7.4", "key": "meta_LC80260322016197_v1", "roll_angle": -0.001, "tile_id": "026032", "sw_version": "LPGS_2.6.2", "identifier": "LC80260322016197LGN00.tar.bz", "projcs": "WGS 84 / UTM zone 15N", "geometry": {"type": "Polygon", "coordinates": [[[-94.2036617, 41.3717716], [-92.0686956, 40.9629603], [-92.6448116, 39.2784859], [-94.724166, 39.6850062], [-94.2036617, 41.3717716]]]}, "bucket": ["gs://descartes-l8/", "gs://descartes-l8/"], "file_md5s": ["c80038509ca5572ecdba473bc3931fab", "92b10252278663b0b2d438bfa6c6b494"], "processed": 1469372319, "published": "2016-07-22T04:49:40Z", "sat_id": "LANDSAT_8", "geotrans": [348592.5, 15, 0, 4582807.5, 0, -15]}',  # noqa
-    "modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1": '{"acquired": "2017-11-01T00:00:00+00:00","area": 1236433958410.1,"bits_per_pixel": [16.24028611111111, 2.332976111111111],"bucket": ["dl-satin_modis-mod11a2-006_r", "dl-satin_modis-mod11a2-006_r"], "descartes_version": "satin-v1", "directory": ["modis:mod11a2:006", "modis:mod11a2:006"], "file_md5s": ["dcab9cdeace57fa4a275e51892e1d95f", "6c026381b1e03c6b2ddbdda96a4358c0"], "file_sizes": [5846503, 4199357], "files": ["MOD11A2.A2017305.h09v05.006.2017314042814.UInt16.tif", "MOD11A2.A2017305.h09v05.006.2017314042814.Byte.tif"], "fill_fraction": 0.9842958333333334,"geometry": {      "coordinates": [[[-117.48665603990703, 39.999999999999154], [-104.4325831465788, 39.999999999999154], [-102.94076527145069, 38.99999999999963], [-102.22229259882958, 38.49999999999986], [-100.83779312081948, 37.500000000000334], [-99.52020554825341, 36.5000000000008], [-97.66196710091624, 35.00000000000151], [-96.49743588031265, 34.00000000000198], [-94.85512379473369, 32.500000000002686], [-93.82621572912193, 31.50000000000316], [-92.37604307034178, 30.000000000003865], [-103.92304845413969, 30.000000000003865], [-105.55449269526743, 31.50000000000316], [-106.71201426908073, 32.500000000002686], [-108.55961536535716, 34.00000000000198], [-109.86971298853625, 35.00000000000151], [-111.24611797498575, 36.00000000000104], [-111.96023124179068, 36.5000000000008], [-113.4425172609276, 37.500000000000334], [-115.00007917368902, 38.49999999999986], [-115.8083609303878, 38.99999999999963], [-117.48665603990703, 39.999999999999154]]],  "type": "Polygon"},"geotrans": [-10007554.677899, 926.6254331391661, 0.0, 4447802.079066, 0.0, -926.6254331383334],"id": "modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1","identifier": "MOD11A2.A2017305.h09v05.006.2017314042814","key": "meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1","modified": "2018-11-12T03:25:33.871326+00:00","owner_type": "core","processed": "2018-11-12T03:25:31+00:00","product": "modis:mod11a2:006","proj4": "+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs ","published": "2017-11-10T00:00:00+00:00","raster_size": [1200, 1200],"sat_id": "modis"}',  # noqa
-    "modis:mod11a2:006:meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1": '{"acquired": "2000-02-18T00:00:00+00:00", "area": 1236433958407.88, "bits_per_pixel": [5.416830555555555, 0.8889755555555555], "bucket": ["dl-satin_modis-mod11a2-006_r", "dl-satin_modis-mod11a2-006_r"], "descartes_version": "satin-v1", "directory": ["modis:mod11a2:006", "modis:mod11a2:006"], "file_md5s": ["19ab952b0ee2997a26cc854b0b1225ba", "7cdcc274be7bd6b0a206949cc8978ced"], "file_sizes": [1950059, 1600156], "files": ["MOD11A2.A2000049.h08v05.006.2015058135046.UInt16.tif", "MOD11A2.A2000049.h08v05.006.2015058135046.Byte.tif"], "fill_fraction": 0.5317729166666667, "geometry": {"coordinates": [[[-130.5407289332235, 39.999999999999154], [-117.48665603990703, 39.999999999999154], [-115.8083609303878, 38.99999999999963], [-115.00007917368902, 38.49999999999986], [-113.4425172609276, 37.500000000000334], [-111.96023124179068, 36.5000000000008], [-111.24611797498575, 36.00000000000104], [-109.86971298853625, 35.00000000000151], [-108.55961536535716, 34.00000000000198], [-106.71201426908073, 32.500000000002686], [-105.55449269526743, 31.50000000000316], [-103.92304845413969, 30.000000000003865], [-115.47005383792722, 30.000000000003865], [-117.28276966140238, 31.50000000000316], [-118.56890474341712, 32.500000000002686], [-119.92049433351035, 33.50000000000222], [-120.6217948503908, 34.00000000000198], [-122.0774588761453, 35.00000000000151], [-123.606797749978, 36.00000000000104], [-124.40025693531675, 36.5000000000008], [-126.04724140102435, 37.500000000000334], [-127.77786574853697, 38.49999999999986], [-128.67595658931336, 38.99999999999963], [-130.5407289332235, 39.999999999999154]]], "type": "Polygon"}, "geotrans": [-11119505.197665, 926.6254331383342, 0.0, 4447802.079066, 0.0, -926.6254331383334], "id": "modis:mod11a2:006:meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1", "identifier": "MOD11A2.A2000049.h08v05.006.2015058135046", "key": "meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1", "modified": "2018-11-15T21:12:31.874628+00:00", "owner_type": "core", "processed": "2018-11-15T21:12:30+00:00", "product": "modis:mod11a2:006", "proj4": "+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs ", "published": "2015-02-27T00:00:00+00:00", "raster_size": [1200, 1200], "sat_id": "modis", "storage_state": "available"}',  # noqa
+IMAGES = {
+    "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1": Image(
+        acquired=datetime.fromisoformat("2016-07-06T16:59:42.753476+00:00"),
+        cs_code="EPSG:32615",
+        product_id="landsat:LC08:PRE:TOAR",
+        bits_per_pixel=[0.836, 1.767, 0.804],
+        id="landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1",
+        cloud_fraction=0.5646,
+        solar_azimuth_angle=131.36710631,
+        bright_fraction=0.2848,
+        files=[
+            File(
+                hash="5b12fa74275aee3234428fc996429256",
+                href="gs://descartes-l8/2016-07-06_027031_L8_432.jp2",
+                size_bytes=49721086,
+            ),
+            File(
+                hash="efb979aeda1b2fbd58fd689f84540165",
+                href="gs://descartes-l8/2016-07-06_027031_L8_567_19a.jp2",
+                size_bytes=43577223,
+            ),
+        ],
+        area=35619.4,
+        alt_cloud_fraction=0.3264,
+        fill_fraction=0.6319,
+        x_pixels=15696,
+        y_pixels=15960,
+        reflectance_scale=[
+            0.1781,
+            0.1746,
+            0.1907,
+            0.2252,
+            0.3711,
+            1.4732,
+            4.5285,
+            0.903,
+            0.1999,
+        ],
+        solar_elevation_angle=64.12277058,
+        confidence_dlsr=1.0,
+        name="meta_LC80270312016188_v1",
+        roll_angle=-0.001,
+        provider_id="LC80270312016188LGN00.tar.bz",
+        geometry=shapely.geometry.shape(
+            {
+                "type": "Polygon",
+                "coordinates": [
+                    [
+                        [-95.2989209, 42.7999878],
+                        [-93.1167728, 42.3858464],
+                        [-93.7138666, 40.703737],
+                        [-95.8364984, 41.1150618],
+                        [-95.2989209, 42.7999878],
+                    ]
+                ],
+            }
+        ),
+        created=datetime.utcfromtimestamp(1468251918),
+        published=datetime.fromisoformat("2016-07-06T23:11:30+00:00"),
+        satellite_id="LANDSAT_8",
+        geotrans=[258292.5, 15.0, 0.0, 4743307.5, 0.0, -15.0],
+        _saved=True,
+    ),
+    "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1": Image(
+        acquired=datetime.fromisoformat("2016-07-15T16:53:59.495435+00:00"),
+        cs_code="EPSG:32615",
+        product_id="landsat:LC08:PRE:TOAR",
+        bits_per_pixel=[1.022, 2.61, 0.804],
+        id="landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1",
+        cloud_fraction=0.1705,
+        solar_azimuth_angle=129.79642888,
+        bright_fraction=0.0571,
+        files=[
+            File(
+                hash="c80038509ca5572ecdba473bc3931fab",
+                href="gs://descartes-l8/2016-07-15_026032_L8_432.jp2",
+                size_bytes=60751671,
+            ),
+            File(
+                hash="92b10252278663b0b2d438bfa6c6b494",
+                href="gs://descartes-l8/2016-07-15_026032_L8_567_19a.jp2",
+                size_bytes=56534564,
+            ),
+        ],
+        area=35599.3,
+        alt_cloud_fraction=0.0947,
+        fill_fraction=0.6439,
+        x_pixels=15536,
+        y_pixels=15816,
+        reflectance_scale=[
+            0.1786,
+            0.1751,
+            0.1913,
+            0.2258,
+            0.3721,
+            1.4773,
+            4.5414,
+            0.9055,
+            0.2005,
+        ],
+        solar_elevation_angle=63.72682179,
+        confidence_dlsr=1.0,
+        name="meta_LC80260322016197_v1",
+        roll_angle=-0.001,
+        provider_id="LC80260322016197LGN00.tar.bz",
+        geometry=shapely.geometry.shape(
+            {
+                "type": "Polygon",
+                "coordinates": [
+                    [
+                        [-94.2036617, 41.3717716],
+                        [-92.0686956, 40.9629603],
+                        [-92.6448116, 39.2784859],
+                        [-94.724166, 39.6850062],
+                        [-94.2036617, 41.3717716],
+                    ]
+                ],
+            }
+        ),
+        created=datetime.utcfromtimestamp(1469372319),
+        published=datetime.fromisoformat("2016-07-22T04:49:40+00:00"),
+        satellite_id="LANDSAT_8",
+        geotrans=[348592.5, 15, 0, 4582807.5, 0, -15],
+        _saved=True,
+    ),
+    "modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1": Image(
+        acquired=datetime.fromisoformat("2017-11-01T00:00:00+00:00"),
+        area=1236433958410.1,
+        bits_per_pixel=[16.24028611111111, 2.332976111111111],
+        files=[
+            File(
+                hash="dcab9cdeace57fa4a275e51892e1d95f",
+                href="gs://dl-satin_modis-mod11a2-006_r/modis:mod11a2:006/MOD11A2.A2017305.h09v05.006.2017314042814.UInt16.tif",
+                size_bytes=5846503,
+            ),
+            File(
+                hash="6c026381b1e03c6b2ddbdda96a4358c0",
+                href="gs://dl-satin_modis-mod11a2-006_r/modis:mod11a2:006/MOD11A2.A2017305.h09v05.006.2017314042814.Byte.tif",
+                size_bytes=4199357,
+            ),
+        ],
+        fill_fraction=0.9842958333333334,
+        geometry=shapely.geometry.shape(
+            {
+                "coordinates": [
+                    [
+                        [-117.48665603990703, 39.999999999999154],
+                        [-104.4325831465788, 39.999999999999154],
+                        [-102.94076527145069, 38.99999999999963],
+                        [-102.22229259882958, 38.49999999999986],
+                        [-100.83779312081948, 37.500000000000334],
+                        [-99.52020554825341, 36.5000000000008],
+                        [-97.66196710091624, 35.00000000000151],
+                        [-96.49743588031265, 34.00000000000198],
+                        [-94.85512379473369, 32.500000000002686],
+                        [-93.82621572912193, 31.50000000000316],
+                        [-92.37604307034178, 30.000000000003865],
+                        [-103.92304845413969, 30.000000000003865],
+                        [-105.55449269526743, 31.50000000000316],
+                        [-106.71201426908073, 32.500000000002686],
+                        [-108.55961536535716, 34.00000000000198],
+                        [-109.86971298853625, 35.00000000000151],
+                        [-111.24611797498575, 36.00000000000104],
+                        [-111.96023124179068, 36.5000000000008],
+                        [-113.4425172609276, 37.500000000000334],
+                        [-115.00007917368902, 38.49999999999986],
+                        [-115.8083609303878, 38.99999999999963],
+                        [-117.48665603990703, 39.999999999999154],
+                    ]
+                ],
+                "type": "Polygon",
+            }
+        ),
+        geotrans=[
+            -10007554.677899,
+            926.6254331391661,
+            0.0,
+            4447802.079066,
+            0.0,
+            -926.6254331383334,
+        ],
+        id="modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1",
+        provider_id="MOD11A2.A2017305.h09v05.006.2017314042814",
+        name="meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1",
+        modified=datetime.fromisoformat("2018-11-12T03:25:33.871326+00:00"),
+        created=datetime.fromisoformat("2018-11-12T03:25:31+00:00"),
+        product_id="modis:mod11a2:006",
+        projection="+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs ",
+        published=datetime.fromisoformat("2017-11-10T00:00:00+00:00"),
+        x_pixels=1200,
+        y_pixels=1200,
+        satellite_id="modis",
+        _saved=True,
+    ),
+    "modis:mod11a2:006:meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1": Image(
+        acquired=datetime.fromisoformat("2000-02-18T00:00:00+00:00"),
+        area=1236433958407.88,
+        bits_per_pixel=[5.416830555555555, 0.8889755555555555],
+        files=[
+            File(
+                hash="19ab952b0ee2997a26cc854b0b1225ba",
+                href="gs://dl-satin_modis-mod11a2-006_r/modis:mod11a2:006/MOD11A2.A2000049.h08v05.006.2015058135046.UInt16.tif",
+                size_bytes=1950059,
+            ),
+            File(
+                hash="7cdcc274be7bd6b0a206949cc8978ced",
+                href="gs://dl-satin_modis-mod11a2-006_r/modis:mod11a2:006/MOD11A2.A2000049.h08v05.006.2015058135046.Byte.tif",
+                size_bytes=1600156,
+            ),
+        ],
+        fill_fraction=0.5317729166666667,
+        geometry=shapely.geometry.shape(
+            {
+                "coordinates": [
+                    [
+                        [-130.5407289332235, 39.999999999999154],
+                        [-117.48665603990703, 39.999999999999154],
+                        [-115.8083609303878, 38.99999999999963],
+                        [-115.00007917368902, 38.49999999999986],
+                        [-113.4425172609276, 37.500000000000334],
+                        [-111.96023124179068, 36.5000000000008],
+                        [-111.24611797498575, 36.00000000000104],
+                        [-109.86971298853625, 35.00000000000151],
+                        [-108.55961536535716, 34.00000000000198],
+                        [-106.71201426908073, 32.500000000002686],
+                        [-105.55449269526743, 31.50000000000316],
+                        [-103.92304845413969, 30.000000000003865],
+                        [-115.47005383792722, 30.000000000003865],
+                        [-117.28276966140238, 31.50000000000316],
+                        [-118.56890474341712, 32.500000000002686],
+                        [-119.92049433351035, 33.50000000000222],
+                        [-120.6217948503908, 34.00000000000198],
+                        [-122.0774588761453, 35.00000000000151],
+                        [-123.606797749978, 36.00000000000104],
+                        [-124.40025693531675, 36.5000000000008],
+                        [-126.04724140102435, 37.500000000000334],
+                        [-127.77786574853697, 38.49999999999986],
+                        [-128.67595658931336, 38.99999999999963],
+                        [-130.5407289332235, 39.999999999999154],
+                    ]
+                ],
+                "type": "Polygon",
+            }
+        ),
+        geotrans=[
+            -11119505.197665,
+            926.6254331383342,
+            0.0,
+            4447802.079066,
+            0.0,
+            -926.6254331383334,
+        ],
+        id="modis:mod11a2:006:meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1",
+        provider_id="MOD11A2.A2000049.h08v05.006.2015058135046",
+        name="meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1",
+        modified=datetime.fromisoformat("2018-11-15T21:12:31.874628+00:00"),
+        created=datetime.fromisoformat("2018-11-15T21:12:30+00:00"),
+        product_id="modis:mod11a2:006",
+        projection="+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs ",
+        published=datetime.fromisoformat("2015-02-27T00:00:00+00:00"),
+        x_pixels=1200,
+        y_pixels=1200,
+        satellite_id="modis",
+        storage_state=StorageState.AVAILABLE,
+        _saved=True,
+    ),
 }
 
 
-def _metadata_get(self, id):
-    return DotDict(json.loads(METADATA[id]))
+def _image_get(id):
+    return IMAGES[id]
 
 
 BANDS_BY_PRODUCT = {
-    "landsat:LC08:PRE:TOAR": '{"derived:bai": {"description": "Burned Area Index", "bands": ["red", "nir"], "data_range": [0, 65535], "name_common": "derived:bai", "physical_range": [-1.0, 1.0], "function_name": "bai_uint16", "dtype": "UInt16", "id": "derived:bai", "name": "derived:bai"}, "landsat:LC08:PRE:TOAR:qa_cloud": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Cloud Classification", "tags": ["class", "cloud", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "name_vendor": "qa_cloud", "data_description": "0: not measured. 1: low-probability. 2: medium-probability. 3: high-probability.", "srcband": 4, "name_common": "qa_cloud", "id": "landsat:LC08:PRE:TOAR:qa_cloud", "nbits": 2, "name": "qa_cloud", "srcfile": 1, "type": "classification", "resolution": 30, "data_range": [0, 3], "resolution_unit": "m", "jpx_layer": 1, "owner_type": "core", "nodata": null, "default_range": [0, 3], "res_factor": 2}, "landsat:LC08:PRE:TOAR:tirs1": {"wavelength_max": 11200, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Thermal infrared TIRS 1", "tags": ["spectral", "thermal", "tirs1", "100m", "landsat"], "color": "Gray", "dtype": "UInt16", "jpx_layer": 3, "name_vendor": "B10", "product": "landsat:LC08:PRE:TOAR", "vendor_order": 10, "physical_range": [-32, 64], "srcband": 3, "name_common": "tirs1", "id": "landsat:LC08:PRE:TOAR:tirs1", "nbits": 14, "type": "spectral", "name": "tirs1", "srcfile": 1, "wavelength_min": 10600, "resolution": 100, "data_range": [0, 16383], "resolution_unit": "m", "wavelength_unit": "nm", "res_factor": 2, "wavelength_fwhm": 600, "owner_type": "core", "default_range": [0, 16383], "processing_level": "TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective"}, "derived:ndwi": {"description": "Normalized Difference Water Index (with SWIR1)", "bands": ["nir", "swir1"], "data_range": [0, 65535], "name_common": "derived:ndwi", "physical_range": [-1.0, 1.0], "function_name": "ndi_uint16", "dtype": "UInt16", "id": "derived:ndwi", "name": "derived:ndwi"}, "derived:ndvi": {"description": "Normalized Difference Vegetation Index", "bands": ["nir", "red"], "data_range": [0, 65535], "name_common": "derived:ndvi", "physical_range": [-1.0, 1.0], "function_name": "ndi_uint16", "dtype": "UInt16", "id": "derived:ndvi", "name": "derived:ndvi"}, "derived:rsqrt": {"description": "SQRT of R", "bands": ["red"], "data_range": [0, 1000], "name_common": "derived:rsqrt", "physical_range": [0, 1.0], "function_name": "sqrt", "dtype": "Float64", "id": "derived:rsqrt", "name": "derived:rsqrt"}, "derived:visual_cloud_mask": {"description": "Visual cloud mask based on grayness and green brightness", "bands": ["red", "green", "blue"], "data_range": [0, 1], "name_common": "derived:visual_cloud_mask", "physical_range": null, "function_name": "visual_cloud_mask", "dtype": "UInt16", "id": "derived:visual_cloud_mask", "name": "derived:visual_cloud_mask"}, "landsat:LC08:PRE:TOAR:qa_water": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Water Classification", "tags": ["class", "water", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "name_vendor": "qa_water", "data_description": "0: not measured. 1: low-probability. 2: medium-probability. 3: high-probability.", "srcband": 1, "name_common": "qa_water", "id": "landsat:LC08:PRE:TOAR:qa_water", "nbits": 2, "name": "qa_water", "srcfile": 1, "type": "classification", "resolution": 30, "data_range": [0, 3], "resolution_unit": "m", "jpx_layer": 1, "owner_type": "core", "nodata": null, "default_range": [0, 3], "res_factor": 2}, "derived:evi": {"description": "Enhanced Vegetation Index", "bands": ["blue", "red", "nir"], "data_range": [0, 65535], "name_common": "derived:evi", "physical_range": [-1.0, 1.0], "function_name": "evi_uint16", "dtype": "UInt16", "id": "derived:evi", "name": "derived:evi"}, "landsat:LC08:PRE:TOAR:alpha": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Alpha (valid data)", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "resolution": 15, "data_description": "0: nodata, 1: valid data", "srcband": 1, "name_common": "alpha", "id": "landsat:LC08:PRE:TOAR:alpha", "nbits": 1, "name": "alpha", "srcfile": 0, "default_range": [0, 1], "data_range": [0, 1], "resolution_unit": "m", "jpx_layer": 1, "owner_type": "core", "nodata": null, "type": "mask", "res_factor": 1}, "landsat:LC08:PRE:TOAR:nir": {"wavelength_max": 878.85, "data_unit": "TOAR", "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "srcfile": 1, "wavelength_unit": "nm", "wavelength_center": 864.7, "processing_level": "TOAR", "jpx_layer": 2, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "wavelength_min": 850.5500000000001, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 1, "name_common": "nir", "vendor_order": 5, "name": "nir", "default_range": [0, 10000], "data_range": [0, 10000], "res_factor": 2, "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "derived:ndwi2": {"description": "Normalized Difference Water Index (with SWIR2)", "bands": ["nir", "swir2"], "data_range": [0, 65535], "name_common": "derived:ndwi2", "physical_range": [-1.0, 1.0], "function_name": "ndi_uint16", "dtype": "UInt16", "id": "derived:ndwi2", "name": "derived:ndwi2"}, "landsat:LC08:PRE:TOAR:cirrus": {"wavelength_max": 1375.0, "data_unit": "TOAR", "color": "Gray", "dtype": "UInt16", "name_vendor": "B9", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:cirrus", "nbits": 14, "srcfile": 1, "wavelength_unit": "nm", "wavelength_center": 1370, "processing_level": "TOAR", "jpx_layer": 3, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Cirrus", "tags": ["spectral", "cirrus", "30m", "landsat"], "resolution_unit": "m", "wavelength_min": 1365.0, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 2, "name_common": "cirrus", "vendor_order": 9, "name": "cirrus", "default_range": [0, 10000], "data_range": [0, 10000], "res_factor": 2, "wavelength_fwhm": 10, "owner_type": "core", "nodata": null, "resolution": 30}, "derived:ndwi1": {"description": "Normalized Difference Water Index (with SWIR1)", "bands": ["nir", "swir1"], "data_range": [0, 65535], "name_common": "derived:ndwi1", "physical_range": [-1.0, 1.0], "function_name": "ndi_uint16", "dtype": "UInt16", "id": "derived:ndwi1", "name": "derived:ndwi1"}, "landsat:LC08:PRE:TOAR:swir1": {"wavelength_max": 1651.25, "data_unit": "TOAR", "color": "Gray", "dtype": "UInt16", "name_vendor": "B6", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:swir1", "nbits": 14, "srcfile": 1, "wavelength_unit": "nm", "wavelength_center": 1608.9, "processing_level": "TOAR", "jpx_layer": 2, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Short wave infrared 1", "tags": ["spectral", "swir", "swir1", "30m", "landsat"], "resolution_unit": "m", "wavelength_min": 1566.5500000000002, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 2, "name_common": "swir1", "vendor_order": 6, "name": "swir1", "default_range": [0, 10000], "data_range": [0, 10000], "res_factor": 2, "wavelength_fwhm": 84.7, "owner_type": "core", "nodata": null, "resolution": 30}, "landsat:LC08:PRE:TOAR:swir2": {"wavelength_max": 2294.0499999999997, "data_unit": "TOAR", "color": "Gray", "dtype": "UInt16", "name_vendor": "B7", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:swir2", "nbits": 14, "srcfile": 1, "wavelength_unit": "nm", "wavelength_center": 2200.7, "processing_level": "TOAR", "jpx_layer": 2, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Short wave infrared 2", "tags": ["spectral", "swir", "swir2", "30m", "landsat"], "resolution_unit": "m", "wavelength_min": 2107.35, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 3, "name_common": "swir2", "vendor_order": 7, "name": "swir2", "default_range": [0, 10000], "data_range": [0, 10000], "res_factor": 2, "wavelength_fwhm": 186.7, "owner_type": "core", "nodata": null, "resolution": 30}, "landsat:LC08:PRE:TOAR:qa_cirrus": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Cirrus Classification", "tags": ["class", "cirrus", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "name_vendor": "qa_cirrus", "data_description": "0: not measured. 1: low-probability. 2: medium-probability. 3: high-probability.", "srcband": 3, "name_common": "qa_cirrus", "id": "landsat:LC08:PRE:TOAR:qa_cirrus", "nbits": 2, "name": "qa_cirrus", "srcfile": 1, "type": "classification", "resolution": 30, "data_range": [0, 3], "resolution_unit": "m", "jpx_layer": 1, "owner_type": "core", "nodata": null, "default_range": [0, 3], "res_factor": 2}, "landsat:LC08:PRE:TOAR:blue": {"wavelength_max": 512.0, "data_unit": "TOAR", "color": "Blue", "dtype": "UInt16", "name_vendor": "B2", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:blue", "nbits": 14, "srcfile": 0, "wavelength_unit": "nm", "wavelength_center": 482, "processing_level": "TOAR", "jpx_layer": 0, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Blue, Pansharpened", "tags": ["spectral", "blue", "15m", "landsat"], "resolution_unit": "m", "wavelength_min": 452.0, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 3, "name_common": "blue", "vendor_order": 2, "name": "blue", "default_range": [0, 4000], "data_range": [0, 10000], "res_factor": 1, "wavelength_fwhm": 60, "owner_type": "core", "nodata": null, "resolution": 15}, "landsat:LC08:PRE:TOAR:bright-mask": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Bright Mask (blue > 20% reflective)", "tags": ["mask", "bright", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "resolution": 30, "data_description": "Bright mask. 0: not-bright, 1: bright", "srcband": 3, "name_common": "bright-mask", "id": "landsat:LC08:PRE:TOAR:bright-mask", "nbits": 1, "name": "bright-mask", "srcfile": 1, "default_range": [0, 1], "data_range": [0, 1], "resolution_unit": "m", "jpx_layer": 0, "owner_type": "core", "nodata": null, "type": "mask", "res_factor": 2}, "landsat:LC08:PRE:TOAR:green": {"wavelength_max": 590.05, "data_unit": "TOAR", "color": "Green", "dtype": "UInt16", "name_vendor": "B3", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:green", "nbits": 14, "srcfile": 0, "wavelength_unit": "nm", "wavelength_center": 561.4, "processing_level": "TOAR", "jpx_layer": 0, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Green, Pansharpened", "tags": ["spectral", "green", "15m", "landsat"], "resolution_unit": "m", "wavelength_min": 532.75, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 2, "name_common": "green", "vendor_order": 3, "name": "green", "default_range": [0, 4000], "data_range": [0, 10000], "res_factor": 1, "wavelength_fwhm": 57.3, "owner_type": "core", "nodata": null, "resolution": 15}, "landsat:LC08:PRE:TOAR:qa_snow": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Snow Classification", "tags": ["class", "snow", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "name_vendor": "qa_snow", "data_description": "0: not measured. 1: low-probability. 2: medium-probability. 3: high-probability.", "srcband": 2, "name_common": "qa_snow", "id": "landsat:LC08:PRE:TOAR:qa_snow", "nbits": 2, "name": "qa_snow", "srcfile": 1, "type": "classification", "resolution": 30, "data_range": [0, 3], "resolution_unit": "m", "jpx_layer": 1, "owner_type": "core", "nodata": null, "default_range": [0, 3], "res_factor": 2}, "landsat:LC08:PRE:TOAR:red": {"wavelength_max": 673.35, "data_unit": "TOAR", "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "srcfile": 0, "wavelength_unit": "nm", "wavelength_center": 654.6, "processing_level": "TOAR", "jpx_layer": 0, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "wavelength_min": 635.85, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 1, "name_common": "red", "vendor_order": 4, "name": "red", "default_range": [0, 4000], "data_range": [0, 10000], "res_factor": 1, "wavelength_fwhm": 37.5, "owner_type": "core", "nodata": null, "resolution": 15}, "landsat:LC08:PRE:TOAR:cloud-mask": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Binary Cloud Mask", "tags": ["mask", "cloud", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "resolution": 30, "data_description": "Cloud mask. 0: cloud-free, 1: cloud", "srcband": 2, "name_common": "cloud-mask", "id": "landsat:LC08:PRE:TOAR:cloud-mask", "nbits": 1, "name": "cloud-mask", "srcfile": 1, "default_range": [0, 1], "data_range": [0, 1], "resolution_unit": "m", "jpx_layer": 0, "owner_type": "core", "nodata": null, "type": "mask", "res_factor": 2}, "landsat:LC08:PRE:TOAR:coastal-aerosol": {"wavelength_max": 451.0, "data_unit": "TOAR", "color": "Gray", "dtype": "UInt16", "name_vendor": "B1", "type": "spectral", "id": "landsat:LC08:PRE:TOAR:coastal-aerosol", "nbits": 14, "srcfile": 1, "wavelength_unit": "nm", "wavelength_center": 443, "processing_level": "TOAR", "jpx_layer": 3, "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Coastal Aerosol", "tags": ["spectral", "aerosol", "coastal", "30m", "landsat"], "resolution_unit": "m", "wavelength_min": 435.0, "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "srcband": 1, "name_common": "coastal-aerosol", "vendor_order": 1, "name": "coastal-aerosol", "default_range": [0, 10000], "data_range": [0, 10000], "res_factor": 2, "wavelength_fwhm": 16, "owner_type": "core", "nodata": null, "resolution": 30}}',  # noqa
-    "modis:mod11a2:006": '{"modis:mod11a2:006:Clear_sky_days": {"data_range": [0, 255], "data_unit": "unitless", "default_range": [1, 255], "description": "Day clear-sky coverage", "dtype": "Byte", "id": "modis:mod11a2:006:Clear_sky_days", "jpx_layer": 0, "name": "Clear_sky_days", "name_vendor": "Clear_sky_days", "nbits": 8, "nodata": 0, "owner_type": "core", "physical_range": [0.0, 255.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 9, "srcfile": 1, "type": "spectral", "vendor_order": 11}, "modis:mod11a2:006:Clear_sky_nights": {"data_range": [0, 255], "data_unit": "unitless", "default_range": [1, 255], "description": "Night clear-sky coverage", "dtype": "Byte", "id": "modis:mod11a2:006:Clear_sky_nights", "jpx_layer": 0, "name": "Clear_sky_nights", "name_vendor": "Clear_sky_nights", "nbits": 8, "nodata": 0, "owner_type": "core", "physical_range": [0.0, 255.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 10, "srcfile": 1, "type": "spectral", "vendor_order": 12}, "modis:mod11a2:006:Day_view_angl": {"data_range": [0, 255], "data_unit": "degree", "default_range": [0, 130], "description": "View zenith angle of day observation", "dtype": "Byte", "id": "modis:mod11a2:006:Day_view_angl", "jpx_layer": 0, "name": "Day_view_angl", "name_vendor": "Day_view_angl", "nbits": 8, "nodata": 255, "owner_type": "core", "physical_range": [-65.0, 190.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 3, "srcfile": 1, "type": "spectral", "vendor_order": 4}, "modis:mod11a2:006:Day_view_time": {"data_range": [0, 255], "data_unit": "hour", "default_range": [0, 240], "description": "Local time of day observation", "dtype": "Byte", "id": "modis:mod11a2:006:Day_view_time", "jpx_layer": 0, "name": "Day_view_time", "name_vendor": "Day_view_time", "nbits": 8, "nodata": 255, "owner_type": "core", "physical_range": [0.0, 25.5], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 2, "srcfile": 1, "type": "spectral", "vendor_order": 3}, "modis:mod11a2:006:Emis_31": {"data_range": [0, 255], "data_unit": "degree", "default_range": [1, 255], "description": "Band 31 emissivity", "dtype": "Byte", "id": "modis:mod11a2:006:Emis_31", "jpx_layer": 0, "name": "Emis_31", "name_vendor": "Emis_31", "nbits": 8, "nodata": 255, "owner_type": "core", "physical_range": [0.49, 1.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 7, "srcfile": 1, "type": "spectral", "vendor_order": 9}, "modis:mod11a2:006:Emis_32": {"data_range": [0, 255], "data_unit": "degree", "default_range": [1, 255], "description": "Band 32 emissivity", "dtype": "Byte", "id": "modis:mod11a2:006:Emis_32", "jpx_layer": 0, "name": "Emis_32", "name_vendor": "Emis_32", "nbits": 8, "nodata": 255, "owner_type": "core", "physical_range": [0.49, 1.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 8, "srcfile": 1, "type": "spectral", "vendor_order": 9}, "modis:mod11a2:006:LST_Day_1km": {"data_range": [0, 65535], "data_unit": "kelvin", "default_range": [7500, 65535], "description": "Daytime Land Surface Temperature", "dtype": "UInt16", "id": "modis:mod11a2:006:LST_Day_1km", "jpx_layer": 0, "name": "LST_Day_1km", "name_vendor": "LST_Day_1km", "nbits": 16, "nodata": 0, "owner_type": "core", "physical_range": [0.0, 1310.7], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 1, "srcfile": 0, "type": "spectral", "vendor_order": 1}, "modis:mod11a2:006:LST_Night_1km": {"data_range": [0, 65535], "data_unit": "kelvin", "default_range": [7500, 65535], "description": "Nighttime Land Surface Temperature", "dtype": "UInt16", "id": "modis:mod11a2:006:LST_Night_1km", "jpx_layer": 0, "name": "LST_Night_1km", "name_vendor": "LST_Day_1km", "nbits": 16, "nodata": 0, "owner_type": "core", "physical_range": [0.0, 1310.7], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 2, "srcfile": 0, "type": "spectral", "vendor_order": 5}, "modis:mod11a2:006:Night_view_angl": {"data_range": [0, 255], "data_unit": "degree", "default_range": [0, 130], "description": "View zenith angle of night observation", "dtype": "Byte", "id": "modis:mod11a2:006:Night_view_angl", "jpx_layer": 0, "name": "Night_view_angl", "name_vendor": "Night_view_angl", "nbits": 8, "nodata": 255, "owner_type": "core", "physical_range": [-65.0, 190.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 6, "srcfile": 1, "type": "spectral", "vendor_order": 8}, "modis:mod11a2:006:Night_view_time": {"data_range": [0, 255], "data_unit": "hour", "default_range": [0, 240], "description": "Local time of night observation", "dtype": "Byte", "id": "modis:mod11a2:006:Night_view_time", "jpx_layer": 0, "name": "Night_view_time", "name_vendor": "Night_view_time", "nbits": 8, "nodata": 255, "owner_type": "core", "physical_range": [0.0, 25.5], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 5, "srcfile": 1, "type": "spectral", "vendor_order": 7}, "modis:mod11a2:006:QC_Day": {"data_range": [0, 255], "data_unit": "bitfield", "default_range": [0, 255], "description": "Daytime LST Quality Indicators", "dtype": "Byte", "id": "modis:mod11a2:006:QC_Day", "jpx_layer": 0, "name": "QC_Day", "name_vendor": "QC_Day", "nbits": 8, "owner_type": "core", "physical_range": [0.0, 255.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 1, "srcfile": 1, "type": "class", "vendor_order": 2}, "modis:mod11a2:006:QC_Night": {"data_range": [0, 255], "data_unit": "bitfield", "default_range": [0, 255], "description": "Nighttime LST Quality Indicators", "dtype": "Byte", "id": "modis:mod11a2:006:QC_Night", "jpx_layer": 0, "name": "QC_Night", "name_vendor": "QC_Night", "nbits": 8, "owner_type": "core", "physical_range": [0.0, 255.0], "product": "modis:mod11a2:006", "res_factor": 1, "resolution": 1000, "resolution_unit": "meters", "srcband": 4, "srcfile": 1, "type": "class", "vendor_order": 6}}',  # noqa
-}
-
-
-def _cached_bands_by_product(product, metadata_client):
-    return DotDict(json.loads(BANDS_BY_PRODUCT[product]))
-
-
-SEARCH = {
-    '{"end_datetime": null, "geom": {"coordinates": [[[-95.836498, 39.278486], [-92.068696, 39.278486], [-92.068696, 42.799988], [-95.836498, 42.799988], [-95.836498, 39.278486]]], "type": "Polygon"}, "products": ["landsat:LC08:PRE:TOAR"], "start_datetime": null}': '{"type": "FeatureCollection", "features": [{"geometry": {"type": "Polygon", "coordinates": [[[-94.2036617, 41.3717716], [-92.0686956, 40.9629603], [-92.6448116, 39.2784859], [-94.724166, 39.6850062], [-94.2036617, 41.3717716]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "key": "meta_LC80260322016197_v1", "properties": {"files": ["2016-07-15_026032_L8_432.jp2", "2016-07-15_026032_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 63.72682179, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-15T16:53:59.495435Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.269, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [348592.5, 15, 0, 4582807.5, 0, -15], "key": "meta_LC80260322016197_v1", "bits_per_pixel": [1.022, 2.61, 0.804], "tile_id": "026032", "ction": 0.6439, "raster_size": [15536, 15816], "solar_azimuth_angle": 129.79642888, "bright_fraction": 0.0571, "file_sizes": [60751671, 56534564], "projcs": "WGS 84 / UTM zone 15N", "area": 35599.3, "terrain_correction": "L1T", "bucket": ["gs://descartes-l8/", "gs://descartes-l8/"], "cloud_fraction_0": 0.0947, "file_md5s": ["c80038509ca5572ecdba473bc3931fab", "92b10252278663b0b2d438bfa6c6b494"], "published": "2016-07-22T04:49:40Z", "cloud_fraction": 0.1705, "confidence_dlsr": 1.0, "reflectance_scale": [0.1786, 0.1751, 0.1913, 0.2258, 0.3721, 1.4773, 4.5414, 0.9055, 0.2005], "sat_id": "LANDSAT_8", "identifier": "LC80260322016197LGN00.tar.bz", "processed": 1469372319}}, {"geometry": {"type": "Polygon", "coordinates": [[[-95.2989209, 42.7999878], [-93.1167728, 42.3858464], [-93.7138666, 40.703737], [-95.8364984, 41.1150618], [-95.2989209, 42.7999878]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "key": "meta_LC80270312016188_v1", "properties": {"files": ["2016-07-06_027031_L8_432.jp2", "2016-07-06_027031_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 64.12277058, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-06T16:59:42.753476Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.958, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [258292.5, 15.0, 0.0, 4743307.5, 0.0, -15.0], "key": "meta_LC80270312016188_v1", "bits_per_pixel": [0.836, 1.767, 0.804], "tile_id": "027031", "ction": 0.6319, "raster_size": [15696, 15960], "solar_azimuth_angle": 131.36710631, "bright_fraction": 0.2848, "file_sizes": [49721086, 43577223], "projcs": "WGS 84 / UTM zone 15N", "area": 35619.4, "terrain_correction": "L1T", "bucket": "gs://descartes-l8/", "cloud_fraction_0": 0.3264, "file_md5s": ["5b12fa74275aee3234428fc996429256", "efb979aeda1b2fbd58fd689f84540165"], "published": "2016-07-06T23:11:30Z", "cloud_fraction": 0.5646, "confidence_dlsr": 1.0, "reflectance_scale": [0.1781, 0.1746, 0.1907, 0.2252, 0.3711, 1.4732, 4.5285, 0.903, 0.1999], "sat_id": "LANDSAT_8", "identifier": "LC80270312016188LGN00.tar.bz", "processed": 1468251918}}], "properties": {"continuation_token": "eyJhIjpbMC4wLCJlbnRyeSNsYW5kc2F0OkxDMDg6UFJFOlRPQVI6bWV0YV9MQzgwMjcwMzEyMDE2MTg4X3YxIl0sInEiOiI5Y2VhYjEwY2M0ZTJlZmY1MjMxOTdiNjg2ODJjMjFkZWUwMmIwNDE5In0.3gfqZBkMQCDvlaoqyWAJWtaPqLc"}}',  # noqa
-    '{"end_datetime": "2016-07-15T00:00:00", "geom": {"coordinates": [[[-95.836498, 39.278486], [-92.068696, 39.278486], [-92.068696, 42.799988], [-95.836498, 42.799988], [-95.836498, 39.278486]]], "type": "Polygon"}, "products": ["landsat:LC08:PRE:TOAR"], "start_datetime": "2016-07-06T00:00:00"}': '{"type": "FeatureCollection", "features": [{"geometry": {"type": "Polygon", "coordinates": [[[-95.2989209, 42.7999878], [-93.1167728, 42.3858464], [-93.7138666, 40.703737], [-95.8364984, 41.1150618], [-95.2989209, 42.7999878]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "key": "meta_LC80270312016188_v1", "properties": {"files": ["2016-07-06_027031_L8_432.jp2", "2016-07-06_027031_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 64.12277058, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-06T16:59:42.753476Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.958, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [258292.5, 15.0, 0.0, 4743307.5, 0.0, -15.0], "key": "meta_LC80270312016188_v1", "bits_per_pixel": [0.836, 1.767, 0.804], "tile_id": "027031", "ction": 0.6319, "raster_size": [15696, 15960], "solar_azimuth_angle": 131.36710631, "bright_fraction": 0.2848, "file_sizes": [49721086, 43577223], "projcs": "WGS 84 / UTM zone 15N", "area": 35619.4, "terrain_correction": "L1T", "bucket": ["gs://descartes-l8/", "gs://descartes-l8/"], "cloud_fraction_0": 0.3264, "file_md5s": ["5b12fa74275aee3234428fc996429256", "efb979aeda1b2fbd58fd689f84540165"], "published": "2016-07-06T23:11:30Z", "cloud_fraction": 0.5646, "confidence_dlsr": 1.0, "reflectance_scale": [0.1781, 0.1746, 0.1907, 0.2252, 0.3711, 1.4732, 4.5285, 0.903, 0.1999], "sat_id": "LANDSAT_8", "identifier": "LC80270312016188LGN00.tar.bz", "processed": 1468251918}}], "properties": {"continuation_token": "eyJhIjpbMC4wLCJlbnRyeSNsYW5kc2F0OkxDMDg6UFJFOlRPQVI6bWV0YV9MQzgwMjcwMzEyMDE2MTg4X3YxIl0sInEiOiJmM2YzNGEzMmFkY2I4MmE2Zjc5YjgwYThlZGQ1NDVmYjJlNThjODZjIn0.KApImo8w0A9OhHJbUHD_QV4qom4"}}',  # noqa
-    '{"end_datetime": null, "geom": {"coordinates": [[[-94.50970627780103, 40.460817879515986], [-93.75494640538922, 40.468212507270195], [-93.76149667591069, 41.04471363474632], [-94.5228005945451, 41.03716803374444], [-94.50970627780103, 40.460817879515986]]], "type": "Polygon"}, "products": ["landsat:LC08:PRE:TOAR"], "start_datetime": null}': '{"type": "FeatureCollection", "features": [{"geometry": {"type": "Polygon", "coordinates": [[[-94.2036617, 41.3717716], [-92.0686956, 40.9629603], [-92.6448116, 39.2784859], [-94.724166, 39.6850062], [-94.2036617, 41.3717716]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "key": "meta_LC80260322016197_v1", "properties": {"files": ["2016-07-15_026032_L8_432.jp2", "2016-07-15_026032_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 63.72682179, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-15T16:53:59.495435Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.269, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [348592.5, 15, 0, 4582807.5, 0, -15], "key": "meta_LC80260322016197_v1", "bits_per_pixel": [1.022, 2.61, 0.804], "tile_id": "026032", "ction": 0.6439, "raster_size": [15536, 15816], "solar_azimuth_angle": 129.79642888, "bright_fraction": 0.0571, "file_sizes": [60751671, 56534564], "projcs": "WGS 84 / UTM zone 15N", "area": 35599.3, "terrain_correction": "L1T", "bucket": ["gs://descartes-l8/", "gs://descartes-l8/"], "cloud_fraction_0": 0.0947, "file_md5s": ["c80038509ca5572ecdba473bc3931fab", "92b10252278663b0b2d438bfa6c6b494"], "published": "2016-07-22T04:49:40Z", "cloud_fraction": 0.1705, "confidence_dlsr": 1.0, "reflectance_scale": [0.1786, 0.1751, 0.1913, 0.2258, 0.3721, 1.4773, 4.5414, 0.9055, 0.2005], "sat_id": "LANDSAT_8", "identifier": "LC80260322016197LGN00.tar.bz", "processed": 1469372319}}, {"geometry": {"type": "Polygon", "coordinates": [[[-95.2989209, 42.7999878], [-93.1167728, 42.3858464], [-93.7138666, 40.703737], [-95.8364984, 41.1150618], [-95.2989209, 42.7999878]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "key": "meta_LC80270312016188_v1", "properties": {"files": ["2016-07-06_027031_L8_432.jp2", "2016-07-06_027031_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 64.12277058, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-06T16:59:42.753476Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.958, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [258292.5, 15.0, 0.0, 4743307.5, 0.0, -15.0], "key": "meta_LC80270312016188_v1", "bits_per_pixel": [0.836, 1.767, 0.804], "tile_id": "027031", "ction": 0.6319, "raster_size": [15696, 15960], "solar_azimuth_angle": 131.36710631, "bright_fraction": 0.2848, "file_sizes": [49721086, 43577223], "projcs": "WGS 84 / UTM zone 15N", "area": 35619.4, "terrain_correction": "L1T", "bucket": "gs://descartes-l8/", "cloud_fraction_0": 0.3264, "file_md5s": ["5b12fa74275aee3234428fc996429256", "efb979aeda1b2fbd58fd689f84540165"], "published": "2016-07-06T23:11:30Z", "cloud_fraction": 0.5646, "confidence_dlsr": 1.0, "reflectance_scale": [0.1781, 0.1746, 0.1907, 0.2252, 0.3711, 1.4732, 4.5285, 0.903, 0.1999], "sat_id": "LANDSAT_8", "identifier": "LC80270312016188LGN00.tar.bz", "processed": 1468251918}}], "properties": {"continuation_token": "eyJhIjpbMC4wLCJlbnRyeSNsYW5kc2F0OkxDMDg6UFJFOlRPQVI6bWV0YV9MQzgwMjcwMzEyMDE2MTg4X3YxIl0sInEiOiJjNzdiNTFjMWE2ODkxYzA3ZmQwZDAzNDdhNGFiODljM2IzMDdjMzlmIn0.eWJvgO5AdrRz2ubnvEFx92PxJ0s"}}',  # noqa
-    '{"end_datetime": null, "geom": {"coordinates": [[[-95.836498, 39.278486], [-92.068696, 39.278486], [-92.068696, 42.799988], [-95.836498, 42.799988], [-95.836498, 39.278486]]], "type": "Polygon"}, "products": null, "start_datetime": null}': '{"type": "FeatureCollection", "features": [{"geometry": {"type": "Polygon", "coordinates": [[[-94.2036617, 41.3717716], [-92.0686956, 40.9629603], [-92.6448116, 39.2784859], [-94.724166, 39.6850062], [-94.2036617, 41.3717716]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "key": "meta_LC80260322016197_v1", "properties": {"files": ["2016-07-15_026032_L8_432.jp2", "2016-07-15_026032_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 63.72682179, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-15T16:53:59.495435Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.269, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [348592.5, 15, 0, 4582807.5, 0, -15], "key": "meta_LC80260322016197_v1", "bits_per_pixel": [1.022, 2.61, 0.804], "tile_id": "026032", "ction": 0.6439, "raster_size": [15536, 15816], "solar_azimuth_angle": 129.79642888, "bright_fraction": 0.0571, "file_sizes": [60751671, 56534564], "projcs": "WGS 84 / UTM zone 15N", "area": 35599.3, "terrain_correction": "L1T", "bucket": "gs://descartes-l8/", "cloud_fraction_0": 0.0947, "file_md5s": ["c80038509ca5572ecdba473bc3931fab", "92b10252278663b0b2d438bfa6c6b494"], "published": "2016-07-22T04:49:40Z", "cloud_fraction": 0.1705, "confidence_dlsr": 1.0, "reflectance_scale": [0.1786, 0.1751, 0.1913, 0.2258, 0.3721, 1.4773, 4.5414, 0.9055, 0.2005], "sat_id": "LANDSAT_8", "identifier": "LC80260322016197LGN00.tar.bz", "processed": 1469372319}}, {"geometry": {"type": "Polygon", "coordinates": [[[-95.2989209, 42.7999878], [-93.1167728, 42.3858464], [-93.7138666, 40.703737], [-95.8364984, 41.1150618], [-95.2989209, 42.7999878]]]}, "type": "Feature", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "key": "meta_LC80270312016188_v1", "properties": {"files": ["2016-07-06_027031_L8_432.jp2", "2016-07-06_027031_L8_567_19a.jp2"], "product": "landsat:LC08:PRE:TOAR", "solar_elevation_angle": 64.12277058, "sw_version": "LPGS_2.6.2", "acquired": "2016-07-06T16:59:42.753476Z", "cs_code": "EPSG:32615", "roll_angle": -0.001, "geolocation_accuracy": 4.958, "descartes_version": "hedj-landsat-0.9.7.4", "geotrans": [258292.5, 15.0, 0.0, 4743307.5, 0.0, -15.0], "key": "meta_LC80270312016188_v1", "bits_per_pixel": [0.836, 1.767, 0.804], "tile_id": "027031", "ction": 0.6319, "raster_size": [15696, 15960], "solar_azimuth_angle": 131.36710631, "bright_fraction": 0.2848, "file_sizes": [49721086, 43577223], "projcs": "WGS 84 / UTM zone 15N", "area": 35619.4, "terrain_correction": "L1T", "bucket": ["gs://descartes-l8/", "gs://descartes-l8/"], "cloud_fraction_0": 0.3264, "file_md5s": ["5b12fa74275aee3234428fc996429256", "efb979aeda1b2fbd58fd689f84540165"], "published": "2016-07-06T23:11:30Z", "cloud_fraction": 0.5646, "confidence_dlsr": 1.0, "reflectance_scale": [0.1781, 0.1746, 0.1907, 0.2252, 0.3711, 1.4732, 4.5285, 0.903, 0.1999], "sat_id": "LANDSAT_8", "identifier": "LC80270312016188LGN00.tar.bz", "processed": 1468251918}}], "properties": {"continuation_token": "eyJhIjpbMC4wLCJlbnRyeSNsYW5kc2F0OkxDMDg6UFJFOlRPQVI6bWV0YV9MQzgwMjcwMzEyMDE2MTg4X3YxIl0sInEiOiJhMjcxZjU0Zjg3NjZkMjE2YjNjNmYwYzA3ZTI0MDZkYTRkOGYzMjlhIn0.CeuBS_JoWC5BqlVQYuh92BmHB94"}}',  # noqa
+    "landsat:LC08:PRE:TOAR": {
+        "qa_cloud": ClassBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Cloud Classification",
+            tags=["class", "cloud", "30m", "landsat"],
+            data_type="UInt16",
+            vendor_band_name="qa_cloud",
+            band_index=3,
+            id="landsat:LC08:PRE:TOAR:qa_cloud",
+            name="qa_cloud",
+            file_index=1,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            data_range=[0, 3],
+            jpx_layer_index=1,
+            display_range=[0, 3],
+            _saved=True,
+        ),
+        "tirs1": SpectralBand(
+            description="Thermal infrared TIRS 1",
+            tags=["spectral", "thermal", "tirs1", "100m", "landsat"],
+            data_type="UInt16",
+            jpx_layer_index=3,
+            vendor_band_name_vendor="B10",
+            product_id="landsat:LC08:PRE:TOAR",
+            sort_order=10,
+            vendor_order=10,
+            physical_range=[-32, 64],
+            band_index=2,
+            id="landsat:LC08:PRE:TOAR:tirs1",
+            name="tirs1",
+            file_index=1,
+            resolution=Resolution(value=100, unit=ResolutionUnit.METERS),
+            data_range=[0, 16383],
+            wavelength_nm_fwhm=600,
+            wavelength_nm_min=10600,
+            wavelength_nm_max=11200,
+            display_range=[0, 16383],
+            _saved=True,
+        ),
+        "qa_water": ClassBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Water Classification",
+            tags=["class", "water", "30m", "landsat"],
+            data_type="UInt16",
+            vendor_band_name="qa_water",
+            band_index=0,
+            id="landsat:LC08:PRE:TOAR:qa_water",
+            name="qa_water",
+            file_index=1,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            data_range=[0, 3],
+            jpx_layer_index=1,
+            display_range=[0, 3],
+            _saved=True,
+        ),
+        "alpha": MaskBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Alpha (valid data)",
+            tags=["mask", "alpha", "15m", "landsat"],
+            data_type="UInt16",
+            resolution=Resolution(value=15, unit=ResolutionUnit.METERS),
+            band_index=0,
+            id="landsat:LC08:PRE:TOAR:alpha",
+            name="alpha",
+            file_index=0,
+            display_range=[0, 1],
+            data_range=[0, 1],
+            jpx_layer_index=1,
+            _saved=True,
+        ),
+        "nir": SpectralBand(
+            wavelength_nm_max=878.85,
+            data_type="UInt16",
+            vendor_band_name="B5",
+            id="landsat:LC08:PRE:TOAR:nir",
+            file_index=1,
+            wavelength_nm_center=864.7,
+            jpx_layer_index=2,
+            productid="landsat:LC08:PRE:TOAR",
+            description="Near Infrared",
+            tags=["spectral", "nir", "near-infrared", "30m", "landsat"],
+            wavelength_nm_min=850.5500000000001,
+            physical_range=[0.0, 1.0],
+            band_index=0,
+            vendor_order=5,
+            sort_order=5,
+            name="nir",
+            display_range=[0, 10000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=28.3,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "cirrus": SpectralBand(
+            wavelength_max=1375.0,
+            data_type="UInt16",
+            vendor_band_name="B9",
+            id="landsat:LC08:PRE:TOAR:cirrus",
+            file_index=1,
+            wavelength_nm_center=1370,
+            jpx_layer_index=3,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Cirrus",
+            tags=["spectral", "cirrus", "30m", "landsat"],
+            wavelength_nm_min=1365.0,
+            physical_range=[0.0, 1.0],
+            band_index=1,
+            vendor_order=9,
+            sort_order=9,
+            name="cirrus",
+            display_range=[0, 10000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=10,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "swir1": SpectralBand(
+            wavelength_nm_max=1651.25,
+            data_type="UInt16",
+            vendor_band_name="B6",
+            id="landsat:LC08:PRE:TOAR:swir1",
+            file_index=1,
+            wavelength_nm_center=1608.9,
+            jpx_layer_index=2,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Short wave infrared 1",
+            tags=["spectral", "swir", "swir1", "30m", "landsat"],
+            wavelength_nm_min=1566.5500000000002,
+            physical_range=[0.0, 1.0],
+            band_index=1,
+            vendor_order=6,
+            sort_order=6,
+            name="swir1",
+            display_range=[0, 10000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=84.7,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "swir2": SpectralBand(
+            wavelength_nm_max=2294.0499999999997,
+            data_type="UInt16",
+            vendor_band_name="B7",
+            id="landsat:LC08:PRE:TOAR:swir2",
+            file_index=1,
+            wavelength_nm_center=2200.7,
+            jpx_layer_index=2,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Short wave infrared 2",
+            tags=["spectral", "swir", "swir2", "30m", "landsat"],
+            wavelength_nm_min=2107.35,
+            physical_range=[0.0, 1.0],
+            band_index=2,
+            vendor_order=7,
+            sort_order=7,
+            name="swir2",
+            display_range=[0, 10000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=186.7,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "qa_cirrus": ClassBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Cirrus Classification",
+            tags=["class", "cirrus", "30m", "landsat"],
+            data_type="UInt16",
+            vendor_band_name="qa_cirrus",
+            band_index=2,
+            id="landsat:LC08:PRE:TOAR:qa_cirrus",
+            name="qa_cirrus",
+            file_index=1,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            data_range=[0, 3],
+            jpx_layer_index=1,
+            display_range=[0, 3],
+            _saved=True,
+        ),
+        "blue": SpectralBand(
+            wavelength_nm_max=512.0,
+            data_type="UInt16",
+            vendor_band_name="B2",
+            id="landsat:LC08:PRE:TOAR:blue",
+            file_index=0,
+            wavelength_nm_center=482,
+            jpx_layer_index=0,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Blue, Pansharpened",
+            tags=["spectral", "blue", "15m", "landsat"],
+            wavelength_nm_min=452.0,
+            physical_range=[0.0, 1.0],
+            band_index=2,
+            vendor_order=2,
+            sort_order=2,
+            name="blue",
+            display_range=[0, 4000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=60,
+            resolution=Resolution(value=15, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "bright-mask": MaskBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Bright Mask (blue > 20% reflective)",
+            tags=["mask", "bright", "30m", "landsat"],
+            data_type="UInt16",
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            band_index=2,
+            id="landsat:LC08:PRE:TOAR:bright-mask",
+            name="bright-mask",
+            file_index=1,
+            display_range=[0, 1],
+            data_range=[0, 1],
+            jpx_layer_index=0,
+            _saved=True,
+        ),
+        "green": SpectralBand(
+            wavelength_nm_max=590.05,
+            data_type="UInt16",
+            vendor_band_name="B3",
+            id="landsat:LC08:PRE:TOAR:green",
+            file_index=0,
+            wavelength_nm_center=561.4,
+            jpx_layer_index=0,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Green, Pansharpened",
+            tags=["spectral", "green", "15m", "landsat"],
+            wavelength_nm_min=532.75,
+            physical_range=[0.0, 1.0],
+            band_index=1,
+            vendor_order=3,
+            sort_order=3,
+            name="green",
+            display_range=[0, 4000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=57.3,
+            resolution=Resolution(value=15, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "qa_snow": ClassBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Snow Classification",
+            tags=["class", "snow", "30m", "landsat"],
+            data_type="UInt16",
+            vendor_band_name="qa_snow",
+            band_index=1,
+            id="landsat:LC08:PRE:TOAR:qa_snow",
+            name="qa_snow",
+            file_index=1,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            data_range=[0, 3],
+            jpx_layer_index=1,
+            display_range=[0, 3],
+            _saved=True,
+        ),
+        "red": SpectralBand(
+            wavelength_nm_max=673.35,
+            data_type="UInt16",
+            vendor_band_name="B4",
+            id="landsat:LC08:PRE:TOAR:red",
+            file_index=0,
+            wavelength_nm_center=654.6,
+            jpx_layer_index=0,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Red, Pansharpened",
+            tags=["spectral", "red", "15m", "landsat"],
+            wavelength_nm_min=635.85,
+            physical_range=[0.0, 1.0],
+            band_index=0,
+            vendor_order=4,
+            sort_order=4,
+            name="red",
+            display_range=[0, 4000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=37.5,
+            resolution=Resolution(value=15, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "cloud-mask": MaskBand(
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Binary Cloud Mask",
+            tags=["mask", "cloud", "30m", "landsat"],
+            data_type="UInt16",
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            band_index=1,
+            id="landsat:LC08:PRE:TOAR:cloud-mask",
+            name="cloud-mask",
+            file_index=1,
+            display_range=[0, 1],
+            data_range=[0, 1],
+            jpx_layer_index=0,
+            _saved=True,
+        ),
+        "coastal-aerosol": SpectralBand(
+            wavelength_nm_max=451.0,
+            data_type="UInt16",
+            vendor_band_name="B1",
+            id="landsat:LC08:PRE:TOAR:coastal-aerosol",
+            name="coastal-aerosol",
+            file_index=1,
+            wavelength_nm_center=443,
+            jpx_layer_index=3,
+            product_id="landsat:LC08:PRE:TOAR",
+            description="Coastal Aerosol",
+            tags=["spectral", "aerosol", "coastal", "30m", "landsat"],
+            wavelength_nm_min=435.0,
+            physical_range=[0.0, 1.0],
+            band_index=0,
+            vendor_order=1,
+            sort_order=1,
+            display_range=[0, 10000],
+            data_range=[0, 10000],
+            wavelength_nm_fwhm=16,
+            resolution=Resolution(value=30, unit=ResolutionUnit.METERS),
+            _saved=True,
+        ),
+        "derived:bai": DerivedBand(
+            description="Burned Area Index",
+            bands=["red", "nir"],
+            data_range=[0, 65535],
+            physical_range=[-1.0, 1.0],
+            function_name="bai_uint16",
+            data_type="UInt16",
+            id="derived:bai",
+            name="derived:bai",
+            _saved=True,
+        ),
+        "derived:evi": DerivedBand(
+            description="Enhanced Vegetation Index",
+            bands=["blue", "red", "nir"],
+            data_range=[0, 65535],
+            physical_range=[-1.0, 1.0],
+            function_name="evi_uint16",
+            data_type="UInt16",
+            id="derived:evi",
+            name="derived:evi",
+            _saved=True,
+        ),
+        "derived:ndvi": DerivedBand(
+            description="Normalized Difference Vegetation Index",
+            bands=["nir", "red"],
+            data_range=[0, 65535],
+            physical_range=[-1.0, 1.0],
+            function_name="ndi_uint16",
+            data_type="UInt16",
+            id="derived:ndvi",
+            name="derived:ndvi",
+            _saved=True,
+        ),
+        "derived:ndwi": DerivedBand(
+            description="Normalized Difference Water Index (with SWIR1)",
+            bands=["nir", "swir1"],
+            data_range=[0, 65535],
+            physical_range=[-1.0, 1.0],
+            function_name="ndi_uint16",
+            data_type="UInt16",
+            id="derived:ndwi",
+            name="derived:ndwi",
+            _saved=True,
+        ),
+        "derived:ndwi1": DerivedBand(
+            description="Normalized Difference Water Index (with SWIR1)",
+            bands=["nir", "swir1"],
+            data_range=[0, 65535],
+            physical_range=[-1.0, 1.0],
+            function_name="ndi_uint16",
+            data_type="UInt16",
+            id="derived:ndwi1",
+            name="derived:ndwi1",
+            _saved=True,
+        ),
+        "derived:ndwi2": DerivedBand(
+            description="Normalized Difference Water Index (with SWIR2)",
+            bands=["nir", "swir2"],
+            data_range=[0, 65535],
+            physical_range=[-1.0, 1.0],
+            function_name="ndi_uint16",
+            data_type="UInt16",
+            id="derived:ndwi2",
+            name="derived:ndwi2",
+            _saved=True,
+        ),
+        "derived:rsqrt": DerivedBand(
+            description="SQRT of R",
+            bands=["red"],
+            data_range=[0, 1000],
+            physical_range=[0, 1.0],
+            function_name="sqrt",
+            data_type="Float64",
+            id="derived:rsqrt",
+            name="derived:rsqrt",
+            _saved=True,
+        ),
+        "derived:visual_cloud_mask": DerivedBand(
+            description="Visual cloud mask based on grayness and green brightness",
+            bands=["red", "green", "blue"],
+            data_range=[0, 1],
+            function_name="visual_cloud_mask",
+            data_type="UInt16",
+            id="derived:visual_cloud_mask",
+            name="derived:visual_cloud_mask",
+            _saved=True,
+        ),
+    },
+    "modis:mod11a2:006": {
+        "Clear_sky_days": SpectralBand(
+            data_range=[0, 255],
+            display_range=[1, 255],
+            description="Day clear-sky coverage",
+            data_type="Byte",
+            id="modis:mod11a2:006:Clear_sky_days",
+            jpx_layer_index=0,
+            name="Clear_sky_days",
+            vendor_band_name="Clear_sky_days",
+            nodata=0,
+            physical_range=[0.0, 255.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=8,
+            file_index=1,
+            vendor_order=11,
+            sort_order=11,
+            _saved=True,
+        ),
+        "Clear_sky_nights": SpectralBand(
+            data_range=[0, 255],
+            display_range=[1, 255],
+            description="Night clear-sky coverage",
+            data_type="Byte",
+            id="modis:mod11a2:006:Clear_sky_nights",
+            jpx_layer_index=0,
+            name="Clear_sky_nights",
+            vendor_band_name="Clear_sky_nights",
+            nodata=0,
+            physical_range=[0.0, 255.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=9,
+            file_index=1,
+            vendor_order=12,
+            sort_order=12,
+            _saved=True,
+        ),
+        "Day_view_angl": SpectralBand(
+            data_range=[0, 255],
+            display_range=[0, 130],
+            description="View zenith angle of day observation",
+            data_type="Byte",
+            id="modis:mod11a2:006:Day_view_angl",
+            jpx_layer_index=0,
+            name="Day_view_angl",
+            vendor_band_name="Day_view_angl",
+            nodata=255,
+            physical_range=[-65.0, 190.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=2,
+            file_index=1,
+            vendor_order=4,
+            sort_order=4,
+            _saved=True,
+        ),
+        "Day_view_time": SpectralBand(
+            data_range=[0, 255],
+            display_range=[0, 240],
+            description="Local time of day observation",
+            data_type="Byte",
+            id="modis:mod11a2:006:Day_view_time",
+            jpx_layer_index=0,
+            name="Day_view_time",
+            vendor_band_name="Day_view_time",
+            nodata=255,
+            physical_range=[0.0, 25.5],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=1,
+            file_index=1,
+            vendor_order=3,
+            sort_order=3,
+            _saved=True,
+        ),
+        "Emis_31": SpectralBand(
+            data_range=[0, 255],
+            display_range=[1, 255],
+            description="Band 31 emissivity",
+            data_type="Byte",
+            id="modis:mod11a2:006:Emis_31",
+            jpx_layer_index=0,
+            name="Emis_31",
+            vendor_band_name="Emis_31",
+            nodata=255,
+            physical_range=[0.49, 1.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=6,
+            file_index=1,
+            vendor_order=9,
+            sort_order=9,
+            _saved=True,
+        ),
+        "Emis_32": SpectralBand(
+            data_range=[0, 255],
+            display_range=[1, 255],
+            description="Band 32 emissivity",
+            data_type="Byte",
+            id="modis:mod11a2:006:Emis_32",
+            jpx_layer_index=0,
+            name="Emis_32",
+            vendor_band_name="Emis_32",
+            nodata=255,
+            physical_range=[0.49, 1.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=7,
+            file_index=1,
+            vendor_order=9,
+            sort_order=9,
+            _saved=True,
+        ),
+        "LST_Day_1km": SpectralBand(
+            data_range=[0, 65535],
+            display_range=[7500, 65535],
+            description="Daytime Land Surface Temperature",
+            data_type="UInt16",
+            id="modis:mod11a2:006:LST_Day_1km",
+            jpx_layer_index=0,
+            name="LST_Day_1km",
+            vendor_band_name="LST_Day_1km",
+            nodata=0,
+            physical_range=[0.0, 1310.7],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=0,
+            file_index=0,
+            vendor_order=1,
+            sort_order=1,
+            _saved=True,
+        ),
+        "LST_Night_1km": SpectralBand(
+            data_range=[0, 65535],
+            display_range=[7500, 65535],
+            description="Nighttime Land Surface Temperature",
+            data_type="UInt16",
+            id="modis:mod11a2:006:LST_Night_1km",
+            jpx_layer_index=0,
+            name="LST_Night_1km",
+            vendor_band_name="LST_Day_1km",
+            nodata=0,
+            physical_range=[0.0, 1310.7],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=2,
+            file_index=0,
+            vendor_order=5,
+            sort_order=5,
+            _saved=True,
+        ),
+        "Night_view_angl": SpectralBand(
+            data_range=[0, 255],
+            display_range=[0, 130],
+            description="View zenith angle of night observation",
+            data_type="Byte",
+            id="modis:mod11a2:006:Night_view_angl",
+            jpx_layer_index=0,
+            name="Night_view_angl",
+            vendor_band_name="Night_view_angl",
+            nodata=255,
+            physical_range=[-65.0, 190.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=5,
+            file_index=1,
+            vendor_order=8,
+            sort_order=8,
+            _saved=True,
+        ),
+        "Night_view_time": SpectralBand(
+            data_range=[0, 255],
+            display_range=[0, 240],
+            description="Local time of night observation",
+            data_type="Byte",
+            id="modis:mod11a2:006:Night_view_time",
+            jpx_layer_index=0,
+            name="Night_view_time",
+            vendor_band_name="Night_view_time",
+            nodata=255,
+            physical_range=[0.0, 25.5],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=4,
+            file_index=1,
+            vendor_order=7,
+            sort_order=7,
+            _saved=True,
+        ),
+        "QC_Day": ClassBand(
+            data_range=[0, 255],
+            default_range=[0, 255],
+            description="Daytime LST Quality Indicators",
+            data_type="Byte",
+            id="modis:mod11a2:006:QC_Day",
+            jpx_layer_index=0,
+            name="QC_Day",
+            vendor_band_name="QC_Day",
+            physical_range=[0.0, 255.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=0,
+            file_index=1,
+            vendor_order=2,
+            sort_order=2,
+            _saved=True,
+        ),
+        "QC_Night": ClassBand(
+            data_range=[0, 255],
+            display_range=[0, 255],
+            description="Nighttime LST Quality Indicators",
+            data_type="Byte",
+            id="modis:mod11a2:006:QC_Night",
+            jpx_layer_index=0,
+            name="QC_Night",
+            vendor_band_name="QC_Night",
+            physical_range=[0.0, 255.0],
+            product_id="modis:mod11a2:006",
+            resolution=Resolution(value=1000, unit=ResolutionUnit.METERS),
+            band_index=3,
+            file_index=1,
+            vendor_order=6,
+            sort_order=6,
+            _saved=True,
+        ),
+    },
 }
 
 
-def _metadata_search(self, **kwargs):
-    return DotDict(
-        json.loads(
-            SEARCH[
-                json.dumps(
-                    {
-                        k: kwargs[k]
-                        for k in ("geom", "products", "start_datetime", "end_datetime")
-                    },
-                    sort_keys=True,
-                )
-            ]
-        )
-    )
+def _cached_bands_by_product(product, _client):
+    return BANDS_BY_PRODUCT[product]
 
 
 alpha = np.ones((122, 120), dtype="uint16")
 alpha[2, 2] = 0
 
 alpha1000 = np.ones((239, 235), dtype="uint16")
 alpha1000[2, 2] = 0
 
 
 RASTER = {
-    '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 600}': (
+    '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="uint16"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
     ),  # noqa
-    '{"bands": ["nir", "alpha"], "data_type": "Int32", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 600}': (
+    '{"bands": ["nir", "alpha"], "data_type": "Int32", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="int32"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
     ),  # noqa
-    '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "resolution": 600}': (
+    '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="uint16"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}}',
     ),  # noqa
-    '{"bands": ["nir", "alpha"], "data_type": "Int32", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "resolution": 600}': (
+    '{"bands": ["nir", "alpha"], "data_type": "Int32", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="int32"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}}',
     ),  # noqa
-    '{"bands": ["nir", "red", "alpha"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 600}': (
+    '{"bands": ["nir", "red", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 600}': (
         np.stack(
             [
                 np.zeros((122, 120), dtype="uint16"),
                 np.zeros((122, 120), dtype="uint16"),
                 alpha,
             ]
         ),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "owner_type": "core", "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
     ),  # noqa
-    '{"bands": ["nir", "red", "alpha"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "resolution": 600}': (
+    '{"bands": ["nir", "red", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack(
             [
                 np.zeros((122, 120), dtype="uint16"),
                 np.zeros((122, 120), dtype="uint16"),
                 alpha,
             ]
         ),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "owner_type": "core", "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}}',
     ),  # noqa
-    '{"bands": ["nir"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 600}': (
+    '{"bands": ["nir"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 600}': (
         np.zeros((122, 120), dtype="uint16"),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"wavelength_max": 878.85, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "wavelength_min": 850.55, "name_vendor": "B5", "product": "landsat:LC08:PRE:TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "id": "landsat:LC08:PRE:TOAR:nir", "vendor_order": 5, "nbits": 14, "type": "spectral", "name": "nir", "wavelength_center": 864.7, "data_range": [0, 10000], "resolution_unit": "m", "wavelength_unit": "nm", "resolution": 30, "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "default_range": [0, 10000], "processing_level": "TOAR"}, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}, "size": [120, 122]}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"wavelength_max": 878.85, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "wavelength_min": 850.55, "name_vendor": "B5", "product": "landsat:LC08:PRE:TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "id": "landsat:LC08:PRE:TOAR:nir", "vendor_order": 5, "nbits": 14, "type": "spectral", "name": "nir", "wavelength_center": 864.7, "data_range": [0, 10000], "resolution_unit": "m", "wavelength_unit": "nm", "resolution": 30, "wavelength_fwhm": 28.3, "nodata": null, "default_range": [0, 10000], "processing_level": "TOAR"}, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}, "size": [120, 122]}',
     ),  # noqa
-    '{"bands": ["nir"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "resolution": 600}': (
+    '{"bands": ["nir"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.zeros((122, 120), dtype="uint16"),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"wavelength_max": 878.85, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "wavelength_min": 850.55, "name_vendor": "B5", "product": "landsat:LC08:PRE:TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "id": "landsat:LC08:PRE:TOAR:nir", "vendor_order": 5, "nbits": 14, "type": "spectral", "name": "nir", "wavelength_center": 864.7, "data_range": [0, 10000], "resolution_unit": "m", "wavelength_unit": "nm", "resolution": 30, "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "default_range": [0, 10000], "processing_level": "TOAR"}, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}, "size": [120, 122]}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"wavelength_max": 878.85, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "wavelength_min": 850.55, "name_vendor": "B5", "product": "landsat:LC08:PRE:TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "id": "landsat:LC08:PRE:TOAR:nir", "vendor_order": 5, "nbits": 14, "type": "spectral", "name": "nir", "wavelength_center": 864.7, "data_range": [0, 10000], "resolution_unit": "m", "wavelength_unit": "nm", "resolution": 30, "wavelength_fwhm": 28.3, "nodata": null, "default_range": [0, 10000], "processing_level": "TOAR"}, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1", "Corder": "RPCL"}}, "size": [120, 122]}',
     ),  # noqa
     '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="uint16"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="uint16"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["nir", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="uint16"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["nir", "alpha"], "data_type": "Int32", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="int32"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["nir", "red", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack(
             [
                 np.zeros((122, 120), dtype="uint16"),
                 np.zeros((122, 120), dtype="uint16"),
                 alpha,
             ]
         ),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "owner_type": "core", "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["nir", "red"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack(
             [np.zeros((122, 120), dtype="uint16"), np.zeros((122, 120), dtype="uint16")]
         ),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "owner_type": "core", "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 10000], "wavelength_max": 878.85, "data_unit": "TOAR", "wavelength_center": 864.7, "color": "Gray", "dtype": "UInt16", "name_vendor": "B5", "id": "landsat:LC08:PRE:TOAR:nir", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 850.55, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "vendor_order": 5, "name": "nir", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 28.3, "nodata": null, "resolution": 30}, "band": 1, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "nodata": null, "resolution": 15}, "band": 2, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 3, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["red", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([np.zeros((122, 120), dtype="uint16"), alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "owner_type": "core", "nodata": null, "resolution": 15}, "band": 1, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "owner_type": "core", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [0, 4000], "wavelength_max": 673.35, "data_unit": "TOAR", "wavelength_center": 654.6, "color": "Red", "dtype": "UInt16", "name_vendor": "B4", "id": "landsat:LC08:PRE:TOAR:red", "nbits": 14, "wavelength_unit": "nm", "wavelength_min": 635.85, "processing_level": "TOAR", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "Top of atmosphere reflectance", "description": "Red, Pansharpened", "tags": ["spectral", "red", "15m", "landsat"], "resolution_unit": "m", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "red", "vendor_order": 4, "name": "red", "type": "spectral", "data_range": [0, 10000], "wavelength_fwhm": 37.5, "nodata": null, "resolution": 15}, "band": 1, "colorInterpretation": "Red", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}, {"description": {"product": "landsat:LC08:PRE:TOAR", "nbits": 1, "description": "Alpha (valid data)", "data_description": "0: nodata, 1: valid data", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_range": [0, 1], "resolution": 15, "resolution_unit": "m", "data_unit_description": "unitless", "name_common": "alpha", "type": "mask", "nodata": null, "default_range": [0, 1], "id": "landsat:LC08:PRE:TOAR:alpha", "name": "alpha"}, "band": 2, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "size": [120, 122], "metadata": {"": {"id": "*", "Corder": "RPCL"}}}',
     ),  # noqa
     '{"bands": ["alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.stack([alpha]),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Alpha (valid data)", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_description": "0: nodata, 1: valid data", "name_common": "alpha", "id": "landsat:LC08:PRE:TOAR:alpha", "nbits": 1, "name": "alpha", "type": "mask", "data_range": [0, 1], "resolution_unit": "m", "default_range": [0, 1], "owner_type": "core", "nodata": null, "resolution": 15}, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "*", "Corder": "RPCL"}}, "size": [120, 122]}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "description": "Alpha (valid data)", "tags": ["mask", "alpha", "15m", "landsat"], "color": "Alpha", "dtype": "UInt16", "data_description": "0: nodata, 1: valid data", "name_common": "alpha", "id": "landsat:LC08:PRE:TOAR:alpha", "nbits": 1, "name": "alpha", "type": "mask", "data_range": [0, 1], "resolution_unit": "m", "default_range": [0, 1], "nodata": null, "resolution": 15}, "colorInterpretation": "Alpha", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "1"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "*", "Corder": "RPCL"}}, "size": [120, 122]}',
     ),  # noqa
     '{"bands": ["nir"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "landsat:LC08:PRE:TOAR:meta_LC80260322016197_v1"], "resolution": 600}': (
         np.zeros((122, 120), dtype="uint16"),
-        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"wavelength_max": 878.85, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "wavelength_min": 850.55, "name_vendor": "B5", "product": "landsat:LC08:PRE:TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "id": "landsat:LC08:PRE:TOAR:nir", "vendor_order": 5, "nbits": 14, "type": "spectral", "name": "nir", "wavelength_center": 864.7, "data_range": [0, 10000], "resolution_unit": "m", "wavelength_unit": "nm", "resolution": 30, "wavelength_fwhm": 28.3, "owner_type": "core", "nodata": null, "default_range": [0, 10000], "processing_level": "TOAR"}, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "*", "Corder": "RPCL"}}, "size": [120, 122]}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [456219.441, 4580160.511], "lowerLeft": [384219.441, 4506960.511], "lowerRight": [456219.441, 4506960.511], "upperLeft": [384219.441, 4580160.511], "center": [420219.441, 4543560.511]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-94.3843159, 41.3646333], [-94.3705723, 40.7054251], [-93.5183204, 40.7123983], [-93.5235196, 41.3717692], [-94.3843159, 41.3646333]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"band": 1, "description": {"wavelength_max": 878.85, "data_unit_description": "Top of atmosphere reflectance", "data_unit": "TOAR", "description": "Near Infrared", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "color": "Gray", "dtype": "UInt16", "wavelength_min": 850.55, "name_vendor": "B5", "product": "landsat:LC08:PRE:TOAR", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "physical_range": [0.0, 1.0], "name_common": "nir", "id": "landsat:LC08:PRE:TOAR:nir", "vendor_order": 5, "nbits": 14, "type": "spectral", "name": "nir", "wavelength_center": 864.7, "data_range": [0, 10000], "resolution_unit": "m", "wavelength_unit": "nm", "resolution": 30, "wavelength_fwhm": 28.3, "nodata": null, "default_range": [0, 10000], "processing_level": "TOAR"}, "colorInterpretation": "Gray", "type": "UInt16", "block": [120, 1], "metadata": {"": {"NBITS": "14"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "geoTransform": [384219.440777, 600.0, 0.0, 4580160.51059, 0.0, -600.0], "metadata": {"": {"id": "*", "Corder": "RPCL"}}, "size": [120, 122]}',
     ),  # noqa
-    '{"bands": ["red", "alpha"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 1000}': (
+    '{"bands": ["red", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 1000}': (
         np.stack([np.zeros((239, 235), dtype="uint16"), alpha1000]),
-        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "metadata": {"": {"NBITS": "1"}}, "type": "UInt16", "description": {"nodata": null, "color": "Alpha", "type": "mask", "id": "landsat:LC08:PRE:TOAR:alpha", "description": "Alpha (valid data)", "resolution_unit": "m", "data_description": "0: nodata, 1: valid data", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "nbits": 1, "owner_type": "core", "tags": ["mask", "alpha", "15m", "landsat"], "name_common": "alpha", "default_range": [0, 1], "name": "alpha", "data_range": [0, 1], "dtype": "UInt16", "resolution": 15}, "band": 2, "colorInterpretation": "Alpha"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
+        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "metadata": {"": {"NBITS": "1"}}, "type": "UInt16", "description": {"nodata": null, "color": "Alpha", "type": "mask", "id": "landsat:LC08:PRE:TOAR:alpha", "description": "Alpha (valid data)", "resolution_unit": "m", "data_description": "0: nodata, 1: valid data", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "nbits": 1, "tags": ["mask", "alpha", "15m", "landsat"], "name_common": "alpha", "default_range": [0, 1], "name": "alpha", "data_range": [0, 1], "dtype": "UInt16", "resolution": 15}, "band": 2, "colorInterpretation": "Alpha"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
     ),  # noqa
-    '{"bands": ["red", "green"], "data_type": "Int32", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 600}': (
+    '{"bands": ["red", "green"], "data_type": "Int32", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 600}': (
         np.stack(
             [np.zeros((122, 120), dtype="int32"), np.zeros((122, 120), dtype="int32")]
         ),
-        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:green", "processing_level": "TOAR", "description": "Green, Pansharpened", "resolution_unit": "m", "wavelength_max": 590.05, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Green", "name_common": "green", "name": "green", "name_vendor": "B3", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 532.75, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "green", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 3, "resolution": 15, "wavelength_center": 561.4, "wavelength_fwhm": 57.3}, "band": 2, "colorInterpretation": "Green"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
+        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:green", "processing_level": "TOAR", "description": "Green, Pansharpened", "resolution_unit": "m", "wavelength_max": 590.05, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Green", "name_common": "green", "name": "green", "name_vendor": "B3", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 532.75, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "green", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 3, "resolution": 15, "wavelength_center": 561.4, "wavelength_fwhm": 57.3}, "band": 2, "colorInterpretation": "Green"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
     ),  # noqa
-    '{"bands": ["red", "green", "blue", "alpha"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 1000}': (
+    '{"bands": ["red", "green", "blue", "alpha"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 1000}': (
         np.stack(
             [
                 np.zeros((239, 235), dtype="uint16"),
                 np.zeros((239, 235), dtype="uint16"),
                 np.zeros((239, 235), dtype="uint16"),
                 alpha1000,
             ]
         ),
-        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:green", "processing_level": "TOAR", "description": "Green, Pansharpened", "resolution_unit": "m", "wavelength_max": 590.05, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Green", "name_common": "green", "name": "green", "name_vendor": "B3", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 532.75, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "green", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 3, "resolution": 15, "wavelength_center": 561.4, "wavelength_fwhm": 57.3}, "band": 2, "colorInterpretation": "Green"}, {"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:blue", "processing_level": "TOAR", "description": "Blue, Pansharpened", "resolution_unit": "m", "wavelength_max": 512.0, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Blue", "name_common": "blue", "name": "blue", "name_vendor": "B2", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 452.0, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "blue", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 2, "resolution": 15, "wavelength_center": 482, "wavelength_fwhm": 60}, "band": 3, "colorInterpretation": "Blue"}, {"block": [235, 1], "metadata": {"": {"NBITS": "1"}}, "type": "UInt16", "description": {"nodata": null, "color": "Alpha", "type": "mask", "id": "landsat:LC08:PRE:TOAR:alpha", "description": "Alpha (valid data)", "resolution_unit": "m", "data_description": "0: nodata, 1: valid data", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "nbits": 1, "owner_type": "core", "tags": ["mask", "alpha", "15m", "landsat"], "name_common": "alpha", "default_range": [0, 1], "name": "alpha", "data_range": [0, 1], "dtype": "UInt16", "resolution": 15}, "band": 4, "colorInterpretation": "Alpha"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
+        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:green", "processing_level": "TOAR", "description": "Green, Pansharpened", "resolution_unit": "m", "wavelength_max": 590.05, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Green", "name_common": "green", "name": "green", "name_vendor": "B3", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 532.75, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "green", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 3, "resolution": 15, "wavelength_center": 561.4, "wavelength_fwhm": 57.3}, "band": 2, "colorInterpretation": "Green"}, {"block": [235, 1], "mask": {"flags": ["PER_DATASET", "ALPHA"], "overviews": []}, "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:blue", "processing_level": "TOAR", "description": "Blue, Pansharpened", "resolution_unit": "m", "wavelength_max": 512.0, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Blue", "name_common": "blue", "name": "blue", "name_vendor": "B2", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 452.0, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "blue", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 2, "resolution": 15, "wavelength_center": 482, "wavelength_fwhm": 60}, "band": 3, "colorInterpretation": "Blue"}, {"block": [235, 1], "metadata": {"": {"NBITS": "1"}}, "type": "UInt16", "description": {"nodata": null, "color": "Alpha", "type": "mask", "id": "landsat:LC08:PRE:TOAR:alpha", "description": "Alpha (valid data)", "resolution_unit": "m", "data_description": "0: nodata, 1: valid data", "product": "landsat:LC08:PRE:TOAR", "data_unit_description": "unitless", "nbits": 1, "tags": ["mask", "alpha", "15m", "landsat"], "name_common": "alpha", "default_range": [0, 1], "name": "alpha", "data_range": [0, 1], "dtype": "UInt16", "resolution": 15}, "band": 4, "colorInterpretation": "Alpha"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
     ),  # noqa
-    '{"bands": ["red", "nir"], "data_type": "UInt16", "inputs": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1", "resolution": 1000}': (
+    '{"bands": ["red", "nir"], "data_type": "UInt16", "inputs": ["landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"], "resolution": 1000}': (
         np.stack(
             [np.zeros((239, 235), dtype="uint16"), np.zeros((239, 235), dtype="uint16")]
         ),
-        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:nir", "processing_level": "TOAR", "description": "Near Infrared", "resolution_unit": "m", "wavelength_max": 878.85, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Gray", "name_common": "nir", "name": "nir", "name_vendor": "B5", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 850.55, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "owner_type": "core", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 10000], "vendor_order": 5, "resolution": 30, "wavelength_center": 864.7, "wavelength_fwhm": 28.3}, "band": 2, "colorInterpretation": "Gray"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
+        '{"metadata": {"": {"Corder": "RPCL", "id": "landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1"}}, "driverShortName": "MEM", "wgs84Extent": {"coordinates": [[[-95.9559596, 42.8041728], [-95.8589268, 40.654253], [-93.0793836, 40.6896344], [-93.0820826, 42.8423136], [-95.9559596, 42.8041728]]], "type": "Polygon"}, "geoTransform": [258292.5, 1000.0, 0.0, 4743307.5, 0.0, -1000.0], "coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 15N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-93],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32615\\"]]"}, "cornerCoordinates": {"upperRight": [493292.5, 4743307.5], "center": [375792.5, 4623807.5], "upperLeft": [258292.5, 4743307.5], "lowerRight": [493292.5, 4504307.5], "lowerLeft": [258292.5, 4504307.5]}, "files": [], "bands": [{"block": [235, 1], "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:red", "processing_level": "TOAR", "description": "Red, Pansharpened", "resolution_unit": "m", "wavelength_max": 673.35, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Red", "name_common": "red", "name": "red", "name_vendor": "B4", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 635.85, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "red", "15m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 4000], "vendor_order": 4, "resolution": 15, "wavelength_center": 654.6, "wavelength_fwhm": 37.5}, "band": 1, "colorInterpretation": "Red"}, {"block": [235, 1], "metadata": {"": {"NBITS": "14"}}, "type": "UInt16", "description": {"nodata": null, "data_unit_description": "Top of atmosphere reflectance", "id": "landsat:LC08:PRE:TOAR:nir", "processing_level": "TOAR", "description": "Near Infrared", "resolution_unit": "m", "wavelength_max": 878.85, "product": "landsat:LC08:PRE:TOAR", "nbits": 14, "wavelength_unit": "nm", "color": "Gray", "name_common": "nir", "name": "nir", "name_vendor": "B5", "data_unit": "TOAR", "data_range": [0, 10000], "wavelength_min": 850.55, "type": "spectral", "dtype": "UInt16", "data_description": "TOAR, 0-10000 is 0 - 100% reflective", "tags": ["spectral", "nir", "near-infrared", "30m", "landsat"], "physical_range": [0.0, 1.0], "default_range": [0, 10000], "vendor_order": 5, "resolution": 30, "wavelength_center": 864.7, "wavelength_fwhm": 28.3}, "band": 2, "colorInterpretation": "Gray"}], "size": [235, 239], "driverLongName": "In Memory Raster"}',
     ),  # noqa
-    '{"bands": ["Clear_sky_days", "Clear_sky_nights"], "data_type": "Byte", "inputs": "modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1", "resolution": 1000}': (
+    '{"bands": ["Clear_sky_days", "Clear_sky_nights"], "data_type": "Byte", "inputs": ["modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1"], "resolution": 1000}': (
         np.stack(
             [np.zeros((688, 473), dtype="uint16"), np.zeros((688, 473), dtype="uint16")]
         ),
-        '{"files": [],"cornerCoordinates": {"upperRight": [340252.341, 6855234.987], "lowerLeft": [298972.341, 6826854.987], "lowerRight": [340252.341, 6826854.987], "upperLeft": [298972.341, 6855234.987], "center": [319612.341, 6841044.987]},"wgs84Extent": {"type": "Polygon", "coordinates": [[[-144.8118058, 61.7770149],   [-144.7805921, 61.5228056],   [-144.0056918, 61.5420874],   [-144.0305346, 61.7965016],   [-144.8118058, 61.7770149]]]},"driverShortName": "MEM","driverLongName": "In Memory Raster","bands": [{"description": {"default_range": [0, 4000],   "wavelength_max": 680.0,   "data_unit": "TOAR",   "color": "Red",   "dtype": "UInt16",   "name_vendor": "B4",   "type": "spectral",   "id": "sentinel-2:L1C:red",   "nbits": 14,   "wavelength_unit": "nm",   "wavelength_min": 650.0,   "processing_level": "TOAR",   "product": "sentinel-2:L1C",   "data_unit_description": "Top of atmosphere reflectance",   "description": "Red",   "tags": ["spectral", "red", "10m", "sentinel-2"],   "resolution_unit": "m",   "vendor_order": 4,   "physical_range": [0.0, 1.0],   "name_common": "red",   "data_description": "TOAR, 0-10000 is 0 - 100% reflective",   "name": "red",   "wavelength_center": 665,   "data_range": [0, 10000],   "wavelength_fwhm": 30,   "owner_type": "core",   "nodata": null,   "resolution": 10},  "mask": {"overviews": [], "flags": ["PER_DATASET", "ALPHA"]},  "band": 1,  "colorInterpretation": "Red",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000],   "wavelength_max": 577.5,   "data_unit": "TOAR",   "color": "Green",   "dtype": "UInt16",   "name_vendor": "B3",   "type": "spectral",   "id": "sentinel-2:L1C:green",   "nbits": 14,   "wavelength_unit": "nm",   "wavelength_min": 542.5,   "processing_level": "TOAR",   "product": "sentinel-2:L1C",   "data_unit_description": "Top of atmosphere reflectance",   "description": "Green",   "tags": ["spectral", "green", "10m", "sentinel-2"],   "resolution_unit": "m",   "vendor_order": 3,   "physical_range": [0.0, 1.0],   "name_common": "green",   "data_description": "TOAR, 0-10000 is 0 - 100% reflective",   "name": "green",   "wavelength_center": 560,   "data_range": [0, 10000],   "wavelength_fwhm": 35,   "owner_type": "core",   "nodata": null,   "resolution": 10},  "mask": {"overviews": [], "flags": ["PER_DATASET", "ALPHA"]},  "band": 2,  "colorInterpretation": "Green",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000],   "wavelength_max": 522.5,   "data_unit": "TOAR",   "color": "Blue",   "dtype": "UInt16",   "name_vendor": "B2",   "type": "spectral",   "id": "sentinel-2:L1C:blue",   "nbits": 14,   "wavelength_unit": "nm",   "wavelength_min": 457.5,   "processing_level": "TOAR",   "product": "sentinel-2:L1C",   "data_unit_description": "Top of atmosphere reflectance",   "description": "Blue",   "tags": ["spectral", "blue", "10m", "sentinel-2"],   "resolution_unit": "m",   "vendor_order": 2,   "physical_range": [0.0, 1.0],   "name_common": "blue",   "data_description": "TOAR, 0-10000 is 0 - 100% reflective",   "name": "blue",   "wavelength_center": 490,   "data_range": [0, 10000],   "wavelength_fwhm": 65,   "owner_type": "core",   "nodata": null,   "resolution": 10},  "mask": {"overviews": [], "flags": ["PER_DATASET", "ALPHA"]},  "band": 3,  "colorInterpretation": "Blue",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 1],   "product": "sentinel-2:L1C",   "nbits": 1,   "description": "Alpha (valid data)",   "tags": ["mask", "alpha", "10m", "sentinel-2"],   "color": "Alpha",   "dtype": "UInt16",   "data_range": [0, 1],   "resolution": 10,   "name": "alpha",   "resolution_unit": "m",   "data_unit_description": "unitless",   "name_common": "alpha",   "owner_type": "core",   "nodata": null,   "type": "mask",   "id": "sentinel-2:L1C:alpha",   "data_description": "0: nodata, 1: valid data"},  "band": 4,  "colorInterpretation": "Alpha",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "1"}}}],"coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 7N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-141],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32607\\"]]"},"geoTransform": [298972.341031, 60.0, 0.0, 6855234.98696, 0.0, -60.0],"metadata": {"": {"id": "sentinel-2:L1C:2017-08-07_07VCJ_99_S2A_v1",  "Corder": "RPCL"}},"size": [688, 473]}',
+        '{"files": [],"cornerCoordinates": {"upperRight": [340252.341, 6855234.987], "lowerLeft": [298972.341, 6826854.987], "lowerRight": [340252.341, 6826854.987], "upperLeft": [298972.341, 6855234.987], "center": [319612.341, 6841044.987]},"wgs84Extent": {"type": "Polygon", "coordinates": [[[-144.8118058, 61.7770149],   [-144.7805921, 61.5228056],   [-144.0056918, 61.5420874],   [-144.0305346, 61.7965016],   [-144.8118058, 61.7770149]]]},"driverShortName": "MEM","driverLongName": "In Memory Raster","bands": [{"description": {"default_range": [0, 4000],   "wavelength_max": 680.0,   "data_unit": "TOAR",   "color": "Red",   "dtype": "UInt16",   "name_vendor": "B4",   "type": "spectral",   "id": "sentinel-2:L1C:red",   "nbits": 14,   "wavelength_unit": "nm",   "wavelength_min": 650.0,   "processing_level": "TOAR",   "product": "sentinel-2:L1C",   "data_unit_description": "Top of atmosphere reflectance",   "description": "Red",   "tags": ["spectral", "red", "10m", "sentinel-2"],   "resolution_unit": "m",   "vendor_order": 4,   "physical_range": [0.0, 1.0],   "name_common": "red",   "data_description": "TOAR, 0-10000 is 0 - 100% reflective",   "name": "red",   "wavelength_center": 665,   "data_range": [0, 10000],   "wavelength_fwhm": 30,     "nodata": null,   "resolution": 10},  "mask": {"overviews": [], "flags": ["PER_DATASET", "ALPHA"]},  "band": 1,  "colorInterpretation": "Red",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000],   "wavelength_max": 577.5,   "data_unit": "TOAR",   "color": "Green",   "dtype": "UInt16",   "name_vendor": "B3",   "type": "spectral",   "id": "sentinel-2:L1C:green",   "nbits": 14,   "wavelength_unit": "nm",   "wavelength_min": 542.5,   "processing_level": "TOAR",   "product": "sentinel-2:L1C",   "data_unit_description": "Top of atmosphere reflectance",   "description": "Green",   "tags": ["spectral", "green", "10m", "sentinel-2"],   "resolution_unit": "m",   "vendor_order": 3,   "physical_range": [0.0, 1.0],   "name_common": "green",   "data_description": "TOAR, 0-10000 is 0 - 100% reflective",   "name": "green",   "wavelength_center": 560,   "data_range": [0, 10000],   "wavelength_fwhm": 35,     "nodata": null,   "resolution": 10},  "mask": {"overviews": [], "flags": ["PER_DATASET", "ALPHA"]},  "band": 2,  "colorInterpretation": "Green",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 4000],   "wavelength_max": 522.5,   "data_unit": "TOAR",   "color": "Blue",   "dtype": "UInt16",   "name_vendor": "B2",   "type": "spectral",   "id": "sentinel-2:L1C:blue",   "nbits": 14,   "wavelength_unit": "nm",   "wavelength_min": 457.5,   "processing_level": "TOAR",   "product": "sentinel-2:L1C",   "data_unit_description": "Top of atmosphere reflectance",   "description": "Blue",   "tags": ["spectral", "blue", "10m", "sentinel-2"],   "resolution_unit": "m",   "vendor_order": 2,   "physical_range": [0.0, 1.0],   "name_common": "blue",   "data_description": "TOAR, 0-10000 is 0 - 100% reflective",   "name": "blue",   "wavelength_center": 490,   "data_range": [0, 10000],   "wavelength_fwhm": 65,     "nodata": null,   "resolution": 10},  "mask": {"overviews": [], "flags": ["PER_DATASET", "ALPHA"]},  "band": 3,  "colorInterpretation": "Blue",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "14"}}}, {"description": {"default_range": [0, 1],   "product": "sentinel-2:L1C",   "nbits": 1,   "description": "Alpha (valid data)",   "tags": ["mask", "alpha", "10m", "sentinel-2"],   "color": "Alpha",   "dtype": "UInt16",   "data_range": [0, 1],   "resolution": 10,   "name": "alpha",   "resolution_unit": "m",   "data_unit_description": "unitless",   "name_common": "alpha",     "nodata": null,   "type": "mask",   "id": "sentinel-2:L1C:alpha",   "data_description": "0: nodata, 1: valid data"},  "band": 4,  "colorInterpretation": "Alpha",  "type": "Byte",  "block": [688, 1],  "metadata": {"": {"NBITS": "1"}}}],"coordinateSystem": {"wkt": "PROJCS[\\"WGS 84 / UTM zone 7N\\",\\n    GEOGCS[\\"WGS 84\\",\\n        DATUM[\\"WGS_1984\\",\\n            SPHEROID[\\"WGS 84\\",6378137,298.257223563,\\n                AUTHORITY[\\"EPSG\\",\\"7030\\"]],\\n            AUTHORITY[\\"EPSG\\",\\"6326\\"]],\\n        PRIMEM[\\"Greenwich\\",0,\\n            AUTHORITY[\\"EPSG\\",\\"8901\\"]],\\n        UNIT[\\"degree\\",0.0174532925199433,\\n            AUTHORITY[\\"EPSG\\",\\"9122\\"]],\\n        AUTHORITY[\\"EPSG\\",\\"4326\\"]],\\n    PROJECTION[\\"Transverse_Mercator\\"],\\n    PARAMETER[\\"latitude_of_origin\\",0],\\n    PARAMETER[\\"central_meridian\\",-141],\\n    PARAMETER[\\"scale_factor\\",0.9996],\\n    PARAMETER[\\"false_easting\\",500000],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"metre\\",1,\\n        AUTHORITY[\\"EPSG\\",\\"9001\\"]],\\n    AXIS[\\"Easting\\",EAST],\\n    AXIS[\\"Northing\\",NORTH],\\n    AUTHORITY[\\"EPSG\\",\\"32607\\"]]"},"geoTransform": [298972.341031, 60.0, 0.0, 6855234.98696, 0.0, -60.0],"metadata": {"": {"id": "sentinel-2:L1C:2017-08-07_07VCJ_99_S2A_v1",  "Corder": "RPCL"}},"size": [688, 473]}',
     ),  # noqa
     '{"bands": ["Clear_sky_days", "Clear_sky_nights"], "data_type": "Byte", "inputs": ["modis:mod11a2:006:meta_MOD11A2.A2017305.h09v05.006.2017314042814_v1", "modis:mod11a2:006:meta_MOD11A2.A2000049.h08v05.006.2015058135046_v1"], "resolution": 600}': (
         np.stack(
             [
                 np.zeros((1853, 3707), dtype="uint16"),
                 np.zeros((1853, 3707), dtype="uint16"),
             ]
         ),
-        '{"files": [], "cornerCoordinates": {"upperRight": [-8895305.198, 4447802.079], "lowerLeft": [-11119505.198, 3336002.079], "lowerRight": [-8895305.198, 3336002.079], "upperLeft": [-11119505.198, 4447802.079], "center": [-10007405.198, 3891902.079]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-130.5407289, 40.0], [-115.4716289, 30.0013537], [-92.3741986, 30.0013537], [-104.4290734, 40.0], [-130.5407289, 40.0]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [1, 255], "product": "modis:mod11a2:006", "vendor_order": 11, "data_unit": "unitless", "description": "Day clear-sky coverage", "resolution_unit": "meters", "dtype": "Byte", "physical_range": [0.0, 255.0], "data_range": [0, 255], "name_vendor": "Clear_sky_days", "nbits": 8, "type": "spectral", "owner_type": "core", "nodata": 0, "resolution": 1000, "id": "modis:mod11a2:006:Clear_sky_days", "name": "Clear_sky_days"}, "noDataValue": 0.0, "band": 1, "colorInterpretation": "Undefined", "type": "Byte", "block": [3707, 1], "metadata": {"": {"NBITS": "8"}}}, {"description": {"default_range": [1, 255], "product": "modis:mod11a2:006", "vendor_order": 12, "data_unit": "unitless", "description": "Night clear-sky coverage", "resolution_unit": "meters", "dtype": "Byte", "physical_range": [0.0, 255.0], "data_range": [0, 255], "name_vendor": "Clear_sky_nights", "nbits": 8, "type": "spectral", "owner_type": "core", "nodata": 0, "resolution": 1000, "id": "modis:mod11a2:006:Clear_sky_nights", "name": "Clear_sky_nights"}, "noDataValue": 0.0, "band": 2, "colorInterpretation": "Undefined", "type": "Byte", "block": [3707, 1], "metadata": {"": {"NBITS": "8"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"unnamed\\",\\n    GEOGCS[\\"unnamed ellipse\\",\\n        DATUM[\\"unknown\\",\\n            SPHEROID[\\"unnamed\\",6371007.181,0]],\\n        PRIMEM[\\"Greenwich\\",0],\\n        UNIT[\\"degree\\",0.0174532925199433]],\\n    PROJECTION[\\"Sinusoidal\\"],\\n    PARAMETER[\\"longitude_of_center\\",0],\\n    PARAMETER[\\"false_easting\\",0],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"Meter\\",1]]"}, "geoTransform": [-11119505.197665, 600.0, 0.0, 4447802.079066, 0.0, -600.0], "metadata": {"": {"id": "*", "Corder": "RPCL"}}, "size": [3707, 1853]}',
+        '{"files": [], "cornerCoordinates": {"upperRight": [-8895305.198, 4447802.079], "lowerLeft": [-11119505.198, 3336002.079], "lowerRight": [-8895305.198, 3336002.079], "upperLeft": [-11119505.198, 4447802.079], "center": [-10007405.198, 3891902.079]}, "wgs84Extent": {"type": "Polygon", "coordinates": [[[-130.5407289, 40.0], [-115.4716289, 30.0013537], [-92.3741986, 30.0013537], [-104.4290734, 40.0], [-130.5407289, 40.0]]]}, "driverShortName": "MEM", "driverLongName": "In Memory Raster", "bands": [{"description": {"default_range": [1, 255], "product": "modis:mod11a2:006", "vendor_order": 11, "data_unit": "unitless", "description": "Day clear-sky coverage", "resolution_unit": "meters", "dtype": "Byte", "physical_range": [0.0, 255.0], "data_range": [0, 255], "name_vendor": "Clear_sky_days", "nbits": 8, "type": "spectral", "nodata": 0, "resolution": 1000, "id": "modis:mod11a2:006:Clear_sky_days", "name": "Clear_sky_days"}, "noDataValue": 0.0, "band": 1, "colorInterpretation": "Undefined", "type": "Byte", "block": [3707, 1], "metadata": {"": {"NBITS": "8"}}}, {"description": {"default_range": [1, 255], "product": "modis:mod11a2:006", "vendor_order": 12, "data_unit": "unitless", "description": "Night clear-sky coverage", "resolution_unit": "meters", "dtype": "Byte", "physical_range": [0.0, 255.0], "data_range": [0, 255], "name_vendor": "Clear_sky_nights", "nbits": 8, "type": "spectral", "nodata": 0, "resolution": 1000, "id": "modis:mod11a2:006:Clear_sky_nights", "name": "Clear_sky_nights"}, "noDataValue": 0.0, "band": 2, "colorInterpretation": "Undefined", "type": "Byte", "block": [3707, 1], "metadata": {"": {"NBITS": "8"}}}], "coordinateSystem": {"wkt": "PROJCS[\\"unnamed\\",\\n    GEOGCS[\\"unnamed ellipse\\",\\n        DATUM[\\"unknown\\",\\n            SPHEROID[\\"unnamed\\",6371007.181,0]],\\n        PRIMEM[\\"Greenwich\\",0],\\n        UNIT[\\"degree\\",0.0174532925199433]],\\n    PROJECTION[\\"Sinusoidal\\"],\\n    PARAMETER[\\"longitude_of_center\\",0],\\n    PARAMETER[\\"false_easting\\",0],\\n    PARAMETER[\\"false_northing\\",0],\\n    UNIT[\\"Meter\\",1]]"}, "geoTransform": [-11119505.197665, 600.0, 0.0, 4447802.079066, 0.0, -600.0], "metadata": {"": {"id": "*", "Corder": "RPCL"}}, "size": [3707, 1853]}',
     ),  # noqa
 }
 
 
 def _raster_ndarray(self, **kwargs):
     a, meta = RASTER[
         json.dumps(
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/tests/test_collection.py` & `descarteslabs-2.0.0/descarteslabs/core/common/collection/tests/test_collection.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,26 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import collections
 import pytest
 import unittest
 
-from descarteslabs.scenes import Collection
+from .. import Collection
 
 
 class SubCollection(Collection):
     def __init__(self, iterable=None, foo=1):
         super(SubCollection, self).__init__(iterable)
         self.foo = foo
         self._secret = True
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/tests/test_display.py` & `descarteslabs-2.0.0/descarteslabs/core/common/display/tests/test_display.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,15 +1,30 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from __future__ import division
 
 import pytest
 import unittest
-import mock
+from unittest import mock
 
 import numpy as np
-from descarteslabs.scenes import display
+from .. import _display
+from .. import display
 
 
 class TestDisplay(unittest.TestCase):
     @staticmethod
     def make_mock_subplots(mock_matplotlib_importer, n_imgs):
         mock_matplotlib = mock.Mock()
         mock_matplotlib_importer.return_value = mock_matplotlib
@@ -17,15 +32,15 @@
         mock_plt = mock_matplotlib.pyplot
         mock_fig = mock.Mock()
         mock_axs = [[mock.Mock()] for i in range(n_imgs)]
 
         mock_plt.subplots.return_value = (mock_fig, mock_axs)
         return mock_plt, mock_fig, mock_axs
 
-    @mock.patch("descarteslabs.client.addons.import_matplotlib_pyplot")
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
     def test_display_2d(self, mock_matplotlib_importer):
         mock_plt, mock_fig, mock_axs = self.make_mock_subplots(
             mock_matplotlib_importer, 1
         )
 
         img = np.arange(6).reshape((3, 2))
 
@@ -35,15 +50,26 @@
         mock_plt.subplots.assert_called_with(1, 1, figsize=(5, 5), squeeze=False)
 
         ax = mock_axs[0][0]
         imshow_args, imshow_kwargs = ax.imshow.call_args
         assert (imshow_args[0] == img_normed).all()
         ax.set_title.assert_called_with("foo")
 
-    @mock.patch("descarteslabs.client.addons.import_matplotlib_pyplot")
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
+    def test_display_multi_cols(self, mock_matplotlib_importer):
+        mock_plt, mock_fig, mock_axs = self.make_mock_subplots(
+            mock_matplotlib_importer, 5
+        )
+
+        img = np.arange(6).reshape((3, 2))
+        display(img, img, img, img, img, ncols=2)
+
+        mock_plt.subplots.assert_called_with(3, 2, figsize=(10, 15), squeeze=False)
+
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
     def test_display_3d_masked(self, mock_matplotlib_importer):
         mock_plt, mock_fig, mock_axs = self.make_mock_subplots(
             mock_matplotlib_importer, 1
         )
 
         img = np.arange(3 * 3 * 2).reshape((3, 3, 2))
         mask = np.zeros_like(img).astype(bool)
@@ -62,15 +88,15 @@
         imshow_args, imshow_kwargs = ax.imshow.call_args
         called_arr = imshow_args[0]
         assert called_arr.shape == (3, 2, 4)
         assert (called_arr[:, :, -1] == alpha).all()
 
         ax.set_title.assert_not_called()
 
-    @mock.patch("descarteslabs.client.addons.import_matplotlib_pyplot")
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
     def test_display_3d_multiple(self, mock_matplotlib_importer):
         mock_plt, mock_fig, mock_axs = self.make_mock_subplots(
             mock_matplotlib_importer, 5
         )
 
         img = np.arange(len(mock_axs) * 3 * 3 * 2).reshape((len(mock_axs), 3, 3, 2))
         with pytest.raises(TypeError, match="To display a 4D ndarray"):
@@ -81,32 +107,32 @@
         for i, ax in enumerate(mock_axs):
             ax = ax[0]
             imshow_args, imshow_kwargs = ax.imshow.call_args
             called_arr = imshow_args[0]
             assert called_arr.shape == (3, 2, 3)
             ax.set_title.assert_called_with(str(i))
 
-    @mock.patch("descarteslabs.client.addons.import_matplotlib_pyplot")
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
     def test_fails_2band(self, mock_matplotlib_importer):
         mock_plt, mock_fig, mock_axs = self.make_mock_subplots(
             mock_matplotlib_importer, 1
         )
 
         img = np.arange(2 * 4 * 2).reshape((2, 4, 2))
 
         with pytest.raises(NotImplementedError):
             display(img)
 
-    @mock.patch("descarteslabs.client.addons.import_matplotlib_pyplot")
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
     def test_fails_wrong_num_titles(self, mock_matplotlib_importer):
         mock_plt, mock_fig, mock_axs = self.make_mock_subplots(
             mock_matplotlib_importer, 5
         )
 
         img = np.arange(len(mock_axs) * 3 * 3 * 2).reshape((len(mock_axs), 3, 3, 2))
         with pytest.raises(ValueError, match="titles"):
             display(*img, title=[1, 2])
 
-    @mock.patch("descarteslabs.client.addons.import_matplotlib_pyplot")
+    @mock.patch.object(_display, "_import_matplotlib_pyplot")
     def test_fails_wrong_kwargs(self, mock_matplotlib_importer):
         with pytest.raises(TypeError, match="what"):
             display(None, title="foo", what="bar")
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/tests/test_geocontext.py` & `descarteslabs-2.0.0/descarteslabs/core/common/geo/tests/test_geocontext.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,45 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import pytest
 import unittest
 import multiprocessing
+import platform
 import concurrent.futures
 import copy
 import warnings
 
-from descarteslabs.scenes import geocontext
-from descarteslabs.scenes.geocontext import EARTH_CIRCUMFERENCE_WGS84
 import shapely.geometry
 
+try:
+    # shapely 2.x
+    from shapely import translate
+except ImportError:
+    # shapely 1.X
+    from shapely.affinity import translate
+
+from .. import geocontext
+from ..geocontext import EARTH_CIRCUMFERENCE_WGS84
+
+
+if platform.system() == "Darwin":
+    multiprocessing.set_start_method("fork")
+
 
 class SimpleContext(geocontext.GeoContext):
     __slots__ = ("foo", "_bar")
 
     def __init__(self, foo=None, bar=None):
         super(SimpleContext, self).__init__()
         self.foo = foo
@@ -20,15 +47,16 @@
 
 
 class TestGeoContext(unittest.TestCase):
     def test_repr(self):
         simple = SimpleContext(1, False)
         r = repr(simple)
         expected = """SimpleContext(foo=1,
-              bar=False)"""
+              bar=False,
+              all_touched=False)"""
         assert r == expected
 
     def test_eq(self):
         simple = SimpleContext(1, False)
         simple2 = SimpleContext(1, False)
         simple_diff = SimpleContext(1, True)
         not_simple = geocontext.GeoContext()
@@ -89,29 +117,41 @@
                 ),
             ),
             "type": "Polygon",
         }
         bounds_wgs84 = (-94.37053769704536, 40.703737, -93.52300099792355, 41.3717716)
         resolution = 40
         crs = "EPSG:32615"
-        align_pixels = False
 
-        ctx = geocontext.AOI(geom, resolution, crs, align_pixels)
+        ctx = geocontext.AOI(geom, resolution=resolution, crs=crs)
         raster_params = ctx.raster_params
         expected = {
             "cutline": geom,
             "resolution": resolution,
             "srs": crs,
             "bounds_srs": "EPSG:4326",
-            "align_pixels": align_pixels,
+            "align_pixels": True,
             "bounds": bounds_wgs84,
             "dimensions": None,
         }
         assert raster_params == expected
 
+        ctx = geocontext.AOI(geom, crs=crs, shape=(512, 512))
+        raster_params = ctx.raster_params
+        expected = {
+            "cutline": geom,
+            "resolution": None,
+            "srs": crs,
+            "bounds_srs": "EPSG:4326",
+            "align_pixels": False,
+            "bounds": bounds_wgs84,
+            "dimensions": (512, 512),
+        }
+        assert raster_params == expected
+
     def test_assign(self):
         geom = {
             "coordinates": [
                 [
                     [-93.52300099792355, 41.241436141055345],
                     [-93.7138666, 40.703737],
                     [-94.37053769704536, 40.83098709945576],
@@ -134,23 +174,23 @@
         ctx3 = ctx2.assign(geometry=None)
         assert ctx3.geometry is None
 
     def test_assign_update_bounds(self):
         geom = shapely.geometry.Point(-90, 30).buffer(1).envelope
         ctx = geocontext.AOI(geometry=geom, resolution=40)
 
-        geom_overlaps = shapely.affinity.translate(geom, xoff=1)
+        geom_overlaps = translate(geom, xoff=1)
         assert geom.intersects(geom_overlaps)
         ctx_overlap = ctx.assign(geometry=geom_overlaps)
         assert ctx_overlap.bounds == ctx.bounds
 
         ctx_updated = ctx.assign(geometry=geom_overlaps, bounds="update")
         assert ctx_updated.bounds == geom_overlaps.bounds
 
-        geom_doesnt_overlap = shapely.affinity.translate(geom, xoff=3)
+        geom_doesnt_overlap = translate(geom, xoff=3)
         with pytest.raises(ValueError, match="Geometry and bounds do not intersect"):
             ctx.assign(geometry=geom_doesnt_overlap)
         ctx_doesnt_overlap_updated = ctx.assign(
             geometry=geom_doesnt_overlap, bounds="update"
         )
         assert ctx_doesnt_overlap_updated.bounds == geom_doesnt_overlap.bounds
 
@@ -310,18 +350,18 @@
         assert tile.proj4 == "+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs "
         assert (
             tile.wkt
             == 'PROJCS["WGS 84 / UTM zone 15N",GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",0],PARAMETER["central_meridian",-93],PARAMETER["scale_factor",0.9996],PARAMETER["false_easting",500000],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Easting",EAST],AXIS["Northing",NORTH],AUTHORITY["EPSG","32615"]]'  # noqa
         )
 
     def test_assign(self):
-        tile = geocontext.DLTile.from_key(self.key2)
+        tile = geocontext.DLTile.from_key(self.key)
         tile = tile.assign(8)
 
-        assert tile.key == self.key2
+        assert tile.key == self.key.replace(":16:", ":8:")
         assert tile.resolution == 960
         assert tile.pad == 8
         assert tile.tilesize == 128
         assert tile.crs == "EPSG:32615"
         assert tile.bounds == (369440.0, 4538880.0, 507680.0, 4677120.0)
         assert tile.bounds_crs == "EPSG:32615"
         assert tile.raster_params == {"dltile": self.key2, "align_pixels": False}
@@ -336,31 +376,65 @@
         tile = geocontext.DLTile.from_key(self.key)
         latlons = tile.rowcol_to_latlon(row=5, col=23)
         rowcols = tile.latlon_to_rowcol(lat=latlons[0], lon=latlons[1])
         assert rowcols[0] == 5
         assert rowcols[1] == 23
 
     def test_iter_from_shape(self):
-        params = {
-            "resolution": 1.5,
-            "tilesize": 512,
-            "pad": 0,
-            "keys_only": True
-        }
+        params = {"resolution": 1.5, "tilesize": 512, "pad": 0, "keys_only": True}
         shape = {
             "type": "Feature",
             "geometry": {
                 "type": "Polygon",
-                "coordinates": [[
-                   [-122.51140471760839, 37.77130087547876],
-                   [-122.45475646845254, 37.77475476721895],
-                   [-122.45303985468301, 37.76657207194229],
-                   [-122.51057242081689, 37.763446782666094],
-                   [-122.51140471760839, 37.77130087547876]]]
-               }, "properties": None
+                "coordinates": [
+                    [
+                        [-122.51140471760839, 37.77130087547876],
+                        [-122.45475646845254, 37.77475476721895],
+                        [-122.45303985468301, 37.76657207194229],
+                        [-122.51057242081689, 37.763446782666094],
+                        [-122.51140471760839, 37.77130087547876],
+                    ]
+                ],
+            },
+            "properties": None,
+        }
+        dltiles1 = [tile for tile in geocontext.DLTile.iter_from_shape(shape, **params)]
+        dltiles2 = geocontext.DLTile.from_shape(shape, **params)
+        assert type(dltiles1[0]) == str
+        assert type(dltiles1[1]) == str
+        assert len(dltiles1) == len(dltiles2)
+
+    def test_iter_from_shape_multi(self):
+        params = {"resolution": 1.5, "tilesize": 512, "pad": 0, "keys_only": True}
+        shape = {
+            "type": "Feature",
+            "geometry": {
+                "type": "MultiPolygon",
+                "coordinates": [
+                    [
+                        [
+                            [-122.51140471760839, 37.77130087547876],
+                            [-122.45475646845254, 37.77475476721895],
+                            [-122.45303985468301, 37.76657207194229],
+                            [-122.51057242081689, 37.763446782666094],
+                            [-122.51140471760839, 37.77130087547876],
+                        ]
+                    ],
+                    [
+                        [
+                            [-123.51140471760839, 37.77130087547876],
+                            [-123.45475646845254, 37.77475476721895],
+                            [-123.45303985468301, 37.76657207194229],
+                            [-123.51057242081689, 37.763446782666094],
+                            [-123.51140471760839, 37.77130087547876],
+                        ]
+                    ],
+                ],
+            },
+            "properties": None,
         }
         dltiles1 = [tile for tile in geocontext.DLTile.iter_from_shape(shape, **params)]
         dltiles2 = geocontext.DLTile.from_shape(shape, **params)
         assert type(dltiles1[0]) == str
         assert type(dltiles1[1]) == str
         assert len(dltiles1) == len(dltiles2)
```

### Comparing `descarteslabs-1.9.1/descarteslabs/scenes/tests/test_helpers.py` & `descarteslabs-2.0.0/descarteslabs/core/common/geo/tests/test_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,32 @@
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import unittest
 import textwrap
 
 import shapely.geometry
 
-from descarteslabs.scenes import _helpers
+from ..utils import (
+    polygon_from_bounds,
+    valid_latlon_bounds,
+    is_geographic_crs,
+    is_wgs84_crs,
+)
 
 
 class TestSimpleHelpers(unittest.TestCase):
     def test_polygon_from_bounds(self):
         bounds = (-95.8364984, 39.2784859, -92.0686956, 42.7999878)
         geom = {
             "coordinates": (
@@ -18,28 +37,28 @@
                     (-95.8364984, 39.2784859),
                     (-92.0686956, 39.2784859),
                 ),
             ),
             "type": "Polygon",
         }
         assert geom == shapely.geometry.box(*bounds).__geo_interface__
-        assert _helpers.polygon_from_bounds(bounds) == \
-            shapely.geometry.box(*bounds).__geo_interface__
+        assert (
+            polygon_from_bounds(bounds)
+            == shapely.geometry.box(*bounds).__geo_interface__
+        )
 
     def test_valid_latlon_bounds(self):
-        assert _helpers.valid_latlon_bounds([-10, 5, 60, 80])
-        assert _helpers.valid_latlon_bounds([-180, -90, 180, 90])
-        assert not _helpers.valid_latlon_bounds(
-            [361760.0, 4531200.0, 515360.0, 4684800.0]
-        )
+        assert valid_latlon_bounds([-10, 5, 60, 80])
+        assert valid_latlon_bounds([-180, -90, 180, 90])
+        assert not valid_latlon_bounds([361760.0, 4531200.0, 515360.0, 4684800.0])
 
     def test_is_geographic_crs(self):
-        assert _helpers.is_geographic_crs("EPSG:4326")
-        assert _helpers.is_geographic_crs("+proj=longlat +datum=NAD27 +no_defs")
-        assert _helpers.is_geographic_crs(
+        assert is_geographic_crs("EPSG:4326")
+        assert is_geographic_crs("+proj=longlat +datum=NAD27 +no_defs")
+        assert is_geographic_crs(
             textwrap.dedent(
                 """\
         GEOGCS["NAD27",
             DATUM["North_American_Datum_1927",
                 SPHEROID["Clarke 1866",6378206.4,294.9786982139006,
                     AUTHORITY["EPSG","7008"]],
                 AUTHORITY["EPSG","6267"]],
@@ -48,19 +67,19 @@
             UNIT["degree",0.0174532925199433,
                 AUTHORITY["EPSG","9122"]],
             AUTHORITY["EPSG","4267"]]
         """
             )
         )
 
-        assert not _helpers.is_geographic_crs("EPSG:32615")
-        assert not _helpers.is_geographic_crs(
+        assert not is_geographic_crs("EPSG:32615")
+        assert not is_geographic_crs(
             "+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs"
         )
-        assert not _helpers.is_geographic_crs(
+        assert not is_geographic_crs(
             textwrap.dedent(
                 """\
         PROJCS["WGS 84 / UTM zone 15N",
             GEOGCS["WGS 84",
                 DATUM["WGS_1984",
                     SPHEROID["WGS 84",6378137,298.257223563,
                         AUTHORITY["EPSG","7030"]],
@@ -82,17 +101,17 @@
             AXIS["Northing",NORTH],
             AUTHORITY["EPSG","32615"]]
         """
             )
         )
 
     def test_is_wgs84_crs(self):
-        assert _helpers.is_wgs84_crs("EPSG:4326")
-        assert _helpers.is_wgs84_crs("+proj=longlat +datum=WGS84 +no_defs")
-        assert _helpers.is_wgs84_crs(
+        assert is_wgs84_crs("EPSG:4326")
+        assert is_wgs84_crs("+proj=longlat +datum=WGS84 +no_defs")
+        assert is_wgs84_crs(
             textwrap.dedent(
                 """\
         GEOGCS["WGS 84",
             DATUM["WGS_1984",
                 SPHEROID["WGS 84",6378137,298.257223563,
                     AUTHORITY["EPSG","7030"]],
                 AUTHORITY["EPSG","6326"]],
@@ -101,16 +120,16 @@
             UNIT["degree",0.0174532925199433,
                 AUTHORITY["EPSG","9122"]],
             AUTHORITY["EPSG","4326"]]
         """
             )
         )
 
-        assert not _helpers.is_wgs84_crs("+proj=longlat +datum=NAD27 +no_defs")
-        assert not _helpers.is_wgs84_crs(
+        assert not is_wgs84_crs("+proj=longlat +datum=NAD27 +no_defs")
+        assert not is_wgs84_crs(
             textwrap.dedent(
                 """\
         GEOGCS["NAD27",
             DATUM["North_American_Datum_1927",
                 SPHEROID["Clarke 1866",6378206.4,294.9786982139006,
                     AUTHORITY["EPSG","7008"]],
                 AUTHORITY["EPSG","6267"]],
@@ -119,19 +138,19 @@
             UNIT["degree",0.0174532925199433,
                 AUTHORITY["EPSG","9122"]],
             AUTHORITY["EPSG","4267"]]
         """
             )
         )
 
-        assert not _helpers.is_wgs84_crs("EPSG:32615")
-        assert not _helpers.is_wgs84_crs("+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs")
-        assert not _helpers.is_wgs84_crs(
-                textwrap.dedent(
-                    """\
+        assert not is_wgs84_crs("EPSG:32615")
+        assert not is_wgs84_crs("+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs")
+        assert not is_wgs84_crs(
+            textwrap.dedent(
+                """\
         PROJCS["WGS 84 / UTM zone 15N",
             GEOGCS["WGS 84",
                 DATUM["WGS_1984",
                     SPHEROID["WGS 84",6378137,298.257223563,
                         AUTHORITY["EPSG","7030"]],
                     AUTHORITY["EPSG","6326"]],
                 PRIMEM["Greenwich",0,
@@ -147,9 +166,9 @@
             PARAMETER["false_northing",0],
             UNIT["metre",1,
                 AUTHORITY["EPSG","9001"]],
             AXIS["Easting",EAST],
             AXIS["Northing",NORTH],
             AUTHORITY["EPSG","32615"]]
         """
-                )
             )
+        )
```

### Comparing `descarteslabs-1.9.1/descarteslabs/third_party/boltons/funcutils.py` & `descarteslabs-2.0.0/descarteslabs/core/third_party/boltons/funcutils.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 # -*- coding: utf-8 -*-
 from __future__ import print_function
+
 """
 Copyright (c) 2013, Mahmoud Hashemi
 
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
 met:
 
@@ -794,15 +795,14 @@
                 self.kwonlydefaults.pop(arg_name, None)
         else:
             d_dict.pop(arg_name, None)
             self.defaults = tuple([d_dict[a] for a in args if a in d_dict])
         return
 
     def _compile(self, src, execdict):
-
         filename = "<%s-%d>" % (self.filename, next(self._compile_count))
         try:
             code = compile(src, filename, "single")
             exec(code, execdict)
         except Exception:
             raise
         return execdict
```

### Comparing `descarteslabs-1.9.1/descarteslabs/workflows/models/xyz.py` & `descarteslabs-2.0.0/descarteslabs/core/compute/compute.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,712 +1,805 @@
-from typing import Any, Callable, Iterator, Optional, Sequence
-import datetime
-import logging
-import threading
-from urllib.parse import urlencode
+# Copyright 2018-2023 Descartes Labs.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import glob
+import gzip
+import inspect
+import io
+import json
+import os
+import re
+import time
 import warnings
+import zipfile
+from datetime import datetime
+from tempfile import NamedTemporaryFile
+from typing import Callable, Dict, Iterable, List, Optional, Type, Union
 
-import grpc
-from descarteslabs.common.proto.xyz import xyz_pb2
+from strenum import StrEnum
 
-from descarteslabs.workflows.client import get_global_grpc_client, Client
-from descarteslabs.workflows.types import Proxytype
+from ..client.services.service import ThirdPartyService
+from ..common.client import Attribute, DatetimeAttribute, Document, DocumentState
+from .compute_client import ComputeClient
 
-from .published_graft import PublishedGraft
-from .utils import (
-    pb_datetime_to_milliseconds,
-    pb_milliseconds_to_datetime,
-    pb_timestamp_to_datetime,
-    py_log_level_to_proto_log_level,
-)
-from .tile_url import tile_url
-from .visualization import VizOption
-
-
-class XYZ(PublishedGraft, message_type=xyz_pb2.XYZ):
-    """
-    Stores proxy objects to be rendered by an XYZ tile server.
-
-    Similar to a `Workflow`, but meant for storing proxy objects
-    so the XYZ tile service can display them, rather than for persisting
-    and sharing workflows between users.
-
-    Use `.url` to generate an XYZ URL template, and `.iter_tile_logs`
-    or `.log_listener` to retrieve log messages that happen while
-    computing them.
-
-    Examples
-    --------
-    >>> from descarteslabs.workflows import Image, XYZ
-    >>> img = Image.from_id("sentinel-2:L1C:2019-05-04_13SDV_99_S2B_v1")
-    >>> rgb = img.pick_bands("red green blue")
-    >>> xyz = XYZ(rgb, name="My RGB") # doctest: +SKIP
-    >>> xyz # doctest: +SKIP
-    <descarteslabs.workflows.models.xyz.XYZ object at 0x...>
-    >>> xyz.id # doctest: +SKIP
-    '24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6'
-    >>> same_xyz = XYZ.get('24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6') # doctest: +SKIP
-    >>> same_xyz.url() # doctest: +SKIP
-    'https://workflows.descarteslabs.com/master/xyz/24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6/{z}/{x}/{y}.png'
-    >>> same_xyz.object # doctest: +SKIP
-    <descarteslabs.workflows.types.geospatial.image.Image object at 0x...>
-
-    >>> from descarteslabs.workflows import ImageCollection, XYZ
-    >>> col = ImageCollection.from_id("landsat:LC08:01:RT:TOAR",
-    ...        start_datetime="2017-01-01",
-    ...        end_datetime="2017-12-31")
-    >>> rgb = col.pick_bands("red green blue")
-    >>> xyz = XYZ(rgb, name="RGB") # doctest: +SKIP
-    >>> xyz.url() # doctest: +SKIP
-    'https://workflows.descarteslabs.com/tiles-ic/xyz/bdbeb4706f3025f4ee4eeff4dec46f6f2554c583d830e5e9/{z}/{x}/{y}.png'
-    """
+
+class FunctionStatus(StrEnum):
+    "The status of the Function."
+
+    AWAITING_BUNDLE = "awaiting_bundle"
+    BUILDING = "building"
+    BUILD_FAILED = "build_failed"
+    RUNNING = "running"
+    SUCCESS = "success"
+    FAILURE = "failure"
+
+
+class JobStatus(StrEnum):
+    """The status of the Job."""
+
+    PENDING = "pending"
+    RUNNING = "running"
+    SUCCESS = "success"
+    FAILURE = "failure"
+    TIMEOUT = "timeout"
+
+
+class Serializable:
+    def serialize(self) -> bytes:
+        raise NotImplementedError()
+
+    @classmethod
+    def deserialize(cls, data: bytes):
+        raise NotImplementedError()
+
+
+class Job(Document):
+    """A single invocation of a Function."""
+
+    id: str = Attribute(str, readonly=True, doc="The ID of the Job.")
+    function_id: str = Attribute(
+        str, mutable=False, doc="The ID of the Function the Job belongs to."
+    )
+    creation_date: datetime = DatetimeAttribute(
+        readonly=True, doc="The date the Job was created."
+    )
+    args: Optional[List] = Attribute(list, doc="The arguments provided to the Job.")
+    kwargs: Optional[Dict] = Attribute(dict, doc="The parameters provided to the Job.")
+    runtime: Optional[int] = Attribute(
+        int, readonly=True, doc="The time it took the Job to complete."
+    )
+    status: JobStatus = Attribute(
+        JobStatus,
+        readonly=True,
+        doc="""The current status of the Job.
+
+        The status may occasionally need to be refreshed by calling :py:meth:`Job.refresh`
+        """,
+    )
 
     def __init__(
         self,
-        proxy_object: Proxytype,
-        name: str = "",
-        description: str = "",
-        public: bool = True,
-        viz_options: Optional[Sequence[VizOption]] = None,
-        days_to_expiration: int = None,
-        client: Optional[Client] = None,
+        function_id: str,
+        args: Optional[List] = None,
+        kwargs: Optional[Dict] = None,
+        **extra,
     ):
         """
-        Construct a new XYZ from a proxy object.
-
-        If the proxy object depends on any parameters (``proxy_object.params`` is not empty),
-        it's first internally converted to a `.Function` that takes those parameters
-        (using `.Function.from_object`).
-
         Parameters
         ----------
-        proxy_object: Proxytype
-            The proxy object to store in this XYZ.
-            If it depends on parameters, ``proxy_object`` is first converted
-            to a `.Function` that takes those parameters.
-        name: str, default ""
-            Name for the new XYZ
-        description: str, default ""
-            Long-form description of this XYZ. Markdown is supported.
-        public: bool, default `True`
-            If ``True`` then this object is shared and accessible to all,
-            otherwise it is private.
-        viz_options: list, default None
-            List of `~.models.VizOption` visualization parameter sets.
-        days_to_expiration: int, default None
-            Days until this XYZ object will expire.
-            If None defaults to 10 days.
-        client: `.workflows.client.Client`, optional, default None
-            Allows you to use a specific client instance with non-default
-            auth and parameters
-
-        Example
-        -------
-        >>> import descarteslabs.workflows as wf
-        >>> img = wf.Image.from_id("sentinel-2:L1C:2019-05-04_13SDV_99_S2B_v1")
-        >>> rgb = img.pick_bands("red green blue")
-        >>> xyz = wf.XYZ(rgb, name="My RGB") # doctest: +SKIP
-        >>> xyz.id # doctest: +SKIP
-        '24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6'
-        """
-        if public and viz_options is None:
-            warnings.warn(
-                "viz_options should be provided for public XYZ instances. "
-                "Provide an empty list if you want to override this."
-            )
+        function_id : str
+            The id of the Function. A function must first be created to create a job.
+        args : List, optional
+            A list of positional arguments to pass to the function.
+        kwargs : Dict, optional
+            A dictionary of named arguments to pass to the function.
+        """
+        super().__init__(function_id=function_id, args=args, kwargs=kwargs, **extra)
 
-        super().__init__(
-            proxy_object,
-            viz_options=viz_options,
-            client=client,
-        )
+    def __repr__(self) -> str:
+        return f"Job {self.id}: {self.status}"
 
-        response_message = self._client.api["CreateXYZ"](
-            xyz_pb2.CreateXYZRequest(
-                name=name,
-                description=description,
-                serialized_graft=self._message.serialized_graft,
-                typespec=self._message.typespec,
-                parameters=self._message.parameters,
-                public=public,
-                viz_options=self._message.viz_options,
-                days_to_expiration=int(days_to_expiration)
-                if days_to_expiration is not None
-                else None,
-                channel=self._message.channel,
-                client_version=self._message.client_version,
-            ),
-            timeout=self._client.DEFAULT_TIMEOUT,
-        )
-        self._message = response_message
+    @property
+    def function(self) -> "Function":
+        """Returns the Function the Job belongs to."""
+        return Function.get(self.function_id)
 
     @classmethod
-    def get(cls, xyz_id: str, client: Optional[Client] = None) -> "XYZ":
-        """
-        Get an existing XYZ by id.
+    def get(cls, id) -> "Job":
+        """Retrieves the Job by id.
 
         Parameters
         ----------
-        id: str
-            The unique id of a `XZY` object
-        client: Optional[Client], default None
-            Allows you to use a specific client instance with non-default
-            auth and parameters
-
-        Returns
-        -------
-        XYZ
+        id : str
+            The id of the Job to fetch.
 
         Example
         -------
-        >>> from descarteslabs.workflows import XYZ
-        >>> xyz = XYZ.get('24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6') # doctest: +SKIP
-        >>> xyz # doctest: +SKIP
-        <descarteslabs.workflows.models.xyz.XYZ object at 0x...>
+        >>> from descarteslabs.compute import Job
+        >>> job = Job.get(<job-id>)
+        Job <job-id>: pending
         """
-        if client is None:
-            client = get_global_grpc_client()
-
-        message = client.api["GetXYZ"](
-            xyz_pb2.GetXYZRequest(xyz_id=xyz_id), timeout=client.DEFAULT_TIMEOUT
-        )
-        return cls._from_proto(message, client=client)
+        client = ComputeClient.get_default_client()
+        response = client.session.get(f"/jobs/{id}")
+        return cls(**response.json(), saved=True)
 
     @classmethod
     def list(
-        cls, public: bool = False, client: Optional[Client] = None
-    ) -> Iterator["XYZ"]:
-        """
-        Get all XYZ objects created by this user.
+        cls,
+        function_id: str = None,
+        status: Union[JobStatus, List[JobStatus]] = None,
+        page_size: int = 100,
+    ) -> Iterable["Job"]:
+        """Retrieves an iterable of all jobs matching the given parameters.
 
         Parameters
         ----------
-        public: bool, default False
-            If ``True`` then return public (shared) XYZ objects created by this
-            user. If ``False`` then return non-public XYZ objects created through
-            the use of workflow map widgets.
-        client: Optional[Client], default None
-            Allows you to use a specific client instance with non-default
-            auth and parameters
-
-        Returns
-        -------
-        Iterator[XYZ]
+        function_id : str, None
+            If set, only jobs for the given function will be included.
+        status : Union[JobStatus, List[JobStatus]], None
+            If set, only jobs matching one of the provided statuses will be included.
+        page_size : int, default=100
+            Maximum number of results per page.
 
         Example
         -------
-        >>> from descarteslabs.workflows import XYZ
-        >>> for xyz in XYZ.list(): # doctest: +SKIP
-        ...     print(xyz.id) # doctest: +SKIP
-        24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6
+        >>> from descarteslabs.compute import Job
+        >>> fn = Job.list(<function_id>)
+        [Job <job-id1>: pending, Job <job-id2>: pending, Job <job-id3>: pending]
         """
-        if client is None:
-            client = get_global_grpc_client()
+        client = ComputeClient.get_default_client()
+        params = {"page_size": page_size}
 
-        iter = client.api["ListXYZ"](
-            xyz_pb2.ListXYZRequest(public=public), timeout=client.STREAM_TIMEOUT
-        )
-        return map(lambda xyz: cls._from_proto(xyz, client=client), iter)
+        if function_id:
+            params["function_id"] = function_id
 
-    @staticmethod
-    def delete_id(id, client=None):
-        """
-        Delete the `XYZ` that has the provided ID. Only the user
-        that created the `XYZ` can delete it.
+        if status:
+            if not isinstance(status, list):
+                status = [status]
+
+            params["status"] = status
+
+        paginator = client.iter_pages("/jobs", params=params)
+
+        for data in paginator:
+            yield cls(**data, saved=True)
 
-        **Warning:** this cannot be undone!
+    def refresh(self) -> None:
+        """Update the Job instance with the latest information from the server."""
+        client = ComputeClient.get_default_client()
+
+        response = client.session.get(f"/jobs/{self.id}")
+        self._load_from_remote(response.json())
+
+    def result(self, cast_type: Optional[Type[Serializable]] = None):
+        """Retrieves the result of the Job.
 
         Parameters
         ----------
-        id: str
-            The ID of the `XYZ` that we wish to delete.
-        client: `.workflows.client.Client`, optional
-            Allows you to use a specific client instance with non-default
-            auth and parameters.
-
-        Example
-        -------
-        >>> from descarteslabs.workflows import XYZ
-        >>> xyz_id = '24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6'
-        >>> xyz = XYZ.get(xyz_id) # doctest: +SKIP
-        >>> xyz # doctest: +SKIP
-        <descarteslabs.workflows.models.xyz.XYZ object at 0x...>
-        >>> XYZ.delete_id(xyz_id) # doctest: +SKIP
-        >>> XYZ.get(xyz_id) # doctest: +SKIP
-        ...
-        NotFound: 404 XYZ '24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6' does not exist.
-        """
-        if client is None:
-            client = get_global_grpc_client()
-
-        client.api["DeleteXYZ"](
-            xyz_pb2.DeleteXYZRequest(xyz_id=id),
-            timeout=client.DEFAULT_TIMEOUT,
-        )
+        cast_type: Type[Serializable], None
+            If set, the result will be deserialized to the given type.
 
-    def delete(self, client: Client = None) -> None:
+        Raises
+        ------
+        ValueError
+            When `cast_type` does not implement Serializable.
         """
-        Delete this XYZ object. Only the user
-        that created the `XYZ` can delete it.
+        client = ComputeClient.get_default_client()
+        response = client.session.get(f"/jobs/{self.id}/result", stream=True)
+        result = response.content
+
+        if not result:
+            return None
+
+        if cast_type:
+            deserialize = getattr(cast_type, "deserialize", None)
+
+            if deserialize and callable(deserialize):
+                return deserialize(result)
+            else:
+                raise ValueError(f"Type {cast_type} must implement Serializable.")
+
+        try:
+            return json.loads(result)
+        except Exception:
+            return result
+
+    def wait_for_completion(self, timeout=None, interval=10):
+        """Waits until the Job is completed.
 
         Parameters
         ----------
-        client: Client, default None
-            Allows you to use a specific client instance with non-default auth and parameters
+        timeout : int, default=None
+            Maximum time to wait before timing out.
+            If not set, the call will block until job completion.
+        interval : int, default=10
+            Interval for how often to check if jobs have been completed.
+        """
+        print(f"Job {self.id} starting status {self.status}")
+        last_status = self.status
+        start_time = time.time()
+
+        while True:
+            self.refresh()
+
+            if self.status != last_status:
+                print(f"Job {self.id} updated from {last_status} to {self.status}")
+                last_status = self.status
+
+            if self.status in [JobStatus.SUCCESS, JobStatus.FAILURE, JobStatus.TIMEOUT]:
+                break
+
+            if timeout:
+                t = timeout - (time.time() - start_time)
+                if t <= 0:
+                    raise TimeoutError(
+                        f"Job {self.id} did not complete before timeout!"
+                    )
+
+                t = min(t, interval)
+            else:
+                t = interval
+
+            time.sleep(t)
 
-        Example
-        -------
-        Returns
-        -------
-        None
+    def save(self):
+        """Creates the Job if it does not already exist.
 
-        Example
-        -------
-        >>> from descarteslabs.workflows import XYZ
-        >>> xyz = XYZ.get('24d0e79c5c1e1f10a0b1177ef3974d7edefd5988291cf2c6') # doctest: +SKIP
-        >>> xyz.delete() # doctest: +SKIP
+        If the job already exists, it will be updated on the server if modifications
+        were made to the Job instance.
         """
-        if client is None:
-            client = self._client
+        if self.state == DocumentState.SAVED:
+            return
 
-        self.delete_id(self.id, client=client)
-        self._message.Clear()
+        client = ComputeClient.get_default_client()
 
-    def url(
-        self,
-        session_id=None,
-        colormap=None,
-        bands=None,
-        scales=None,
-        reduction=None,
-        checkerboard=None,
-        **arguments,
-    ):
-        """
-        URL template for displaying this `XYZ` object on a web map,
-        like ``https://workflows.descarteslabs.com/v0-5/xyz/1234567/{z}/{x}/{y}.png``
+        if self.state == DocumentState.MODIFIED:
+            response = client.session.patch(
+                f"/jobs/{self.id}", json=self.to_dict(only_modified=True)
+            )
+        elif self.state == DocumentState.NEW:
+            response = client.session.post(
+                "/jobs", json=self.to_dict(exclude_none=True)
+            )
+        else:
+            raise ValueError(
+                f"Unexpected Job state {self.state}."
+                f'Reload the job from the server: Job.get("{self.id}")'
+            )
 
-        The returned URL uses the `XYZ/OpenStreetMap tiling scheme
-        <https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames>`_.
+        self._load_from_remote(response.json())
 
-        `object` must be an `~.geospatial.Image`, an `~.geospatial.ImageCollection`, or a `.Function`
-        that returns an `~.geospatial.Image` or `~.geospatial.ImageCollection` for the URL to work.
+    def log(self, timestamps: bool = True):
+        """Retrieves the log for the job.
 
         Parameters
         ----------
-        session_id: str, optional, default None
-            Unique, client-generated ID that logs will be stored under.
-            Since multiple users may access tiles from the same `XYZ` object,
-            each user should set their own ``session_id`` to get individual logs.
-        colormap: str, optional, default None
-            Name of the colormap to use. If set, the displayed `~.geospatial.Image`
-            or `~.geospatial.ImageCollection` must have 1 band.
-        bands: list of str, optional, default None
-            The band names to select from the imagery. If None (default),
-            the imagery should already have 1-3 bands selected.
-        scales: list of lists, optional, default None
-            The scaling to apply to each band in the `~.geospatial.Image`.
-            If displaying an `~.geospatial.ImageCollection`, it is reduced into
-            an `~.geospatial.Image` before scaling.
-
-            If the `~.geospatial.Image` or `~.geospatial.ImageCollection` contains 3 bands,
-            ``scales`` must be a list like ``[(0, 1), (0, 1), (-1, 1)]``.
-
-            If the `~.geospatial.Image` or `~.geospatial.ImageCollection` contains 1 band,
-            ``scales`` must be a list like ``[(0, 1)]``, or just ``(0, 1)`` for convenience
-
-            If None, each 256x256 tile will be scaled independently.
-        reduction: str, optional, default None
-            One of "mosaic", "min", "max", "mean", "median", "sum", "std", or "count".
-            If displaying an `~.geospatial.ImageCollection`, this method is used to reduce it into
-            an `~.geospatial.Image`. The reduction is performed before applying a colormap or scaling.
-            If displaying an `~.geospatial.Image`, reduction is ignored.
-        checkerboard: bool, optional, default None
-            Whether to display a checkerboarded background for missing or masked data.
-        **arguments: Any
-            Values for all the arguments that `object` takes, if it's a `.Function`.
-            Can be given as Proxytypes, or as Python objects like numbers,
-            lists, and dicts that can be promoted to them.
-            These arguments cannot depend on any parameters.
+        timestamps : bool, True
+            If set, log timestamps will be included and converted to the users system
+            timezone from UTC.
 
-        Returns
-        -------
-        url: str
-            Tile URL containing ``{z}``, ``{x}``, and ``{y}`` as Python format string parameters,
-            and query arguments URL-quoted.
+            You may consider disabling this if you use a structured logger.
+        """
+        client = ComputeClient.get_default_client()
+        logs = client.iter_log_lines(f"/jobs/{self.id}/log", timestamps=timestamps)
 
-        Raises
-        ------
-        TypeError
-            If the ``scales`` are of invalid type.
+        for log in logs:
+            print(log)
 
-            If the ``arguments`` names or types don't match the arguments that
-            the `object` takes. (Those required arguments are equivalent to `params`.)
 
-        Example
-        -------
-        >>> import descarteslabs.workflows as wf
-        >>> img = wf.Image.from_id("sentinel-2:L1C:2019-05-04_13SDV_99_S2B_v1")
-        >>> red = img.pick_bands("red")
-        >>> viz = red ** wf.parameter("exponent", wf.Float)
-        >>> xyz = wf.XYZ(viz, name="Red band raised to exponent") # doctest: +SKIP
-        >>> xyz.url("some_session", colormap="magma", scales=[(0.2, 0.8)], exponent=2.5) # doctest: +SKIP
-        'https://workflows.descarteslabs.com/v0-0/xyz/0d21037edb4bdd16b735f24bb3bff6d4202a71c20404b101/
-         {z}/{x}/{y}.png?session_id=some_session&colormap=magma&scales=[[0.2, 0.8]]&exponent=2.5'
-
-        >>> import descarteslabs.workflows as wf
-        >>> col = wf.ImageCollection.from_id("landsat:LC08:01:RT:TOAR",
-        ...        start_datetime="2017-01-01",
-        ...        end_datetime="2017-12-31")
-        >>> red = col.pick_bands("red")
-        >>> viz = red ** wf.parameter("exponent", wf.Float)
-        >>> xyz = wf.XYZ(viz, name="Red band ImageCollection raised to exponent") # doctest: +SKIP
-        >>> xyz.url("some_session", reduction="min", exponent=2.5) # doctest: +SKIP
-        'https://workflows.descarteslabs.com/v0-0/xyz/bdbeb4706f3025f4ee4eeff4dec46f6f2554c583d830e5e9/
-         {z}/{x}/{y}.png?session_id=some_session&reduction=min&exponent=2.5'
-        """
-        url_template = self._message.url_template
-
-        return tile_url(
-            url_template,
-            self.object,
-            session_id=session_id,
-            colormap=colormap,
-            bands=bands,
-            scales=scales,
-            reduction=reduction,
-            checkerboard=checkerboard,
-            **arguments,
-        )
+class Cpus(float):
+    """Validates CPUs for a Function"""
 
-    def wmts_url(self, tile_matrix_sets=None, dimensions=None) -> str:
-        """
-        Get the WMTS endpoint which gives access to this XYZ object.
+    NON_NUMERIC = r"[^0-9.]"
 
-        Parameters
-        ----------
-        tile_matrix_sets: str or list, optional
-            Desired tile matrix sets. Defaults to EPSG:3857.
-        dimensions: bool, optional
-            If True, then provide dimensions definitions to WMTS. If
-            False, then generate a layer for each possible dimensions
-            attribute combination. If not specified, the WMTS service itself
-            will determine how to handle dimensions (currently it does
-            not provide dimensions definitions).
+    def __new__(cls, value):
+        if isinstance(value, str):
+            value = re.sub(cls.NON_NUMERIC, "", value)
 
-        Returns
-        -------
-        wmts_url: str
-            The URL for the WMTS service endpoint corresponding to this XYZ object.
+        return super().__new__(cls, value)
 
-        Example
-        -------
-        >>> from descarteslabs.workflows import Image, XYZ
-        >>> img = Image.from_id("sentinel-2:L1C:2019-05-04_13SDV_99_S2B_v1")
-        >>> rgb = img.pick_bands("red green blue")
-        >>> xyz = XYZ(rgb, name="My RGB") # doctest: +SKIP
-        >>> xyz.wmts_url() # doctest: +SKIP
-        'https://workflows.prod.descarteslabs.com/master/wmts/xyz/...'
-        """
-        url_params = {}
-
-        if tile_matrix_sets:
-            url_params["tile_matrix_sets"] = tile_matrix_sets
-        if dimensions is not None:
-            url_params["dimensions"] = "true" if dimensions else "false"
-
-        wmts_url = self._message.wmts_url_template
-        if url_params:
-            wmts_url = f"{wmts_url}?{urlencode(url_params, doseq=True)}"
 
-        return wmts_url
+class Memory(int):
+    """Validates Memory for a Function"""
 
-    def iter_tile_logs(
-        self,
-        session_id: str,
-        start_datetime: datetime.datetime = None,
-        level: int = None,
-    ) -> Iterator[xyz_pb2.XYZLogRecord]:
-        """
-        Iterator over log messages generated while computing tiles
+    MEMORY_MB = re.compile(r"[\s]*mb|mi$", flags=re.IGNORECASE)
+    MEMORY_GB = re.compile(r"[\s]*gb|gi$", flags=re.IGNORECASE)
 
-        Parameters
-        ----------
-        session_id: str
-            Unique, client-generated that logs are stored under.
-        start_datetime: datetime.datetime
-            Only return log records occuring after this datetime
-        level: int, default logging.DEBUG
-            Only return log records at or above this log level.
-            See https://docs.python.org/3/library/logging.html#logging-levels for valid
-            log levels.
+    def __new__(cls, memory: Union[str, int, float]) -> None:
+        if isinstance(memory, str):
+            if memory.isnumeric():
+                pass
+            elif re.search(cls.MEMORY_MB, memory):
+                memory = re.sub(cls.MEMORY_MB, "", memory)
+            elif re.search(cls.MEMORY_GB, memory):
+                memory = re.sub(cls.MEMORY_GB, "", memory)
+                memory = int(float(memory) * 1024)
+            else:
+                raise ValueError(f"Unable to convert memory to megabytes: {memory}")
 
-        Yields
-        ------
-        log_record: descarteslabs.common.proto.xyz_pb2.XYZLogRecord
-            Logs in protobuf message objects,
-            with fields ``session_id`` and ``record``, with the ``record`` field
-            containing ``level``, ``message``, and ``timestamp``.
+        return super().__new__(cls, memory)
 
-        Example
-        -------
-        >>> from descarteslabs.workflows import Image, XYZ
-        >>> img = Image.from_id("sentinel-2:L1C:2019-05-04_13SDV_99_S2B_v1")
-        >>> rgb = img.pick_bands("red green blue")
-        >>> xyz = XYZ(rgb, name="My RGB") # doctest: +SKIP
-        >>> url = xyz.url(session_id="some_session") # doctest: +SKIP
-        >>> for record in xyz.iter_tile_logs("some_session", start_datetime=datetime.datetime.now()): # doctest: +SKIP
-        ...     print(record.level, record.message)
-        >>>     # any logs that occur loading tiles from the generated URL will be printed here
-        """
-        return _tile_log_stream(
-            self.id,
-            session_id,
-            start_datetime=start_datetime,
-            level=level,
-            client=self._client,
-        )
 
-    def log_listener(self) -> "XYZLogListener":
-        """An `XYZLogListener` to trigger callbacks when logs occur computing tiles.
+class Function(Document):
+    """The serverless cloud function that you can call directly or submit many jobs to."""
 
-        Example
-        -------
-        >>> from descarteslabs.workflows import Image, XYZ
-        >>> img = Image.from_id("sentinel-2:L1C:2019-05-04_13SDV_99_S2B_v1")
-        >>> rgb = img.pick_bands("red green blue")
-        >>> xyz = XYZ(rgb, name="My RGB") # doctest: +SKIP
-        >>> url = xyz.url(session_id="some_session") # doctest: +SKIP
-        >>> listener = xyz.log_listener() # doctest: +SKIP
-        >>> log = []
-        >>> listener.add_callback(lambda record: log.append(record.message)) # doctest: +SKIP
-        >>> listener.listen("some_session") # doctest: +SKIP
-        >>> # any logs that occur loading tiles from the generated URL will be appended
-        >>> # to `log` in the background
+    id: str = Attribute(str, readonly=True, doc="The ID of the Function.")
+    creation_date: datetime = DatetimeAttribute(
+        readonly=True,
+        doc="""The date the Function was created.""",
+    )
+    name: str = Attribute(str, doc="The name of the Function.")
+    image: str = Attribute(
+        str,
+        mutable=False,
+        doc="The base image used to create the Function.",
+    )
+    cpus: float = Attribute(
+        Cpus,
+        doc="The number of cpus to request when executing the Function.",
+    )
+    memory: int = Attribute(
+        Memory,
+        doc="The amount of memory, in megabytes, to request when executing the Function.",
+    )
+    maximum_concurrency: int = Attribute(
+        int,
+        doc="The maximum number of Jobs that execute at the same time for this Function.",
+    )
+    status: FunctionStatus = Attribute(
+        FunctionStatus,
+        readonly=True,
+        doc="The status of the Function.",
+    )
+    timeout: int = Attribute(
+        int,
+        doc="The number of seconds Jobs can run before timing out for this Function.",
+    )
+    retry_count: int = Attribute(
+        int,
+        doc="The total number of retries requested for a Job before it failed.",
+    )
+
+    def __init__(
+        self,
+        function: Callable = None,
+        requirements: List[str] = None,
+        # include_data: List[str] = None,
+        name: str = None,
+        image: str = None,
+        cpus: Cpus = None,
+        memory: Memory = None,
+        maximum_concurrency: int = None,
+        timeout: int = None,
+        retry_count: int = None,
+        **extra,
+    ):  # check to see if we need more validation here (type conversions)
         """
-        return XYZLogListener(self.id, client=self._client)
+        Parameters
+        ----------
+        function : Callable
+            The function to be called in a Compute Job.
+        requirements : List[str], optional
+            A list of Python dependencies required by this function.
+        include_data : List[str], optional
+            Non-Python data files to include in the task group.
+        name : str, optional
+            Name of the function, will take name of function if not provided.
+        image : str
+            The location of a docker image to be used for the environment where the function
+            will be executed.
+        cpus : Cpus
+            The number of CPUs requested for a single Job.
+        memory : Memory
+            The maximum memory requirement for a single Job.
+        maximum_concurrency : str
+            The maximum number of jobs to run in parallel.
+        timeout : int, optional
+            Maximum runtime for a single job in seconds. Job will be killed if it exceeds
+            this limit.
+        retry_count : int, optional
+            Number of times to retry a job if it fails.
+
+        Examples
+        --------
+        Retrieving an existing function and executing it.
+
+        >>> fn = Function.get(<function-id>)
+        >>> fn()
+        Job <job id>: "pending"
+
+        Creating a new function.
+
+        >>> from descarteslabs.compute import Function
+        >>> def test_func():
+        ...     print("Hello :)")
+        >>> fn = Function(
+        ...     test_func,
+        ...     requirements=[],
+        ...     name="my_func",
+        ...     image="test_image",
+        ...     cpus=1,
+        ...     memory=16,
+        ...     maximum_concurrency=5,
+        ...     timeout=3600,
+        ...     retry_count=1,
+        ... )
+        >>> fn()
+        Job <job id>: "pending"
+        """
+        self._function = function
+        self._requirements = requirements
+        # self._include_data = include_data
+
+        # if user doesn't give a name, use the name of the function
+        if not name and self._function:
+            name = self._function.__name__
 
-    @property
-    def id(self) -> str:
-        """str: The globally unique identifier for the `XYZ`"""
-        return self._message.id
+        super().__init__(
+            name=name,
+            image=image,
+            cpus=cpus,
+            memory=memory,
+            maximum_concurrency=maximum_concurrency,
+            timeout=timeout,
+            retry_count=retry_count,
+            **extra,
+        )
 
-    @property
-    def created_timestamp(self) -> datetime.datetime:
-        """
-        datetime.datetime or None: The UTC date this `XYZ` was created,
-        or None if it hasn't been saved yet. Cannot be modified.
-        """
-        return pb_milliseconds_to_datetime(self._message.created_timestamp)
+    def __call__(self, *args, **kwargs):
+        self.save()
+        job = Job(function_id=self.id, args=args, kwargs=kwargs)
+        job.save()
+        return job
 
-    @property
-    def updated_timestamp(self) -> datetime.datetime:
-        """
-        datetime.datetime or None: The UTC date this `XYZ` was most recently modified,
-        or None if it hasn't been saved yet. Updated automatically.
-        """
-        return pb_milliseconds_to_datetime(self._message.updated_timestamp)
+    def _bundle(self) -> str:
+        function = self._function
 
-    @property
-    def expires_timestamp(self) -> datetime.datetime:
-        """
-        datetime.datetime: The UTC date this `XYZ` will be expired.
-        """
-        return pb_timestamp_to_datetime(self._message.expires_timestamp)
+        if not function:
+            raise ValueError("Function not provided!")
 
-    @property
-    def name(self) -> str:
-        """str: The name of this XYZ."""
-        return self._message.name
+        if function.__name__ == "<lambda>":
+            raise ValueError("Cannot execute lambda functions. Use `def` instead.")
 
-    @property
-    def description(self) -> str:
-        """str: A long-form description of this `XYZ`. Markdown is supported."""
-        return self._message.description
+        try:
+            src = inspect.getsource(function)
+        except Exception:
+            # Unable to retrieve the source try dill
+            try:
+                import dill
+
+                src = dill.source.getsource(function)
+            except ImportError:
+                raise ValueError(
+                    "Unable to retrieve the source of interactively defined functions."
+                    " To support this install dill: pip install dill"
+                )
+
+        src = src.strip()
+        main = f"{src}\n\n\nmain = {function.__name__}\n"
+
+        if self._requirements:
+            requirements = "\n".join(self._requirements) + "\n"
+        else:
+            requirements = None
 
-    @property
-    def user(self) -> str:
-        """str: The user ID which created this `XYZ`."""
-        return self._message.user
+        # include_data = self._data_globs_to_paths()
 
-    @property
-    def org(self) -> str:
-        """str: The org of the user which created this `XYZ`."""
-        return self._message.org
+        try:
+            with NamedTemporaryFile(delete=False, suffix=".zip", mode="wb") as f:
+                with zipfile.ZipFile(
+                    f, mode="w", compression=zipfile.ZIP_DEFLATED
+                ) as bundle:
+                    bundle.writestr("function.py", main)
+
+                    # TODO: include data
+                    # for file_path in include_data:
+                    #     bundle.write(file_path, os.path.relpath(file_path, "data"))
+
+                    if requirements:
+                        bundle.writestr("requirements.txt", requirements)
+
+            return f.name
+        except Exception:
+            if os.path.exists(f.name):
+                os.remove(f.name)
+            raise
+
+    def _data_globs_to_paths(self) -> List[str]:
+        data_files = []
+
+        for pattern in self._include_data:
+            is_glob = glob.has_magic(pattern)
+            matches = glob.glob(pattern)
+
+            if not matches:
+                if is_glob:
+                    warnings.warn(f"Include data pattern had no matches: {pattern}")
+                else:
+                    raise ValueError(f"No data file found for path: {pattern}")
+
+            for relative_path in matches:
+                path = os.path.abspath(relative_path)
+
+                if os.path.exists(path):
+                    if os.path.isdir(path):
+                        relative_path = relative_path.rstrip("/")
+
+                        raise ValueError(
+                            "Cannot accept directories as include data."
+                            " Use globs instead: {} OR {}".format(
+                                f"{relative_path}/*.*", f"{relative_path}/**/*.*"
+                            )
+                        )
+                    else:
+                        data_files.append(path)
+                else:
+                    raise ValueError(f"Data file does not exist: {path}")
 
-    @property
-    def public(self) -> bool:
-        """bool: True if this `XYZ` is shared."""
-        return self._message.public
-
-
-class XYZLogListener(object):
-    """
-    Calls callback functions in a background thread when XYZ log records occur.
-
-    Note: the thread is automatically cleaned up on garbage collection.
-
-    Example
-    -------
-    >>> from descarteslabs.workflows import Image, XYZ
-    >>> img = Image.from_id("landsat:LC08:PRE:TOAR:meta_LC80270312016188_v1")
-    >>> xyz = XYZ(img) # doctest: +SKIP
-    >>> listener = xyz.log_listener() # doctest: +SKIP
-    >>> def callback(msg):
-    ...     print(msg.level, msg.message)
-    >>> listener.add_callback(callback) # doctest: +SKIP
-    >>> listener.listen("session_id", start_datetime=datetime.datetime.now())  # doctest: +SKIP
-    >>> # later
-    >>> listener.stop()  # doctest: +SKIP
-    """
-
-    def __init__(self, xyz_id: str, client: Optional[Client] = None):
-        self.xyz_id = xyz_id
-        self.callbacks = []
-        self._rendezvous = None
-        self._thread = None
-        self._client = client if client is not None else get_global_grpc_client()
-
-    def add_callback(self, callback: Callable[[xyz_pb2.XYZLogRecord], Any]):
-        """
-        Function will be called with ``descarteslabs.common.proto.xyz_pb2.XYZLogRecord``
-        on each log record.
+        return data_files
+
+    @classmethod
+    def get(cls, id: str):
+        """Get Function by id.
 
         Parameters
         ----------
-        callback: callable
-            Function that takes one argument, a
-            ``descarteslabs.common.proto.xyz_pb2.XYZLogRecord`` protobuf message object.
-            This message contains the fields ``code``, ``message``,
-            ``timestamp``, ``session_id``.
-            This message contains the fields ``session_id`` and ``record``, with the
-            ``record`` field containing ``level``, ``message``, and ``timestamp``.
-
-            The function will be called within a separate thread,
-            therefore it must behave thread-safely. Any errors raised by the function will
-            terminate the listener.
+        id : str
+            Id of function to get.
 
         Example
         -------
-        >>> from descarteslabs.workflows import XYZLogListener
-        >>> listener = XYZLogListener("xyz_id") # doctest: +SKIP
-        >>> def callback(msg):
-        ...     print(msg.level, msg.message)
-        >>> listener.add_callback(callback) # doctest: +SKIP
+        >>> from descarteslabs.compute import Function
+        >>> fn = Function.get(<func_id>)
+        <Function name="test_name" image=test_image cpus=1 memory=16 maximum_concurrency=5 timeout=3 retries=1
         """
-        self.callbacks.append(callback)
+        client = ComputeClient.get_default_client()
+        response = client.session.get(f"/functions/{id}")
+        return cls(**response.json(), saved=True)
 
-    def listen(
-        self,
-        session_id: str,
-        start_datetime: datetime.datetime = None,
-        level: int = None,
+    @classmethod
+    def list(
+        cls,
+        status: Union[FunctionStatus, List[FunctionStatus], None] = None,
+        page_size: int = 100,
     ):
-        """
-        Start listening for logs.
+        """Lists all Functions for a user.
 
         Parameters
         ----------
-        session_id: str
-            Unique, client-generated ID that logs are stored under.
-            See `XYZ.url` for more information.
-        start_datetime: datetime.datetime
-            Only listen for log records occuring after this datetime. Must be tz-aware.
-        level: int, default logging.DEBUG
-            Only listen for log records at or above this log level.
-            See https://docs.python.org/3/library/logging.html#logging-levels for valid
-            log levels.
+        status : FunctionStatus, List[FunctionStatus], optional
+            Functions with any of the specified statuses will be included.
+        page_size : int, default=100
+            Maximum number of results per page.
 
         Example
         -------
-        >>> from descarteslabs.workflows import XYZLogListener
-        >>> listener = XYZLogListener("xyz_id") # doctest: +SKIP
-        >>> listener.listen(
-        ...     "session-id",
-        ...     start_datetime=datetime.datetime.now(datetime.timezone.utc),
-        ...     level=logging.WARNING,
-        ... ) #doctest: +SKIP
-        """
-        self._rendezvous = _tile_log_stream(
-            self.xyz_id,
-            session_id,
-            start_datetime=start_datetime,
-            level=level,
-            client=self._client,
-        )
-        self._thread = threading.Thread(target=self._listener)
-        self._thread.daemon = True
-        self._thread.start()
+        >>> from descarteslabs.compute import Function
+        >>> fn = Function.list()
+        """
+        client = ComputeClient.get_default_client()
+        params = {"page_size": page_size}
 
-    def running(self) -> bool:
-        """bool: whether this is an active listener
+        if status:
+            if not isinstance(status, list):
+                status = [status]
 
-        Example
-        -------
-        >>> from descarteslabs.workflows import XYZLogListener
-        >>> listener = XYZLogListener("xyz_id") # doctest: +SKIP
-        >>> listener.listen("session-id", start_datetime=datetime.datetime.now()) # doctest: +SKIP
-        >>> listener.running() # doctest: +SKIP
-        True
+            params["status"] = status
+
+        paginator = client.iter_pages("/functions", params=params)
+
+        for data in paginator:
+            yield cls(**data, saved=True)
+
+    @classmethod
+    def update_credentials(cls):
+        """Updates the credentials for the Functions and Jobs run by this user.
+
+        These credentials are used by other Descarteslabs services.
+
+        If the user invalidates existing credentials and needs to update them,
+        you should call this method.
+
+        Notes
+        -----
+        Credentials are automatically updated when a new Function is created.
         """
-        return self._thread and self._thread.is_alive()
+        client = ComputeClient.get_default_client()
+        client.set_credentials()
 
-    def stop(self, timeout: Optional[int] = None) -> bool:
+    @property
+    def jobs(self) -> Iterable[Job]:
+        """Returns all the Jobs for the Function."""
+        return Job.list(self.id)
+
+    def build_log(self):
+        """Retrieves the build log for the Function."""
+        client = ComputeClient.get_default_client()
+        response = client.session.get(f"/functions/{self.id}/log")
+
+        print(gzip.decompress(response.content).decode())
+
+    def save(self):
+        """Creates the Function if it does not already exist.
+
+        If the Function already exists, it will be updated on the server if the Function
+        instance was modified.
+
+        Examples
+        --------
+        Create a Function without creating jobs:
+
+        >>> from descarteslabs.compute import Function
+        >>> def test_func():
+        ...     print("Hello :)")
+        >>> fn = Function(
+        ...     test_func,
+        ...     requirements=[],
+        ...     name="my_func",
+        ...     image="test_image",
+        ...     cpus=1,
+        ...     memory=16,
+        ...     maximum_concurrency=5,
+        ...     timeout=3600,
+        ...     retry_count=1,
+        ... )
+        >>> fn.save()
+
+        Updating a Function:
+
+        >>> from descarteslabs.compute import Function
+        >>> fn = Function.get(<func_id>)
+        >>> fn.memory = 4096  # 4 Gi
+        >>> fn.save()
         """
-        Cancel and clean up the listener. Blocks up to ``timeout`` seconds, or forever if None.
 
-        Returns True if the background thread stopped successfully.
+        if self.state == DocumentState.SAVED:
+            # Document already exists on the server without changes locally
+            return
 
-        Example
-        -------
-        >>> from descarteslabs.workflows import XYZLogListener
-        >>> listener = XYZLogListener("xyz_id") # doctest: +SKIP
-        >>> listener.listen("session-id", start_datetime=datetime.datetime.now()) # doctest: +SKIP
-        >>> listener.stop() # doctest: +SKIP
-        >>> listener.running() # doctest: +SKIP
-        False
-        """
-        self._rendezvous.cancel()
-        self._thread.join(timeout)
-        return not self._thread.is_alive()
+        client = ComputeClient.get_default_client()
 
-    def _listener(self):
-        try:
-            for msg in self._rendezvous:
-                for callback in self.callbacks:
-                    callback(msg)
-        except grpc.RpcError:
-            return
+        if self.state == DocumentState.NEW:
+            self.update_credentials()
 
-    def __del__(self):
-        if self.running():
-            self.stop(0)
-
-
-def _tile_log_stream(
-    xyz_id: str,
-    session_id: str,
-    start_datetime: datetime.datetime = None,
-    level: int = None,
-    client: Optional[Client] = None,
-) -> Iterator[xyz_pb2.XYZLogRecord]:
-    if client is None:
-        client = get_global_grpc_client()
-
-    if start_datetime is None:
-        start_timestamp = 0
-    else:
-        start_timestamp = pb_datetime_to_milliseconds(start_datetime)
-
-    if level is None:
-        level = logging.DEBUG
-    else:
-        level = py_log_level_to_proto_log_level(level)
-
-    msg = xyz_pb2.GetXYZSessionLogsRequest(
-        session_id=session_id,
-        xyz_id=xyz_id,
-        start_timestamp=start_timestamp,
-        level=level,
-    )
+            code_bundle_path = self._bundle()
+            response = client.session.post(
+                "/functions", json=self.to_dict(exclude_none=True)
+            )
+            response_json = response.json()
+            self._load_from_remote(response_json["function"])
+
+            # Upload the bundle to s3
+            s3_client = ThirdPartyService()
+            upload_url = response_json["bundle_upload_url"]
+            code_bundle = io.open(code_bundle_path, "rb")
+            headers = {
+                "content-type": "application/octet-stream",
+            }
+            s3_client.session.put(upload_url, data=code_bundle, headers=headers)
+
+            # Complete the upload with compute
+            response = client.session.post(f"/functions/{self.id}/bundle")
+            self._load_from_remote(response.json())
+        elif self.state == DocumentState.MODIFIED:
+            response = client.session.patch(
+                f"/functions/{self.id}", json=self.to_dict(only_modified=True)
+            )
+            self._load_from_remote(response.json())
+        else:
+            raise ValueError(
+                f"Unexpected Function state {self.state}."
+                f'Reload the function from the server: Function.get("{self.id}")'
+            )
+
+        self._load_from_remote(response.json())
+
+    def map(self, args, iterargs=None) -> List[Job]:
+        """Submits multiple jobs efficiently with positional args to each function call.
+
+        Preferred over repeatedly calling the function, such as in a loop, when submitting
+        multiple jobs.
+
+        Parameters
+        ----------
+        args : iterable
+            An iterable of arguments. A job will be submitted with each element as the
+            first positional argument to the function.
+        kwargs : List[iterable], optional
+            If additional iterable arguments are passed, the function must take that
+            many arguments and is applied to the items from all iterables in parallel.
+        """
+        client = ComputeClient.get_default_client()
+
+        # save in case the function doesn't exist yet
+        self.save()
+
+        response = client.session.post(
+            "/jobs/bulk",
+            json={"function_id": self.id, "bulk_args": args, "bulk_kwargs": iterargs},
+        )
+
+        return [Job(**job, saved=True) for job in response.json()]
+
+    def rerun(self):
+        """Submits all the failed and timed out jobs to be rerun."""
+        client = ComputeClient.get_default_client()
+
+        response = client.session.post("/jobs/rerun", json={"function_id": self.id})
+        return [Job(**job, saved=True) for job in response.json()]
+
+    def refresh(self):
+        """Updates the Function instance with data from the server."""
+        client = ComputeClient.get_default_client()
+
+        response = client.session.get(f"/functions/{self.id}")
+        self._load_from_remote(response.json())
+
+    def iter_results(self, cast_type: Type[Serializable] = None):
+        """Iterates over all successful job results."""
+        # TODO: optimize by filtering on server
+        for job in self.jobs:
+            if job.status != JobStatus.SUCCESS:
+                continue
+            yield job.result(cast_type=cast_type)
+
+    def results(self, cast_type: Type[Serializable] = None):
+        """Retrieves all the job results for the Function as a list.
+
+        Notes
+        -----
+        This immediately downloads all results into a list and could run out of memory.
+        If the result set is large, strongly consider using :py:meth:`Function.refresh`
+        instead.
+        """
+        return list(self.iter_results(cast_type=cast_type))
+
+    def wait_for_completion(self, timeout=None, interval=10):
+        """Waits until all submitted jobs for a given Function are completed.
+
+        Parameters
+        ----------
+        timeout : int, default=None
+            Maximum time to wait before timing out. If not set, this will hang until
+            completion.
+        interval : int, default=10
+            Interval for how often to check if jobs have been completed.
+        """
+        print(f"Function {self.name} starting status {self.status}")
+        last_status = self.status
+        start_time = time.time()
+
+        while True:
+            self.refresh()
+
+            if self.status != last_status:
+                print(
+                    f"Function {self.name} updated from {last_status} to {self.status}"
+                )
+                last_status = self.status
+
+            if self.status in [FunctionStatus.SUCCESS, FunctionStatus.FAILURE]:
+                break
+
+            if timeout:
+                t = timeout - (time.time() - start_time)
+                if t <= 0:
+                    raise TimeoutError(
+                        f"Function {self.name} did not complete before timeout!"
+                    )
+
+                t = min(t, interval)
+            else:
+                t = interval
 
-    return client.api["GetXYZSessionLogs"](msg, timeout=client.STREAM_TIMEOUT)
+            time.sleep(t)
```

### Comparing `descarteslabs-1.9.1/setup.py` & `descarteslabs-2.0.0/setup.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,38 +1,39 @@
 #!/usr/bin/env python
 
-# Copyright 2018-2020 Descartes Labs.
+# Copyright 2018-2023 Descartes Labs.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+
 import ast
 import re
 import sys
 
 from setuptools import find_packages, setup
 
 # Parse the docstring out of descarteslabs/__init__.py
 _docstring_re = re.compile(r'"""((.|\n)*)\n"""', re.MULTILINE)
 with open("descarteslabs/__init__.py", "rb") as f:
     __doc__ = _docstring_re.search(f.read().decode("utf-8")).group(1)
 
 DOCLINES = __doc__.split("\n")
 
-# Parse version out of descarteslabs/client/version.py
+# Parse version out of descarteslabs/core/client/version.py
 _version_re = re.compile(r"__version__\s+=\s+(.*)")
-with open("descarteslabs/client/version.py", "rb") as f:
+with open("descarteslabs/core/client/version.py", "rb") as f:
     version = str(
         ast.literal_eval(_version_re.search(f.read().decode("utf-8")).group(1))
     )
 
 
 def check_setuptools():
     import pkg_resources
@@ -43,91 +44,86 @@
         sys.exit(
             "Your Python is using an outdated version of `setuptools`. Please "
             "run `pip install -U setuptools` and try again."
         )
 
 
 def do_setup():
+    viz_requires = [
+        "matplotlib>=3.1.2",
+    ]
+    tests_requires = [
+        "pytest==6.0.0",
+        "responses==0.12.1",
+        "freezegun==0.3.12",
+    ]
     setup(
         name="descarteslabs",
         description=DOCLINES[0],
         long_description="\n".join(DOCLINES[2:]),
         author="Descartes Labs",
         author_email="hello@descarteslabs.com",
         url="https://github.com/descarteslabs/descarteslabs-python",
         classifiers=[
             "Programming Language :: Python",
             "Programming Language :: Python :: 3",
-            "Programming Language :: Python :: 3.6",
             "Programming Language :: Python :: 3.7",
             "Programming Language :: Python :: 3.8",
+            "Programming Language :: Python :: 3.9",
+            "Programming Language :: Python :: 3.10",
+            "Programming Language :: Python :: 3.11",
         ],
         license="Apache 2.0",
         download_url=(
             "https://github.com/descarteslabs/descarteslabs-python/archive/v{}.tar.gz".format(
                 version
             )
         ),
         version=version,
         packages=find_packages(),
         package_data={
             "descarteslabs": [
-                "client/services/tasks/tests/data/dl_test_package/package/*.pyx",
-                "client/services/tasks/tests/data/dl_test_package/*.json",
-                "client/services/tasks/tests/data/*.txt",
+                "config/settings.toml",
             ]
         },
         include_package_data=True,
         entry_points={
             "console_scripts": [
-                "descarteslabs = descarteslabs.client.scripts.__main__:main"
+                "descarteslabs = descarteslabs.core.client.scripts.__main__:main"
             ]
         },
-        python_requires="~=3.6",
+        python_requires="~=3.7",
         install_requires=[
             "affine>=2.2.2",
-            "backports-datetime-fromisoformat>=1.0.0;python_version<'3.7'",
-            "blosc==1.10.2",
+            "blosc>=1.10.6",
             "cachetools>=3.1.1",
-            "cloudpickle==0.4.0;python_version<'3.8'",
-            "cloudpickle==1.6.0;python_version>='3.8'",
-            "dataclasses>=0.8;python_version<'3.7'",
+            "dill>=0.3.6",
+            "dynaconf>=3.1.11",
             "geojson>=2.5.0",
-            "grpcio>=1.35.0,<2",
-            "imagecodecs>=2020.5.30;python_version<'3.7'",
-            "imagecodecs>=2021.5.20;python_version>='3.7'",
+            "imagecodecs>=2021.5.20",
+            "lazy_object_proxy>=1.7.1",
             "mercantile>=1.1.3",
-            "numpy>=1.18.1",
-            "Pillow>=8.1.1",
-            "protobuf>=3.14.0,<4",
-            "pyarrow>=3.0.0",
+            "numpy>=1.21.6,<1.23.0;python_version<'3.8'",
+            "numpy>=1.21.6;python_version>='3.8' and python_version<'3.11'",
+            "numpy>=1.23.2;python_version>='3.11'",
+            "Pillow>=9.2.0",
             "pytz>=2021.1",
-            "requests[security]>=2.25.1,<3",
-            "six>=1.15.0",
-            "shapely>=1.7.1,<2",
-            "tifffile==2020.9.3;python_version<'3.7'",
-            "tifffile==2021.4.8;python_version>='3.7'",
+            "requests>=2.28.1,<3",
+            # It is not obvious but dynaconf requires pkg_resources from setuptools.
+            "setuptools>=65.6.3",
+            "shapely>=1.8.1",
+            "strenum>=0.4.8",
+            "tifffile==2021.4.8",
             "tqdm>=4.32.1",
+            "urllib3>=1.26.12,<2",
         ],
         extras_require={
-            "complete": [
-                "matplotlib>=3.1.2",
-                "ipyleaflet>=0.13.3,<1",
-                "ipywidgets>=7.5.1,<8",
-                "traitlets>=4.3.3,<6;python_version<'3.7'",
-                "traitlets==5.0.5,<6;python_version>='3.7'",
-                "markdown2>=2.4.0,<3",
-            ],
-            "tests": [
-                "hypothesis[numpy]==5.7.0",
-                "mock",
-                "pytest==6.0.0",
-                "responses==0.12.1",
-                "freezegun==0.3.12",
-            ],
+            "visualization": viz_requires,
+            "complete": viz_requires,
+            "tests": tests_requires,
         },
         data_files=[("docs/descarteslabs", ["README.md"])],
     )
 
 
 if __name__ == "__main__":
     check_setuptools()
```

