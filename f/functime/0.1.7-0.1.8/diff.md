# Comparing `tmp/functime-0.1.7-py3-none-any.whl.zip` & `tmp/functime-0.1.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,41 +1,41 @@
-Zip file size: 45191 bytes, number of entries: 39
--rw-r--r--  2.0 unx       29 b- defN 23-Jun-11 07:48 functime/__init__.py
--rw-r--r--  2.0 unx      117 b- defN 23-Jun-11 07:48 functime/__main__.py
--rw-r--r--  2.0 unx     1141 b- defN 23-Jun-11 07:48 functime/config.py
--rw-r--r--  2.0 unx     6010 b- defN 23-Jun-11 07:48 functime/cross_validation.py
--rw-r--r--  2.0 unx     2059 b- defN 23-Jun-11 07:48 functime/offsets.py
--rw-r--r--  2.0 unx    15284 b- defN 23-Jun-11 07:48 functime/preprocessing.py
--rw-r--r--  2.0 unx     1909 b- defN 23-Jun-11 07:48 functime/ranges.py
--rw-r--r--  2.0 unx     2556 b- defN 23-Jun-11 07:48 functime/stats.py
--rw-r--r--  2.0 unx      155 b- defN 23-Jun-11 07:48 functime/base/__init__.py
--rw-r--r--  2.0 unx     2793 b- defN 23-Jun-11 07:48 functime/base/metric.py
--rw-r--r--  2.0 unx     3111 b- defN 23-Jun-11 07:48 functime/base/model.py
--rw-r--r--  2.0 unx     2237 b- defN 23-Jun-11 07:48 functime/base/transformer.py
--rw-r--r--  2.0 unx       81 b- defN 23-Jun-11 07:48 functime/cli/__init__.py
--rw-r--r--  2.0 unx      139 b- defN 23-Jun-11 07:48 functime/cli/_styling.py
--rw-r--r--  2.0 unx     1463 b- defN 23-Jun-11 07:48 functime/cli/deploy.py
--rw-r--r--  2.0 unx     1438 b- defN 23-Jun-11 07:48 functime/cli/entrypoint.py
--rw-r--r--  2.0 unx     2474 b- defN 23-Jun-11 07:48 functime/cli/list.py
--rw-r--r--  2.0 unx     3093 b- defN 23-Jun-11 07:48 functime/cli/login.py
--rw-r--r--  2.0 unx     1112 b- defN 23-Jun-11 07:48 functime/cli/token.py
--rw-r--r--  2.0 unx     2172 b- defN 23-Jun-11 07:48 functime/cli/usage.py
--rw-r--r--  2.0 unx      285 b- defN 23-Jun-11 07:48 functime/feature_extraction/__init__.py
--rw-r--r--  2.0 unx     3507 b- defN 23-Jun-11 07:48 functime/feature_extraction/calendar.py
--rw-r--r--  2.0 unx      421 b- defN 23-Jun-11 07:48 functime/forecasting/__init__.py
--rw-r--r--  2.0 unx     4989 b- defN 23-Jun-11 07:48 functime/forecasting/_base.py
--rw-r--r--  2.0 unx     9921 b- defN 23-Jun-11 07:48 functime/forecasting/auto.py
--rw-r--r--  2.0 unx     3788 b- defN 23-Jun-11 07:48 functime/forecasting/forecasters.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-11 07:48 functime/io/__init__.py
--rw-r--r--  2.0 unx      494 b- defN 23-Jun-11 07:48 functime/io/_serialize.py
--rw-r--r--  2.0 unx     5664 b- defN 23-Jun-11 07:48 functime/io/client.py
--rw-r--r--  2.0 unx      229 b- defN 23-Jun-11 07:48 functime/metrics/__init__.py
--rw-r--r--  2.0 unx     3710 b- defN 23-Jun-11 07:48 functime/metrics/multi_objective.py
--rw-r--r--  2.0 unx     6822 b- defN 23-Jun-11 07:48 functime/metrics/point.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-11 07:48 functime/metrics/probabilistic.py
--rw-r--r--  2.0 unx    34523 b- defN 23-Jun-11 07:49 functime-0.1.7.dist-info/LICENSE
--rw-r--r--  2.0 unx     7605 b- defN 23-Jun-11 07:49 functime-0.1.7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-11 07:49 functime-0.1.7.dist-info/WHEEL
--rw-r--r--  2.0 unx       52 b- defN 23-Jun-11 07:49 functime-0.1.7.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        9 b- defN 23-Jun-11 07:49 functime-0.1.7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3186 b- defN 23-Jun-11 07:49 functime-0.1.7.dist-info/RECORD
-39 files, 134670 bytes uncompressed, 40127 bytes compressed:  70.2%
+Zip file size: 46547 bytes, number of entries: 39
+-rw-r--r--  2.0 unx       29 b- defN 23-Jun-12 08:06 functime/__init__.py
+-rw-r--r--  2.0 unx      117 b- defN 23-Jun-12 08:06 functime/__main__.py
+-rw-r--r--  2.0 unx     1141 b- defN 23-Jun-12 08:06 functime/config.py
+-rw-r--r--  2.0 unx     6010 b- defN 23-Jun-12 08:06 functime/cross_validation.py
+-rw-r--r--  2.0 unx     2241 b- defN 23-Jun-12 08:06 functime/offsets.py
+-rw-r--r--  2.0 unx    19281 b- defN 23-Jun-12 08:06 functime/preprocessing.py
+-rw-r--r--  2.0 unx     1909 b- defN 23-Jun-12 08:06 functime/ranges.py
+-rw-r--r--  2.0 unx     2556 b- defN 23-Jun-12 08:06 functime/stats.py
+-rw-r--r--  2.0 unx      155 b- defN 23-Jun-12 08:06 functime/base/__init__.py
+-rw-r--r--  2.0 unx     2793 b- defN 23-Jun-12 08:06 functime/base/metric.py
+-rw-r--r--  2.0 unx     3111 b- defN 23-Jun-12 08:06 functime/base/model.py
+-rw-r--r--  2.0 unx     2237 b- defN 23-Jun-12 08:06 functime/base/transformer.py
+-rw-r--r--  2.0 unx       81 b- defN 23-Jun-12 08:06 functime/cli/__init__.py
+-rw-r--r--  2.0 unx      139 b- defN 23-Jun-12 08:06 functime/cli/_styling.py
+-rw-r--r--  2.0 unx     1463 b- defN 23-Jun-12 08:06 functime/cli/deploy.py
+-rw-r--r--  2.0 unx     1438 b- defN 23-Jun-12 08:06 functime/cli/entrypoint.py
+-rw-r--r--  2.0 unx     2474 b- defN 23-Jun-12 08:06 functime/cli/list.py
+-rw-r--r--  2.0 unx     3093 b- defN 23-Jun-12 08:06 functime/cli/login.py
+-rw-r--r--  2.0 unx     1112 b- defN 23-Jun-12 08:06 functime/cli/token.py
+-rw-r--r--  2.0 unx     2172 b- defN 23-Jun-12 08:06 functime/cli/usage.py
+-rw-r--r--  2.0 unx      285 b- defN 23-Jun-12 08:06 functime/feature_extraction/__init__.py
+-rw-r--r--  2.0 unx     4221 b- defN 23-Jun-12 08:06 functime/feature_extraction/calendar.py
+-rw-r--r--  2.0 unx      421 b- defN 23-Jun-12 08:06 functime/forecasting/__init__.py
+-rw-r--r--  2.0 unx     4989 b- defN 23-Jun-12 08:06 functime/forecasting/_base.py
+-rw-r--r--  2.0 unx     9921 b- defN 23-Jun-12 08:06 functime/forecasting/auto.py
+-rw-r--r--  2.0 unx     3908 b- defN 23-Jun-12 08:06 functime/forecasting/forecasters.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-12 08:06 functime/io/__init__.py
+-rw-r--r--  2.0 unx      494 b- defN 23-Jun-12 08:06 functime/io/_serialize.py
+-rw-r--r--  2.0 unx     5664 b- defN 23-Jun-12 08:06 functime/io/client.py
+-rw-r--r--  2.0 unx      229 b- defN 23-Jun-12 08:06 functime/metrics/__init__.py
+-rw-r--r--  2.0 unx     3826 b- defN 23-Jun-12 08:06 functime/metrics/multi_objective.py
+-rw-r--r--  2.0 unx     6810 b- defN 23-Jun-12 08:06 functime/metrics/point.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-12 08:06 functime/metrics/probabilistic.py
+-rw-r--r--  2.0 unx    34523 b- defN 23-Jun-12 08:06 functime-0.1.8.dist-info/LICENSE
+-rw-r--r--  2.0 unx     7564 b- defN 23-Jun-12 08:06 functime-0.1.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-12 08:06 functime-0.1.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       52 b- defN 23-Jun-12 08:06 functime-0.1.8.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        9 b- defN 23-Jun-12 08:06 functime-0.1.8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3186 b- defN 23-Jun-12 08:06 functime-0.1.8.dist-info/RECORD
+39 files, 139746 bytes uncompressed, 41483 bytes compressed:  70.3%
```

## zipnote {}

```diff
@@ -93,26 +93,26 @@
 
 Filename: functime/metrics/point.py
 Comment: 
 
 Filename: functime/metrics/probabilistic.py
 Comment: 
 
-Filename: functime-0.1.7.dist-info/LICENSE
+Filename: functime-0.1.8.dist-info/LICENSE
 Comment: 
 
-Filename: functime-0.1.7.dist-info/METADATA
+Filename: functime-0.1.8.dist-info/METADATA
 Comment: 
 
-Filename: functime-0.1.7.dist-info/WHEEL
+Filename: functime-0.1.8.dist-info/WHEEL
 Comment: 
 
-Filename: functime-0.1.7.dist-info/entry_points.txt
+Filename: functime-0.1.8.dist-info/entry_points.txt
 Comment: 
 
-Filename: functime-0.1.7.dist-info/top_level.txt
+Filename: functime-0.1.8.dist-info/top_level.txt
 Comment: 
 
-Filename: functime-0.1.7.dist-info/RECORD
+Filename: functime-0.1.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## functime/offsets.py

```diff
@@ -1,22 +1,9 @@
 from typing import List, Tuple, Union
 
-### Polars offset aliases:
-# 1ns (1 nanosecond)
-# 1us (1 microsecond)
-# 1ms (1 millisecond)
-# 1s (1 second)
-# 1m (1 minute)
-# 1h (1 hour)
-# 1d (1 day)
-# 1w (1 week)
-# 1mo (1 calendar month)
-# 1y (1 calendar year)
-# 1i (1 index count)
-
 OFFSET_ALIASES = {"s", "m", "h", "d", "w", "mo", "y", "i"}
 
 
 def _strip_freq_alias(freq: str) -> Tuple[int, str]:
     """Return (index count, offset string) given Polars offset alias.
 
     For example, `freq = "3mo"` returns `(3, "mo")`.
@@ -31,15 +18,29 @@
 
 def freq_to_sp(freq: str, include_dec: bool = False) -> Union[List[int], List[float]]:
     """Return seasonal periods given offset alias.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
+
+        The offset is dictated by the following string language:\n
+        - 1ns (1 nanosecond)
+        - 1us (1 microsecond)
+        - 1ms (1 millisecond)
+        - 1s (1 second)
+        - 1m (1 minute)
+        - 1h (1 hour)
+        - 1d (1 day)
+        - 1w (1 week)
+        - 1mo (1 calendar month)
+        - 1q (1 calendar quarter)
+        - 1y (1 calendar year)
+        - 1i (1 index count)
     include_dec : bool
         If True, return floating point seasonal periods.
         Otherwise, all seasonal periods are rounded down
         to the nearest integer.
 
     Returns
     -------
```

## functime/preprocessing.py

```diff
@@ -17,24 +17,46 @@
 
 def PL_NUMERIC_COLS(*exclude):
     return pl.col(PL_NUMERIC_DTYPES).exclude(exclude)
 
 
 @transformer
 def coerce_dtypes(schema: Mapping[str, pl.DataType]):
+    """Coerces the column datatypes of a DataFrame using the provided schema.
+
+    Parameters
+    ----------
+    schema : Mapping[str, pl.DataType]
+        A dictionary-like object mapping column names to the desired data types.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         X_new = X.cast({pl.col(col).cast(dtype) for col, dtype in schema.items()})
         artifacts = {"X_new": X_new}
         return artifacts
 
     return transform
 
 
 @transformer
 def resample(freq: str, agg_method: str, impute_method: Union[str, int, float]):
+    """
+    Resamples and transforms a DataFrame using the specified frequency, aggregation method, and imputation method.
+
+    Parameters
+    ----------
+    freq : str
+        Offset alias supported by Polars.
+    agg_method : str
+        The aggregation method to use for resampling. Supported values are 'sum', 'mean', and 'median'.
+    impute_method : Union[str, int, float]
+        The method used for imputing missing values. If a string, supported values are 'ffill' (forward fill)
+        and 'bfill' (backward fill). If an int or float, missing values will be filled with the provided value.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         entity_col, time_col, target_col = X.columns
         agg_exprs = {
             "sum": pl.sum(target_col),
             "mean": pl.mean(target_col),
             "median": pl.median(target_col),
         }
@@ -57,14 +79,22 @@
         return artifacts
 
     return transform
 
 
 @transformer
 def lag(lags: List[int]):
+    """Applies lag transformation to a LazyFrame.
+
+    Parameters
+    ----------
+    lags : List[int]
+        A list of lag values to apply.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         entity_col = X.columns[0]
         time_col = X.columns[1]
         max_lag = max(lags)
         lagged_series = [
             (
                 pl.all()
@@ -95,14 +125,35 @@
 
 @transformer
 def roll(
     window_sizes: List[int],
     stats: List[Literal["mean", "min", "max", "mlm", "sum", "std", "cv"]],
     freq: str,
 ):
+    """
+    Performs rolling window calculations on specified columns of a DataFrame.
+
+    Parameters
+    ----------
+    window_sizes : List[int]
+        A list of integers representing the window sizes for the rolling calculations.
+    stats : List[Literal["mean", "min", "max", "mlm", "sum", "std", "cv"]]
+        A list of statistical measures to calculate for each rolling window.\n
+        Supported values are:\n
+        - 'mean' for mean
+        - 'min' for minimum
+        - 'max' for maximum
+        - 'mlm' for maximum minus minimum
+        - 'sum' for sum
+        - 'std' for standard deviation
+        - 'cv' for coefficient of variation
+    freq : str
+        Offset alias supported by Polars.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         entity_col, time_col = X.columns[:2]
         offset_n, offset_alias = _strip_freq_alias(freq)
         values = pl.all().exclude([entity_col, time_col])
         stat_exprs = {
             "mean": lambda w: values.mean().suffix(f"__rolling_mean_{w}"),
             "min": lambda w: values.min().suffix(f"__rolling_min_{w}"),
@@ -141,14 +192,26 @@
         return artifacts
 
     return transform
 
 
 @transformer
 def scale(use_mean: bool = True, use_std: bool = True, rescale_bool: bool = True):
+    """
+    Performs scaling and rescaling operations on the numeric columns of a DataFrame.
+
+    Parameters
+    ----------
+    use_mean : bool
+        Whether to subtract the mean from the numeric columns. Defaults to True.
+    use_std : bool
+        Whether to divide the numeric columns by the standard deviation. Defaults to True.
+    rescale_bool : bool
+        Whether to rescale boolean columns to the range [-1, 1]. Defaults to True.
+    """
 
     if not (use_mean or use_std):
         raise ValueError("At least one of `use_mean` or `use_std` must be set to True")
 
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         idx_cols = X.columns[:2]
         entity_col, time_col = idx_cols
@@ -222,14 +285,32 @@
 @transformer
 def impute(
     method: Union[
         Literal["mean", "median", "fill", "ffill", "bfill", "interpolate"],
         Union[int, float],
     ]
 ):
+    """
+    Performs missing value imputation on numeric columns of a DataFrame.
+
+    Parameters
+    ----------
+    method : Union[str, int, float]
+        The imputation method to use.
+
+        Supported methods are:\n
+        - 'mean': Replace missing values with the mean of the corresponding column.
+        - 'median': Replace missing values with the median of the corresponding column.
+        - 'fill': Replace missing values with the mean for float columns and the median for integer columns.
+        - 'ffill': Forward fill missing values.
+        - 'bfill': Backward fill missing values.
+        - 'interpolate': Interpolate missing values using linear interpolation.
+        - int or float: Replace missing values with the specified constant.
+    """
+
     def method_to_expr(entity_col, time_col):
         """Fill-in methods."""
         return {
             "mean": PL_NUMERIC_COLS(entity_col, time_col).fill_null(
                 PL_NUMERIC_COLS(entity_col, time_col).mean().over(entity_col)
             ),
             "median": PL_NUMERIC_COLS(entity_col, time_col).fill_null(
@@ -264,14 +345,24 @@
         return {"X_new": X_new}
 
     return transform
 
 
 @transformer
 def diff(order: int, sp: int = 1):
+    """Difference time-series in panel data given order and seasonal period.
+
+    Parameters
+    ----------
+    order : int
+        The order to difference.
+    sp : int
+        Seasonal periodicity.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         def _diff(X):
             X_new = (
                 X.groupby(entity_col, maintain_order=True)
                 .agg([pl.col(time_col), PL_FLOAT_COLS - PL_FLOAT_COLS.shift(sp)])
                 .explode(pl.all().exclude(entity_col))
             )
@@ -323,14 +414,26 @@
         return X.select(idx_cols).join(X_new, on=idx_cols, how="left")
 
     return transform, invert
 
 
 @transformer
 def boxcox(method: str = "mle"):
+    """Applies the Box-Cox transformation to numeric columns in a DataFrame.
+
+    Parameters
+    ----------
+    method : str
+        The method used to determine the lambda parameter of the Box-Cox transformation.
+
+        Supported methods:\n
+        - `mle`: maximum likelihood estimation
+        - `pearsonr`: Pearson correlation coefficient
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         idx_cols = X.columns[:2]
         entity_col, time_col = idx_cols
         gb = X.groupby(X.columns[0])
         # Step 1. Compute optimal lambdas
         lmbds = gb.agg(
             PL_NUMERIC_COLS(entity_col, time_col)
@@ -372,14 +475,24 @@
         return X_new
 
     return transform, invert
 
 
 @transformer
 def reindex_panel(freq: str, sort: bool = False):
+    """Reindexes a panel DataFrame to a specified frequency.
+
+    Parameters
+    ----------
+    freq : str
+        Offset alias supported by Polars.
+    sort : bool
+        If True, sort DataFrame by the entity and time columns.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         # Create new index
         entity_col = X.columns[0]
         time_col = X.columns[1]
         dtypes = X.dtypes[:2]
 
         with pl.StringCache():
@@ -411,16 +524,27 @@
         return artifacts
 
     return transform
 
 
 @transformer
 def zero_pad(freq: str, include_null: bool = True, include_nan: bool = True):
+    """Reindexes a panel DataFrame to a specified frequency and fills nulls/nans with zeros.
+
+    Parameters
+    ----------
+    freq : str
+        Offset alias supported by Polars.
+    include_null : bool
+        If True, fill null values with zeros.
+    include_nan : bool
+        If True, fill NaN values with zeros.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
-        """Reindex panel then fill nulls / nans with 0."""
         target_cols = X.columns[2:]
         transform = reindex_panel(freq=freq)
 
         if include_null and include_nan:
             expr = [pl.col(col).fill_null(0).fill_nan(0) for col in target_cols]
         elif include_null:
             expr = [pl.col(col).fill_null(0) for col in target_cols]
```

## functime/cli/entrypoint.py

```diff
@@ -5,15 +5,15 @@
 from functime.cli.login import login_cli
 from functime.cli.token import token_cli
 from functime.cli.usage import usage_cli
 
 
 def version_callback(value: bool):
     if value:
-        __version__ = "0.1.7"
+        __version__ = "0.1.8"
 
         typer.echo(f"functime version: {__version__}")
         raise typer.Exit()
 
 
 entrypoint_cli_typer = typer.Typer(
     no_args_is_help=True,
```

## functime/feature_extraction/calendar.py

```diff
@@ -11,14 +11,30 @@
 
 @transformer
 def add_calendar_effects(
     attrs: List[
         Literal["minute", "hour", "day", "weekday", "week", "month", "quarter", "year"]
     ],
 ):
+    """Extract calendar effects from time column, returns calendar effects as categorical columns.
+
+    Parameters
+    ----------
+    attrs : list of str
+        List of calendar effects to be applied to the time column:\n
+        - "minute"
+        - "hour"
+        - "day"
+        - "weekday"
+        - "week"
+        - "month"
+        - "quarter"
+        - "year"
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         time_col = pl.col(X.columns[1])
         X_new = X.with_columns(
             [
                 getattr(time_col.dt, attr)()
                 .alias(attr)
                 .cast(pl.Utf8)
@@ -30,14 +46,25 @@
         return artifacts
 
     return transform
 
 
 @transformer
 def add_holiday_effects(country_codes: List[str], freq: str):
+    """Extract holiday effects from time column for specified ISO-2 country codes and frequency.
+
+    Parameters
+    ----------
+    country_codes : List[str]
+        A list of ISO-2 country codes.
+    freq : str
+        Sampling frequency at which to group data.
+        Must be specified as an offset alias supported by Polars.
+    """
+
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         time_col = X.columns[1]
         dt_min_max = X.select(
             [pl.col(time_col).min().alias("min"), pl.col(time_col).max().alias("max")]
         ).collect(streaming=True)
         dt_min, dt_max = dt_min_max[0, "min"], dt_min_max[0, "max"]
         years = range(dt_min.year, dt_max.year + 1)
```

## functime/forecasting/forecasters.py

```diff
@@ -21,15 +21,15 @@
 
 class ElasticNet(BaseForecaster):
     """ElasticNet forecaster.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -41,15 +41,15 @@
 
 class KNN(BaseForecaster):
     """K-nearest neighbors forecaster.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -61,15 +61,15 @@
 
 class Lasso(BaseForecaster):
     """LASSO regression forecaster.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -81,15 +81,15 @@
 
 class LightGBM(BaseForecaster):
     """LightGBM forecaster.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -101,15 +101,15 @@
 
 class LinearModel(BaseForecaster):
     """Linear autoregressive forecaster.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -121,15 +121,15 @@
 
 class Ridge(BaseForecaster):
     """Ridge regression forecaster.
 
     Parameters
     ----------
     freq : str
-        Offset alias.
+        Offset alias supported by Polars.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
```

## functime/metrics/multi_objective.py

```diff
@@ -18,32 +18,32 @@
     underforecast,
 )
 
 
 @dataclass(frozen=True)
 class Metrics:
     mae: float
+    mse: float
     smape: float
+    rmse: float
     rmsse: float
     mase: float
-    bias: float
     overforecast: float
     underforecast: float
 
 
 def summarize_scores(
     scores: pl.DataFrame, agg_method: Literal["mean", "median"] = "mean"
 ) -> Metrics:
     """Given a DataFrame of forecast metrics, return a dataclass of metrics aggregated by `agg_method`.
 
     Parameters
     ----------
     scores : pl.DataFrame
         DataFrame of scores. N rows of entities by M columns of metrics.
-
     agg_method : str
         Method ("mean", "median") to aggregate scores across entities by.
 
     Returns
     -------
     metrics : Metrics
         Dataclass of scores aggregated across entities.
@@ -58,35 +58,32 @@
 
 
 def score_forecast(
     y_true: pl.DataFrame, y_pred: pl.DataFrame, y_train: pl.DataFrame
 ) -> pl.DataFrame:
     """Return DataFrame of forecast metrics across entities.
 
-    Metrics returned:
+    Metrics returned:\n
     - MAE
     - MASE
     - MSE
     - Overforecast
     - RMSE
     - RMSSE
     - SMAPE
     - Underforecast
 
-    Note: MAPE is excluded to avoid potential divide by zero errors.
-    We recommend looking at SMAPE instead.
+    Note: SMAPE is used instead of MAPE to avoid potential divide by zero errors.
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
-
     y_train : pl.DataFrame
         Observed training values.
 
     Returns
     -------
     scores : pl.DataFrame
         DataFrame with computed metrics column by column across entities row by row.
@@ -112,15 +109,15 @@
 def score_backtest(
     y_true: pl.DataFrame,
     y_preds: pl.DataFrame,
     agg_method: Literal["mean", "median"] = "mean",
 ) -> pl.DataFrame:
     """Return DataFrame of forecast metrics across entities.
 
-    Metrics returned:
+    Metrics returned:\n
     - MAE
     - MASE
     - MSE
     - Overforecast
     - RMSE
     - RMSSE
     - SMAPE
@@ -129,20 +126,19 @@
     Note: MAPE is excluded to avoid potential divide by zero errors.
     We recommend looking at SMAPE instead.
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
-    y_pred : pl.DataFrame
-        Predicted values.
-
-    y_train : pl.DataFrame
-        Observed training values.
+    y_preds : pl.DataFrame
+        Stacked predicted values across CV splits.
+        DataFrame contains four columns: entity, time, target, "split".
+    agg_method : str
+        Method ("mean", "median") to aggregate scores across entities by.
 
     Returns
     -------
     scores : pl.DataFrame
         DataFrame with computed metrics column by column across entities row by row.
     """
     entity_col, time_col, target_col = y_preds.columns[:3]
```

## functime/metrics/point.py

```diff
@@ -20,15 +20,14 @@
 def mae(y_true: pl.DataFrame, y_pred: pl.DataFrame) -> pl.DataFrame:
     """Return mean absolute error (MAE).
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -41,15 +40,14 @@
 def mfe(y_true: pl.DataFrame, y_pred: pl.DataFrame) -> pl.DataFrame:
     """Return mean forecast error (MFE) AKA bias.
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -62,15 +60,14 @@
 def mape(y_true: pl.DataFrame, y_pred: pl.DataFrame):
     """Return mean absolute percentage error (MAPE).
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -83,15 +80,14 @@
 def mse(y_true: pl.DataFrame, y_pred: pl.DataFrame):
     """Return mean squared error (MSE).
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -104,15 +100,14 @@
 def rmse(y_true: pl.DataFrame, y_pred: pl.DataFrame):
     """Return root mean squared error (RMSE).
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -127,15 +122,14 @@
 
     Use third version of SMAPE formula from https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error to deal with zero division error
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -152,18 +146,16 @@
 ):
     """Return mean absolute scaled error (MASE).
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
-
     y_train : pl.DataFrame
         Observed training values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -190,18 +182,16 @@
 ):
     """Return root mean squared scaled error (RMSSE).
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
-
     y_train : pl.DataFrame
         Observed training values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -228,15 +218,14 @@
 
     Overforecast (positive forecast bias) is the difference between actual and predicted for predicted values greater than actual.
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
@@ -251,15 +240,14 @@
 
     Underforecast (negative forecast bias) is the difference between actual and predicted for predicted values less than actual.
 
     Parameters
     ----------
     y_true : pl.DataFrame
         Ground truth (correct) target values.
-
     y_pred : pl.DataFrame
         Predicted values.
 
     Returns
     -------
     scores : pl.DataFrame
         Score per series.
```

## Comparing `functime-0.1.7.dist-info/LICENSE` & `functime-0.1.8.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `functime-0.1.7.dist-info/METADATA` & `functime-0.1.8.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: functime
-Version: 0.1.7
+Version: 0.1.8
 Summary: The easiest way to run and scale time-series machine learning in the Cloud.
 Author-email: functime Team <team@functime.ai>, Chris Lo <chris@functime.ai>, Daryl Lim <daryl@functime.ai>
 Project-URL: Homepage, https://github.com/indexhub-ai/functime
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Science/Research
 Classifier: Intended Audience :: Developers
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
@@ -44,15 +44,15 @@
 
 ![functime](https://github.com/indexhub-ai/functime/raw/main/static/images/functime_banner.png)
 
 [![Python](https://img.shields.io/pypi/pyversions/functime)](https://pypi.org/project/functime/)
 [![PyPi](https://img.shields.io/pypi/v/functime?color=blue)](https://pypi.org/project/functime/)
 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
 [![GitHub Publish to PyPI](https://github.com/indexhub-ai/functime/actions/workflows/publish.yml/badge.svg)](https://github.com/indexhub-ai/functime/actions/workflows/publish.yml)
-[![GitHub Build Docs](https://github.com/indexhub-ai/functime/actions/workflows/docs.yml/badge.svg)](https://github.com/indexhub-ai/functime/actions/workflows/docs.yml)
+[![GitHub Build Docs](https://github.com/indexhub-ai/functime/actions/workflows/docs.yml/badge.svg)](https://docs.functime.ai/)
 [![GitHub Run Quickstart](https://github.com/indexhub-ai/functime/actions/workflows/quickstart.yml/badge.svg)](https://github.com/indexhub-ai/functime/actions/workflows/quickstart.yml)
 
 </div>
 
 ---
 **functime** is a powerful and easy-to-use [Cloud service](https://functime.ai) for AutoML forecasting and time-series embeddings.
 The `functime` [Python package](https://pypi.org/project/functime/) provides a scikit-learn API and command-line interface to interact with **functime Cloud**.
```

## Comparing `functime-0.1.7.dist-info/RECORD` & `functime-0.1.8.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 functime/__init__.py,sha256=NM7kykIVEhdbgnsILzqU4tR0tYjnm-Z5vRxMJNSD78Q,29
 functime/__main__.py,sha256=HpYJUAIeN5HXQhaM5_kDwo441jDPe9GJ8dLjF9HE9VQ,117
 functime/config.py,sha256=ybZS5SKL6jaqeOQytE8CQFUfKlBcQ8AXoxWVYVIOngA,1141
 functime/cross_validation.py,sha256=mpMVwjtEiUA4FXXW7VkTiBayDh9tLB8MtAEOqBp50SM,6010
-functime/offsets.py,sha256=lm_fK56LzQwZUZIff3Ukymj1uB67cwH-Jt4vf1tYzCs,2059
-functime/preprocessing.py,sha256=P2ijmmnjI4LXy2NBm_FLarspxr0y9izAoYJSFW-hALw,15284
+functime/offsets.py,sha256=MO-St46MdhutFtkPJyr5XskYr_0yj_l1nnxh-1fC7GQ,2241
+functime/preprocessing.py,sha256=qTgbKPNx80J4U5K1RCgQybxjLDOc3fH1RsyBi1N_rQ4,19281
 functime/ranges.py,sha256=L0XyUhs7ovEkGzAvJ408m3AmpGp1dDxVBRnOX259K40,1909
 functime/stats.py,sha256=hadK1-5bbLhtEOKEdre4thjV6Mv-RqUeJns1YvOvz00,2556
 functime/base/__init__.py,sha256=QhTMdB5mW3GgG7feOGltOa89cwEptd5ndcc4e4kUUUM,155
 functime/base/metric.py,sha256=f_lx6CV0tMbMB54I3pC2osP-6lzpu2692Xcqb_jWcy8,2793
 functime/base/model.py,sha256=RTTsmkRj0U1XpDdzEvKn1VRrnjwirQfulZW--TZ5LI8,3111
 functime/base/transformer.py,sha256=mL0ljSUtdJ6ZX-nEck553pbHk6odZdkqxnGkfYDqWJs,2237
 functime/cli/__init__.py,sha256=VZ9aBV8IvuZx_C375Oet2ixLHXlY7yPKYSFNepsr06E,81
 functime/cli/_styling.py,sha256=I0vvmyiNdrf_sugxJ10PkeON6hdHVTUMk0OOXEDJGUI,139
 functime/cli/deploy.py,sha256=2I9yoD3DMzgavI7g7epo63m44VN0IA25DQ0YWe5lUqU,1463
-functime/cli/entrypoint.py,sha256=V28XOS4eBlrb6oCVADDeeVd_GtamovUvGdQXfD3M-FQ,1438
+functime/cli/entrypoint.py,sha256=4yHcpLc68zardAKj3FvN_B1gBLjC_a9Yp8N0KIqPcPM,1438
 functime/cli/list.py,sha256=kxlarIBbE7uyuP-l0oJXWFhqDVRG2HJ7J5DH2GygnRo,2474
 functime/cli/login.py,sha256=are8-NBrkN6TVwBDxvnvAlQr7IBx_1nm-KA-hOpj9fI,3093
 functime/cli/token.py,sha256=yzNiXiqveOFGrUQCp1zCr-bvzzgITLhCZ7-HVMKXkRc,1112
 functime/cli/usage.py,sha256=T2Vlsk41s_fKXjkGK2Ki-qfZ7fanZCh3AUbAfuixeYo,2172
 functime/feature_extraction/__init__.py,sha256=GS4FtQUUuzJZAJJ4g7fgamtbZhAecz8iwaQsejPTVhs,285
-functime/feature_extraction/calendar.py,sha256=bNIE9xA0DnhMCnnQNNuyamDErCwbAJwH-zBnWjjHa-I,3507
+functime/feature_extraction/calendar.py,sha256=iJhwWnh-kdF97ljC59ysJQWFw-a9namQp_DQVUBSK-M,4221
 functime/forecasting/__init__.py,sha256=eQ2NVNZ9-FXG0vC7U9Fx7drScTmnyLToORdXfgpN5wk,421
 functime/forecasting/_base.py,sha256=7dHPy2AWtKPeG3T_dn33p932mL7VmsKnQusCDPtvjFY,4989
 functime/forecasting/auto.py,sha256=wG4aIwLxLck31LLrKDwNLWevznJhh--aN4fo_-C-Ivs,9921
-functime/forecasting/forecasters.py,sha256=QR-ZSQAS3JNkkNCs_Uiw1NyVltAoAhSeD9F4ABEqU50,3788
+functime/forecasting/forecasters.py,sha256=_POugsD_BTMNCiui17uN2uV9KtZH1llgwae-7bDcPf4,3908
 functime/io/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 functime/io/_serialize.py,sha256=C1gLl-KZMMKLICWepIjiYIv8-gnjYlfF_eTFuB0YW-Q,494
 functime/io/client.py,sha256=L8OiNUUCFgHddgfSty4sWzqvpI_2JAl8JdJeIghhOaA,5664
 functime/metrics/__init__.py,sha256=Bx-vU-jxkAg-zy2mVWYDtNOkluvgKJnL9uf0IhKIapw,229
-functime/metrics/multi_objective.py,sha256=UgX_mRdHjZ0agjOxjB_Whuw2zrbFBdsQk_TT8dEDQEc,3710
-functime/metrics/point.py,sha256=r-aw7-au54c3oYzdVud0FK_9GQouFtmH3RjVdL8EJGY,6822
+functime/metrics/multi_objective.py,sha256=EP9sGQ4HSCRN1SQazoJfntcovMP6RAVf7hZMXgcA2gE,3826
+functime/metrics/point.py,sha256=HlkcYvGAtFPr8kiTHQnoXZujysg2DK-BuUJVmLwiNKM,6810
 functime/metrics/probabilistic.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-functime-0.1.7.dist-info/LICENSE,sha256=hIahDEOTzuHCU5J2nd07LWwkLW7Hko4UFO__ffsvB-8,34523
-functime-0.1.7.dist-info/METADATA,sha256=vAfYC5RRhc5aTU6TtgbFKkMTImykcUDHTk6PJ4jrbIg,7605
-functime-0.1.7.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-functime-0.1.7.dist-info/entry_points.txt,sha256=y-9Na7pOh73f05jw87NkCt13P24wV_2qPEDF6ylwSXI,52
-functime-0.1.7.dist-info/top_level.txt,sha256=RUXkPSxtl5ViacwkIXqV7W8uyhA9yNRqrLMFS-jhFP4,9
-functime-0.1.7.dist-info/RECORD,,
+functime-0.1.8.dist-info/LICENSE,sha256=hIahDEOTzuHCU5J2nd07LWwkLW7Hko4UFO__ffsvB-8,34523
+functime-0.1.8.dist-info/METADATA,sha256=-wGzlNqFNmQET0Sd1IcN2hVWC4EVQc-7saAwn1jwoLE,7564
+functime-0.1.8.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+functime-0.1.8.dist-info/entry_points.txt,sha256=y-9Na7pOh73f05jw87NkCt13P24wV_2qPEDF6ylwSXI,52
+functime-0.1.8.dist-info/top_level.txt,sha256=RUXkPSxtl5ViacwkIXqV7W8uyhA9yNRqrLMFS-jhFP4,9
+functime-0.1.8.dist-info/RECORD,,
```

